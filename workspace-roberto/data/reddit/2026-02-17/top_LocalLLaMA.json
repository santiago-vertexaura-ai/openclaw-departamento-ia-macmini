{"kind": "Listing", "data": {"after": "t3_1r6gg04", "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "", "author_fullname": "t2_25gokyeald", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Qwen 3.5 goes bankrupt on Vending-Bench 2", "link_flair_richtext": [{"e": "text", "t": "Funny"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 121, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6ghty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "", "ups": 600, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Funny", "can_mod_post": false, "score": 600, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://preview.redd.it/dj0x1zeo9wjg1.png?width=140&amp;height=121&amp;auto=webp&amp;s=7d02de643f4bb13ee85747204e06fbba4c604c8c", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [{"a": ":Discord:", "e": "emoji", "u": "https://emoji.redditmedia.com/08m5x9chttjf1_t5_81eyvm/Discord"}], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1771264161.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dj0x1zeo9wjg1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dj0x1zeo9wjg1.png?auto=webp&amp;s=e437dc212275d2690b6aa4efbf92f87a89ae4123", "width": 733, "height": 638}, "resolutions": [{"url": "https://preview.redd.it/dj0x1zeo9wjg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bba8f4bbbb945db1ea45c3db24d51f84e1b08a71", "width": 108, "height": 94}, {"url": "https://preview.redd.it/dj0x1zeo9wjg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d938d578baa0f6975397ad62f1c0c5b7368bd82", "width": 216, "height": 188}, {"url": "https://preview.redd.it/dj0x1zeo9wjg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b177775ad15080b81bd62cebbcdab35e9c3d76dc", "width": 320, "height": 278}, {"url": "https://preview.redd.it/dj0x1zeo9wjg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e961cc9b6b922483e81871381dc9dca90d6aae60", "width": 640, "height": 557}], "variants": {}, "id": "dj0x1zeo9wjg1"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "65c366b0-bf8e-11ed-86ac-725137141d5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": ":Discord:", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0dd3bb", "id": "1r6ghty", "is_robot_indexable": true, "report_reasons": null, "author": "Deep-Vermicelli-4591", "discussion_type": null, "num_comments": 76, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/LocalLLaMA/comments/1r6ghty/qwen_35_goes_bankrupt_on_vendingbench_2/", "stickied": false, "url": "https://i.redd.it/dj0x1zeo9wjg1.png", "subreddit_subscribers": 627043, "created_utc": 1771264161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "", "author_fullname": "t2_58qturpl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 of the top 5 most used models on OpenRouter this week are Open Source!", "link_flair_richtext": [{"e": "text", "t": "Discussion"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6g14s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "", "ups": 337, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 337, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://preview.redd.it/54xxp91s6wjg1.png?width=140&amp;height=78&amp;auto=webp&amp;s=a93cf5e34d0a0afbe2cf6e18fa4ead46b7a4380c", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [{"a": ":Discord:", "e": "emoji", "u": "https://emoji.redditmedia.com/08m5x9chttjf1_t5_81eyvm/Discord"}], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1771263164.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/54xxp91s6wjg1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/54xxp91s6wjg1.png?auto=webp&amp;s=b52634608e87a844e700f90e69c1113c2df4bb9c", "width": 2752, "height": 1536}, "resolutions": [{"url": "https://preview.redd.it/54xxp91s6wjg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=48baffbe3feff9dd614232f7f28d439c2a6353fe", "width": 108, "height": 60}, {"url": "https://preview.redd.it/54xxp91s6wjg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ce918abd8f120016641e2ec0dd611d24d0bc4dd", "width": 216, "height": 120}, {"url": "https://preview.redd.it/54xxp91s6wjg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=adc569a4176ddd117f331d8757617188d3b718ca", "width": 320, "height": 178}, {"url": "https://preview.redd.it/54xxp91s6wjg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=10b8a71332018921514258bd081fc7ed68e28e72", "width": 640, "height": 357}, {"url": "https://preview.redd.it/54xxp91s6wjg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1846886679a7317ae8f7d62c5a2a7c6c3e836b4b", "width": 960, "height": 535}, {"url": "https://preview.redd.it/54xxp91s6wjg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=03bb2ad677a7c5993ed489c80d0f1ffc2b70b59c", "width": 1080, "height": 602}], "variants": {}, "id": "54xxp91s6wjg1"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": ":Discord:", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#646d73", "id": "1r6g14s", "is_robot_indexable": true, "report_reasons": null, "author": "abdouhlili", "discussion_type": null, "num_comments": 67, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/LocalLLaMA/comments/1r6g14s/4_of_the_top_5_most_used_models_on_openrouter/", "stickied": false, "url": "https://i.redd.it/54xxp91s6wjg1.png", "subreddit_subscribers": 627043, "created_utc": 1771263164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "Honestly it's quite an insane improvement, QWEN 3.5 even had some builds that were closer to (if not better than) Opus 4.6/GPT-5.2/Gemini 3 Pro.\n\nBenchmark:\u00a0[https://minebench.ai/](https://minebench.ai/)  \nGit Repository:\u00a0[https://github.com/Ammaar-Alam/minebench](https://github.com/Ammaar-Alam/minebench)\n\n[Previous post comparing Opus 4.5 and 4.6, also answered some questions about the benchmark](https://www.reddit.com/r/ClaudeAI/comments/1qx3war/difference_between_opus_46_and_opus_45_on_my_3d/)\n\n[Previous post comparing Opus 4.6 and GPT-5.2 Pro](https://www.reddit.com/r/OpenAI/comments/1r3v8sd/difference_between_opus_46_and_gpt52_pro_on_a/)\n\n*(Disclaimer: This is a benchmark I made, so technically self-promotion, but I thought it was a cool comparison :)*", "author_fullname": "t2_1tzwjlrt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Difference Between QWEN 3 Max-Thinking and QWEN 3.5 on a Spatial Reasoning Benchmark (MineBench)", "link_flair_richtext": [{"e": "text", "t": "New Model"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"r2ue8llcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/r2ue8llcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=3c2f3c30e957490dd663bdd81a17da5b6b80c89c"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/r2ue8llcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=739aee24516e5e3e226cfa6383ac10220fc8339a"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/r2ue8llcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=d7d573d63496ddf08f803544c196c7874ab3b3b7"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/r2ue8llcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=c36b6a2377da879608ddba9ce8cb6391b632a090"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/r2ue8llcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=e97e71323caf2aea002e1a1f40ba3e43f7a6bda3"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/r2ue8llcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=63989664f1b650378534f4422e7742f3a3ef8dc8"}], "s": {"y": 1080, "gif": "https://i.redd.it/r2ue8llcdwjg1.gif", "mp4": "https://preview.redd.it/r2ue8llcdwjg1.gif?format=mp4&amp;s=9d084b6954470da37f26ec1850689bcc0acf73cc", "x": 1920}, "id": "r2ue8llcdwjg1"}, "7uugoklcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7uugoklcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=55e03552c3bb0e4d925638e06c272c9667ac15b0"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/7uugoklcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=7569f8a8d414076c7d842fb0bc85413fef67cee2"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/7uugoklcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=ac227281d633fc92195379a6e48ff980722cedb2"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/7uugoklcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=21e095ed8324eea6ee764535b0ee653be645387f"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/7uugoklcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=31aad756d23501109e8fa0bb7d6a61a99523622a"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/7uugoklcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=48e8c1b3359ce641b574e362d87ed65021af5b15"}], "s": {"y": 1080, "gif": "https://i.redd.it/7uugoklcdwjg1.gif", "mp4": "https://preview.redd.it/7uugoklcdwjg1.gif?format=mp4&amp;s=ca65031b4b2042079a527f85becdba866cdc720e", "x": 1920}, "id": "7uugoklcdwjg1"}, "6q4jnllcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/6q4jnllcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=613e9fb7d4afca22c1c34991906d0443f15c0cec"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/6q4jnllcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=b08f318a2f55e355ffc01e7380d1f5f37c744de8"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/6q4jnllcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=edc86deb0335309963ad8fe480736947ff9f2c76"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/6q4jnllcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=7d0fed2d61a0c6161da608b5ff4a4f55b8588f2c"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/6q4jnllcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=c8f44904223393f9e810a91124315c024bfe3493"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/6q4jnllcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=a94ff8a830e01c4669b871e3df79cdfdb4cdbfe8"}], "s": {"y": 1080, "gif": "https://i.redd.it/6q4jnllcdwjg1.gif", "mp4": "https://preview.redd.it/6q4jnllcdwjg1.gif?format=mp4&amp;s=610d8af4d46e01bd39a30c8e99c6c1667b31d47c", "x": 1920}, "id": "6q4jnllcdwjg1"}, "oq43kklcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/oq43kklcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=9a1689186bbbce03abc0db9e51b45d78142587e1"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/oq43kklcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=2c3056ab7e4288430d5e8b4a1f7ae895644f9994"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/oq43kklcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=72a2ca40e266e6d783c6d18b1a6791106b6dbd8d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/oq43kklcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=a79c1cf79a70e13a563266354f6757a95d24afe3"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/oq43kklcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=c026ebbc54f10c77dccdc9210df68b34fdaf9500"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/oq43kklcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=82a17f1be2614bb7a41cb831adbebf6ac3f655cf"}], "s": {"y": 1080, "gif": "https://i.redd.it/oq43kklcdwjg1.gif", "mp4": "https://preview.redd.it/oq43kklcdwjg1.gif?format=mp4&amp;s=b99382b45eb8ac9709ad9026ab1821c52f780e28", "x": 1920}, "id": "oq43kklcdwjg1"}, "am9cbllcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/am9cbllcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=0f34bda39482dee949bead20f4bc4693b84bbb6e"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/am9cbllcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=776c769e0fa31c07bc771ac5fe70a0b04d493e6d"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/am9cbllcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=32111c712be2ff06a8dccf369ce117903a10aae2"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/am9cbllcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=5a23cfff59719bd018a139abaaeddaf11a95fc35"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/am9cbllcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=4c2f3fdfae57107918340f4b210aabcef694d536"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/am9cbllcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=d0bd4039bce2d85f8f212d15f3c83776759c841d"}], "s": {"y": 1080, "gif": "https://i.redd.it/am9cbllcdwjg1.gif", "mp4": "https://preview.redd.it/am9cbllcdwjg1.gif?format=mp4&amp;s=f873f74c83119da65ed4810ecad027c02a9f0886", "x": 1920}, "id": "am9cbllcdwjg1"}, "v5pdollcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/v5pdollcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=0ef32fb637a89acbe2551ed81ffe2c5454b33b1d"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/v5pdollcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=81ff9f994c61122088fb186c89866769f847c45a"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/v5pdollcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=c74d329fc4143654c8e1310aa55faa5e9b40e193"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/v5pdollcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=f25b3486a3be63ca91b00266a6e4074e60fac15d"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/v5pdollcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=5932fdfbd6cc3407a0ae36ebdcc14ebd82b6394a"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/v5pdollcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=d519a74e974578e58d7de6732dd12737aa09bc2d"}], "s": {"y": 1080, "gif": "https://i.redd.it/v5pdollcdwjg1.gif", "mp4": "https://preview.redd.it/v5pdollcdwjg1.gif?format=mp4&amp;s=faf25a9bd8b4cdbfb9711d9390c1c4351d306f2d", "x": 1920}, "id": "v5pdollcdwjg1"}, "f0gvxklcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/f0gvxklcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=a1507d4948ee4b83adac848c8caa0476e21a65eb"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/f0gvxklcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=0ebb17e8005b23e92ec99cb5a8eaecbe893df7bb"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/f0gvxklcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=0ebddf9a33151d8bf3d339b12320e18fa5192267"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/f0gvxklcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=a0812a3e364954d161cd0da73959eeac8f5ce456"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/f0gvxklcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=ae2cdda280633f04efa394a4885e0d010fbe5528"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/f0gvxklcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=b12d5386546cd21c575423f0a7f88ca7be0665f4"}], "s": {"y": 1080, "gif": "https://i.redd.it/f0gvxklcdwjg1.gif", "mp4": "https://preview.redd.it/f0gvxklcdwjg1.gif?format=mp4&amp;s=187d7fb33e3328ee1e5c1c9832442e35b8c0edbd", "x": 1920}, "id": "f0gvxklcdwjg1"}, "2507sklcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/2507sklcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=b99d0f1f793a53e573dab29bddf0fa33c3b20f1d"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/2507sklcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=d001319eade59f498a08647c4ffa73f747713755"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/2507sklcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=9cbecfb71a5fe043f5001f39a2d5c1500811ebe1"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/2507sklcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=04d830fa423a2b0d1217606392e5eb3a44a99b4a"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/2507sklcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=117e782de01b3b072158e27a324b77825fce49a8"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/2507sklcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=5c0b916196335f357a3d07affecd5e0eafb74762"}], "s": {"y": 1080, "gif": "https://i.redd.it/2507sklcdwjg1.gif", "mp4": "https://preview.redd.it/2507sklcdwjg1.gif?format=mp4&amp;s=f7ba603b3b47e6c3bd20c09585892bc9d8168241", "x": 1920}, "id": "2507sklcdwjg1"}, "nqq2kllcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/nqq2kllcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=a76875875dac6ef4151ed92b432dd67161b00297"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/nqq2kllcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=6a527bacb0370530aed5ddd1cb2c4d4e143f7e6d"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/nqq2kllcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=62b49046edb5b540d7766b18c1d49a0bc7603206"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/nqq2kllcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=f68c8b83e642a0817415926371731b5da9174998"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/nqq2kllcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=5fb34b52bd23c43f81686231969ee0c3065baae5"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/nqq2kllcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=3daf56d60d9c5c98f62a38a4fd0a2a184ae10a6d"}], "s": {"y": 1080, "gif": "https://i.redd.it/nqq2kllcdwjg1.gif", "mp4": "https://preview.redd.it/nqq2kllcdwjg1.gif?format=mp4&amp;s=0acc11aef2429d4a627cca6c62b6355663ffe386", "x": 1920}, "id": "nqq2kllcdwjg1"}, "oz33grlcdwjg1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/oz33grlcdwjg1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=84ff973501afd0d52b4f5b35acc1e3a9ac6d7e28"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/oz33grlcdwjg1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=c45f37b128be0207e14510d426976dfd9eff6c90"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/oz33grlcdwjg1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=40ddd4176cd9247cd23db5a9274eb409b5ea7931"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/oz33grlcdwjg1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=21fa91377de9492c824126103ebc36689f5d5ea0"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/oz33grlcdwjg1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=12c5cd8795cec406e0d1246ae1e89757fa1cc533"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/oz33grlcdwjg1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=b8aba42b8f53c63b2985b4769377cb20b873392a"}], "s": {"y": 1080, "gif": "https://i.redd.it/oz33grlcdwjg1.gif", "mp4": "https://preview.redd.it/oz33grlcdwjg1.gif?format=mp4&amp;s=e0af49f30d17ea9ea87fa0210d1f3918518b9ba8", "x": 1920}, "id": "oz33grlcdwjg1"}}, "name": "t3_1r6h3ha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 267, "domain": "reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "6q4jnllcdwjg1", "id": 865732699}, {"media_id": "7uugoklcdwjg1", "id": 865732700}, {"media_id": "am9cbllcdwjg1", "id": 865732701}, {"media_id": "v5pdollcdwjg1", "id": 865732702}, {"media_id": "oq43kklcdwjg1", "id": 865732703}, {"media_id": "f0gvxklcdwjg1", "id": 865732704}, {"media_id": "r2ue8llcdwjg1", "id": 865732705}, {"media_id": "2507sklcdwjg1", "id": 865732706}, {"media_id": "oz33grlcdwjg1", "id": 865732707}, {"media_id": "nqq2kllcdwjg1", "id": 865732708}]}, "link_flair_text": "New Model", "can_mod_post": false, "score": 267, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://preview.redd.it/6q4jnllcdwjg1.gif?frame=1&amp;width=140&amp;height=78&amp;auto=webp&amp;s=417f825a142e023132f72a89b718db9c2b167d19", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1771265429.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Honestly it&amp;#39;s quite an insane improvement, QWEN 3.5 even had some builds that were closer to (if not better than) Opus 4.6/GPT-5.2/Gemini 3 Pro.&lt;/p&gt;\n\n&lt;p&gt;Benchmark:\u00a0&lt;a href=\"https://minebench.ai/\"&gt;https://minebench.ai/&lt;/a&gt;&lt;br/&gt;\nGit Repository:\u00a0&lt;a href=\"https://github.com/Ammaar-Alam/minebench\"&gt;https://github.com/Ammaar-Alam/minebench&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/ClaudeAI/comments/1qx3war/difference_between_opus_46_and_opus_45_on_my_3d/\"&gt;Previous post comparing Opus 4.5 and 4.6, also answered some questions about the benchmark&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/OpenAI/comments/1r3v8sd/difference_between_opus_46_and_gpt52_pro_on_a/\"&gt;Previous post comparing Opus 4.6 and GPT-5.2 Pro&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(Disclaimer: This is a benchmark I made, so technically self-promotion, but I thought it was a cool comparison :)&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1r6h3ha", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1r6h3ha", "is_robot_indexable": true, "report_reasons": null, "author": "ENT_Alam", "discussion_type": null, "num_comments": 48, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LocalLLaMA/comments/1r6h3ha/difference_between_qwen_3_maxthinking_and_qwen_35/", "stickied": false, "url": "https://www.reddit.com/gallery/1r6h3ha", "subreddit_subscribers": 627043, "created_utc": 1771265429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "It's been about 125 years of AI since the last Gemma, Google doesn't love us anymore and has abandoned us to Qwen's rational models. I miss the creativity of Gemma's, and also their really useful sizes.\n\nDon't abandon us, Mommy Google, give us Gemma 4!", "author_fullname": "t2_26eg8mdjd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google doesn't love us anymore.", "link_flair_richtext": [{"e": "text", "t": "Discussion"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6f61k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 261, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 261, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771261311.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LocalLLaMA", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s been about 125 years of AI since the last Gemma, Google doesn&amp;#39;t love us anymore and has abandoned us to Qwen&amp;#39;s rational models. I miss the creativity of Gemma&amp;#39;s, and also their really useful sizes.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t abandon us, Mommy Google, give us Gemma 4!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#646d73", "id": "1r6f61k", "is_robot_indexable": true, "report_reasons": null, "author": "DrNavigat", "discussion_type": null, "num_comments": 109, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LocalLLaMA/comments/1r6f61k/google_doesnt_love_us_anymore/", "stickied": false, "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r6f61k/google_doesnt_love_us_anymore/", "subreddit_subscribers": 627043, "created_utc": 1771261311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "Google released FunctionGemma a few weeks ago - a 270M parameter model specifically for function calling. Tiny enough to run on a phone CPU at 125 tok/s. The model card says upfront that it needs fine-tuning for multi-turn use cases, and our testing confirmed it: base accuracy on multi-turn tool calling ranged from 9.9% to 38.8% depending on the task.\n\nWe fine-tuned it on three different multi-turn tasks using knowledge distillation from a 120B teacher:\n\n| Task | Base | Tuned | Teacher (120B) |\n|------|------|-------|----------------|\n| Smart home control | 38.8% | **96.7%** | 92.1% |\n| Banking voice assistant | 23.4% | **90.9%** | 97.0% |\n| Shell commands (Gorilla) | 9.9% | **96.0%** | 97.0% |\n\nThe smart home and shell command models actually beat the teacher. The banking task is harder (14 functions + ASR noise in the input) but still a massive jump.\n\nAll models, training data, and datasets are open:\n\n- Smart home model: [HuggingFace](https://huggingface.co/distil-labs/distil-home-assistant-functiongemma)\n- Smart home data: [GitHub](https://github.com/distil-labs/distil-smart-home)\n- Voice assistant data: [GitHub](https://github.com/distil-labs/distil-voice-assistant-banking)\n- Shell commands data + demo: [GitHub](https://github.com/distil-labs/distil-SHELLper)\n\nFull writeup with methodology: [Making FunctionGemma Work: Multi-Turn Tool Calling at 270M Parameters](https://www.distillabs.ai/blog/making-functiongemma-work-multi-turn-tool-calling-at-270m-parameters)\n\nWe used [Distil Labs](https://www.distillabs.ai/) (our platform) for the training pipeline. Happy to answer questions about the process, the results, or FunctionGemma in general.\n\n", "author_fullname": "t2_gf676", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fine-tuned FunctionGemma 270M for multi-turn tool calling - went from 10-39% to 90-97% accuracy", "link_flair_richtext": [{"e": "text", "t": "Tutorial | Guide"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6gx75", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 140, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tutorial | Guide", "can_mod_post": false, "score": 140, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://preview.redd.it/45vz9gsccwjg1.png?width=140&amp;height=93&amp;auto=webp&amp;s=756e160017cba45aa81c1857ea9d40a69ead7c91", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1771265060.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google released FunctionGemma a few weeks ago - a 270M parameter model specifically for function calling. Tiny enough to run on a phone CPU at 125 tok/s. The model card says upfront that it needs fine-tuning for multi-turn use cases, and our testing confirmed it: base accuracy on multi-turn tool calling ranged from 9.9% to 38.8% depending on the task.&lt;/p&gt;\n\n&lt;p&gt;We fine-tuned it on three different multi-turn tasks using knowledge distillation from a 120B teacher:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Task&lt;/th&gt;\n&lt;th&gt;Base&lt;/th&gt;\n&lt;th&gt;Tuned&lt;/th&gt;\n&lt;th&gt;Teacher (120B)&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Smart home control&lt;/td&gt;\n&lt;td&gt;38.8%&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;96.7%&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;92.1%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Banking voice assistant&lt;/td&gt;\n&lt;td&gt;23.4%&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;90.9%&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;97.0%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Shell commands (Gorilla)&lt;/td&gt;\n&lt;td&gt;9.9%&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;96.0%&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;97.0%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;The smart home and shell command models actually beat the teacher. The banking task is harder (14 functions + ASR noise in the input) but still a massive jump.&lt;/p&gt;\n\n&lt;p&gt;All models, training data, and datasets are open:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Smart home model: &lt;a href=\"https://huggingface.co/distil-labs/distil-home-assistant-functiongemma\"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Smart home data: &lt;a href=\"https://github.com/distil-labs/distil-smart-home\"&gt;GitHub&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Voice assistant data: &lt;a href=\"https://github.com/distil-labs/distil-voice-assistant-banking\"&gt;GitHub&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Shell commands data + demo: &lt;a href=\"https://github.com/distil-labs/distil-SHELLper\"&gt;GitHub&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Full writeup with methodology: &lt;a href=\"https://www.distillabs.ai/blog/making-functiongemma-work-multi-turn-tool-calling-at-270m-parameters\"&gt;Making FunctionGemma Work: Multi-Turn Tool Calling at 270M Parameters&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We used &lt;a href=\"https://www.distillabs.ai/\"&gt;Distil Labs&lt;/a&gt; (our platform) for the training pipeline. Happy to answer questions about the process, the results, or FunctionGemma in general.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/45vz9gsccwjg1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/45vz9gsccwjg1.png?auto=webp&amp;s=ef9100af4d1c3e5817e2c19f170efdbe9f324487", "width": 1200, "height": 800}, "resolutions": [{"url": "https://preview.redd.it/45vz9gsccwjg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8bdc5a47e24f885b79d6c81d43e5da316b83fbc4", "width": 108, "height": 72}, {"url": "https://preview.redd.it/45vz9gsccwjg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=389aa687e01603c896bd7d3798bace36eb0149ca", "width": 216, "height": 144}, {"url": "https://preview.redd.it/45vz9gsccwjg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0199ca6829be604bc79c9c738451ce929ff86319", "width": 320, "height": 213}, {"url": "https://preview.redd.it/45vz9gsccwjg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1eec91fa23850fedabefb7e68dc6cda809eefd2b", "width": 640, "height": 426}, {"url": "https://preview.redd.it/45vz9gsccwjg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9176037d35a0a092f48916d765f11eadc2f61ba", "width": 960, "height": 640}, {"url": "https://preview.redd.it/45vz9gsccwjg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=041e7b4352ba2906a176f1597477dcda7db6e2f7", "width": 1080, "height": 720}], "variants": {}, "id": "45vz9gsccwjg1"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1r6gx75", "is_robot_indexable": true, "report_reasons": null, "author": "party-horse", "discussion_type": null, "num_comments": 26, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LocalLLaMA/comments/1r6gx75/finetuned_functiongemma_270m_for_multiturn_tool/", "stickied": false, "url": "https://i.redd.it/45vz9gsccwjg1.png", "subreddit_subscribers": 627043, "created_utc": 1771265060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "Where did leakers go", "author_fullname": "t2_1k20gof6xh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where are Qwen 3.5 2B, 9B, and 35B-A3B", "link_flair_richtext": [{"e": "text", "t": "Question | Help"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6w0la", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 122, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question | Help", "can_mod_post": false, "score": 122, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771301523.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LocalLLaMA", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where did leakers go&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#5a74cc", "id": "1r6w0la", "is_robot_indexable": true, "report_reasons": null, "author": "Admirable_Flower_287", "discussion_type": null, "num_comments": 40, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LocalLLaMA/comments/1r6w0la/where_are_qwen_35_2b_9b_and_35ba3b/", "stickied": false, "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r6w0la/where_are_qwen_35_2b_9b_and_35ba3b/", "subreddit_subscribers": 627043, "created_utc": 1771301523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "The reason I'm asking this question because some folks(including me) are in self-doubt little bit. Maybe because after seeing threads about comparison with Online models(More than Trillions of parameters).\n\nOf course, we can't expect same coding performance &amp; output from these 20-100B models.\n\nSome didn't even utilize full potential of these local models. I think only 1/3 of folks hit the turbo with these models.\n\nPersonally I never tried Agentic coding as my current laptop(just 8GB VRAM + 32GB RAM) is useless for that.\n\nLets say I have enough VRAM to run Q6/Q8 of these 20-100B models with 128K-256K context.\n\nBut are these models enough to do good level coding? Like Agentic Coding .... Solving Leetcode issues, Code analysis, Code reviews, Optimizations, Automations, etc., Of course include Vibe coding at last.\n\nPlease share your thoughts. Thanks.\n\nI'm not gonna create(though I can't) Billion dollar company, I just want to create basic level Websites, Apps, Games. That's it. Majority of those creations gonna be Freeware/Opensource.\n\nWhat models am I talking about? Here below:\n\n* GPT-OSS-20B\n* Devstral-Small-2-24B-Instruct-2512\n* Qwen3-30B-A3B\n* Qwen3-30B-Coder\n* Nemotron-3-Nano-30B-A3B\n* Qwen3-32B\n* GLM-4.7-Flash\n* Seed-OSS-36B\n* Kimi-Linear-48B-A3B\n* Qwen3-Next-80B-A3B\n* Qwen3-Coder-Next\n* GLM-4.5-Air\n* GPT-OSS-120B\n\n**EDIT** : Adding few more models after suggestions from few comments:\n\n* Devstral-2-123B-Instruct-2512 - Q4 @ 75GB, Q5 @ 90GB, Q6 @ 100GB\n* Step-3.5-Flash - Q4 @ 100-120GB\n* MiniMax-M2.1, 2 - Q4 @ 120-140GB\n* Qwen3-235B-A22B - Q4 @ 125-135GB\n\nIn Future, I'll go up to 200B models after getting additional GPUs.", "author_fullname": "t2_1deiadfhb1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are 20-100B models enough for Good Coding?", "link_flair_richtext": [{"e": "text", "t": "Discussion"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6jklq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1771298299.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771270712.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LocalLLaMA", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The reason I&amp;#39;m asking this question because some folks(including me) are in self-doubt little bit. Maybe because after seeing threads about comparison with Online models(More than Trillions of parameters).&lt;/p&gt;\n\n&lt;p&gt;Of course, we can&amp;#39;t expect same coding performance &amp;amp; output from these 20-100B models.&lt;/p&gt;\n\n&lt;p&gt;Some didn&amp;#39;t even utilize full potential of these local models. I think only 1/3 of folks hit the turbo with these models.&lt;/p&gt;\n\n&lt;p&gt;Personally I never tried Agentic coding as my current laptop(just 8GB VRAM + 32GB RAM) is useless for that.&lt;/p&gt;\n\n&lt;p&gt;Lets say I have enough VRAM to run Q6/Q8 of these 20-100B models with 128K-256K context.&lt;/p&gt;\n\n&lt;p&gt;But are these models enough to do good level coding? Like Agentic Coding .... Solving Leetcode issues, Code analysis, Code reviews, Optimizations, Automations, etc., Of course include Vibe coding at last.&lt;/p&gt;\n\n&lt;p&gt;Please share your thoughts. Thanks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not gonna create(though I can&amp;#39;t) Billion dollar company, I just want to create basic level Websites, Apps, Games. That&amp;#39;s it. Majority of those creations gonna be Freeware/Opensource.&lt;/p&gt;\n\n&lt;p&gt;What models am I talking about? Here below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;GPT-OSS-20B&lt;/li&gt;\n&lt;li&gt;Devstral-Small-2-24B-Instruct-2512&lt;/li&gt;\n&lt;li&gt;Qwen3-30B-A3B&lt;/li&gt;\n&lt;li&gt;Qwen3-30B-Coder&lt;/li&gt;\n&lt;li&gt;Nemotron-3-Nano-30B-A3B&lt;/li&gt;\n&lt;li&gt;Qwen3-32B&lt;/li&gt;\n&lt;li&gt;GLM-4.7-Flash&lt;/li&gt;\n&lt;li&gt;Seed-OSS-36B&lt;/li&gt;\n&lt;li&gt;Kimi-Linear-48B-A3B&lt;/li&gt;\n&lt;li&gt;Qwen3-Next-80B-A3B&lt;/li&gt;\n&lt;li&gt;Qwen3-Coder-Next&lt;/li&gt;\n&lt;li&gt;GLM-4.5-Air&lt;/li&gt;\n&lt;li&gt;GPT-OSS-120B&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt; : Adding few more models after suggestions from few comments:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Devstral-2-123B-Instruct-2512 - Q4 @ 75GB, Q5 @ 90GB, Q6 @ 100GB&lt;/li&gt;\n&lt;li&gt;Step-3.5-Flash - Q4 @ 100-120GB&lt;/li&gt;\n&lt;li&gt;MiniMax-M2.1, 2 - Q4 @ 120-140GB&lt;/li&gt;\n&lt;li&gt;Qwen3-235B-A22B - Q4 @ 125-135GB&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In Future, I&amp;#39;ll go up to 200B models after getting additional GPUs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#646d73", "id": "1r6jklq", "is_robot_indexable": true, "report_reasons": null, "author": "pmttyji", "discussion_type": null, "num_comments": 72, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LocalLLaMA/comments/1r6jklq/are_20100b_models_enough_for_good_coding/", "stickied": false, "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r6jklq/are_20100b_models_enough_for_good_coding/", "subreddit_subscribers": 627043, "created_utc": 1771270712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "# Model Summary\n\nCohere Labs Tiny Aya is an open weights research release of a pretrained 3.35 billion parameter model optimized for efficient, strong, and balanced multilingual representation across 70+ languages, including many lower-resourced ones. The model is designed to support downstream adaptation, instruction tuning, and local deployment under realistic compute constraints.\n\nDeveloped by: [Cohere](https://cohere.com/) and [Cohere](https://cohere.com/research) Labs\n\n* Point of Contact: [**Cohere Labs**](https://cohere.com/research)\n* License: [CC-BY-NC](https://cohere.com/cohere-labs-cc-by-nc-license), requires also adhering to [**Cohere Lab's Acceptable Use Policy**](https://docs.cohere.com/docs/c4ai-acceptable-use-policy)\n* Model: tiny-aya-it-global\n* Model Size: 3.35B\n* Context length: 8K input\n\nFor more details about this model family, please check out our [blog post](https://cohere.com/blog/cohere-labs-tiny-aya) and [tech report](https://github.com/Cohere-Labs/tiny-aya-tech-report/blob/main/tiny_aya_tech_report.pdf).\n\nlooks like different models are for different families of languages:\n\n* [https://huggingface.co/CohereLabs/tiny-aya-earth-GGUF](https://huggingface.co/CohereLabs/tiny-aya-earth-GGUF)\n* [https://huggingface.co/CohereLabs/tiny-aya-fire-GGUF](https://huggingface.co/CohereLabs/tiny-aya-fire-GGUF)\n* [https://huggingface.co/CohereLabs/tiny-aya-water-GGUF](https://huggingface.co/CohereLabs/tiny-aya-water-GGUF)\n* [https://huggingface.co/CohereLabs/tiny-aya-global-GGUF](https://huggingface.co/CohereLabs/tiny-aya-global-GGUF)\n\n# Usage and Limitations\n\n# \n\n# Intended Usage\n\nTiny Aya is a family of massively multilingual small language models built to bring capable AI to languages that are often underserved by existing models. The models support languages across Indic, East and Southeast Asian, African, European, and Middle Eastern language families, with a deliberate emphasis on low-resource language performance.\n\nIntended applications include multilingual text generation, conversational AI, summarization, translation and cross-lingual tasks, as well as research in multilingual NLP and low-resource language modeling. The models are also suited for efficient deployment in multilingual regions, helping bridge the digital language divide for underrepresented language communities.\n\n# \n\n# Strengths\n\nTiny Aya demonstrates strong open-ended generation quality across its full language coverage, with particularly notable performance on low-resource languages. The model performs well on translation, summarization, and cross-lingual tasks, benefiting from training signal shared across language families and scripts.\n\n# \n\n# Limitations\n\n**Reasoning tasks.** The model's strongest performance is on open-ended generation and conversational tasks. Chain-of-thought reasoning tasks such as multilingual math (MGSM) are comparatively weaker.\n\n**Factual knowledge.** As with any language model, outputs may contain incorrect or outdated statements, particularly in lower-resource languages with thinner training data coverage.\n\n**Uneven resource distribution.** High-resource languages benefit from richer training signal and tend to exhibit more consistent quality across tasks. The lowest-resource languages in the model's coverage may show greater variability, and culturally specific nuance, sarcasm, or figurative language may be less reliably handled in these languages.\n\n**Task complexity.** The model performs best with clear prompts and instructions. Highly complex or open-ended reasoning, particularly in lower-resource languages, remains challenging.", "author_fullname": "t2_vqgbql9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tiny Aya", "link_flair_richtext": [{"e": "text", "t": "New Model"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r70ohs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "#bbbdbf", "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "New Model", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1771317458.0, "author_flair_css_class": null, "author_flair_richtext": [{"e": "text", "t": "llama.cpp"}], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1771317238.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "self.LocalLLaMA", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Model Summary&lt;/h1&gt;\n\n&lt;p&gt;Cohere Labs Tiny Aya is an open weights research release of a pretrained 3.35 billion parameter model optimized for efficient, strong, and balanced multilingual representation across 70+ languages, including many lower-resourced ones. The model is designed to support downstream adaptation, instruction tuning, and local deployment under realistic compute constraints.&lt;/p&gt;\n\n&lt;p&gt;Developed by: &lt;a href=\"https://cohere.com/\"&gt;Cohere&lt;/a&gt; and &lt;a href=\"https://cohere.com/research\"&gt;Cohere&lt;/a&gt; Labs&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Point of Contact: &lt;a href=\"https://cohere.com/research\"&gt;&lt;strong&gt;Cohere Labs&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;License: &lt;a href=\"https://cohere.com/cohere-labs-cc-by-nc-license\"&gt;CC-BY-NC&lt;/a&gt;, requires also adhering to &lt;a href=\"https://docs.cohere.com/docs/c4ai-acceptable-use-policy\"&gt;&lt;strong&gt;Cohere Lab&amp;#39;s Acceptable Use Policy&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Model: tiny-aya-it-global&lt;/li&gt;\n&lt;li&gt;Model Size: 3.35B&lt;/li&gt;\n&lt;li&gt;Context length: 8K input&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For more details about this model family, please check out our &lt;a href=\"https://cohere.com/blog/cohere-labs-tiny-aya\"&gt;blog post&lt;/a&gt; and &lt;a href=\"https://github.com/Cohere-Labs/tiny-aya-tech-report/blob/main/tiny_aya_tech_report.pdf\"&gt;tech report&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;looks like different models are for different families of languages:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://huggingface.co/CohereLabs/tiny-aya-earth-GGUF\"&gt;https://huggingface.co/CohereLabs/tiny-aya-earth-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://huggingface.co/CohereLabs/tiny-aya-fire-GGUF\"&gt;https://huggingface.co/CohereLabs/tiny-aya-fire-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://huggingface.co/CohereLabs/tiny-aya-water-GGUF\"&gt;https://huggingface.co/CohereLabs/tiny-aya-water-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://huggingface.co/CohereLabs/tiny-aya-global-GGUF\"&gt;https://huggingface.co/CohereLabs/tiny-aya-global-GGUF&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Usage and Limitations&lt;/h1&gt;\n\n&lt;h1&gt;Intended Usage&lt;/h1&gt;\n\n&lt;p&gt;Tiny Aya is a family of massively multilingual small language models built to bring capable AI to languages that are often underserved by existing models. The models support languages across Indic, East and Southeast Asian, African, European, and Middle Eastern language families, with a deliberate emphasis on low-resource language performance.&lt;/p&gt;\n\n&lt;p&gt;Intended applications include multilingual text generation, conversational AI, summarization, translation and cross-lingual tasks, as well as research in multilingual NLP and low-resource language modeling. The models are also suited for efficient deployment in multilingual regions, helping bridge the digital language divide for underrepresented language communities.&lt;/p&gt;\n\n&lt;h1&gt;Strengths&lt;/h1&gt;\n\n&lt;p&gt;Tiny Aya demonstrates strong open-ended generation quality across its full language coverage, with particularly notable performance on low-resource languages. The model performs well on translation, summarization, and cross-lingual tasks, benefiting from training signal shared across language families and scripts.&lt;/p&gt;\n\n&lt;h1&gt;Limitations&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Reasoning tasks.&lt;/strong&gt; The model&amp;#39;s strongest performance is on open-ended generation and conversational tasks. Chain-of-thought reasoning tasks such as multilingual math (MGSM) are comparatively weaker.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Factual knowledge.&lt;/strong&gt; As with any language model, outputs may contain incorrect or outdated statements, particularly in lower-resource languages with thinner training data coverage.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Uneven resource distribution.&lt;/strong&gt; High-resource languages benefit from richer training signal and tend to exhibit more consistent quality across tasks. The lowest-resource languages in the model&amp;#39;s coverage may show greater variability, and culturally specific nuance, sarcasm, or figurative language may be less reliably handled in these languages.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Task complexity.&lt;/strong&gt; The model performs best with clear prompts and instructions. Highly complex or open-ended reasoning, particularly in lower-resource languages, remains challenging.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ.png?auto=webp&amp;s=284cb77a65d7fa660e1e258577d2c2e89f641973", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8987ef005b272bd97ba9b25134ddbe29396e37e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ecbae20b4174716cc70dd29c875585d3ca936d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=94b2655256bff673cb7b4130c4def4a73bf956f5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=be774ebf8e563e02054cf418e91e66e26816b27a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2923d64a15f16e8814df2b69c22adf2719657480", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=78d5ffc3f3e70cd078b8e13257a543029202f6a1", "width": 1080, "height": 567}], "variants": {}, "id": "6W2m5wucHzO0VdZPunddX9uAVqD9tkBB8s-rQ7kvZmQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "llama.cpp", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1r70ohs", "is_robot_indexable": true, "report_reasons": null, "author": "jacek2023", "discussion_type": null, "num_comments": 16, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/LocalLLaMA/comments/1r70ohs/tiny_aya/", "stickied": false, "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r70ohs/tiny_aya/", "subreddit_subscribers": 627043, "created_utc": 1771317238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "\"262k natively, extensible up to 1M tokens\"\n\nOkay, who has tried this?  How coherent is it at even 500k tokens?   Throw a big code repo in and see if the agent can do work, solve an issue.    I know some of you big boys got big rigs.   If anyone ever uses past 500k, please don't forget to share with us how performant it was!", "author_fullname": "t2_ah13x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Qwen3.5-397B up to 1 million context length", "link_flair_richtext": [{"e": "text", "t": "Discussion"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6qy55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "#bbbdbf", "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [{"e": "text", "t": "llama.cpp"}], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771287773.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "self.LocalLLaMA", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;262k natively, extensible up to 1M tokens&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Okay, who has tried this?  How coherent is it at even 500k tokens?   Throw a big code repo in and see if the agent can do work, solve an issue.    I know some of you big boys got big rigs.   If anyone ever uses past 500k, please don&amp;#39;t forget to share with us how performant it was!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "llama.cpp", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#646d73", "id": "1r6qy55", "is_robot_indexable": true, "report_reasons": null, "author": "segmond", "discussion_type": null, "num_comments": 22, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/LocalLLaMA/comments/1r6qy55/qwen35397b_up_to_1_million_context_length/", "stickied": false, "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r6qy55/qwen35397b_up_to_1_million_context_length/", "subreddit_subscribers": 627043, "created_utc": 1771287773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "I am writing this between sounds of fireworks.\n\nI learned everything about LLM, RAG and others stuff related to AI for a longg time here.\n\nMay your year be filled with perfect timing, rich flavors, and the joy of creating something truly special.\n\nHappy lunar new year, here\u2019s to a masterpiece of a year ahead!", "author_fullname": "t2_u82qr8p5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey, it's lunar new year, and this is not a post about local LLM", "link_flair_richtext": [{"e": "text", "t": "Generation"}], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r6gg04", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Generation", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771264051.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LocalLLaMA", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am writing this between sounds of fireworks.&lt;/p&gt;\n\n&lt;p&gt;I learned everything about LLM, RAG and others stuff related to AI for a longg time here.&lt;/p&gt;\n\n&lt;p&gt;May your year be filled with perfect timing, rich flavors, and the joy of creating something truly special.&lt;/p&gt;\n\n&lt;p&gt;Happy lunar new year, here\u2019s to a masterpiece of a year ahead!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "23bddba8-ff56-11ed-9688-1a11994b71f7", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#b5a3d0", "id": "1r6gg04", "is_robot_indexable": true, "report_reasons": null, "author": "Vozer_bros", "discussion_type": null, "num_comments": 7, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LocalLLaMA/comments/1r6gg04/hey_its_lunar_new_year_and_this_is_not_a_post/", "stickied": false, "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r6gg04/hey_its_lunar_new_year_and_this_is_not_a_post/", "subreddit_subscribers": 627043, "created_utc": 1771264051.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}
