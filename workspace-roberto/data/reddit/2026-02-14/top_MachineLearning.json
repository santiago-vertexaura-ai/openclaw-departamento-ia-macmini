{"kind": "Listing", "data": {"after": "t3_1r3tn73", "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I\u2019m a final-year PhD student in the U.S. working primarily on NLP. I\u2019ve been on the job market this year (since October), and I\u2019m trying to understand where I might be going wrong.\n\nMy priority was academia, but after submitting 30 tenure-track applications, I\u2019ve heard nothing but crickets.\n\nI also applied for industry roles:  \n\\~200 applications \u2192 8 interviews, no offers.\n\n**My research profile:**  \n17 peer-reviewed papers and 1 pre-print, \\~13 first-author, about 8 in A/A\\* ACLvenues (rest are workshops), \\~430 citations. I\u2019ve also completed internships at well-known companies and published work from them, but that didn\u2019t convert into return offers.\n\nIn interviews, I often run into one of two issues:\n\n* My research area is seen as too narrow or outdated (summarization) or not aligned with what the team currently needs, **or**\n* The process becomes heavily LeetCode/SWE-style, which is not my strongest area.\n\nI\u2019m trying to figure out what I should be doing differently.\n\n**For industry roles:**\n\n* What skills should I be improving that hiring managers are actually looking for? More LeetCode? Implementing ML algorithms from scratch?\n\n**For postdoc opportunities:**\n\n* Should I start cold-emailing professors directly about postdocs (I\u2019m defending in four months)?\n\n", "author_fullname": "t2_6lfcalue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Struggling on the NLP job market as a final-year PhD , looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r467ra", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771029413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a final-year PhD student in the U.S. working primarily on NLP. I\u2019ve been on the job market this year (since October), and I\u2019m trying to understand where I might be going wrong.&lt;/p&gt;\n\n&lt;p&gt;My priority was academia, but after submitting 30 tenure-track applications, I\u2019ve heard nothing but crickets.&lt;/p&gt;\n\n&lt;p&gt;I also applied for industry roles:&lt;br/&gt;\n~200 applications \u2192 8 interviews, no offers.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My research profile:&lt;/strong&gt;&lt;br/&gt;\n17 peer-reviewed papers and 1 pre-print, ~13 first-author, about 8 in A/A* ACLvenues (rest are workshops), ~430 citations. I\u2019ve also completed internships at well-known companies and published work from them, but that didn\u2019t convert into return offers.&lt;/p&gt;\n\n&lt;p&gt;In interviews, I often run into one of two issues:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;My research area is seen as too narrow or outdated (summarization) or not aligned with what the team currently needs, &lt;strong&gt;or&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;The process becomes heavily LeetCode/SWE-style, which is not my strongest area.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m trying to figure out what I should be doing differently.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;For industry roles:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What skills should I be improving that hiring managers are actually looking for? More LeetCode? Implementing ML algorithms from scratch?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;For postdoc opportunities:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Should I start cold-emailing professors directly about postdocs (I\u2019m defending in four months)?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r467ra", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativeBed838", "discussion_type": null, "num_comments": 31, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r467ra/d_struggling_on_the_nlp_job_market_as_a_finalyear/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r467ra/d_struggling_on_the_nlp_job_market_as_a_finalyear/", "subreddit_subscribers": 3022491, "created_utc": 1771029413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "We evaluated 22 model configurations across different effort/thinking levels on Deep Research Bench (169 web research tasks, human-verified answers). For two of the most capable models, higher effort settings scored worse.  \n  \nGPT-5 at low effort scored 0.496 on DRB. At high effort, it dropped to 0.481, and cost 55% more per query ($0.25 \u2192 $0.39). Gemini 3 Flash showed a 5-point drop going from 0.504 at low effort, to 0.479 at high effort.  \n  \nMost models cluster well under a dollar per task, making deep research surprisingly affordable. Methodology, pareto analysis of accuracy vs cost are at [https://everyrow.io/docs/notebooks/deep-research-bench-pareto-analysis](https://everyrow.io/docs/notebooks/deep-research-bench-pareto-analysis)", "author_fullname": "t2_4hfcm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[R] Higher effort settings reduce deep research accuracy for GPT-5 and Gemini Flash 3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "three", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r3w853", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Research", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1771005615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We evaluated 22 model configurations across different effort/thinking levels on Deep Research Bench (169 web research tasks, human-verified answers). For two of the most capable models, higher effort settings scored worse.  &lt;/p&gt;\n\n&lt;p&gt;GPT-5 at low effort scored 0.496 on DRB. At high effort, it dropped to 0.481, and cost 55% more per query ($0.25 \u2192 $0.39). Gemini 3 Flash showed a 5-point drop going from 0.504 at low effort, to 0.479 at high effort.  &lt;/p&gt;\n\n&lt;p&gt;Most models cluster well under a dollar per task, making deep research surprisingly affordable. Methodology, pareto analysis of accuracy vs cost are at &lt;a href=\"https://everyrow.io/docs/notebooks/deep-research-bench-pareto-analysis\"&gt;https://everyrow.io/docs/notebooks/deep-research-bench-pareto-analysis&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA.png?auto=webp&amp;s=1f8c2b277cda50ddecd2ab8438af75ce6c7ce7d1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2afe65521535b0c97550dee39067e27097546a2", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d01af9123d9746c6de2bfaa8ca3458a31155a64", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=401d23a9c67b4203d531ca18d660b79563f15a82", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cea2e0dd197697189c01933c4b09dce1a1c2267b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e51a7ef20456925e42e5c8ff595517ca0eab695", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5b2a5c1e960d4ff8528549f2cc4bd2ac28434d4", "width": 1080, "height": 567}], "variants": {}, "id": "PAfzP8_fjhuX4IJFbJ4Ak963wflG-EdScFlAWJCsnpA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bb90e510-4e82-11e6-8635-0ee522e2349b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#f1f10e", "id": "1r3w853", "is_robot_indexable": true, "report_reasons": null, "author": "ddp26", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r3w853/r_higher_effort_settings_reduce_deep_research/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r3w853/r_higher_effort_settings_reduce_deep_research/", "subreddit_subscribers": 3022491, "created_utc": 1771005615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "It will be released in one day, so created this. \n\n", "author_fullname": "t2_70mnmect", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] ARR Jan ARR Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r4fotm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771058699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It will be released in one day, so created this. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r4fotm", "is_robot_indexable": true, "report_reasons": null, "author": "Striking-Warning9533", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r4fotm/d_arr_jan_arr_discussion/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r4fotm/d_arr_jan_arr_discussion/", "subreddit_subscribers": 3022491, "created_utc": 1771058699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I recently tried out Minimax 2.5, which just dropped, and from what I\u2019ve heard, the results are pretty impressive. I gave it a go on zenmux, and I have to say, it really covers a lot of ground. The flexibility, speed, and accuracy are definitely noticeable improvements.\n\n\n\nNow, I\u2019m thinking about deploying it locally. I\u2019ve used Ollama for deployments before, but I noticed that for Minimax 2.5, Ollama only offers a cloud version. I\u2019m curious about other deployment options and wondering what the difficulty level and hardware costs would be for a local setup.\n\n\n\nHas anyone tried deploying Minimax 2.5 locally, or can share any insights into the hardware requirements? Any advice would be greatly appreciated.", "author_fullname": "t2_1yxv5gf9d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Minimax 2.5 is out, considering local deployment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r48dvk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771035452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently tried out Minimax 2.5, which just dropped, and from what I\u2019ve heard, the results are pretty impressive. I gave it a go on zenmux, and I have to say, it really covers a lot of ground. The flexibility, speed, and accuracy are definitely noticeable improvements.&lt;/p&gt;\n\n&lt;p&gt;Now, I\u2019m thinking about deploying it locally. I\u2019ve used Ollama for deployments before, but I noticed that for Minimax 2.5, Ollama only offers a cloud version. I\u2019m curious about other deployment options and wondering what the difficulty level and hardware costs would be for a local setup.&lt;/p&gt;\n\n&lt;p&gt;Has anyone tried deploying Minimax 2.5 locally, or can share any insights into the hardware requirements? Any advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r48dvk", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic_Spirit_8436", "discussion_type": null, "num_comments": 3, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r48dvk/d_minimax_25_is_out_considering_local_deployment/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r48dvk/d_minimax_25_is_out_considering_local_deployment/", "subreddit_subscribers": 3022491, "created_utc": 1771035452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I released a new version of my side project: SoproTTS\n\nA 135M parameter TTS model trained for \\~$100 on 1 GPU, running \\~20\u00d7 real-time on a base MacBook M3 CPU.\n\nv1.5 highlights (on CPU):\n\n\u2022 250 ms TTFA streaming latency  \n\u2022 0.05 RTF (\\~20\u00d7 real-time)  \n\u2022 Zero-shot voice cloning  \n\u2022 Smaller, faster, more stable\n\nStill not perfect (OOD voices can be tricky, and there are still some artifacts), but a decent upgrade. Training code TBA.\n\nRepo (demo inside):\u00a0[https://github.com/samuel-vitorino/sopro](https://github.com/samuel-vitorino/sopro)", "author_fullname": "t2_12onk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] SoproTTS v1.5: A 135M zero-shot voice cloning TTS model trained for ~$100 on 1 GPU, running ~20\u00d7 real-time on the CPU", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r3ul8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Project", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1771001966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I released a new version of my side project: SoproTTS&lt;/p&gt;\n\n&lt;p&gt;A 135M parameter TTS model trained for ~$100 on 1 GPU, running ~20\u00d7 real-time on a base MacBook M3 CPU.&lt;/p&gt;\n\n&lt;p&gt;v1.5 highlights (on CPU):&lt;/p&gt;\n\n&lt;p&gt;\u2022 250 ms TTFA streaming latency&lt;br/&gt;\n\u2022 0.05 RTF (~20\u00d7 real-time)&lt;br/&gt;\n\u2022 Zero-shot voice cloning&lt;br/&gt;\n\u2022 Smaller, faster, more stable&lt;/p&gt;\n\n&lt;p&gt;Still not perfect (OOD voices can be tricky, and there are still some artifacts), but a decent upgrade. Training code TBA.&lt;/p&gt;\n\n&lt;p&gt;Repo (demo inside):\u00a0&lt;a href=\"https://github.com/samuel-vitorino/sopro\"&gt;https://github.com/samuel-vitorino/sopro&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg.png?auto=webp&amp;s=36753d3efbf97901e7d295acc1f7e33fca567c79", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc2a176bb5db34f53a49cdaac4b238a48365c782", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=00c2580ea158085543fb4404d5ce17d9293a842e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=354b82732e6d5d6775a75440d9946172dce376a3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=da1477f6d55802f7b1774132df25fe189eeac4e5", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9984caf74d27f5dc2404172f9e489f7f24bb1050", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6d382c0cf961bbcc0bf038ea90bdb64543a577d1", "width": 1080, "height": 540}], "variants": {}, "id": "9mtKXNVthZuNnxQnJ7fWe87INdTTdgLsOm_BU2s_REg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c6dea51c-19d3-11f0-81a2-deb9d8e21ccb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7d659a", "id": "1r3ul8s", "is_robot_indexable": true, "report_reasons": null, "author": "SammyDaBeast", "discussion_type": null, "num_comments": 1, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r3ul8s/p_soprotts_v15_a_135m_zeroshot_voice_cloning_tts/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r3ul8s/p_soprotts_v15_a_135m_zeroshot_voice_cloning_tts/", "subreddit_subscribers": 3022491, "created_utc": 1771001966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "When I'm training an MoE model with modelscope-swift (with megatron as the backend), I find the gradient norm goes up and down during the training phase. Although the language modeling loss continually goes down, I want to figure out **why** the training process would behave like this. Is it a problem, and **how** to resolve this issue?\n\nSome details:\n\n* init: norm with std=0.02\n* lr: warmup 2.5k steps and constant to 4e-4, bsz: 4M tokens\n* setting: pre-training from scratch\n* model: a smaller Qwen3-MoE model of 3B-A900M\n\n\n\nhttps://preview.redd.it/hg2fed5u2ejg1.png?width=352&amp;format=png&amp;auto=webp&amp;s=b49e0a9c6bd46e0f1f0d0b49f37773dfc271700d\n\nhttps://preview.redd.it/zesiw2fu2ejg1.png?width=364&amp;format=png&amp;auto=webp&amp;s=0ab4d5391721d0cd97b24f1450f307db63b58689\n\n  \n\n\n", "author_fullname": "t2_2box301j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Interesting Gradient Norm Goes Down-Up-Down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 121, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hg2fed5u2ejg1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/hg2fed5u2ejg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f2bebcefc344098af7dd2a503c99d41884adfdec"}, {"y": 187, "x": 216, "u": "https://preview.redd.it/hg2fed5u2ejg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=40bc50160321849424b3a3133f1795c1207e9b4c"}, {"y": 277, "x": 320, "u": "https://preview.redd.it/hg2fed5u2ejg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9b0ce6f1179acc8e68f75963281652e94ba24b0"}], "s": {"y": 305, "x": 352, "u": "https://preview.redd.it/hg2fed5u2ejg1.png?width=352&amp;format=png&amp;auto=webp&amp;s=b49e0a9c6bd46e0f1f0d0b49f37773dfc271700d"}, "id": "hg2fed5u2ejg1"}, "zesiw2fu2ejg1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 102, "x": 108, "u": "https://preview.redd.it/zesiw2fu2ejg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d8a5492657cfed5ddb58359dcd75bb20768fae2"}, {"y": 205, "x": 216, "u": "https://preview.redd.it/zesiw2fu2ejg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e296e09f6e9c8153156ab233bae032943bea38f"}, {"y": 305, "x": 320, "u": "https://preview.redd.it/zesiw2fu2ejg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8eb6d629b07a4b661d238a8be6b558b0d7fd2642"}], "s": {"y": 347, "x": 364, "u": "https://preview.redd.it/zesiw2fu2ejg1.png?width=364&amp;format=png&amp;auto=webp&amp;s=0ab4d5391721d0cd97b24f1450f307db63b58689"}, "id": "zesiw2fu2ejg1"}}, "name": "t3_1r4bbbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://preview.redd.it/hg2fed5u2ejg1.png?width=140&amp;height=121&amp;auto=webp&amp;s=c61e1c948658db8d5b030e0293726d132eddbee5", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771043971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I&amp;#39;m training an MoE model with modelscope-swift (with megatron as the backend), I find the gradient norm goes up and down during the training phase. Although the language modeling loss continually goes down, I want to figure out &lt;strong&gt;why&lt;/strong&gt; the training process would behave like this. Is it a problem, and &lt;strong&gt;how&lt;/strong&gt; to resolve this issue?&lt;/p&gt;\n\n&lt;p&gt;Some details:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;init: norm with std=0.02&lt;/li&gt;\n&lt;li&gt;lr: warmup 2.5k steps and constant to 4e-4, bsz: 4M tokens&lt;/li&gt;\n&lt;li&gt;setting: pre-training from scratch&lt;/li&gt;\n&lt;li&gt;model: a smaller Qwen3-MoE model of 3B-A900M&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hg2fed5u2ejg1.png?width=352&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b49e0a9c6bd46e0f1f0d0b49f37773dfc271700d\"&gt;https://preview.redd.it/hg2fed5u2ejg1.png?width=352&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b49e0a9c6bd46e0f1f0d0b49f37773dfc271700d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zesiw2fu2ejg1.png?width=364&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0ab4d5391721d0cd97b24f1450f307db63b58689\"&gt;https://preview.redd.it/zesiw2fu2ejg1.png?width=364&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0ab4d5391721d0cd97b24f1450f307db63b58689&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r4bbbd", "is_robot_indexable": true, "report_reasons": null, "author": "Spico197", "discussion_type": null, "num_comments": 8, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r4bbbd/d_interesting_gradient_norm_goes_downupdown/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r4bbbd/d_interesting_gradient_norm_goes_downupdown/", "subreddit_subscribers": 3022491, "created_utc": 1771043971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "submitted a paper there but no emails yet should I wait till tmrw?", "author_fullname": "t2_a9zefvqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[R] Lrec 26 acceptance emails", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "three", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r47czy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Research", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771032578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;submitted a paper there but no emails yet should I wait till tmrw?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bb90e510-4e82-11e6-8635-0ee522e2349b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#f1f10e", "id": "1r47czy", "is_robot_indexable": true, "report_reasons": null, "author": "ChestFree776", "discussion_type": null, "num_comments": 2, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r47czy/r_lrec_26_acceptance_emails/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r47czy/r_lrec_26_acceptance_emails/", "subreddit_subscribers": 3022491, "created_utc": 1771032578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "This post details my exploration for a \"stable stack\" for streaming deep RL (ObGD, SparseInit, LayerNorm, and online normalization) using 433,000 observations of real, non-stationary SSH attack traffic.\n\n**Learnings From Tests:**\n\n* **Computational Efficiency:** Using JAX's AOT compilation pipeline and `cost_analysis()`, the tests measure the per-update FLOP counts. An MLP with two hidden layers of 128 nodes each learner requires 271k FLOPs per update, capable of processing 477k observations/second maintaining significant headroom even on high-bandwidth links on low(er) powered edge devices. \n* **Normalization on Non-Stationary Streams:** The experiments found that EMA (decay=0.99) significantly outperforms Welford\u2019s cumulative algorithm on adversarial traffic with sudden bursts. EMA\u2019s exponential forgetting allows for faster recovery from distribution shifts compared to cumulative statistics. Regardless of EMA or Welford what is evident that external normailzation of input data is pretty much required. \n* **Gradient Coherence:** Global scalar bounding (ObGD) (Elsayed et al. 2024) was found to be critical for maintaining stability in single-sample streaming updates. Per-unit Adaptive Gradient Clipping (AGC) doesn't work well for the tests I'm doing here. \n\n**Full Post and Empirical Analysis:**\n[Validating Streaming Deep RL on Attack Traffic](https://blog.9600baud.net/streaming-deep-rl-honeypot.html)\n\nThis is my early learnings on RL prediction as I work through the steps of the Alberta Plan for AI research. Feedback, suggestions for further tests and related literature would be appreciated. ", "author_fullname": "t2_25np6zeq7a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Benchmarking Deep RL Stability Capable of Running on Edge Devices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r41k5r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Project", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1771017722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This post details my exploration for a &amp;quot;stable stack&amp;quot; for streaming deep RL (ObGD, SparseInit, LayerNorm, and online normalization) using 433,000 observations of real, non-stationary SSH attack traffic.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Learnings From Tests:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Computational Efficiency:&lt;/strong&gt; Using JAX&amp;#39;s AOT compilation pipeline and &lt;code&gt;cost_analysis()&lt;/code&gt;, the tests measure the per-update FLOP counts. An MLP with two hidden layers of 128 nodes each learner requires 271k FLOPs per update, capable of processing 477k observations/second maintaining significant headroom even on high-bandwidth links on low(er) powered edge devices. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Normalization on Non-Stationary Streams:&lt;/strong&gt; The experiments found that EMA (decay=0.99) significantly outperforms Welford\u2019s cumulative algorithm on adversarial traffic with sudden bursts. EMA\u2019s exponential forgetting allows for faster recovery from distribution shifts compared to cumulative statistics. Regardless of EMA or Welford what is evident that external normailzation of input data is pretty much required. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Gradient Coherence:&lt;/strong&gt; Global scalar bounding (ObGD) (Elsayed et al. 2024) was found to be critical for maintaining stability in single-sample streaming updates. Per-unit Adaptive Gradient Clipping (AGC) doesn&amp;#39;t work well for the tests I&amp;#39;m doing here. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Full Post and Empirical Analysis:&lt;/strong&gt;\n&lt;a href=\"https://blog.9600baud.net/streaming-deep-rl-honeypot.html\"&gt;Validating Streaming Deep RL on Attack Traffic&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is my early learnings on RL prediction as I work through the steps of the Alberta Plan for AI research. Feedback, suggestions for further tests and related literature would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wqE0ohoos7bGLeQAT3ouPj_2aRn-1wKsqpJSzuzY86A.png?auto=webp&amp;s=dd32f6ce0d034af09f8dabf7829f266dd81c1795", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/wqE0ohoos7bGLeQAT3ouPj_2aRn-1wKsqpJSzuzY86A.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6332400f4259b1db44b778f3ba5b81320c06615", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/wqE0ohoos7bGLeQAT3ouPj_2aRn-1wKsqpJSzuzY86A.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3aff50da8205571b4155f5ffb78fb373f55d73c", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/wqE0ohoos7bGLeQAT3ouPj_2aRn-1wKsqpJSzuzY86A.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c985ae62782afd27f18a72989556df61edacc128", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/wqE0ohoos7bGLeQAT3ouPj_2aRn-1wKsqpJSzuzY86A.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5d20db4e5d4959cf3314003c74c617c5047d644a", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/wqE0ohoos7bGLeQAT3ouPj_2aRn-1wKsqpJSzuzY86A.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=750a1b353193f874f93b3e03a136823722c46695", "width": 960, "height": 960}], "variants": {}, "id": "wqE0ohoos7bGLeQAT3ouPj_2aRn-1wKsqpJSzuzY86A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c6dea51c-19d3-11f0-81a2-deb9d8e21ccb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7d659a", "id": "1r41k5r", "is_robot_indexable": true, "report_reasons": null, "author": "debian_grey_beard", "discussion_type": null, "num_comments": 1, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r41k5r/d_benchmarking_deep_rl_stability_capable_of/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r41k5r/d_benchmarking_deep_rl_stability_capable_of/", "subreddit_subscribers": 3022491, "created_utc": 1771017722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "## Context\n\nI'm training a Spanish legal NER model (RoBERTa-based, 28 PII categories) using curriculum learning. For the real-world legal corpus (BOE/BORME gazette), I built a multi-annotator pipeline with 5 annotators:\n\n| Annotator | Type | Strengths |\n|-----------|------|-----------|\n| RoBERTa-v2 | Transformer (fine-tuned) | PERSON, ORG, LOC |\n| Flair | Transformer (off-the-shelf) | PERSON, ORG, LOC |\n| GLiNER | Zero-shot NER | DATE, ADDRESS, broad coverage |\n| Gazetteer | Dictionary lookup | LOC (cities, provinces) |\n| Cargos | Rule-based | ROLE (job titles) |\n\nConsensus rule: an entity is accepted if \u2265N annotators agree on span (IoU \u226580%) AND category.\n\n## The problem\n\nNot all annotators can detect all categories. DATE is only detectable by GLiNER + RoBERTa-v2. ADDRESS is similar. So I use **asymmetric thresholds**:\n\n| Category | Threshold | Rationale |\n|----------|-----------|-----------|\n| PERSON_NAME | \u22653 | 4 annotators capable |\n| ORGANIZATION | \u22653 | 3 annotators capable |\n| LOCATION | \u22653 | 4 annotators capable (best agreement) |\n| DATE | \u22652 | Only 2 annotators capable |\n| ADDRESS | \u22652 | Only 2 annotators capable |\n\n## Actual data (the cliff effect)\n\nI computed retention curves across all thresholds. Here's what the data shows:\n\n| Category | Total | \u22651 | \u22652 | \u22653 | \u22654 | =5 |\n|----------|------:|---:|---:|---:|---:|---:|\n| PERSON_NAME | 257k | 257k | 98k (38%) | 46k (18%) | 0 | 0 |\n| ORGANIZATION | 974k | 974k | 373k (38%) | 110k (11%) | 0 | 0 |\n| LOCATION | 475k | 475k | 194k (41%) | 104k (22%) | 40k (8%) | 0 |\n| DATE | 275k | 275k | 24k (8.8%) | **0** | 0 | 0 |\n| ADDRESS | 54k | 54k | 1.4k (2.6%) | **0** | 0 | 0 |\n\nKey observations:\n\n- **DATE and ADDRESS drop to exactly 0 at \u22653.** A uniform threshold would eliminate them entirely.\n- **LOCATION is the only category reaching \u22654** (gazetteer + flair + gliner + v2 all detect it).\n- **No entity in the entire corpus gets 5/5 agreement.** The annotators are too heterogeneous.\n- Even PERSON_NAME only retains 18% at \u22653.\n\n![Retention curves showing the cliff effect per category](docs/reports2/es/figures/consensus_threshold_analysis.png)\n\n## My concerns\n\n1. **\u22652 for DATE/ADDRESS essentially means \"both annotators agree\"**, which is weaker than a true multi-annotator consensus. Is this still meaningfully better than single-annotator?\n2. **Category-specific thresholds introduce a confound** \u2014 are we measuring annotation quality or annotator capability coverage?\n3. **Alternative approach:** Should I add more DATE/ADDRESS-capable annotators (e.g., regex date patterns, address parser) to enable a uniform \u22653 threshold instead?\n\n## Question\n\nFor those who've worked with multi-annotator NER pipelines: **is varying the consensus threshold per entity category a valid practice, or should I invest in adding specialized annotators to enable uniform thresholds?**\n\nAny pointers to papers studying this would be appreciated. The closest I've found is Rodrigues &amp; Pereira (2018) on learning from crowds, but it doesn't address category-asymmetric agreement.\n", "author_fullname": "t2_21hskkec7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Asymmetric consensus thresholds for multi-annotator NER \u2014 valid approach or methodological smell?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "name": "t3_1r4gjme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://preview.redd.it/aukkp6r9kfjg1.png?width=140&amp;height=56&amp;auto=webp&amp;s=eae33a942346954fe71859c63edebcc16ecc25d1", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1771061909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Context&lt;/h2&gt;\n\n&lt;p&gt;I&amp;#39;m training a Spanish legal NER model (RoBERTa-based, 28 PII categories) using curriculum learning. For the real-world legal corpus (BOE/BORME gazette), I built a multi-annotator pipeline with 5 annotators:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Annotator&lt;/th&gt;\n&lt;th&gt;Type&lt;/th&gt;\n&lt;th&gt;Strengths&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;RoBERTa-v2&lt;/td&gt;\n&lt;td&gt;Transformer (fine-tuned)&lt;/td&gt;\n&lt;td&gt;PERSON, ORG, LOC&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Flair&lt;/td&gt;\n&lt;td&gt;Transformer (off-the-shelf)&lt;/td&gt;\n&lt;td&gt;PERSON, ORG, LOC&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;GLiNER&lt;/td&gt;\n&lt;td&gt;Zero-shot NER&lt;/td&gt;\n&lt;td&gt;DATE, ADDRESS, broad coverage&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Gazetteer&lt;/td&gt;\n&lt;td&gt;Dictionary lookup&lt;/td&gt;\n&lt;td&gt;LOC (cities, provinces)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Cargos&lt;/td&gt;\n&lt;td&gt;Rule-based&lt;/td&gt;\n&lt;td&gt;ROLE (job titles)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Consensus rule: an entity is accepted if \u2265N annotators agree on span (IoU \u226580%) AND category.&lt;/p&gt;\n\n&lt;h2&gt;The problem&lt;/h2&gt;\n\n&lt;p&gt;Not all annotators can detect all categories. DATE is only detectable by GLiNER + RoBERTa-v2. ADDRESS is similar. So I use &lt;strong&gt;asymmetric thresholds&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Category&lt;/th&gt;\n&lt;th&gt;Threshold&lt;/th&gt;\n&lt;th&gt;Rationale&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;PERSON_NAME&lt;/td&gt;\n&lt;td&gt;\u22653&lt;/td&gt;\n&lt;td&gt;4 annotators capable&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ORGANIZATION&lt;/td&gt;\n&lt;td&gt;\u22653&lt;/td&gt;\n&lt;td&gt;3 annotators capable&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LOCATION&lt;/td&gt;\n&lt;td&gt;\u22653&lt;/td&gt;\n&lt;td&gt;4 annotators capable (best agreement)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;DATE&lt;/td&gt;\n&lt;td&gt;\u22652&lt;/td&gt;\n&lt;td&gt;Only 2 annotators capable&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ADDRESS&lt;/td&gt;\n&lt;td&gt;\u22652&lt;/td&gt;\n&lt;td&gt;Only 2 annotators capable&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;h2&gt;Actual data (the cliff effect)&lt;/h2&gt;\n\n&lt;p&gt;I computed retention curves across all thresholds. Here&amp;#39;s what the data shows:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Category&lt;/th&gt;\n&lt;th align=\"right\"&gt;Total&lt;/th&gt;\n&lt;th align=\"right\"&gt;\u22651&lt;/th&gt;\n&lt;th align=\"right\"&gt;\u22652&lt;/th&gt;\n&lt;th align=\"right\"&gt;\u22653&lt;/th&gt;\n&lt;th align=\"right\"&gt;\u22654&lt;/th&gt;\n&lt;th align=\"right\"&gt;=5&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;PERSON_NAME&lt;/td&gt;\n&lt;td align=\"right\"&gt;257k&lt;/td&gt;\n&lt;td align=\"right\"&gt;257k&lt;/td&gt;\n&lt;td align=\"right\"&gt;98k (38%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;46k (18%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ORGANIZATION&lt;/td&gt;\n&lt;td align=\"right\"&gt;974k&lt;/td&gt;\n&lt;td align=\"right\"&gt;974k&lt;/td&gt;\n&lt;td align=\"right\"&gt;373k (38%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;110k (11%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;LOCATION&lt;/td&gt;\n&lt;td align=\"right\"&gt;475k&lt;/td&gt;\n&lt;td align=\"right\"&gt;475k&lt;/td&gt;\n&lt;td align=\"right\"&gt;194k (41%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;104k (22%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;40k (8%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;DATE&lt;/td&gt;\n&lt;td align=\"right\"&gt;275k&lt;/td&gt;\n&lt;td align=\"right\"&gt;275k&lt;/td&gt;\n&lt;td align=\"right\"&gt;24k (8.8%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ADDRESS&lt;/td&gt;\n&lt;td align=\"right\"&gt;54k&lt;/td&gt;\n&lt;td align=\"right\"&gt;54k&lt;/td&gt;\n&lt;td align=\"right\"&gt;1.4k (2.6%)&lt;/td&gt;\n&lt;td align=\"right\"&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Key observations:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;DATE and ADDRESS drop to exactly 0 at \u22653.&lt;/strong&gt; A uniform threshold would eliminate them entirely.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;LOCATION is the only category reaching \u22654&lt;/strong&gt; (gazetteer + flair + gliner + v2 all detect it).&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;No entity in the entire corpus gets 5/5 agreement.&lt;/strong&gt; The annotators are too heterogeneous.&lt;/li&gt;\n&lt;li&gt;Even PERSON_NAME only retains 18% at \u22653.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;![Retention curves showing the cliff effect per category](docs/reports2/es/figures/consensus_threshold_analysis.png)&lt;/p&gt;\n\n&lt;h2&gt;My concerns&lt;/h2&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;\u22652 for DATE/ADDRESS essentially means &amp;quot;both annotators agree&amp;quot;&lt;/strong&gt;, which is weaker than a true multi-annotator consensus. Is this still meaningfully better than single-annotator?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Category-specific thresholds introduce a confound&lt;/strong&gt; \u2014 are we measuring annotation quality or annotator capability coverage?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Alternative approach:&lt;/strong&gt; Should I add more DATE/ADDRESS-capable annotators (e.g., regex date patterns, address parser) to enable a uniform \u22653 threshold instead?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;Question&lt;/h2&gt;\n\n&lt;p&gt;For those who&amp;#39;ve worked with multi-annotator NER pipelines: &lt;strong&gt;is varying the consensus threshold per entity category a valid practice, or should I invest in adding specialized annotators to enable uniform thresholds?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Any pointers to papers studying this would be appreciated. The closest I&amp;#39;ve found is Rodrigues &amp;amp; Pereira (2018) on learning from crowds, but it doesn&amp;#39;t address category-asymmetric agreement.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/aukkp6r9kfjg1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/aukkp6r9kfjg1.png?auto=webp&amp;s=adabddced82299d44151529c905e66a759eb5533", "width": 2682, "height": 1074}, "resolutions": [{"url": "https://preview.redd.it/aukkp6r9kfjg1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f9657f6a9b940b1b2dd8152add686445f7ed013", "width": 108, "height": 43}, {"url": "https://preview.redd.it/aukkp6r9kfjg1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5099aad60596f856dbe6ab200c993c0600194f68", "width": 216, "height": 86}, {"url": "https://preview.redd.it/aukkp6r9kfjg1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e1a279dcfbaaf335e4e235a3e2f3f8f049ee243c", "width": 320, "height": 128}, {"url": "https://preview.redd.it/aukkp6r9kfjg1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=27b0d9dc5765dce73efcf5fc86defc958bdc04b9", "width": 640, "height": 256}, {"url": "https://preview.redd.it/aukkp6r9kfjg1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d84f87cd2d3c0bb03628cdc57a17d9c74dc1313", "width": 960, "height": 384}, {"url": "https://preview.redd.it/aukkp6r9kfjg1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c69c9b5c3c11d8dffe5f1cea84c24cf53c85918d", "width": 1080, "height": 432}], "variants": {}, "id": "aukkp6r9kfjg1"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r4gjme", "is_robot_indexable": true, "report_reasons": null, "author": "AlexAlves87", "discussion_type": null, "num_comments": 4, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r4gjme/d_asymmetric_consensus_thresholds_for/", "stickied": false, "url": "https://i.redd.it/aukkp6r9kfjg1.png", "subreddit_subscribers": 3022491, "created_utc": 1771061909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "So I am using a R(2+1)D with kinetics 400 weights to train a classifier on two sets of videos. The problem is that one of the two classes has all videos of the same resolution and fps, forcing the model to learn those features instead of actually learning pixel changes over time, like R(2+1)D is supposed to.  \nOn the other class, there is diversity and equivalent representation across resolutions, which makes the model totally unusable without any preprocessing.\n\nI have tried preprocessing by re encoding all the videos to random resolutions but the model still finds shortcuts.\n\nNeed suggestions and help with this, any help is greatly appreciated, thanks!", "author_fullname": "t2_5w4ugtm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] How do your control video resolution and fps for a R(2+1)D model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r3tn73", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1770999837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am using a R(2+1)D with kinetics 400 weights to train a classifier on two sets of videos. The problem is that one of the two classes has all videos of the same resolution and fps, forcing the model to learn those features instead of actually learning pixel changes over time, like R(2+1)D is supposed to.&lt;br/&gt;\nOn the other class, there is diversity and equivalent representation across resolutions, which makes the model totally unusable without any preprocessing.&lt;/p&gt;\n\n&lt;p&gt;I have tried preprocessing by re encoding all the videos to random resolutions but the model still finds shortcuts.&lt;/p&gt;\n\n&lt;p&gt;Need suggestions and help with this, any help is greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r3tn73", "is_robot_indexable": true, "report_reasons": null, "author": "BatBoy117", "discussion_type": null, "num_comments": 1, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r3tn73/d_how_do_your_control_video_resolution_and_fps/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r3tn73/d_how_do_your_control_video_resolution_and_fps/", "subreddit_subscribers": 3022491, "created_utc": 1770999837.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}
