{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "We've been doing on-device accuracy testing across multiple Snapdragon SoCs and the results have been eye-opening.\n\nSame model. Same quantization. Same ONNX export. Deployed to 5 different chipsets:\n\n|Device|Accuracy|\n|:-|:-|\n|Snapdragon 8 Gen 3|91.8%|\n|Snapdragon 8 Gen 2|89.1%|\n|Snapdragon 7s Gen 2|84.3%|\n|Snapdragon 6 Gen 1|79.6%|\n|Snapdragon 4 Gen 2|71.2%|\n\nCloud benchmark reported 94.2%.\n\nThe spread comes down to three things we've observed:\n\n1. **NPU precision handling**\u00a0\u2014 INT8 rounding behavior differs across Hexagon generations. Not all INT8 is created equal.\n2. **Operator fusion differences**\u00a0\u2014 the QNN runtime optimizes the graph differently per SoC, sometimes trading accuracy for throughput.\n3. **Memory-constrained fallback**\u00a0\u2014 on lower-tier chips, certain ops fall back from NPU to CPU, changing the execution path entirely.\n\nNone of this shows up in cloud-based benchmarks. You only see it when you run on real hardware.\n\nCurious if others are seeing similar drift across chipsets \u2014 or if anyone has a good strategy for catching this before shipping. Most CI pipelines we've seen only test on cloud GPUs and call it a day.", "author_fullname": "t2_24mcgva8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] We tested the same INT8 model on 5 Snapdragon chipsets. Accuracy ranged from 93% to 71%. Same weights, same ONNX file.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r7ruu8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 105, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 105, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771384857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve been doing on-device accuracy testing across multiple Snapdragon SoCs and the results have been eye-opening.&lt;/p&gt;\n\n&lt;p&gt;Same model. Same quantization. Same ONNX export. Deployed to 5 different chipsets:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Device&lt;/th&gt;\n&lt;th align=\"left\"&gt;Accuracy&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Snapdragon 8 Gen 3&lt;/td&gt;\n&lt;td align=\"left\"&gt;91.8%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Snapdragon 8 Gen 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;89.1%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Snapdragon 7s Gen 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;84.3%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Snapdragon 6 Gen 1&lt;/td&gt;\n&lt;td align=\"left\"&gt;79.6%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Snapdragon 4 Gen 2&lt;/td&gt;\n&lt;td align=\"left\"&gt;71.2%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Cloud benchmark reported 94.2%.&lt;/p&gt;\n\n&lt;p&gt;The spread comes down to three things we&amp;#39;ve observed:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;NPU precision handling&lt;/strong&gt;\u00a0\u2014 INT8 rounding behavior differs across Hexagon generations. Not all INT8 is created equal.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Operator fusion differences&lt;/strong&gt;\u00a0\u2014 the QNN runtime optimizes the graph differently per SoC, sometimes trading accuracy for throughput.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Memory-constrained fallback&lt;/strong&gt;\u00a0\u2014 on lower-tier chips, certain ops fall back from NPU to CPU, changing the execution path entirely.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;None of this shows up in cloud-based benchmarks. You only see it when you run on real hardware.&lt;/p&gt;\n\n&lt;p&gt;Curious if others are seeing similar drift across chipsets \u2014 or if anyone has a good strategy for catching this before shipping. Most CI pipelines we&amp;#39;ve seen only test on cloud GPUs and call it a day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r7ruu8", "is_robot_indexable": true, "report_reasons": null, "author": "NoAdministration6906", "discussion_type": null, "num_comments": 17, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r7ruu8/d_we_tested_the_same_int8_model_on_5_snapdragon/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r7ruu8/d_we_tested_the_same_int8_model_on_5_snapdragon/", "subreddit_subscribers": 3023520, "created_utc": 1771384857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I\u2019m a researcher currently trying to replicate published results, and I\u2019m running into reproducibility issues more often than I expected. I\u2019m trying to calibrate whether this is \u201cnormal\u201d or a sign I\u2019m missing something fundamental. I have been careful about all the parameter as stated in papers. Despite that, I\u2019m still seeing noticeable deviations from reported numbers\u2014sometimes small but consistent gaps, sometimes larger swings across runs.\n\nFor example, I was trying to replicate *\u201cMachine Theory of Mind\u201d* (ICML 2018), and I keep hitting discrepancies that I can\u2019t fully understand. My labmates also tried to replicate the paper they were not able to replicate results even closely.\n\nWhat are the papers **you tried but couldn\u2019t replicate** no matter what you did?", "author_fullname": "t2_1fl8ol13rb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] How often do you run into reproducibility issues when trying to replicate papers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r7jbw6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771363624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a researcher currently trying to replicate published results, and I\u2019m running into reproducibility issues more often than I expected. I\u2019m trying to calibrate whether this is \u201cnormal\u201d or a sign I\u2019m missing something fundamental. I have been careful about all the parameter as stated in papers. Despite that, I\u2019m still seeing noticeable deviations from reported numbers\u2014sometimes small but consistent gaps, sometimes larger swings across runs.&lt;/p&gt;\n\n&lt;p&gt;For example, I was trying to replicate &lt;em&gt;\u201cMachine Theory of Mind\u201d&lt;/em&gt; (ICML 2018), and I keep hitting discrepancies that I can\u2019t fully understand. My labmates also tried to replicate the paper they were not able to replicate results even closely.&lt;/p&gt;\n\n&lt;p&gt;What are the papers &lt;strong&gt;you tried but couldn\u2019t replicate&lt;/strong&gt; no matter what you did?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r7jbw6", "is_robot_indexable": true, "report_reasons": null, "author": "ArtVoyager77", "discussion_type": null, "num_comments": 55, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r7jbw6/d_how_often_do_you_run_into_reproducibility/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r7jbw6/d_how_often_do_you_run_into_reproducibility/", "subreddit_subscribers": 3023520, "created_utc": 1771363624.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "Built a text-only baseline: trained a Random Forest on \\~90,000 resolved Polymarket questions (YES/NO).\n\nFeatures: TF-IDF (word ngrams, optional char ngrams) + a few cheap flags (date/number/%/currency, election/macro/M&amp;A keywords).\n\nResult: \\~80% accuracy on 15.000 held-out data/questions (plus decent Brier/logloss after calibration).\n\nLiked the idea played a bit more with differnt data sets and did some cross validation with Kalshi data and saw similar results. Now having this running with paper money and competing with stat of the art LLM's as benchmakrs. Lets see.\n\nCurrently looks like just from the formulation of the question at polymarket (in the given data set) we can predict with 80% accurarcy if it's a YES or NO.\n\nHappy to share further insights or get feedback if someone tried smth similar?\n\nSource of the paper trading. Model is called \"mystery:rf-v1\":\u00a0[Agent Leaderboard | Oracle Markets](https://oraclemarkets.io/leaderboard). Did not publish accuary so far there.", "author_fullname": "t2_d316uyuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] Random Forest on ~100k Polymarket questions \u2014 80% accuracy (text-only)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r7jyi9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Project", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1771376384.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1771365005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Built a text-only baseline: trained a Random Forest on ~90,000 resolved Polymarket questions (YES/NO).&lt;/p&gt;\n\n&lt;p&gt;Features: TF-IDF (word ngrams, optional char ngrams) + a few cheap flags (date/number/%/currency, election/macro/M&amp;amp;A keywords).&lt;/p&gt;\n\n&lt;p&gt;Result: ~80% accuracy on 15.000 held-out data/questions (plus decent Brier/logloss after calibration).&lt;/p&gt;\n\n&lt;p&gt;Liked the idea played a bit more with differnt data sets and did some cross validation with Kalshi data and saw similar results. Now having this running with paper money and competing with stat of the art LLM&amp;#39;s as benchmakrs. Lets see.&lt;/p&gt;\n\n&lt;p&gt;Currently looks like just from the formulation of the question at polymarket (in the given data set) we can predict with 80% accurarcy if it&amp;#39;s a YES or NO.&lt;/p&gt;\n\n&lt;p&gt;Happy to share further insights or get feedback if someone tried smth similar?&lt;/p&gt;\n\n&lt;p&gt;Source of the paper trading. Model is called &amp;quot;mystery:rf-v1&amp;quot;:\u00a0&lt;a href=\"https://oraclemarkets.io/leaderboard\"&gt;Agent Leaderboard | Oracle Markets&lt;/a&gt;. Did not publish accuary so far there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo.png?auto=webp&amp;s=6c1a390aa085574615ca68ed3a738d116b435744", "width": 1344, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f58bf5a4f18dfa5feccc589c7aab59977d839ab8", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=76865268f4882461c410343fb6dd1e700670a9ab", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5cbbd4ea2fa310eb36afd73ae3a302ee85129727", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5956cd1abe0c1a90266089736b0f635329738aa", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d5b85b0422551e8f90ecdd2ff1c9ec3d67edf02", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=edf6f0cf99afbdb971dbbb4cbcdb4372c4fbdd3a", "width": 1080, "height": 617}], "variants": {}, "id": "ZWylNOxzsWqrEt0WYWkmwZh3UyRvmlCO46xSDyriyQo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c6dea51c-19d3-11f0-81a2-deb9d8e21ccb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7d659a", "id": "1r7jyi9", "is_robot_indexable": true, "report_reasons": null, "author": "No_Syrup_4068", "discussion_type": null, "num_comments": 22, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r7jyi9/p_random_forest_on_100k_polymarket_questions_80/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r7jyi9/p_random_forest_on_100k_polymarket_questions_80/", "subreddit_subscribers": 3023520, "created_utc": 1771365005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "About me: Finishing a PhD in Math (specializing in geometry and gauge theory) with a growing interest in the theoretical foundations and applications of ML. I had some questions for Math PhDs who transitioned to doing ML research.\n\n1. Which textbooks or seminal papers offer the most \"mathematically satisfying\" treatment of ML? Which resources best bridge the gap between abstract theory and the heuristics of modern ML research?\n2. How did your specific mathematical background influence your perspective on the field? Did your specific doctoral sub-field already have established links to ML?\n\nField Specific\n\n1. Aside from the standard E(n)-equivariant networks and GDL frameworks, what are the most non-trivial applications of geometry in ML today?\n2.  Is the use of stochastic calculus on manifolds in ML deep and structural (e.g., in diffusion models or optimization), or is it currently applied in a more rudimentary fashion?\n3.  Between the different degrees of rigidity in geometry (topological, differential, algebraic, and symplectic geometry etc.) which sub-field currently hosts the most active and rigorous intersections with ML research?\n\n", "author_fullname": "t2_ralh9n80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Seeking perspectives from PhDs in math regarding ML research.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r7qbsk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771380802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About me: Finishing a PhD in Math (specializing in geometry and gauge theory) with a growing interest in the theoretical foundations and applications of ML. I had some questions for Math PhDs who transitioned to doing ML research.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which textbooks or seminal papers offer the most &amp;quot;mathematically satisfying&amp;quot; treatment of ML? Which resources best bridge the gap between abstract theory and the heuristics of modern ML research?&lt;/li&gt;\n&lt;li&gt;How did your specific mathematical background influence your perspective on the field? Did your specific doctoral sub-field already have established links to ML?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Field Specific&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Aside from the standard E(n)-equivariant networks and GDL frameworks, what are the most non-trivial applications of geometry in ML today?&lt;/li&gt;\n&lt;li&gt; Is the use of stochastic calculus on manifolds in ML deep and structural (e.g., in diffusion models or optimization), or is it currently applied in a more rudimentary fashion?&lt;/li&gt;\n&lt;li&gt; Between the different degrees of rigidity in geometry (topological, differential, algebraic, and symplectic geometry etc.) which sub-field currently hosts the most active and rigorous intersections with ML research?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r7qbsk", "is_robot_indexable": true, "report_reasons": null, "author": "smallstep_", "discussion_type": null, "num_comments": 4, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r7qbsk/d_seeking_perspectives_from_phds_in_math/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r7qbsk/d_seeking_perspectives_from_phds_in_math/", "subreddit_subscribers": 3023520, "created_utc": 1771380802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I'm a PhD student researching ML reproducibility, and one thing that keeps surprising me is how many teams have no systematic way to track which data went into which model.\n\nThe typical workflow I see (and have been guilty of myself):\n\n1. Load some CSVs\n2. Clean and transform them through a chain of pandas operations\n3. Train a model\n4. Three months later, someone asks \"what data was this model trained on?\" and you're digging through old notebooks trying to reconstruct the answer\n\nThe academic literature on reproducibility keeps pointing to data provenance as a core problem, papers can't be replicated because the exact data pipeline isn't documented. And now with the EU AI Act requiring data documentation for high-risk AI systems (Article 10), this is becoming a regulatory requirement too, not just good practice.\n\nI've been working on an approach to this as part of my PhD research: function hooking to automatically intercept pandas/numpy I/O operations and record the full lineage graph without any manual logging. The idea is you add one import line and your existing code is tracked \u2014 no MLflow experiment setup, no decorator syntax, no config files.\n\nI built it into an open-source tool called [AutoLineage](https://github.com/kishanraj41/autolineage) (`pip install autolineage`). It's early, just hit v0.1.0, but it tracks reads/writes across pandas, numpy, pickle, and joblib, generates visual lineage graphs, and can produce EU AI Act compliance reports.\n\nI'm curious about a few things from this community:\n\n* **How do you currently handle data lineage?** MLflow? DVC? Manual documentation? Nothing?\n* **What's the biggest pain point?** Is it the initial tracking, or more the \"6 months later someone needs to audit this\" problem?\n* **Would zero-config automatic tracking actually be useful to you**, or is the manual approach fine because you need more control over what gets logged?\n\nGenuinely looking for feedback on whether this is a real problem worth solving or if existing tools handle it well enough. The academic framing suggests it's a gap, but I want to hear from practitioners.\n\nGitHub: [https://github.com/kishanraj41/autolineage](https://github.com/kishanraj41/autolineage) PyPI: [https://pypi.org/project/autolineage/](https://pypi.org/project/autolineage/)", "author_fullname": "t2_akkorj5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] How do you track data lineage in your ML pipelines? Most teams I've talked to do it manually (or not at all)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "three", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r7usv0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Research", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1771393607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a PhD student researching ML reproducibility, and one thing that keeps surprising me is how many teams have no systematic way to track which data went into which model.&lt;/p&gt;\n\n&lt;p&gt;The typical workflow I see (and have been guilty of myself):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Load some CSVs&lt;/li&gt;\n&lt;li&gt;Clean and transform them through a chain of pandas operations&lt;/li&gt;\n&lt;li&gt;Train a model&lt;/li&gt;\n&lt;li&gt;Three months later, someone asks &amp;quot;what data was this model trained on?&amp;quot; and you&amp;#39;re digging through old notebooks trying to reconstruct the answer&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The academic literature on reproducibility keeps pointing to data provenance as a core problem, papers can&amp;#39;t be replicated because the exact data pipeline isn&amp;#39;t documented. And now with the EU AI Act requiring data documentation for high-risk AI systems (Article 10), this is becoming a regulatory requirement too, not just good practice.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on an approach to this as part of my PhD research: function hooking to automatically intercept pandas/numpy I/O operations and record the full lineage graph without any manual logging. The idea is you add one import line and your existing code is tracked \u2014 no MLflow experiment setup, no decorator syntax, no config files.&lt;/p&gt;\n\n&lt;p&gt;I built it into an open-source tool called &lt;a href=\"https://github.com/kishanraj41/autolineage\"&gt;AutoLineage&lt;/a&gt; (&lt;code&gt;pip install autolineage&lt;/code&gt;). It&amp;#39;s early, just hit v0.1.0, but it tracks reads/writes across pandas, numpy, pickle, and joblib, generates visual lineage graphs, and can produce EU AI Act compliance reports.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious about a few things from this community:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;How do you currently handle data lineage?&lt;/strong&gt; MLflow? DVC? Manual documentation? Nothing?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;What&amp;#39;s the biggest pain point?&lt;/strong&gt; Is it the initial tracking, or more the &amp;quot;6 months later someone needs to audit this&amp;quot; problem?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Would zero-config automatic tracking actually be useful to you&lt;/strong&gt;, or is the manual approach fine because you need more control over what gets logged?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Genuinely looking for feedback on whether this is a real problem worth solving or if existing tools handle it well enough. The academic framing suggests it&amp;#39;s a gap, but I want to hear from practitioners.&lt;/p&gt;\n\n&lt;p&gt;GitHub: &lt;a href=\"https://github.com/kishanraj41/autolineage\"&gt;https://github.com/kishanraj41/autolineage&lt;/a&gt; PyPI: &lt;a href=\"https://pypi.org/project/autolineage/\"&gt;https://pypi.org/project/autolineage/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA.png?auto=webp&amp;s=1e1b7e59e8e16af89aec0f0c52cd37dbcc94df4e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a1f1b3ef8c21acfa2739aad8483d9f45eea5a3d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6c4a7755efaa0f9a8789a4521441030e2d2c3c94", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=918fe1742494169ae90f6fd3379c0409264bf727", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1f91fa3c3b4c6dbdfb703fac96bf8a7661428a5", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d181b6d931499fb3ac54be9bce8ed967ab11e0f7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c90374d3c6e96863e6175f93c4360fff0496dbbc", "width": 1080, "height": 540}], "variants": {}, "id": "juCzItM7vFT6nTvDcr65ACUPwAmY_aDbM3-rL8I7egA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bb90e510-4e82-11e6-8635-0ee522e2349b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#f1f10e", "id": "1r7usv0", "is_robot_indexable": true, "report_reasons": null, "author": "Achilles_411", "discussion_type": null, "num_comments": 6, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r7usv0/d_how_do_you_track_data_lineage_in_your_ml/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r7usv0/d_how_do_you_track_data_lineage_in_your_ml/", "subreddit_subscribers": 3023520, "created_utc": 1771393607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I've been spending time with Apache ADBC (Arrow Database Connectivity) and DuckLake (lakehouse architecture using DuckDB) to read columnar data. I realized XGBoost took Arrow tables as a data input and I was able to pass arrow tables with little memory overhead to train. I also wanted to try to not use scikit-learn so I built a train and test split function with PyArrow instead. ADBC also allows you to stream larger than memory data and train a model in the right circumstances.", "author_fullname": "t2_cd8k7vs5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] I trained an XGBoost model with DuckLake and ADBC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r7gu62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Project", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771358184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been spending time with Apache ADBC (Arrow Database Connectivity) and DuckLake (lakehouse architecture using DuckDB) to read columnar data. I realized XGBoost took Arrow tables as a data input and I was able to pass arrow tables with little memory overhead to train. I also wanted to try to not use scikit-learn so I built a train and test split function with PyArrow instead. ADBC also allows you to stream larger than memory data and train a model in the right circumstances.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c6dea51c-19d3-11f0-81a2-deb9d8e21ccb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7d659a", "id": "1r7gu62", "is_robot_indexable": true, "report_reasons": null, "author": "empty_cities", "discussion_type": null, "num_comments": 0, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r7gu62/p_i_trained_an_xgboost_model_with_ducklake_and/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r7gu62/p_i_trained_an_xgboost_model_with_ducklake_and/", "subreddit_subscribers": 3023520, "created_utc": 1771358184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I cooked up a new fast geometric regression algorithm and show that it is a suitable replacement for MLPs. Check out the paper:\n\n[https://doi.org/10.5281/zenodo.18673034](https://doi.org/10.5281/zenodo.18673034)\n\nWhats inside? New research indicates that many representations within LLMs create geometric structures to model language. ( [https://arxiv.org/abs/2601.04480](https://arxiv.org/abs/2601.04480) , [https://arxiv.org/abs/2510.26745](https://arxiv.org/abs/2510.26745) ) MLPs store geometric representations in highly inefficient ways, so I say it is time to look for new methods that encode regressions directly in geometry. Enter K-Splanifolds, a fast high dimensional spline manifold that encodes geometric representations natively and can create similar representations as MLPs with 1/10th the bytes. The paper above includes a number of experiments that show it is a promising technique that can be used as part of a larger system to completely replace the MLP decoders in LLMs. I am looking for feedback from interested researchers so please find my contacts in the paper or leave a comment.", "author_fullname": "t2_lrannsv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[R] K-Splanifolds: Advancing General Purpose Regression with Linear-Time Parametric Spline Manifolds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "three", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r7v6dh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Research", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771394867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I cooked up a new fast geometric regression algorithm and show that it is a suitable replacement for MLPs. Check out the paper:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://doi.org/10.5281/zenodo.18673034\"&gt;https://doi.org/10.5281/zenodo.18673034&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Whats inside? New research indicates that many representations within LLMs create geometric structures to model language. ( &lt;a href=\"https://arxiv.org/abs/2601.04480\"&gt;https://arxiv.org/abs/2601.04480&lt;/a&gt; , &lt;a href=\"https://arxiv.org/abs/2510.26745\"&gt;https://arxiv.org/abs/2510.26745&lt;/a&gt; ) MLPs store geometric representations in highly inefficient ways, so I say it is time to look for new methods that encode regressions directly in geometry. Enter K-Splanifolds, a fast high dimensional spline manifold that encodes geometric representations natively and can create similar representations as MLPs with 1/10th the bytes. The paper above includes a number of experiments that show it is a promising technique that can be used as part of a larger system to completely replace the MLP decoders in LLMs. I am looking for feedback from interested researchers so please find my contacts in the paper or leave a comment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bb90e510-4e82-11e6-8635-0ee522e2349b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#f1f10e", "id": "1r7v6dh", "is_robot_indexable": true, "report_reasons": null, "author": "1ncehost", "discussion_type": null, "num_comments": 5, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r7v6dh/r_ksplanifolds_advancing_general_purpose/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r7v6dh/r_ksplanifolds_advancing_general_purpose/", "subreddit_subscribers": 3023520, "created_utc": 1771394867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "I'm working on a research project where I've gotten to the point of confirmation and I'm working on the proof. The POC works and the results give extremely strong evidence supporting the proposed method across various datasets.\n\nHere's the heart of the problem: I'm not in academia, I've never attempted publication, and I have limited credentials. I'm in the public sector with close relationships with certain academic organizations and national labs, as well as a host of experienced folks in the operational workspace. The research is self-driven and self-motivated but is built off of years of personal experience and a literal ton of white papers, so I'm aware of the SOTA and other similar approaches (which will be included in the paper).\n\nI'd like to reach out to some folks in various capacities, maybe even reach out to the local university, to ask for guidance, recommendations, and review. I'm absolutely open to bringing in a partner for co-authorship as long as they contribute or provide mentorship. I just have zero sense as to the risk of doing so. I don't feel like theft is a common problem but theft is a spectrum--it could happen at any point with any level of granularity. I understand that it might sound like I'm conflating IP/copyright/patent theft but I'm not. I want other people to use the proposed method, to add on to it, to enhance it, to reference it in other work, or to just use it operationally, but to do so _after_ it's been published or made available.\n\nIf anyone has any advice on this, I'd love to hear it. ", "author_fullname": "t2_131bi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Should unpublished research material be kept close and guarded, and how often does academic or IP theft occur during research?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1r778tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1771337990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a research project where I&amp;#39;ve gotten to the point of confirmation and I&amp;#39;m working on the proof. The POC works and the results give extremely strong evidence supporting the proposed method across various datasets.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the heart of the problem: I&amp;#39;m not in academia, I&amp;#39;ve never attempted publication, and I have limited credentials. I&amp;#39;m in the public sector with close relationships with certain academic organizations and national labs, as well as a host of experienced folks in the operational workspace. The research is self-driven and self-motivated but is built off of years of personal experience and a literal ton of white papers, so I&amp;#39;m aware of the SOTA and other similar approaches (which will be included in the paper).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to reach out to some folks in various capacities, maybe even reach out to the local university, to ask for guidance, recommendations, and review. I&amp;#39;m absolutely open to bringing in a partner for co-authorship as long as they contribute or provide mentorship. I just have zero sense as to the risk of doing so. I don&amp;#39;t feel like theft is a common problem but theft is a spectrum--it could happen at any point with any level of granularity. I understand that it might sound like I&amp;#39;m conflating IP/copyright/patent theft but I&amp;#39;m not. I want other people to use the proposed method, to add on to it, to enhance it, to reference it in other work, or to just use it operationally, but to do so &lt;em&gt;after&lt;/em&gt; it&amp;#39;s been published or made available.&lt;/p&gt;\n\n&lt;p&gt;If anyone has any advice on this, I&amp;#39;d love to hear it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "15995904-19d4-11f0-b8c9-0eed6ea89bc1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#26c4d9", "id": "1r778tn", "is_robot_indexable": true, "report_reasons": null, "author": "WadeEffingWilson", "discussion_type": null, "num_comments": 11, "send_replies": true, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/1r778tn/d_should_unpublished_research_material_be_kept/", "stickied": false, "url": "https://www.reddit.com/r/MachineLearning/comments/1r778tn/d_should_unpublished_research_material_be_kept/", "subreddit_subscribers": 3023520, "created_utc": 1771337990.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}
