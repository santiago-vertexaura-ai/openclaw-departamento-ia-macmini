{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"surprisetalk"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"<em>Anthropic</em> and the Government of Rwanda sign MOU for AI in health and education"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.<em>anthropic</em>.com/news/<em>anthropic</em>-rwanda-mou"}},"_tags":["story","author_surprisetalk","story_47046640"],"author":"surprisetalk","created_at":"2026-02-17T12:10:16Z","created_at_i":1771330216,"num_comments":0,"objectID":"47046640","points":2,"story_id":47046640,"title":"Anthropic and the Government of Rwanda sign MOU for AI in health and education","updated_at":"2026-02-17T12:48:48Z","url":"https://www.anthropic.com/news/anthropic-rwanda-mou"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"everlier"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hi<p>Agentic coding is rapidly changing our ways of developing software. Not everyone can afford a subscription, though, but they shouldn't be excluded from the process of learning these new tools.<p>Just wanted to share a few tips on running near-frontier agentic coding setup almost for free.<p>1. APIs. Most of the agentic coding tools use two types of APIs - OpenAI or <em>Anthropic</em> compatible. OpenAI is must more common, but <em>Anthropic</em> is associated with Claude Code ecosystem. There are also OSS adapters to convert between the two as needed. Essentially, you need to find providers that serve inference for free.<p>1. OpenRouter. They always have a few models that are completely free at the expense of storing and using everything you send to them. There are frequent promotional periods after new model releases. You need to top up your account by ~$10, though, to avoid rate limits as they are applied based on your balance. After that, ensure to use Model IDs with `:free` postfix and your balance will not be consumed, you can use those indefinitely.<p>2. OpenCode. This is a great agentic harness (albeit its heavily tuned for larger models), its parent company also provides inference APIs. Due to the popularity, many LLM providers offer free tiers of the models there. Same caveat applies - you data will be stored and used.<p>3. Local inference. If you happened to have a ~6-8GB VRAM and ~32GB RAM - then you should be able to run staple ~30B-sized MoE models. GLM-4.7-Flash is currently the best one for using inside a harness, it's even capable enough to drive simple tasks in OpenCode, but I recommend simpler harnesses for better results.<p>4. What to expect. Most of these offerings come with a compromise in terms of data collection and/or inference quality. For example, OpenCode's free Kimi 2.5 is clearly different from the paid one from official provider. In general - do not trust any claims that compare smaller open weight models with the cloud offering, they are not there yet. However you can get really far and models like Kimi 2.5 are still very capable.<p>Thanks!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Tell HN: Tips for (mostly) free agentic coding setup"}},"_tags":["story","author_everlier","story_47046601","ask_hn"],"author":"everlier","children":[47046611],"created_at":"2026-02-17T12:05:12Z","created_at_i":1771329912,"num_comments":1,"objectID":"47046601","points":1,"story_id":47046601,"story_text":"Hi<p>Agentic coding is rapidly changing our ways of developing software. Not everyone can afford a subscription, though, but they shouldn&#x27;t be excluded from the process of learning these new tools.<p>Just wanted to share a few tips on running near-frontier agentic coding setup almost for free.<p>1. APIs. Most of the agentic coding tools use two types of APIs - OpenAI or Anthropic compatible. OpenAI is must more common, but Anthropic is associated with Claude Code ecosystem. There are also OSS adapters to convert between the two as needed. Essentially, you need to find providers that serve inference for free.<p>1. OpenRouter. They always have a few models that are completely free at the expense of storing and using everything you send to them. There are frequent promotional periods after new model releases. You need to top up your account by ~$10, though, to avoid rate limits as they are applied based on your balance. After that, ensure to use Model IDs with `:free` postfix and your balance will not be consumed, you can use those indefinitely.<p>2. OpenCode. This is a great agentic harness (albeit its heavily tuned for larger models), its parent company also provides inference APIs. Due to the popularity, many LLM providers offer free tiers of the models there. Same caveat applies - you data will be stored and used.<p>3. Local inference. If you happened to have a ~6-8GB VRAM and ~32GB RAM - then you should be able to run staple ~30B-sized MoE models. GLM-4.7-Flash is currently the best one for using inside a harness, it&#x27;s even capable enough to drive simple tasks in OpenCode, but I recommend simpler harnesses for better results.<p>4. What to expect. Most of these offerings come with a compromise in terms of data collection and&#x2F;or inference quality. For example, OpenCode&#x27;s free Kimi 2.5 is clearly different from the paid one from official provider. In general - do not trust any claims that compare smaller open weight models with the cloud offering, they are not there yet. However you can get really far and models like Kimi 2.5 are still very capable.<p>Thanks!","title":"Tell HN: Tips for (mostly) free agentic coding setup","updated_at":"2026-02-17T12:07:32Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"supreeth_ravi"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hi HN,<p>Been working on a way to get &quot;agent-per-row&quot; behavior in Postgres without actually running LLMs inside the database.<p>The problem: Calling LLMs from triggers/functions blocks transactions, exhausts connections, and breaks ACID. Saw some projects doing this and it felt dangerous for production.<p>The solution: DB-adjacent architecture. Lightweight triggers enqueue jobs to an outbox table. An external Python worker (agentd) polls, executes AI calls, and writes back safely with schema validation and CAS.<p>What you can build:<p>Auto-classify support tickets on INSERT<p>Content moderation that doesn't block your app<p>Lead scoring, fraud detection, and invoice extraction<p>Anything where data arrives and needs AI enrichment<p>Works with OpenAI, <em>Anthropic</em>, OpenRouter, or any Agent.<p>One SQL line to add AI to any table:<p>SELECT agent_runtime.agent_watch('tickets', 'id', 'classifier', 'v1', '{&quot;priority&quot;:&quot;$.priority&quot;}');<p>Includes 9 example use cases in the repo. Would love feedback on the architecture."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PgCortex \u2013 AI enrichment per Postgres row, zero transaction blocking"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/supreeth-ravi/pgcortex"}},"_tags":["story","author_supreeth_ravi","story_47045690","show_hn"],"author":"supreeth_ravi","created_at":"2026-02-17T10:14:41Z","created_at_i":1771323281,"num_comments":0,"objectID":"47045690","points":1,"story_id":47045690,"story_text":"Hi HN,<p>Been working on a way to get &quot;agent-per-row&quot; behavior in Postgres without actually running LLMs inside the database.<p>The problem: Calling LLMs from triggers&#x2F;functions blocks transactions, exhausts connections, and breaks ACID. Saw some projects doing this and it felt dangerous for production.<p>The solution: DB-adjacent architecture. Lightweight triggers enqueue jobs to an outbox table. An external Python worker (agentd) polls, executes AI calls, and writes back safely with schema validation and CAS.<p>What you can build:<p>Auto-classify support tickets on INSERT<p>Content moderation that doesn&#x27;t block your app<p>Lead scoring, fraud detection, and invoice extraction<p>Anything where data arrives and needs AI enrichment<p>Works with OpenAI, Anthropic, OpenRouter, or any Agent.<p>One SQL line to add AI to any table:<p>SELECT agent_runtime.agent_watch(&#x27;tickets&#x27;, &#x27;id&#x27;, &#x27;classifier&#x27;, &#x27;v1&#x27;, &#x27;{&quot;priority&quot;:&quot;$.priority&quot;}&#x27;);<p>Includes 9 example use cases in the repo. Would love feedback on the architecture.","title":"Show HN: PgCortex \u2013 AI enrichment per Postgres row, zero transaction blocking","updated_at":"2026-02-17T10:17:18Z","url":"https://github.com/supreeth-ravi/pgcortex"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"petethomas"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Are <em>Anthropic</em>'s new AI work tools game-changing for professionals?"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.ft.com/content/92dfd571-8d34-42f1-8be8-dce126998e37"}},"_tags":["story","author_petethomas","story_47044617"],"author":"petethomas","created_at":"2026-02-17T07:16:53Z","created_at_i":1771312613,"num_comments":0,"objectID":"47044617","points":2,"story_id":47044617,"title":"Are Anthropic's new AI work tools game-changing for professionals?","updated_at":"2026-02-17T09:06:47Z","url":"https://www.ft.com/content/92dfd571-8d34-42f1-8be8-dce126998e37"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"al1nasir"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hey HN!<p>I built CodeGraph CLI because I was tired of grep-ing through \nmassive codebases trying to understand how things work.<p>It combines three things:\n- tree-sitter (AST parsing, error-tolerant)\n- SQLite (dependency graph: nodes + edges)\n- LanceDB (vector embeddings, disk-based)<p>The key insight: pure vector search misses structural \nrelationships. So I combined vector search with BFS graph \ntraversal \u2014 find semantically similar code, then expand \nto dependencies/dependents.<p>Result: ask &quot;how does authentication work?&quot; and it finds \nvalidate_token(), its caller login_handler(), AND the \ndependency TokenStore \u2014 because it understands both \nmeaning AND structure.<p>Other features:\n- Impact analysis (multi-hop BFS: what breaks before you change it)\n- Multi-agent system via CrewAI (4 specialized agents)\n- Visual code explorer (browser-based)\n- Auto-generate docs/READMEs\n- 100% local-first (works with Ollama, zero data leaves machine)\n- 6 LLM providers (Ollama, OpenAI, <em>Anthropic</em>, Groq, Gemini, OpenRouter)\n- 5 embedding models (from zero-dependency hash to 1.5B code model)<p>Quick start:\n  pip install codegraph-cli\n  cg config setup\n  cg project index ./your-project\n  cg chat start<p>MIT licensed. Python 3.9+.<p>Happy to answer questions about the graph-augmented RAG \narchitecture or any technical decisions."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: CodeGraph CLI \u2013 Chat with your codebase using graph-augmented RAG"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/al1-nasir/codegraph-cli"}},"_tags":["story","author_al1nasir","story_47043764","show_hn"],"author":"al1nasir","created_at":"2026-02-17T04:39:54Z","created_at_i":1771303194,"num_comments":0,"objectID":"47043764","points":3,"story_id":47043764,"story_text":"Hey HN!<p>I built CodeGraph CLI because I was tired of grep-ing through \nmassive codebases trying to understand how things work.<p>It combines three things:\n- tree-sitter (AST parsing, error-tolerant)\n- SQLite (dependency graph: nodes + edges)\n- LanceDB (vector embeddings, disk-based)<p>The key insight: pure vector search misses structural \nrelationships. So I combined vector search with BFS graph \ntraversal \u2014 find semantically similar code, then expand \nto dependencies&#x2F;dependents.<p>Result: ask &quot;how does authentication work?&quot; and it finds \nvalidate_token(), its caller login_handler(), AND the \ndependency TokenStore \u2014 because it understands both \nmeaning AND structure.<p>Other features:\n- Impact analysis (multi-hop BFS: what breaks before you change it)\n- Multi-agent system via CrewAI (4 specialized agents)\n- Visual code explorer (browser-based)\n- Auto-generate docs&#x2F;READMEs\n- 100% local-first (works with Ollama, zero data leaves machine)\n- 6 LLM providers (Ollama, OpenAI, Anthropic, Groq, Gemini, OpenRouter)\n- 5 embedding models (from zero-dependency hash to 1.5B code model)<p>Quick start:\n  pip install codegraph-cli\n  cg config setup\n  cg project index .&#x2F;your-project\n  cg chat start<p>MIT licensed. Python 3.9+.<p>Happy to answer questions about the graph-augmented RAG \narchitecture or any technical decisions.","title":"Show HN: CodeGraph CLI \u2013 Chat with your codebase using graph-augmented RAG","updated_at":"2026-02-17T04:49:46Z","url":"https://github.com/al1-nasir/codegraph-cli"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"rjpruitt16"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hey HN, I built this because I kept losing progress in LangGraph workflows when OpenRouter or OpenAI returned 429s.\nThe problem: You're 7 steps into an agent workflow. Step 7 hits a rate limit. Everything crashes. Restart from step 1.\nClient-side retries don't help at scale:<p>100 workers all retry independently \u2192 retry storm\nSequential fallbacks are slow (try OpenRouter, wait 5s, try <em>Anthropic</em>, wait 5s)\nNo coordination across instances<p>So I built a coordination layer that:<p>Races multiple providers simultaneously (OpenRouter + <em>Anthropic</em> + OpenAI)\nCoordinates retries across all workers (no retry storms)\nResumes workflows via webhooks (idempotent keys = checkpoints)<p>It runs on Fly.io's anycast network + BEAM for distributed coordination.\nArchitecture deep dive: <a href=\"https://www.ezthrottle.network/blog/making-failure-boring-again\" rel=\"nofollow\">https://www.ezthrottle.network/blog/making-failure-boring-ag...</a>\nHappy to answer questions about the approach or why BEAM made this possible when other languages would struggle."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Stop Losing LangGraph Progress to 429 Errors"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.ezthrottle.network/blog/stop-losing-langgraph-progress"}},"_tags":["story","author_rjpruitt16","story_47043197","show_hn"],"author":"rjpruitt16","created_at":"2026-02-17T03:01:42Z","created_at_i":1771297302,"num_comments":0,"objectID":"47043197","points":1,"story_id":47043197,"story_text":"Hey HN, I built this because I kept losing progress in LangGraph workflows when OpenRouter or OpenAI returned 429s.\nThe problem: You&#x27;re 7 steps into an agent workflow. Step 7 hits a rate limit. Everything crashes. Restart from step 1.\nClient-side retries don&#x27;t help at scale:<p>100 workers all retry independently \u2192 retry storm\nSequential fallbacks are slow (try OpenRouter, wait 5s, try Anthropic, wait 5s)\nNo coordination across instances<p>So I built a coordination layer that:<p>Races multiple providers simultaneously (OpenRouter + Anthropic + OpenAI)\nCoordinates retries across all workers (no retry storms)\nResumes workflows via webhooks (idempotent keys = checkpoints)<p>It runs on Fly.io&#x27;s anycast network + BEAM for distributed coordination.\nArchitecture deep dive: <a href=\"https:&#x2F;&#x2F;www.ezthrottle.network&#x2F;blog&#x2F;making-failure-boring-again\" rel=\"nofollow\">https:&#x2F;&#x2F;www.ezthrottle.network&#x2F;blog&#x2F;making-failure-boring-ag...</a>\nHappy to answer questions about the approach or why BEAM made this possible when other languages would struggle.","title":"Show HN: Stop Losing LangGraph Progress to 429 Errors","updated_at":"2026-02-17T03:06:46Z","url":"https://www.ezthrottle.network/blog/stop-losing-langgraph-progress"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"jdkee"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"The One Woman <em>Anthropic</em> Trusts to Teach AI Morals"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.wsj.com/tech/ai/<em>anthropic</em>-amanda-askell-philosopher-ai-3c031883"}},"_tags":["story","author_jdkee","story_47040207"],"author":"jdkee","children":[47040630,47040317],"created_at":"2026-02-16T20:54:47Z","created_at_i":1771275287,"num_comments":1,"objectID":"47040207","points":6,"story_id":47040207,"title":"The One Woman Anthropic Trusts to Teach AI Morals","updated_at":"2026-02-17T02:32:16Z","url":"https://www.wsj.com/tech/ai/anthropic-amanda-askell-philosopher-ai-3c031883"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"general_reveal"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"<em>Anthropic</em> got an 11% user boost from its OpenAI-bashing Super Bowl ad"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.cnbc.com/2026/02/13/<em>anthropic</em>-open-ai-super-bowl-ads.html"}},"_tags":["story","author_general_reveal","story_47040040"],"author":"general_reveal","children":[47042033],"created_at":"2026-02-16T20:40:14Z","created_at_i":1771274414,"num_comments":1,"objectID":"47040040","points":6,"story_id":47040040,"title":"Anthropic got an 11% user boost from its OpenAI-bashing Super Bowl ad","updated_at":"2026-02-17T01:15:31Z","url":"https://www.cnbc.com/2026/02/13/anthropic-open-ai-super-bowl-ads.html"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"heavymemory"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"<em>Anthropic</em> Raised $30B. Where Does It Go?"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://fromtheprism.com/<em>anthropic</em>-30-billion"}},"_tags":["story","author_heavymemory","story_47040033"],"author":"heavymemory","children":[47043846,47043342],"created_at":"2026-02-16T20:39:09Z","created_at_i":1771274349,"num_comments":3,"objectID":"47040033","points":1,"story_id":47040033,"title":"Anthropic Raised $30B. Where Does It Go?","updated_at":"2026-02-17T04:56:16Z","url":"https://fromtheprism.com/anthropic-30-billion"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"c420"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Pentagon reviewing <em>Anthropic</em> partnership over terms of use dispute"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://thehill.com/policy/defense/5740369-pentagon-<em>anthropic</em>-relationship-review/"}},"_tags":["story","author_c420","story_47039465"],"author":"c420","created_at":"2026-02-16T19:54:29Z","created_at_i":1771271669,"num_comments":0,"objectID":"47039465","points":2,"story_id":47039465,"title":"Pentagon reviewing Anthropic partnership over terms of use dispute","updated_at":"2026-02-16T22:06:32Z","url":"https://thehill.com/policy/defense/5740369-pentagon-anthropic-relationship-review/"}],"hitsPerPage":10,"nbHits":3105,"nbPages":100,"page":0,"params":"query=Anthropic&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":12,"processingTimingsMS":{"_request":{"roundTrip":14},"fetch":{"query":5,"scanning":2,"total":8},"getIdx":{"load":{"gens":2,"total":3},"total":3},"total":12},"query":"Anthropic","serverTimeMS":14}
