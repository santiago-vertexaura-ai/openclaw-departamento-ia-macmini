{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"coolwulf"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["how","teams","use","claude","code"],"value":"Hey HN,<p>I've been building CoolWulf AI (<a href=\"https://coolwulfai.com\" rel=\"nofollow\">https://coolwulfai.com</a>), a self-hosted personal AI assistant. After seeing OpenClaw blow up, I wanted to share what I've been working on \u2014 a different approach to the same problem.<p>*Why I built this:*<p>I tried OpenClaw and found the <em>Node</em>.js/TypeScript stack heavy for what's essentially a local agent. pnpm, <em>Node</em> 22+, React \u2014 lots of moving parts. I wanted something that's a single binary, zero runtime dependencies, and feels native on macOS. So I built it in Go.<p>*<em>How</em> it's different from OpenClaw:*<p>- *Single binary, no runtime needed.* Download, set your API key, run. No <em>Node</em>.js, no pnpm, no build step. One ~100 MB binary.\n- *Built in Go.* Fast startup, low memory footprint, compiles to a native executable. No garbage collector pauses from a JS runtime sitting in the background.\n- *macOS-native integrations.* Deep AppleScript-based control of Apple Notes, Reminders, Calendar, Terminal.app, and WeChat desktop. These aren't browser hacks \u2014 they <em>use</em> the native accessibility and scripting APIs.\n- *WeChat support.* This was a big one for me. WeChat desktop on macOS is a native Cocoa/Qt app with a readable accessibility tree. CoolWulf can read messages, send messages, search contacts, and navigate chats \u2014 all via AX APIs and CGEvent. I haven't seen another AI agent do this.\n- *Simpler setup.* Web-based first-time wizard. Configure your LLM provider, connect Gmail/Calendar via OAuth, enable messaging connectors \u2014 all from the browser. No terminal wizards, no YAML files.<p>*What it does:*<p>- 20+ LLM providers (OpenAI, <em>Claude</em>, Gemini, DeepSeek, Groq, Ollama, local models via vLLM/LM Studio)\n- Messaging: WhatsApp, <em>Teams</em>, Telegram, Slack, WeChat\n- Email: Gmail and Yahoo Mail with full OAuth\n- Calendar: Google Calendar + Apple Calendar\n- Browser automation: Chrome CDP + Playwright via MCP\n- Task management: org-mode style with scheduled tasks, cron jobs, automatic execution\n- Persistent memory: SQLite + vector embeddings for semantic search across conversations\n- Background heartbeat: runs 24/7, monitors your systems, executes due tasks, sends alerts\n- Web dashboard for chat, tasks, scheduled jobs, and settings<p>*Architecture choices:*<p>Go was the right call. The binary compiles in seconds, cross-compiles trivially, and the concurrency model (goroutines for heartbeat, browser sessions, connector polling) maps perfectly to an always-on agent. SQLite with vector extensions (sqlite-vec) gives us semantic memory without running a separate vector DB.<p>Try it: <a href=\"https://coolwulfai.com\" rel=\"nofollow\">https://coolwulfai.com</a><p>Happy to answer questions about the Go implementation, WeChat automation, or the macOS accessibility approach."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: CoolWulf AI \u2013 A personal AI assistant built in Go, optimized for macOS"},"url":{"matchLevel":"none","matchedWords":[],"value":"http://coolwulfAI.com"}},"_tags":["story","author_coolwulf","story_47044036","show_hn"],"author":"coolwulf","children":[47044074],"created_at":"2026-02-17T05:32:16Z","created_at_i":1771306336,"num_comments":1,"objectID":"47044036","points":1,"story_id":47044036,"story_text":"Hey HN,<p>I&#x27;ve been building CoolWulf AI (<a href=\"https:&#x2F;&#x2F;coolwulfai.com\" rel=\"nofollow\">https:&#x2F;&#x2F;coolwulfai.com</a>), a self-hosted personal AI assistant. After seeing OpenClaw blow up, I wanted to share what I&#x27;ve been working on \u2014 a different approach to the same problem.<p>*Why I built this:*<p>I tried OpenClaw and found the Node.js&#x2F;TypeScript stack heavy for what&#x27;s essentially a local agent. pnpm, Node 22+, React \u2014 lots of moving parts. I wanted something that&#x27;s a single binary, zero runtime dependencies, and feels native on macOS. So I built it in Go.<p>*How it&#x27;s different from OpenClaw:*<p>- *Single binary, no runtime needed.* Download, set your API key, run. No Node.js, no pnpm, no build step. One ~100 MB binary.\n- *Built in Go.* Fast startup, low memory footprint, compiles to a native executable. No garbage collector pauses from a JS runtime sitting in the background.\n- *macOS-native integrations.* Deep AppleScript-based control of Apple Notes, Reminders, Calendar, Terminal.app, and WeChat desktop. These aren&#x27;t browser hacks \u2014 they use the native accessibility and scripting APIs.\n- *WeChat support.* This was a big one for me. WeChat desktop on macOS is a native Cocoa&#x2F;Qt app with a readable accessibility tree. CoolWulf can read messages, send messages, search contacts, and navigate chats \u2014 all via AX APIs and CGEvent. I haven&#x27;t seen another AI agent do this.\n- *Simpler setup.* Web-based first-time wizard. Configure your LLM provider, connect Gmail&#x2F;Calendar via OAuth, enable messaging connectors \u2014 all from the browser. No terminal wizards, no YAML files.<p>*What it does:*<p>- 20+ LLM providers (OpenAI, Claude, Gemini, DeepSeek, Groq, Ollama, local models via vLLM&#x2F;LM Studio)\n- Messaging: WhatsApp, Teams, Telegram, Slack, WeChat\n- Email: Gmail and Yahoo Mail with full OAuth\n- Calendar: Google Calendar + Apple Calendar\n- Browser automation: Chrome CDP + Playwright via MCP\n- Task management: org-mode style with scheduled tasks, cron jobs, automatic execution\n- Persistent memory: SQLite + vector embeddings for semantic search across conversations\n- Background heartbeat: runs 24&#x2F;7, monitors your systems, executes due tasks, sends alerts\n- Web dashboard for chat, tasks, scheduled jobs, and settings<p>*Architecture choices:*<p>Go was the right call. The binary compiles in seconds, cross-compiles trivially, and the concurrency model (goroutines for heartbeat, browser sessions, connector polling) maps perfectly to an always-on agent. SQLite with vector extensions (sqlite-vec) gives us semantic memory without running a separate vector DB.<p>Try it: <a href=\"https:&#x2F;&#x2F;coolwulfai.com\" rel=\"nofollow\">https:&#x2F;&#x2F;coolwulfai.com</a><p>Happy to answer questions about the Go implementation, WeChat automation, or the macOS accessibility approach.","title":"Show HN: CoolWulf AI \u2013 A personal AI assistant built in Go, optimized for macOS","updated_at":"2026-02-17T06:39:16Z","url":"http://coolwulfAI.com"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Poomba"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["how","teams","use","claude","code"],"value":"I'm trying to decide whether to adopt Cursor for our company, but we're in a heavily regulated industry and our compliance <em>team</em> is flagging concerns about HIPAA/SOC2/audit trails.<p>The thing is, there are companies in regulated industries using it [1][2]. But Cursor has no HIPAA BAA, no FedRAMP certification, and is cloud-only with all requests routing through their AWS infrastructure. (This is probably true for <em>Claude</em> and other <em>codi</em>ng assistants, though I've only looked seriously at Cursor.)<p>So <em>how</em> are regulated companies actually making this work? Or do most just avoid Cursor and other AI <em>codi</em>ng tools altogether?<p>[1] 165 healthcare companies <em>use</em> Cursor according to Bloomberry: https://bloomberry.com/data/cursor/<p>[2] Cursor's customers include Sanofi, Johnson &amp; Johnson, and Neuralink: https://cursor.com/customers"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["how","use"],"value":"Ask HN: <em>How</em> do companies that <em>use</em> Cursor handle compliance?"}},"_tags":["story","author_Poomba","story_47043484","ask_hn"],"author":"Poomba","children":[47043995,47043504,47043810],"created_at":"2026-02-17T03:48:00Z","created_at_i":1771300080,"num_comments":2,"objectID":"47043484","points":6,"story_id":47043484,"story_text":"I&#x27;m trying to decide whether to adopt Cursor for our company, but we&#x27;re in a heavily regulated industry and our compliance team is flagging concerns about HIPAA&#x2F;SOC2&#x2F;audit trails.<p>The thing is, there are companies in regulated industries using it [1][2]. But Cursor has no HIPAA BAA, no FedRAMP certification, and is cloud-only with all requests routing through their AWS infrastructure. (This is probably true for Claude and other coding assistants, though I&#x27;ve only looked seriously at Cursor.)<p>So how are regulated companies actually making this work? Or do most just avoid Cursor and other AI coding tools altogether?<p>[1] 165 healthcare companies use Cursor according to Bloomberry: https:&#x2F;&#x2F;bloomberry.com&#x2F;data&#x2F;cursor&#x2F;<p>[2] Cursor&#x27;s customers include Sanofi, Johnson &amp; Johnson, and Neuralink: https:&#x2F;&#x2F;cursor.com&#x2F;customers","title":"Ask HN: How do companies that use Cursor handle compliance?","updated_at":"2026-02-17T12:40:02Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Reebz"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["teams","use","claude","code"],"value":"Hi HN, this is nothing fancy, but a tool I built for myself as a minimalist way to track usage. Also (and probably more importantly), colleagues who are marketers, writers, designers, and other non-engineering backgrounds who are/becoming power users of <em>Claude</em> Cowork or <em>Claude</em> <em>Code</em> and needed to keep better watch of usage.<p>Once Opus 4.6 landed, I was quickly aware I needed to keep an eye on usage as I capped out session limits faster than ever. I got frustrated checking usage manually and then explored the other apps and widgets out there. They're really good, and some are great, but they're just so feature-heavy and complex with that ICP in mind I mentioned earlier.<p>Tokens just don't feel like anything to me.... I'd watch them tick over in the thousands and then millions. So I just ignored them as I was planning and then inverted the usage metrics that <em>Claude</em> provides (i.e. start at 100% and not 0%), which helped me land on a battery concept. This felt good and definitely made sense to the people I asked. Then I was focused on adding only the bare minimum features... or &quot;Simplify, and add lightness&quot; in the words of Colin Chapman.<p>Anyway, that's the story and yes, the app is largely vibe coded before folks start to go digging through commits. I quite enjoyed the process and I wouldn't have hand-coded something like this myself (the issue-pain wouldn't have met the effort-required threshold). If anyone is curious, my workflow and tools <em>used</em> were <em>Claude</em> <em>Code</em>, with ui-ux-pro-max for design, heavy usage of compound-engineering (plan &gt; work &gt; review &gt; compound). Strongly recommend this plugin. I also <em>used</em> Condcutor on and off, but 80% of the work ended up just being done with CC in iTerm2. It handled the agent <em>teams</em> much better.<p>Let me know if you have any bugs or feedback."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["how","claude"],"value":"<em>Show</em> HN: <em>Claude</em> Battery \u2013 usage at a glance. A minimalist macOS menu bar widget"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude"],"value":"https://github.com/Reebz/<em>claude</em>-battery"}},"_tags":["story","author_Reebz","story_47035304","show_hn"],"author":"Reebz","children":[47035356,47035387],"created_at":"2026-02-16T14:21:45Z","created_at_i":1771251705,"num_comments":4,"objectID":"47035304","points":1,"story_id":47035304,"story_text":"Hi HN, this is nothing fancy, but a tool I built for myself as a minimalist way to track usage. Also (and probably more importantly), colleagues who are marketers, writers, designers, and other non-engineering backgrounds who are&#x2F;becoming power users of Claude Cowork or Claude Code and needed to keep better watch of usage.<p>Once Opus 4.6 landed, I was quickly aware I needed to keep an eye on usage as I capped out session limits faster than ever. I got frustrated checking usage manually and then explored the other apps and widgets out there. They&#x27;re really good, and some are great, but they&#x27;re just so feature-heavy and complex with that ICP in mind I mentioned earlier.<p>Tokens just don&#x27;t feel like anything to me.... I&#x27;d watch them tick over in the thousands and then millions. So I just ignored them as I was planning and then inverted the usage metrics that Claude provides (i.e. start at 100% and not 0%), which helped me land on a battery concept. This felt good and definitely made sense to the people I asked. Then I was focused on adding only the bare minimum features... or &quot;Simplify, and add lightness&quot; in the words of Colin Chapman.<p>Anyway, that&#x27;s the story and yes, the app is largely vibe coded before folks start to go digging through commits. I quite enjoyed the process and I wouldn&#x27;t have hand-coded something like this myself (the issue-pain wouldn&#x27;t have met the effort-required threshold). If anyone is curious, my workflow and tools used were Claude Code, with ui-ux-pro-max for design, heavy usage of compound-engineering (plan &gt; work &gt; review &gt; compound). Strongly recommend this plugin. I also used Condcutor on and off, but 80% of the work ended up just being done with CC in iTerm2. It handled the agent teams much better.<p>Let me know if you have any bugs or feedback.","title":"Show HN: Claude Battery \u2013 usage at a glance. A minimalist macOS menu bar widget","updated_at":"2026-02-16T15:00:31Z","url":"https://github.com/Reebz/claude-battery"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"san-techie21"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["teams","use","claude","code"],"value":"Hi HN,<p>I'm a security engineer with 15+ years in enterprise security. After watching OpenClaw explode to 180K stars while binding to 0.0.0.0 by default, shipping no encryption, and accumulating 512 CVEs \u2014 I decided to build what I think a personal AI agent should look like when security comes first.<p>Gulama is an open-source personal AI agent with 15+ security mechanisms built into the core:<p>- AES-256-GCM encryption for all credentials and memories (never plaintext)\n- Sandboxed execution via bubblewrap/Docker (same sandbox Anthropic <em>uses</em> for <em>Claude</em> <em>Code</em>)\n- Ed25519-signed skills (no unsigned <em>code</em> runs \u2014 unlike ClawHub's 230+ malicious skills)\n- Cedar-inspired policy engine for deterministic authorization\n- Canary tokens for prompt injection detection\n- Egress filtering + DLP to prevent data exfiltration\n- Gateway binds 127.0.0.1 ONLY by default (not 0.0.0.0)\n- Cryptographic hash-chain audit trail<p>Beyond security, it's a full-featured agent:<p>- 100+ LLM providers via LiteLLM (Anthropic, OpenAI, DeepSeek, Ollama, etc.)\n- 19 built-in skills (files, shell, web, browser, email, calendar, GitHub, Notion, Spotify, voice, MCP bridge, and more)\n- 10 communication channels (CLI, Telegram, Discord, Slack, WhatsApp, Matrix, <em>Teams</em>, Web UI, Voice Wake)\n- Full MCP server + client support\n- Multi-agent orchestration with background sub-agents\n- RAG-powered memory via ChromaDB\n- Self-modifying: the agent writes its own new skills at runtime (sandboxed)\n- 5 autonomy levels from &quot;ask before everything&quot; to full autopilot<p>Install: pip install gulama &amp;&amp; gulama setup &amp;&amp; gulama chat<p>Stack: Python 3.12+, FastAPI, LiteLLM, SQLite, ChromaDB, Click\nPyPI: <a href=\"https://pypi.org/project/gulama/\" rel=\"nofollow\">https://pypi.org/project/gulama/</a><p>Happy to answer any questions about the security architecture or design decisions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["how"],"value":"<em>Show</em> HN: Gulama \u2013 Security-first open-source AI agent (OpenClaw alternative)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/san-techie21/gulama-bot"}},"_tags":["story","author_san-techie21","story_47031982","show_hn"],"author":"san-techie21","children":[47043547],"created_at":"2026-02-16T07:27:20Z","created_at_i":1771226840,"num_comments":1,"objectID":"47031982","points":1,"story_id":47031982,"story_text":"Hi HN,<p>I&#x27;m a security engineer with 15+ years in enterprise security. After watching OpenClaw explode to 180K stars while binding to 0.0.0.0 by default, shipping no encryption, and accumulating 512 CVEs \u2014 I decided to build what I think a personal AI agent should look like when security comes first.<p>Gulama is an open-source personal AI agent with 15+ security mechanisms built into the core:<p>- AES-256-GCM encryption for all credentials and memories (never plaintext)\n- Sandboxed execution via bubblewrap&#x2F;Docker (same sandbox Anthropic uses for Claude Code)\n- Ed25519-signed skills (no unsigned code runs \u2014 unlike ClawHub&#x27;s 230+ malicious skills)\n- Cedar-inspired policy engine for deterministic authorization\n- Canary tokens for prompt injection detection\n- Egress filtering + DLP to prevent data exfiltration\n- Gateway binds 127.0.0.1 ONLY by default (not 0.0.0.0)\n- Cryptographic hash-chain audit trail<p>Beyond security, it&#x27;s a full-featured agent:<p>- 100+ LLM providers via LiteLLM (Anthropic, OpenAI, DeepSeek, Ollama, etc.)\n- 19 built-in skills (files, shell, web, browser, email, calendar, GitHub, Notion, Spotify, voice, MCP bridge, and more)\n- 10 communication channels (CLI, Telegram, Discord, Slack, WhatsApp, Matrix, Teams, Web UI, Voice Wake)\n- Full MCP server + client support\n- Multi-agent orchestration with background sub-agents\n- RAG-powered memory via ChromaDB\n- Self-modifying: the agent writes its own new skills at runtime (sandboxed)\n- 5 autonomy levels from &quot;ask before everything&quot; to full autopilot<p>Install: pip install gulama &amp;&amp; gulama setup &amp;&amp; gulama chat<p>Stack: Python 3.12+, FastAPI, LiteLLM, SQLite, ChromaDB, Click\nPyPI: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;gulama&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;gulama&#x2F;</a><p>Happy to answer any questions about the security architecture or design decisions.","title":"Show HN: Gulama \u2013 Security-first open-source AI agent (OpenClaw alternative)","updated_at":"2026-02-17T04:00:01Z","url":"https://github.com/san-techie21/gulama-bot"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"alexhans"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["teams","use","claude","code"],"value":"I've been working on a site [1] to give people control of their LLM workflows through AI evals - automated checks that, once defined, let you move fast without regressions and cut through hype with proof.<p>That one-liner is aimed at software engineers, but I've spent my career helping cross-functional <em>teams</em> collaborate, and that's really what this is about. AI agents make powerful workflows very plausible, but only if <em>teams</em> can grow them incrementally without losing control - no vendor lock-in, no discipline silos, no blind trust in outputs.<p>The site tries to meet different audiences where they are, with mostly practice over theory: tool comparisons, minimal approaches, and freedom to work at whatever level of complexity serves you - whether that's <em>Claude</em> <em>Code</em> with Agent Skills, local models, or custom Python agents.<p>As a fun &quot;eat your own dog food&quot; experiment, I <em>use</em> the site itself as the reproducible cookbook (&quot;eval-ception&quot;) [2]. It's the quickest way to feel what different eval tools are actually like in practice.<p>I welcome feedback, contributions, or stories. More on the project and what's coming [3]. It's a rewarding area once you realize you can keep control and move methodically - doesn't matter if it's the smallest model or a swarm.<p>[1] <a href=\"https://ai-evals.io/\" rel=\"nofollow\">https://ai-evals.io/</a><p>[2] <a href=\"https://ai-evals.io/cookbook/eval-ception.html\" rel=\"nofollow\">https://ai-evals.io/cookbook/eval-ception.html</a><p>[3] <a href=\"https://ai-evals.io/about/\" rel=\"nofollow\">https://ai-evals.io/about/</a>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["how"],"value":"<em>Show</em> HN: AI-Evals.io \u2013 Evaluate this site with the tools it reviews"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://ai-evals.io/"}},"_tags":["story","author_alexhans","story_47026263","show_hn"],"author":"alexhans","children":[47043322],"created_at":"2026-02-15T18:49:49Z","created_at_i":1771181389,"num_comments":0,"objectID":"47026263","points":4,"story_id":47026263,"story_text":"I&#x27;ve been working on a site [1] to give people control of their LLM workflows through AI evals - automated checks that, once defined, let you move fast without regressions and cut through hype with proof.<p>That one-liner is aimed at software engineers, but I&#x27;ve spent my career helping cross-functional teams collaborate, and that&#x27;s really what this is about. AI agents make powerful workflows very plausible, but only if teams can grow them incrementally without losing control - no vendor lock-in, no discipline silos, no blind trust in outputs.<p>The site tries to meet different audiences where they are, with mostly practice over theory: tool comparisons, minimal approaches, and freedom to work at whatever level of complexity serves you - whether that&#x27;s Claude Code with Agent Skills, local models, or custom Python agents.<p>As a fun &quot;eat your own dog food&quot; experiment, I use the site itself as the reproducible cookbook (&quot;eval-ception&quot;) [2]. It&#x27;s the quickest way to feel what different eval tools are actually like in practice.<p>I welcome feedback, contributions, or stories. More on the project and what&#x27;s coming [3]. It&#x27;s a rewarding area once you realize you can keep control and move methodically - doesn&#x27;t matter if it&#x27;s the smallest model or a swarm.<p>[1] <a href=\"https:&#x2F;&#x2F;ai-evals.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;ai-evals.io&#x2F;</a><p>[2] <a href=\"https:&#x2F;&#x2F;ai-evals.io&#x2F;cookbook&#x2F;eval-ception.html\" rel=\"nofollow\">https:&#x2F;&#x2F;ai-evals.io&#x2F;cookbook&#x2F;eval-ception.html</a><p>[3] <a href=\"https:&#x2F;&#x2F;ai-evals.io&#x2F;about&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;ai-evals.io&#x2F;about&#x2F;</a>","title":"Show HN: AI-Evals.io \u2013 Evaluate this site with the tools it reviews","updated_at":"2026-02-17T03:20:46Z","url":"https://ai-evals.io/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Nlupus"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["how","teams","use","claude","code"],"value":"I've been building lifecycle messaging systems for SaaS companies for 10+ years. Every company needs one (welcome emails, onboarding sequences, upgrade nudges, etc) but building one from scratch is tedious and most <em>teams</em> either copy generic templates or hire a consultant.<p>I took the approach I've battle-tested across dozens of projects and wrapped it into a CLI tool that runs on <em>Claude</em> <em>Code</em>.<p>Mango Lollipop runs entirely through <em>Claude</em> <em>Code</em> locally.<p>You give it your product URL, it analyzes your business, and walks you through building a complete messaging system using the AARRR pirate metrics framework.<p>It will take about 15 minutes from init to a complete v0.1 messaging system ready to implement and test.<p>What it produces:<p>- A structured messaging matrix with triggers, guards, suppressions, and timing for every message\n- Full message copy (email, in-app, SMS, push) written in your brand voice\n- An Excel workbook for your <em>team's</em> source of truth\n- An interactive HTML dashboard with journey maps and message previews\n- Developer hand-off docs with event specs and <em>code</em> examples<p>Demo with sample outputs here <a href=\"https://sr-kai.github.io/mango-lollipop/\" rel=\"nofollow\">https://sr-kai.github.io/mango-lollipop/</a><p>The whole thing is built as markdown skills (slash commands). Each step is independent so you can review, iterate, and course-correct before moving on.<p>I built it on <em>Claude</em> <em>Code</em>, but since the skills are just markdown files, it should work in any AI coding tool that supports them, like Cursor, OpenCode, Windsurf, etc.<p>Different models produce WILDLY different copy, I recommend trying a few to see what works best for your <em>use</em>-case.<p>npm install -g mango-lollipop<p>GitHub: <a href=\"https://github.com/sr-kai/mango-lollipop\" rel=\"nofollow\">https://github.com/sr-kai/mango-lollipop</a><p>I'd love feedback on the approach and <em>how</em> you build similar system.<p>The trigger/wait/guard/suppression model is not the most elegant solution, so if you have a better implementation please share your experience."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Mango Lollipop \u2013 AI-powered lifecycle messaging generator"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/sr-kai/mango-lollipop"}},"_tags":["story","author_Nlupus","story_46997378","show_hn"],"author":"Nlupus","created_at":"2026-02-13T00:38:00Z","created_at_i":1770943080,"num_comments":0,"objectID":"46997378","points":2,"story_id":46997378,"story_text":"I&#x27;ve been building lifecycle messaging systems for SaaS companies for 10+ years. Every company needs one (welcome emails, onboarding sequences, upgrade nudges, etc) but building one from scratch is tedious and most teams either copy generic templates or hire a consultant.<p>I took the approach I&#x27;ve battle-tested across dozens of projects and wrapped it into a CLI tool that runs on Claude Code.<p>Mango Lollipop runs entirely through Claude Code locally.<p>You give it your product URL, it analyzes your business, and walks you through building a complete messaging system using the AARRR pirate metrics framework.<p>It will take about 15 minutes from init to a complete v0.1 messaging system ready to implement and test.<p>What it produces:<p>- A structured messaging matrix with triggers, guards, suppressions, and timing for every message\n- Full message copy (email, in-app, SMS, push) written in your brand voice\n- An Excel workbook for your team&#x27;s source of truth\n- An interactive HTML dashboard with journey maps and message previews\n- Developer hand-off docs with event specs and code examples<p>Demo with sample outputs here <a href=\"https:&#x2F;&#x2F;sr-kai.github.io&#x2F;mango-lollipop&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;sr-kai.github.io&#x2F;mango-lollipop&#x2F;</a><p>The whole thing is built as markdown skills (slash commands). Each step is independent so you can review, iterate, and course-correct before moving on.<p>I built it on Claude Code, but since the skills are just markdown files, it should work in any AI coding tool that supports them, like Cursor, OpenCode, Windsurf, etc.<p>Different models produce WILDLY different copy, I recommend trying a few to see what works best for your use-case.<p>npm install -g mango-lollipop<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sr-kai&#x2F;mango-lollipop\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sr-kai&#x2F;mango-lollipop</a><p>I&#x27;d love feedback on the approach and how you build similar system.<p>The trigger&#x2F;wait&#x2F;guard&#x2F;suppression model is not the most elegant solution, so if you have a better implementation please share your experience.","title":"Show HN: Mango Lollipop \u2013 AI-powered lifecycle messaging generator","updated_at":"2026-02-13T08:58:49Z","url":"https://github.com/sr-kai/mango-lollipop"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"boundedreason"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["how","teams","use","claude","code"],"value":"What this is:<p>Copy-paste LLM prompts that turn ChatGPT or <em>Claude</em> into a structured decision analyst for laptops, monitors, tablets, phones, and SaaS subscriptions. You define constraints, weight what matters to your workflow, and get scored recommendations with sensitivity analysis.\nWhy I built this:<p>With the rise of LLMs (AI), I wanted to find a way to harness the computing power and ease of <em>use</em> the chat interface provides.  The major problem: LLMs don\u2019t always provide repeatable, traceable results if you ask the same question twice or even against 2 competing products. That is the dilemma this product aims to solve.  Is this a PDF, yes, but it harnesses my systems analysis experience to help hard-<em>code</em> a framework for a person off the street to turn their AI chat box into an objective decision-helper in just 15 to 20 minutes of <em>use</em>.<p>I spent 10+ years applying decision science in defense and systems analysis\u2014graduate work at Naval Postgraduate School, leading <em>teams</em> through decisions where the cost of choosing wrong wasn't just money; it was mission failure or lives at risk.<p>The method used uses multi-attribute utility theory: define hard constraints (binary gates), eliminate non-viable options, score remaining candidates on mission-critical attributes with explicit weights, then run sensitivity analysis to see what changes the outcome.<p>I <em>use</em> this myself all the time.  The most recent was trying to upgrade my own laptop (Surface Pro stuck at Windows 10).<p>BLUF benefits:<p>\u2022 Helps prevent over-obsessing over specs (32GB RAM! RTX 4080!) while ignoring mission fit (do I really game that often?)<p>\u2022 Fleshes out hard constraints that sometimes come up until after purchase (bought Windows laptop, needs a way to support a MacOS app)<p>\u2022 Future-proofing: ensuring I won\u2019t pay feature I'll statistically never <em>use</em><p>\u2022 Aims to parse through the noise (SEO type posts) and get you a great first-pass research report of what you should value and why.<p>Consumer purchases don't need full enterprise rigor, but they deserve better than &quot;Top 10 Laptops 2026&quot; affiliate listicles or chatbots hallucinating specs.<p><em>How</em> the framework works:\n1. Mission definition: What must work reliably? (Video editing vs office work vs travel)<p>2. Hard constraints: Binary gates (budget ceiling, OS requirements, battery minimums)<p>3. Candidate generation: AI searches current market without SEO or affiliate bias<p>4. Weighted scoring: Performance, battery, reliability, portability\u2014you control the weights<p>5. Efficient frontier: Which options dominate? Which are just expensive?<p>6. Sensitivity analysis: &quot;If battery life matters 25% instead of 15%, MacBook Air wins. If reliability matters more, ThinkPad wins.&quot;<p>The PDFs include example case studies I\u2019ve developed: policy analyst choosing ThinkPad X1 Carbon over MacBook Air (why reliability and docking beat battery life for enterprise work), freelance designer choosing Figma over Affinity Designer (why collaboration features justified 6x higher cost), consultant choosing Obsidian over Notion (why offline-first beat ease-of-<em>use</em>).<p>No barriers: No sign-up. No account. You get a PDF with prompts and case studies. Open ChatGPT or <em>Claude</em> (free version works), paste the prompt, answer questions. That's it.<p>I built this because I was tired of seeing people (and myself) wasting money on impressive-sounding specs that don't match their actual workflow. If you've ever regretted a tech purchase 3 weeks later, this might help.<p>Try it (I'd offer it free but then I loose my IP):\n\u2022 Tech &amp; Electronics: <a href=\"https://decisioncontrolworks.gumroad.com/l/auzhsa\" rel=\"nofollow\">https://decisioncontrolworks.gumroad.com/l/auzhsa</a>\n\u2022 Software &amp; Subscriptions: <a href=\"https://decisioncontrolworks.gumroad.com/l/zaucxt\" rel=\"nofollow\">https://decisioncontrolworks.gumroad.com/l/zaucxt</a><p>Curious what HN thinks\u2014especially if anyone's tried applying formal decision methods to everyday purchases."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Multi-attribute decision frameworks for tech purchases"}},"_tags":["story","author_boundedreason","story_46955606","show_hn"],"author":"boundedreason","children":[47015070,46975995],"created_at":"2026-02-10T05:01:51Z","created_at_i":1770699711,"num_comments":4,"objectID":"46955606","points":1,"story_id":46955606,"story_text":"What this is:<p>Copy-paste LLM prompts that turn ChatGPT or Claude into a structured decision analyst for laptops, monitors, tablets, phones, and SaaS subscriptions. You define constraints, weight what matters to your workflow, and get scored recommendations with sensitivity analysis.\nWhy I built this:<p>With the rise of LLMs (AI), I wanted to find a way to harness the computing power and ease of use the chat interface provides.  The major problem: LLMs don\u2019t always provide repeatable, traceable results if you ask the same question twice or even against 2 competing products. That is the dilemma this product aims to solve.  Is this a PDF, yes, but it harnesses my systems analysis experience to help hard-code a framework for a person off the street to turn their AI chat box into an objective decision-helper in just 15 to 20 minutes of use.<p>I spent 10+ years applying decision science in defense and systems analysis\u2014graduate work at Naval Postgraduate School, leading teams through decisions where the cost of choosing wrong wasn&#x27;t just money; it was mission failure or lives at risk.<p>The method used uses multi-attribute utility theory: define hard constraints (binary gates), eliminate non-viable options, score remaining candidates on mission-critical attributes with explicit weights, then run sensitivity analysis to see what changes the outcome.<p>I use this myself all the time.  The most recent was trying to upgrade my own laptop (Surface Pro stuck at Windows 10).<p>BLUF benefits:<p>\u2022 Helps prevent over-obsessing over specs (32GB RAM! RTX 4080!) while ignoring mission fit (do I really game that often?)<p>\u2022 Fleshes out hard constraints that sometimes come up until after purchase (bought Windows laptop, needs a way to support a MacOS app)<p>\u2022 Future-proofing: ensuring I won\u2019t pay feature I&#x27;ll statistically never use<p>\u2022 Aims to parse through the noise (SEO type posts) and get you a great first-pass research report of what you should value and why.<p>Consumer purchases don&#x27;t need full enterprise rigor, but they deserve better than &quot;Top 10 Laptops 2026&quot; affiliate listicles or chatbots hallucinating specs.<p>How the framework works:\n1. Mission definition: What must work reliably? (Video editing vs office work vs travel)<p>2. Hard constraints: Binary gates (budget ceiling, OS requirements, battery minimums)<p>3. Candidate generation: AI searches current market without SEO or affiliate bias<p>4. Weighted scoring: Performance, battery, reliability, portability\u2014you control the weights<p>5. Efficient frontier: Which options dominate? Which are just expensive?<p>6. Sensitivity analysis: &quot;If battery life matters 25% instead of 15%, MacBook Air wins. If reliability matters more, ThinkPad wins.&quot;<p>The PDFs include example case studies I\u2019ve developed: policy analyst choosing ThinkPad X1 Carbon over MacBook Air (why reliability and docking beat battery life for enterprise work), freelance designer choosing Figma over Affinity Designer (why collaboration features justified 6x higher cost), consultant choosing Obsidian over Notion (why offline-first beat ease-of-use).<p>No barriers: No sign-up. No account. You get a PDF with prompts and case studies. Open ChatGPT or Claude (free version works), paste the prompt, answer questions. That&#x27;s it.<p>I built this because I was tired of seeing people (and myself) wasting money on impressive-sounding specs that don&#x27;t match their actual workflow. If you&#x27;ve ever regretted a tech purchase 3 weeks later, this might help.<p>Try it (I&#x27;d offer it free but then I loose my IP):\n\u2022 Tech &amp; Electronics: <a href=\"https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;auzhsa\" rel=\"nofollow\">https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;auzhsa</a>\n\u2022 Software &amp; Subscriptions: <a href=\"https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;zaucxt\" rel=\"nofollow\">https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;zaucxt</a><p>Curious what HN thinks\u2014especially if anyone&#x27;s tried applying formal decision methods to everyday purchases.","title":"Show HN: Multi-attribute decision frameworks for tech purchases","updated_at":"2026-02-16T20:35:00Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"bsgeraci"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["how","teams","use","claude","code"],"value":"I'm a software engineer who keeps getting pulled into DevOps no matter <em>how</em> hard I try to escape it. I recently moved into a Lead DevOps Engineer role writing tooling to automate a lot of the pain away. On my own time outside of work, I built Artifact Keeper \u2014 a self-hosted artifact registry that supports 45+ package formats. Security scanning, SSO, replication, WASM plugins \u2014 it's all in the MIT-licensed release. No enterprise tier. No feature gates. No surprise invoices.<p>Your package managers \u2014 pip, npm, docker, cargo, helm, go, all of them \u2014 talk directly to it using their native protocols. Security scanning with Trivy, Grype, and OpenSCAP is built in, with a policy engine that can quarantine bad artifacts before they hit your builds. And if you need a format it doesn't support yet, there's a WASM plugin system so you can add your own without forking the backend.<p>Why I built it:<p>Part of what pulled me into computers in the first place was open source. I grew up poor in New Orleans, and the only hardware I had access to in the early 2000s were some Compaq Pentium IIs my dad brought home after his work was tossing them out. I put Linux on them, and it ran circles around Windows 2000 and Millennium on that low-end hardware. That experience taught me that the best software is software that's open for everyone to see, <em>use</em>, and that actually runs well on whatever you've got.<p>Fast forward to today, and I see the same pattern everywhere: GitLab, JFrog, Harbor, and others ship a limited &quot;community&quot; edition and then hide the features <em>teams</em> actually need behind some paywall. I get it \u2014 paychecks have to come from somewhere. But I wanted to prove that a fully-featured artifact registry could exist as genuinely open-source software. Every feature. No exceptions.<p>The specific features came from real pain points. Artifactory's search is painfully slow \u2014 that's why I integrated Meilisearch. Security scanning that doesn't require a separate enterprise license was another big one. And I wanted replication that didn't need a central coordinator \u2014 so I built a peer mesh where any node can replicate to any other node. I haven't deployed this at work yet \u2014 right now I'm running it at home for my personal projects \u2014 but I'd love to see it tested at scale, and that's a big part of why I'm sharing it here.<p>The AI story (I'm going to be honest about this):<p>I built this in about three weeks using <em>Claude</em> <em>Code</em>. I know a lot of you will say this is probably vibe coding garbage \u2014 but if that's the case, it's an impressive pile of vibe coding garbage. Go look at the codebase. The backend is ~80% Rust with 429 unit tests, 33 PostgreSQL migrations, a layered architecture, and a full CI/CD pipeline with E2E tests, stress testing, and failure injection.<p>AI didn't make the design decisions for me. I still had to design the WASM plugin system, figure out <em>how</em> the scanning engines complement each other, and architect the mesh replication. Years of domain knowledge drove the design \u2014 AI just let me build it way faster. I'm floored at what these tools make possible for a tinkerer and security nerd like me.<p>Tech stack: Rust on Axum, PostgreSQL 16, Meilisearch, Trivy + Grype + OpenSCAP, Wasmtime WASM plugins (hot-reloadable), mesh replication with chunked transfers. Frontend is Next.js 15 plus native Swift (iOS/macOS) and Kotlin (Android) apps. OpenAPI 3.1 spec with auto-generated TypeScript and Rust SDKs.<p>Try it:<p><pre><code>  git clone https://github.com/artifact-keeper/artifact-keeper.git\n  cd artifact-keeper\n  docker compose up -d\n</code></pre>\nThen visit http://localhost:30080<p>Live demo: <a href=\"https://demo.artifactkeeper.com\" rel=\"nofollow\">https://demo.artifactkeeper.com</a>\nDocs: <a href=\"https://artifactkeeper.com/docs/\" rel=\"nofollow\">https://artifactkeeper.com/docs/</a><p>I'd love any feedback \u2014 what you think of the approach, what you'd want to see, what you hate about Artifactory or Nexus that you wish someone would just fix. It doesn't have to be a PR. Open an issue, start a discussion, or just tell me here.<p><a href=\"https://github.com/artifact-keeper\" rel=\"nofollow\">https://github.com/artifact-keeper</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Artifact Keeper \u2013 Open-Source Artifactory/Nexus Alternative in Rust"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/artifact-keeper"}},"_tags":["story","author_bsgeraci","story_46909037","show_hn"],"author":"bsgeraci","children":[46910237,46909898,46910129,46910503,46915730,46912233,46917265,46911929,46910948,46917499,46945846,46920860,46911892,46916733,46911160,46923600,46912699,46912141,46910688,46914046,46913461,46911533,46917136,46909867,46914037,46910433],"created_at":"2026-02-06T04:12:59Z","created_at_i":1770351179,"num_comments":68,"objectID":"46909037","points":166,"story_id":46909037,"story_text":"I&#x27;m a software engineer who keeps getting pulled into DevOps no matter how hard I try to escape it. I recently moved into a Lead DevOps Engineer role writing tooling to automate a lot of the pain away. On my own time outside of work, I built Artifact Keeper \u2014 a self-hosted artifact registry that supports 45+ package formats. Security scanning, SSO, replication, WASM plugins \u2014 it&#x27;s all in the MIT-licensed release. No enterprise tier. No feature gates. No surprise invoices.<p>Your package managers \u2014 pip, npm, docker, cargo, helm, go, all of them \u2014 talk directly to it using their native protocols. Security scanning with Trivy, Grype, and OpenSCAP is built in, with a policy engine that can quarantine bad artifacts before they hit your builds. And if you need a format it doesn&#x27;t support yet, there&#x27;s a WASM plugin system so you can add your own without forking the backend.<p>Why I built it:<p>Part of what pulled me into computers in the first place was open source. I grew up poor in New Orleans, and the only hardware I had access to in the early 2000s were some Compaq Pentium IIs my dad brought home after his work was tossing them out. I put Linux on them, and it ran circles around Windows 2000 and Millennium on that low-end hardware. That experience taught me that the best software is software that&#x27;s open for everyone to see, use, and that actually runs well on whatever you&#x27;ve got.<p>Fast forward to today, and I see the same pattern everywhere: GitLab, JFrog, Harbor, and others ship a limited &quot;community&quot; edition and then hide the features teams actually need behind some paywall. I get it \u2014 paychecks have to come from somewhere. But I wanted to prove that a fully-featured artifact registry could exist as genuinely open-source software. Every feature. No exceptions.<p>The specific features came from real pain points. Artifactory&#x27;s search is painfully slow \u2014 that&#x27;s why I integrated Meilisearch. Security scanning that doesn&#x27;t require a separate enterprise license was another big one. And I wanted replication that didn&#x27;t need a central coordinator \u2014 so I built a peer mesh where any node can replicate to any other node. I haven&#x27;t deployed this at work yet \u2014 right now I&#x27;m running it at home for my personal projects \u2014 but I&#x27;d love to see it tested at scale, and that&#x27;s a big part of why I&#x27;m sharing it here.<p>The AI story (I&#x27;m going to be honest about this):<p>I built this in about three weeks using Claude Code. I know a lot of you will say this is probably vibe coding garbage \u2014 but if that&#x27;s the case, it&#x27;s an impressive pile of vibe coding garbage. Go look at the codebase. The backend is ~80% Rust with 429 unit tests, 33 PostgreSQL migrations, a layered architecture, and a full CI&#x2F;CD pipeline with E2E tests, stress testing, and failure injection.<p>AI didn&#x27;t make the design decisions for me. I still had to design the WASM plugin system, figure out how the scanning engines complement each other, and architect the mesh replication. Years of domain knowledge drove the design \u2014 AI just let me build it way faster. I&#x27;m floored at what these tools make possible for a tinkerer and security nerd like me.<p>Tech stack: Rust on Axum, PostgreSQL 16, Meilisearch, Trivy + Grype + OpenSCAP, Wasmtime WASM plugins (hot-reloadable), mesh replication with chunked transfers. Frontend is Next.js 15 plus native Swift (iOS&#x2F;macOS) and Kotlin (Android) apps. OpenAPI 3.1 spec with auto-generated TypeScript and Rust SDKs.<p>Try it:<p><pre><code>  git clone https:&#x2F;&#x2F;github.com&#x2F;artifact-keeper&#x2F;artifact-keeper.git\n  cd artifact-keeper\n  docker compose up -d\n</code></pre>\nThen visit http:&#x2F;&#x2F;localhost:30080<p>Live demo: <a href=\"https:&#x2F;&#x2F;demo.artifactkeeper.com\" rel=\"nofollow\">https:&#x2F;&#x2F;demo.artifactkeeper.com</a>\nDocs: <a href=\"https:&#x2F;&#x2F;artifactkeeper.com&#x2F;docs&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;artifactkeeper.com&#x2F;docs&#x2F;</a><p>I&#x27;d love any feedback \u2014 what you think of the approach, what you&#x27;d want to see, what you hate about Artifactory or Nexus that you wish someone would just fix. It doesn&#x27;t have to be a PR. Open an issue, start a discussion, or just tell me here.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;artifact-keeper\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;artifact-keeper</a>","title":"Show HN: Artifact Keeper \u2013 Open-Source Artifactory/Nexus Alternative in Rust","updated_at":"2026-02-16T22:52:46Z","url":"https://github.com/artifact-keeper"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"antves"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["how","teams","use","claude","code"],"value":"Hi HN! Smooth CLI (<a href=\"https://www.smooth.sh\">https://www.smooth.sh</a>) is a browser that agents like <em>Claude</em> <em>Code</em> can <em>use</em> to navigate the web reliably, quickly, and affordably. It lets agents specify tasks using natural language, hiding UI complexity, and allowing them to focus on higher-level intents to carry out complex web tasks. It can also <em>use</em> your IP address while running browsers in the cloud, which helps a lot with roadblocks like captchas (<a href=\"https://docs.smooth.sh/features/use-my-ip\">https://docs.smooth.sh/features/<em>use</em>-my-ip</a>).<p>Here\u2019s a demo: <a href=\"https://www.youtube.com/watch?v=62jthcU705k\" rel=\"nofollow\">https://www.youtube.com/watch?v=62jthcU705k</a>  Docs start at <a href=\"https://docs.smooth.sh\">https://docs.smooth.sh</a>.<p>Agents like <em>Claude</em> <em>Code</em>, etc are amazing but mostly restrained to the CLI, while a ton of valuable work needs a browser. This is a fundamental limitation to what these agents can do.<p>So far, attempts to add browsers to these agents (<em>Claude</em>\u2019s built-in --chrome, Playwright MCP, agent-browser, etc.) all have interfaces that are unnatural for browsing. They expose hundreds of tools - e.g. click, type, select, etc - and the action space is too complex. (For an example, see the low-level details listed at <a href=\"https://github.com/vercel-labs/agent-browser\" rel=\"nofollow\">https://github.com/vercel-labs/agent-browser</a>). Also, they don\u2019t handle the billion edge cases of the internet like iframes nested in iframes nested in shadow-doms and so on. The internet is super messy! Tools that rely on the accessibility tree, in particular, unfortunately do not work for a lot of websites.<p>We believe that these tools are at the wrong level of abstraction: they make the agent focus on UI details instead of the task to be accomplished.<p>Using a giant general-purpose model like Opus to click on buttons and fill out forms ends up being slow and expensive. The context window gets bogged down with details like clicks and keystrokes, and the model has to figure out <em>how</em> to do browser navigation each time. A smaller model in a system specifically designed for browsing can actually do this much better and at a fraction of the cost and latency.<p>Security matters too - probably more than people realize. When you run an agent on the web, you should treat it like an untrusted actor. It should access the web using a sandboxed machine and have minimal permissions by default. Virtual browsers are the perfect environment for that. There\u2019s a good write up by Paul Kinlan that explains this very well (see <a href=\"https://aifoc.us/the-browser-is-the-sandbox\" rel=\"nofollow\">https://aifoc.us/the-browser-is-the-sandbox</a> and <a href=\"https://news.ycombinator.com/item?id=46762150\">https://news.ycombinator.com/item?id=46762150</a>). Browsers were built to interact with untrusted software safely. They\u2019re an isolation boundary that already works.<p>Smooth CLI is a browser designed for agents based on what they\u2019re good at. We expose a higher-level interface to let the agent think in <em>terms</em> of goals and tasks, not low-level details.<p>For example, instead of this:<p><pre><code>  click(x=342, y=128)\n  type(&quot;search query&quot;)\n  click(x=401, y=130)\n  scroll(down=500)\n  click(x=220, y=340)\n  ...50 more steps\n</code></pre>\nYour agent just says:<p><pre><code>  Search for flights from NYC to LA and find the cheapest option\n</code></pre>\nAgents like <em>Claude</em> <em>Code</em> can <em>use</em> the Smooth CLI to extract hard-to-reach data, fill-in forms, download files, interact with dynamic content, handle authentication, vibe-test apps, and a lot more.<p>Smooth enables agents to launch as many browsers and tasks as they want, autonomously, and on-demand. If the agent is carrying out work on someone\u2019s behalf, the agent\u2019s browser presents itself to the web as a device on the user\u2019s network. The need for this feature may diminish over time, but for now it\u2019s a necessary primitive. To support this, Smooth offers a \u201cself\u201d proxy that creates a secure tunnel and routes all browser traffic through your machine\u2019s IP address (<a href=\"https://docs.smooth.sh/features/use-my-ip\">https://docs.smooth.sh/features/<em>use</em>-my-ip</a>). This is one of our favorite features because it makes the agent look like it\u2019s running on your machine, while keeping all the benefits of running in the cloud.<p>We also take away as much security responsibility from the agent as possible. The agent should not be aware of authentication details or be responsible for handling malicious behavior such as prompt injections. While some security responsibility will always remain with the agent, the browser should minimize this burden as much as possible.<p>We\u2019re biased of course, but in our tests, running <em>Claude</em> with Smooth CLI has been 20x faster and 5x cheaper than <em>Claude</em> <em>Code</em> with the --chrome flag (<a href=\"https://www.smooth.sh/images/comparison.gif\">https://www.smooth.sh/images/comparison.gif</a>). Happy to explain further <em>how</em> we\u2019ve tested this and to answer any questions about it!<p>Instructions to install: <a href=\"https://docs.smooth.sh/cli\">https://docs.smooth.sh/cli</a>. Plans and pricing: <a href=\"https://docs.smooth.sh/pricing\">https://docs.smooth.sh/pricing</a>.<p>It\u2019s free to try, and we'd love to get feedback/ideas if you give it a go :)<p>We\u2019d love to hear what you think, especially if you\u2019ve tried using browsers with AI agents. Happy to answer questions, dig into tradeoffs, or explain any part of the design and implementation!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Smooth CLI \u2013 Token-efficient browser for AI agents"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://docs.smooth.sh/cli/overview"}},"_tags":["story","author_antves","story_46901233","show_hn"],"author":"antves","children":[46913400,46914704,46915680,46921351,46915565,46922449,46915749,46922098,46922448,46991822,46914060,46918926,46915615,46916157,46917918,46915124,46913274,46915648,46915993,46913203,46913165,46913412],"created_at":"2026-02-05T16:13:33Z","created_at_i":1770308013,"num_comments":73,"objectID":"46901233","points":108,"story_id":46901233,"story_text":"Hi HN! Smooth CLI (<a href=\"https:&#x2F;&#x2F;www.smooth.sh\">https:&#x2F;&#x2F;www.smooth.sh</a>) is a browser that agents like Claude Code can use to navigate the web reliably, quickly, and affordably. It lets agents specify tasks using natural language, hiding UI complexity, and allowing them to focus on higher-level intents to carry out complex web tasks. It can also use your IP address while running browsers in the cloud, which helps a lot with roadblocks like captchas (<a href=\"https:&#x2F;&#x2F;docs.smooth.sh&#x2F;features&#x2F;use-my-ip\">https:&#x2F;&#x2F;docs.smooth.sh&#x2F;features&#x2F;use-my-ip</a>).<p>Here\u2019s a demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=62jthcU705k\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=62jthcU705k</a>  Docs start at <a href=\"https:&#x2F;&#x2F;docs.smooth.sh\">https:&#x2F;&#x2F;docs.smooth.sh</a>.<p>Agents like Claude Code, etc are amazing but mostly restrained to the CLI, while a ton of valuable work needs a browser. This is a fundamental limitation to what these agents can do.<p>So far, attempts to add browsers to these agents (Claude\u2019s built-in --chrome, Playwright MCP, agent-browser, etc.) all have interfaces that are unnatural for browsing. They expose hundreds of tools - e.g. click, type, select, etc - and the action space is too complex. (For an example, see the low-level details listed at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vercel-labs&#x2F;agent-browser\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vercel-labs&#x2F;agent-browser</a>). Also, they don\u2019t handle the billion edge cases of the internet like iframes nested in iframes nested in shadow-doms and so on. The internet is super messy! Tools that rely on the accessibility tree, in particular, unfortunately do not work for a lot of websites.<p>We believe that these tools are at the wrong level of abstraction: they make the agent focus on UI details instead of the task to be accomplished.<p>Using a giant general-purpose model like Opus to click on buttons and fill out forms ends up being slow and expensive. The context window gets bogged down with details like clicks and keystrokes, and the model has to figure out how to do browser navigation each time. A smaller model in a system specifically designed for browsing can actually do this much better and at a fraction of the cost and latency.<p>Security matters too - probably more than people realize. When you run an agent on the web, you should treat it like an untrusted actor. It should access the web using a sandboxed machine and have minimal permissions by default. Virtual browsers are the perfect environment for that. There\u2019s a good write up by Paul Kinlan that explains this very well (see <a href=\"https:&#x2F;&#x2F;aifoc.us&#x2F;the-browser-is-the-sandbox\" rel=\"nofollow\">https:&#x2F;&#x2F;aifoc.us&#x2F;the-browser-is-the-sandbox</a> and <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46762150\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46762150</a>). Browsers were built to interact with untrusted software safely. They\u2019re an isolation boundary that already works.<p>Smooth CLI is a browser designed for agents based on what they\u2019re good at. We expose a higher-level interface to let the agent think in terms of goals and tasks, not low-level details.<p>For example, instead of this:<p><pre><code>  click(x=342, y=128)\n  type(&quot;search query&quot;)\n  click(x=401, y=130)\n  scroll(down=500)\n  click(x=220, y=340)\n  ...50 more steps\n</code></pre>\nYour agent just says:<p><pre><code>  Search for flights from NYC to LA and find the cheapest option\n</code></pre>\nAgents like Claude Code can use the Smooth CLI to extract hard-to-reach data, fill-in forms, download files, interact with dynamic content, handle authentication, vibe-test apps, and a lot more.<p>Smooth enables agents to launch as many browsers and tasks as they want, autonomously, and on-demand. If the agent is carrying out work on someone\u2019s behalf, the agent\u2019s browser presents itself to the web as a device on the user\u2019s network. The need for this feature may diminish over time, but for now it\u2019s a necessary primitive. To support this, Smooth offers a \u201cself\u201d proxy that creates a secure tunnel and routes all browser traffic through your machine\u2019s IP address (<a href=\"https:&#x2F;&#x2F;docs.smooth.sh&#x2F;features&#x2F;use-my-ip\">https:&#x2F;&#x2F;docs.smooth.sh&#x2F;features&#x2F;use-my-ip</a>). This is one of our favorite features because it makes the agent look like it\u2019s running on your machine, while keeping all the benefits of running in the cloud.<p>We also take away as much security responsibility from the agent as possible. The agent should not be aware of authentication details or be responsible for handling malicious behavior such as prompt injections. While some security responsibility will always remain with the agent, the browser should minimize this burden as much as possible.<p>We\u2019re biased of course, but in our tests, running Claude with Smooth CLI has been 20x faster and 5x cheaper than Claude Code with the --chrome flag (<a href=\"https:&#x2F;&#x2F;www.smooth.sh&#x2F;images&#x2F;comparison.gif\">https:&#x2F;&#x2F;www.smooth.sh&#x2F;images&#x2F;comparison.gif</a>). Happy to explain further how we\u2019ve tested this and to answer any questions about it!<p>Instructions to install: <a href=\"https:&#x2F;&#x2F;docs.smooth.sh&#x2F;cli\">https:&#x2F;&#x2F;docs.smooth.sh&#x2F;cli</a>. Plans and pricing: <a href=\"https:&#x2F;&#x2F;docs.smooth.sh&#x2F;pricing\">https:&#x2F;&#x2F;docs.smooth.sh&#x2F;pricing</a>.<p>It\u2019s free to try, and we&#x27;d love to get feedback&#x2F;ideas if you give it a go :)<p>We\u2019d love to hear what you think, especially if you\u2019ve tried using browsers with AI agents. Happy to answer questions, dig into tradeoffs, or explain any part of the design and implementation!","title":"Show HN: Smooth CLI \u2013 Token-efficient browser for AI agents","updated_at":"2026-02-17T01:15:31Z","url":"https://docs.smooth.sh/cli/overview"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"aray07"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["how","teams","use","claude","code"],"value":"Boris Cherny (<em>Claude</em> <em>Code</em> creator) recently dropped a threads on <em>how</em> his <em>team</em> at Anthropic <em>uses</em> <em>Claude</em> <em>Code</em>.<p>The key insight: they don't treat it as a static config. After every correction, they tell <em>Claude</em> &quot;Update your <em>CLAUDE</em>.md so you don't make that mistake again.&quot; <em>Claude</em> writes a rule for itself. They review it, commit it to git. The mistake never happens again.<p>I cross-referenced his tweets with Anthropic's official docs and other best practices for <em>CLAUDE</em>.md and then packaged it into a starter kit:<p><pre><code>  - Fill-in-the-blank templates for Next.js/TypeScript, Python/FastAPI, and a generic\n  catch-all\n  - The workflow patterns his <em>team</em> actually <em>uses</em> (plan mode, verification loops, subagent\n  strategy)\n  - Every claim cited back to the source tweet or doc\n</code></pre>\nRepo: <a href=\"https://github.com/abhishekray07/claude-md-templates\" rel=\"nofollow\">https://github.com/abhishekray07/<em>claude</em>-md-templates</a><p>What's in your <em>CLAUDE</em>.md that's made a measurable difference?"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude"],"value":"Show HN: <em>Claude</em>.md templates based on Boris Cherny's advice"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude"],"value":"https://github.com/abhishekray07/<em>claude</em>-md-templates"}},"_tags":["story","author_aray07","story_46900083","show_hn"],"author":"aray07","created_at":"2026-02-05T14:35:41Z","created_at_i":1770302141,"num_comments":0,"objectID":"46900083","points":10,"story_id":46900083,"story_text":"Boris Cherny (Claude Code creator) recently dropped a threads on how his team at Anthropic uses Claude Code.<p>The key insight: they don&#x27;t treat it as a static config. After every correction, they tell Claude &quot;Update your CLAUDE.md so you don&#x27;t make that mistake again.&quot; Claude writes a rule for itself. They review it, commit it to git. The mistake never happens again.<p>I cross-referenced his tweets with Anthropic&#x27;s official docs and other best practices for CLAUDE.md and then packaged it into a starter kit:<p><pre><code>  - Fill-in-the-blank templates for Next.js&#x2F;TypeScript, Python&#x2F;FastAPI, and a generic\n  catch-all\n  - The workflow patterns his team actually uses (plan mode, verification loops, subagent\n  strategy)\n  - Every claim cited back to the source tweet or doc\n</code></pre>\nRepo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;abhishekray07&#x2F;claude-md-templates\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;abhishekray07&#x2F;claude-md-templates</a><p>What&#x27;s in your CLAUDE.md that&#x27;s made a measurable difference?","title":"Show HN: Claude.md templates based on Boris Cherny's advice","updated_at":"2026-02-12T21:30:32Z","url":"https://github.com/abhishekray07/claude-md-templates"}],"hitsPerPage":10,"nbHits":89,"nbPages":9,"page":0,"params":"query=how+teams+use+Claude+Code&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":22,"processingTimingsMS":{"_request":{"queue":1,"roundTrip":29},"afterFetch":{"format":{"highlighting":1,"total":2}},"fetch":{"query":7,"scanning":14,"total":22},"total":22},"query":"how teams use Claude Code","serverTimeMS":26}
