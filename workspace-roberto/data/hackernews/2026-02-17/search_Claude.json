{"exhaustive":{"nbHits":true,"typo":true},"exhaustiveNbHits":true,"exhaustiveTypo":true,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"CosmoSantoni"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"HiddenState monitors the ML ecosystem every few hours and clusters what it finds by the specific mechanism being worked on. Not by topic. By what constraint is being attacked and by whom alongside a detailed summary with sources.<p>Today it processed over 1,000 items. Three unrelated groups all released web environment simulators for training browsing agents within 24 hours. Curated biological datasets for ML pretraining appeared on PapersWithCode and Bluesky simultaneously from completely different orgs. Three separate papers applied RL to extend reasoning beyond text modalities. If you're working in any of those areas, that convergence matters and it's not something you'd catch from any single feed. Importantly, it gives you an insight into which direction the ML glacier is moving in.<p>Each mechanism is scored 0 to 100 on convergence across independent sources, implementation evidence, engagement, and significance. Orgs are deduplicated so the same lab appearing across platforms doesn't inflate the signal. Most ML aggregators summarize, meanwhile HiddenState acts as a filter. 99% of what it collects gets thrown out.<p>Python, SQLite, <em>Claude</em> for clustering, Cloudflare Pages. Free, no tracking.<p>Let me know if you were aware of any of today's/recent patterns or if you have feedback for improving the site or methodology. Cheers!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: HiddenState \u2013 99% of ML news is noise. This finds the 1%"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://hiddenstate.io/archive/2026-02-17"}},"_tags":["story","author_CosmoSantoni","story_47046912","show_hn"],"author":"CosmoSantoni","children":[47046942],"created_at":"2026-02-17T12:46:51Z","created_at_i":1771332411,"num_comments":1,"objectID":"47046912","points":1,"story_id":47046912,"story_text":"HiddenState monitors the ML ecosystem every few hours and clusters what it finds by the specific mechanism being worked on. Not by topic. By what constraint is being attacked and by whom alongside a detailed summary with sources.<p>Today it processed over 1,000 items. Three unrelated groups all released web environment simulators for training browsing agents within 24 hours. Curated biological datasets for ML pretraining appeared on PapersWithCode and Bluesky simultaneously from completely different orgs. Three separate papers applied RL to extend reasoning beyond text modalities. If you&#x27;re working in any of those areas, that convergence matters and it&#x27;s not something you&#x27;d catch from any single feed. Importantly, it gives you an insight into which direction the ML glacier is moving in.<p>Each mechanism is scored 0 to 100 on convergence across independent sources, implementation evidence, engagement, and significance. Orgs are deduplicated so the same lab appearing across platforms doesn&#x27;t inflate the signal. Most ML aggregators summarize, meanwhile HiddenState acts as a filter. 99% of what it collects gets thrown out.<p>Python, SQLite, Claude for clustering, Cloudflare Pages. Free, no tracking.<p>Let me know if you were aware of any of today&#x27;s&#x2F;recent patterns or if you have feedback for improving the site or methodology. Cheers!","title":"Show HN: HiddenState \u2013 99% of ML news is noise. This finds the 1%","updated_at":"2026-02-17T12:50:33Z","url":"https://hiddenstate.io/archive/2026-02-17"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"everlier"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Hi<p>Agentic coding is rapidly changing our ways of developing software. Not everyone can afford a subscription, though, but they shouldn't be excluded from the process of learning these new tools.<p>Just wanted to share a few tips on running near-frontier agentic coding setup almost for free.<p>1. APIs. Most of the agentic coding tools use two types of APIs - OpenAI or Anthropic compatible. OpenAI is must more common, but Anthropic is associated with <em>Claude</em> Code ecosystem. There are also OSS adapters to convert between the two as needed. Essentially, you need to find providers that serve inference for free.<p>1. OpenRouter. They always have a few models that are completely free at the expense of storing and using everything you send to them. There are frequent promotional periods after new model releases. You need to top up your account by ~$10, though, to avoid rate limits as they are applied based on your balance. After that, ensure to use Model IDs with `:free` postfix and your balance will not be consumed, you can use those indefinitely.<p>2. OpenCode. This is a great agentic harness (albeit its heavily tuned for larger models), its parent company also provides inference APIs. Due to the popularity, many LLM providers offer free tiers of the models there. Same caveat applies - you data will be stored and used.<p>3. Local inference. If you happened to have a ~6-8GB VRAM and ~32GB RAM - then you should be able to run staple ~30B-sized MoE models. GLM-4.7-Flash is currently the best one for using inside a harness, it's even capable enough to drive simple tasks in OpenCode, but I recommend simpler harnesses for better results.<p>4. What to expect. Most of these offerings come with a compromise in terms of data collection and/or inference quality. For example, OpenCode's free Kimi 2.5 is clearly different from the paid one from official provider. In general - do not trust any claims that compare smaller open weight models with the cloud offering, they are not there yet. However you can get really far and models like Kimi 2.5 are still very capable.<p>Thanks!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Tell HN: Tips for (mostly) free agentic coding setup"}},"_tags":["story","author_everlier","story_47046601","ask_hn"],"author":"everlier","children":[47046611],"created_at":"2026-02-17T12:05:12Z","created_at_i":1771329912,"num_comments":1,"objectID":"47046601","points":1,"story_id":47046601,"story_text":"Hi<p>Agentic coding is rapidly changing our ways of developing software. Not everyone can afford a subscription, though, but they shouldn&#x27;t be excluded from the process of learning these new tools.<p>Just wanted to share a few tips on running near-frontier agentic coding setup almost for free.<p>1. APIs. Most of the agentic coding tools use two types of APIs - OpenAI or Anthropic compatible. OpenAI is must more common, but Anthropic is associated with Claude Code ecosystem. There are also OSS adapters to convert between the two as needed. Essentially, you need to find providers that serve inference for free.<p>1. OpenRouter. They always have a few models that are completely free at the expense of storing and using everything you send to them. There are frequent promotional periods after new model releases. You need to top up your account by ~$10, though, to avoid rate limits as they are applied based on your balance. After that, ensure to use Model IDs with `:free` postfix and your balance will not be consumed, you can use those indefinitely.<p>2. OpenCode. This is a great agentic harness (albeit its heavily tuned for larger models), its parent company also provides inference APIs. Due to the popularity, many LLM providers offer free tiers of the models there. Same caveat applies - you data will be stored and used.<p>3. Local inference. If you happened to have a ~6-8GB VRAM and ~32GB RAM - then you should be able to run staple ~30B-sized MoE models. GLM-4.7-Flash is currently the best one for using inside a harness, it&#x27;s even capable enough to drive simple tasks in OpenCode, but I recommend simpler harnesses for better results.<p>4. What to expect. Most of these offerings come with a compromise in terms of data collection and&#x2F;or inference quality. For example, OpenCode&#x27;s free Kimi 2.5 is clearly different from the paid one from official provider. In general - do not trust any claims that compare smaller open weight models with the cloud offering, they are not there yet. However you can get really far and models like Kimi 2.5 are still very capable.<p>Thanks!","title":"Tell HN: Tips for (mostly) free agentic coding setup","updated_at":"2026-02-17T12:07:32Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ath_ray"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Codex CLI vs. <em>Claude</em> Code on Autonomy"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"https://blog.nilenso.com/blog/2026/02/12/codex-cli-vs-<em>claude</em>-code-on-autonomy/"}},"_tags":["story","author_ath_ray","story_47046580"],"author":"ath_ray","created_at":"2026-02-17T12:01:04Z","created_at_i":1771329664,"num_comments":0,"objectID":"47046580","points":1,"story_id":47046580,"title":"Codex CLI vs. Claude Code on Autonomy","updated_at":"2026-02-17T12:02:17Z","url":"https://blog.nilenso.com/blog/2026/02/12/codex-cli-vs-claude-code-on-autonomy/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"superproton"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Hey HN! I'm Fran, a full-stack dev working on this as a side project.\nThe problem: I've been building SaaS products and the feedback loop is broken. Feature requests come in through Slack DMs, support tickets, emails, Twitter \u2014 everywhere except somewhere useful. By the time you look at them, half are duplicates and the rest have no signal on priority.\nSo I built <em>Plaude</em>ra \u2014 a public feedback board with voting, an embeddable widget, and AI-powered duplicate detection.\nThe AI part is practical, not flashy: when someone submits &quot;add night theme option&quot; and you already have &quot;dark mode support&quot; with 24 votes, it catches that and suggests a merge. Keeps the board clean without manual triage.\nStack: Next.js, TypeScript, PostgreSQL. The widget is a lightweight embed \u2014 single script tag, no framework dependency.\nCurrently offering lifetime deals at $49 while I'm in early growth mode.\nHappy to answer any questions about the tech, the AI dedup approach, or the indie SaaS journey. Also genuinely looking for feedback \u2014 I eat my own dog food, so <em>Plaude</em>ra's own feedback board is at feedback.<em>plaude</em>ra.com."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: I turn scattered feedback into a prioritized roadmap in 5 min"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"https://<em>plaude</em>ra.com"}},"_tags":["story","author_superproton","story_47046372","show_hn"],"author":"superproton","children":[47046623],"created_at":"2026-02-17T11:34:06Z","created_at_i":1771328046,"num_comments":1,"objectID":"47046372","points":2,"story_id":47046372,"story_text":"Hey HN! I&#x27;m Fran, a full-stack dev working on this as a side project.\nThe problem: I&#x27;ve been building SaaS products and the feedback loop is broken. Feature requests come in through Slack DMs, support tickets, emails, Twitter \u2014 everywhere except somewhere useful. By the time you look at them, half are duplicates and the rest have no signal on priority.\nSo I built Plaudera \u2014 a public feedback board with voting, an embeddable widget, and AI-powered duplicate detection.\nThe AI part is practical, not flashy: when someone submits &quot;add night theme option&quot; and you already have &quot;dark mode support&quot; with 24 votes, it catches that and suggests a merge. Keeps the board clean without manual triage.\nStack: Next.js, TypeScript, PostgreSQL. The widget is a lightweight embed \u2014 single script tag, no framework dependency.\nCurrently offering lifetime deals at $49 while I&#x27;m in early growth mode.\nHappy to answer any questions about the tech, the AI dedup approach, or the indie SaaS journey. Also genuinely looking for feedback \u2014 I eat my own dog food, so Plaudera&#x27;s own feedback board is at feedback.plaudera.com.","title":"Show HN: I turn scattered feedback into a prioritized roadmap in 5 min","updated_at":"2026-02-17T12:08:03Z","url":"https://plaudera.com"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"LowResBudget"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Hi. Poor developer here.<p>I'm trying to learn AI coding (already have multiple years experience with &quot;normal&quot; programming in various languages.) I want to know how to make my budget (about $30/month) go furthest.<p>At the moment, I am using:<p>Z.ai $6/month plan:<p>Ok model (GLM 4.7) It seems to rate limit/throttle aggressively if I use it a lot.<p>and<p>Github copilot $10/month plan:<p>Seems to reduce model context to 100k tokens, and only offers unlimited access to smaller model (GPT5-mini, Grok Code Fast 1 etc). These models are ok for making precise edits to specific code, but they seem to get stuck when the program is large and has a lot of concurrency etc.<p>I also have free plans for web/mobile-chat for every model I can find.<p>I only have older computers, so editors like Cursor or Antigravity are too slow to be usable. So I prefer something that can work with a CLI (opencode preferably).<p>Do I already have the best deal? Or is there something I am missing. When I try to compare plans, it is confusing and they are not often clear about actual usage limits.<p>Are Codex or <em>Claude</em> even options at this price point if I want to code for multiple hours per day?"},"title":{"matchLevel":"none","matchedWords":[],"value":"Ask HN: What is the best bang for buck budget AI coding?"}},"_tags":["story","author_LowResBudget","story_47046139","ask_hn"],"author":"LowResBudget","children":[47046370,47046162],"created_at":"2026-02-17T11:08:37Z","created_at_i":1771326517,"num_comments":2,"objectID":"47046139","points":1,"story_id":47046139,"story_text":"Hi. Poor developer here.<p>I&#x27;m trying to learn AI coding (already have multiple years experience with &quot;normal&quot; programming in various languages.) I want to know how to make my budget (about $30&#x2F;month) go furthest.<p>At the moment, I am using:<p>Z.ai $6&#x2F;month plan:<p>Ok model (GLM 4.7) It seems to rate limit&#x2F;throttle aggressively if I use it a lot.<p>and<p>Github copilot $10&#x2F;month plan:<p>Seems to reduce model context to 100k tokens, and only offers unlimited access to smaller model (GPT5-mini, Grok Code Fast 1 etc). These models are ok for making precise edits to specific code, but they seem to get stuck when the program is large and has a lot of concurrency etc.<p>I also have free plans for web&#x2F;mobile-chat for every model I can find.<p>I only have older computers, so editors like Cursor or Antigravity are too slow to be usable. So I prefer something that can work with a CLI (opencode preferably).<p>Do I already have the best deal? Or is there something I am missing. When I try to compare plans, it is confusing and they are not often clear about actual usage limits.<p>Are Codex or Claude even options at this price point if I want to code for multiple hours per day?","title":"Ask HN: What is the best bang for buck budget AI coding?","updated_at":"2026-02-17T11:34:33Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"spooneybarger"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Teaching <em>Claude</em> to Write Pony"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"https://www.ponylang.io/blog/2026/02/teaching-<em>claude</em>-to-write-pony/"}},"_tags":["story","author_spooneybarger","story_47046132"],"author":"spooneybarger","children":[47046271],"created_at":"2026-02-17T11:07:53Z","created_at_i":1771326473,"num_comments":1,"objectID":"47046132","points":3,"story_id":47046132,"title":"Teaching Claude to Write Pony","updated_at":"2026-02-17T11:51:48Z","url":"https://www.ponylang.io/blog/2026/02/teaching-claude-to-write-pony/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"atfzl"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Stop Using Lovable for Prototyping \u2013 Use Storybook and <em>Claude</em> Instead"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"https://atfzl.com/stop-using-lovable-for-prototyping-use-storybook-<em>claude</em>-instead/"}},"_tags":["story","author_atfzl","story_47045823"],"author":"atfzl","created_at":"2026-02-17T10:31:06Z","created_at_i":1771324266,"num_comments":0,"objectID":"47045823","points":1,"story_id":47045823,"title":"Stop Using Lovable for Prototyping \u2013 Use Storybook and Claude Instead","updated_at":"2026-02-17T10:33:02Z","url":"https://atfzl.com/stop-using-lovable-for-prototyping-use-storybook-claude-instead/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"localforthewin"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Built because AI coding assistants burn massive context window reading entire files to answer structural questions.<p>mcp-codebase-index parses your codebase into functions, classes, imports, and dependency graphs, then exposes 17 query tools via MCP.<p>Measured results: 58-99% token reduction per query (87% average). In multi-turn conversations, 97%+ cumulative savings.<p>Zero dependencies (stdlib ast + regex). Works with <em>Claude</em> Code, Cursor, and any MCP client.<p><pre><code>  pip install &quot;mcp-codebase-index[mcp]&quot;</code></pre>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: MCP Codebase Index \u2013 87% fewer tokens when AI navigates your codebase"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/MikeRecognex/mcp-codebase-index"}},"_tags":["story","author_localforthewin","story_47045572","show_hn"],"author":"localforthewin","children":[47045585],"created_at":"2026-02-17T09:56:07Z","created_at_i":1771322167,"num_comments":0,"objectID":"47045572","points":1,"story_id":47045572,"story_text":"Built because AI coding assistants burn massive context window reading entire files to answer structural questions.<p>mcp-codebase-index parses your codebase into functions, classes, imports, and dependency graphs, then exposes 17 query tools via MCP.<p>Measured results: 58-99% token reduction per query (87% average). In multi-turn conversations, 97%+ cumulative savings.<p>Zero dependencies (stdlib ast + regex). Works with Claude Code, Cursor, and any MCP client.<p><pre><code>  pip install &quot;mcp-codebase-index[mcp]&quot;</code></pre>","title":"Show HN: MCP Codebase Index \u2013 87% fewer tokens when AI navigates your codebase","updated_at":"2026-02-17T10:14:02Z","url":"https://github.com/MikeRecognex/mcp-codebase-index"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"jeffchoi"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"I built an MCP server that lets AI assistants (<em>Claude</em>, Cursor, etc.) query multiple databases through a single, unified interface.<p>While using <em>Claude</em> Code, I found it painful to manage separate connections for MySQL, MongoDB, and AWS Athena. So I\nbuilt a server that provides one consistent set of tools (query, list_collections, describe_collection, etc.) that\nwork the same way across all supported databases.<p>Key features:\n- Read-only by default \u2013 Write access requires explicit opt-in, so you won't accidentally mutate production data\n- Multiple simultaneous connections \u2013 Tag them as PROD, STAGING, ANALYTICS, etc. and manage them all at once\n- Extensible \u2013 Add new database connectors by implementing the McpConnector interface<p>Built with TypeScript. Supports MySQL 5.7+, MongoDB 4.4+, and AWS Athena.<p>This is an open-source project \u2013 feedback, issues, and PRs are all welcome. If you try it out and have any\nsuggestions or ideas for improvement, please feel free to share!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: MCP Storage Map \u2013 One MCP Server for MySQL, MongoDB, and Athena"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/cyhoon/mcp-storage-map"}},"_tags":["story","author_jeffchoi","story_47045460","show_hn"],"author":"jeffchoi","created_at":"2026-02-17T09:39:10Z","created_at_i":1771321150,"num_comments":0,"objectID":"47045460","points":1,"story_id":47045460,"story_text":"I built an MCP server that lets AI assistants (Claude, Cursor, etc.) query multiple databases through a single, unified interface.<p>While using Claude Code, I found it painful to manage separate connections for MySQL, MongoDB, and AWS Athena. So I\nbuilt a server that provides one consistent set of tools (query, list_collections, describe_collection, etc.) that\nwork the same way across all supported databases.<p>Key features:\n- Read-only by default \u2013 Write access requires explicit opt-in, so you won&#x27;t accidentally mutate production data\n- Multiple simultaneous connections \u2013 Tag them as PROD, STAGING, ANALYTICS, etc. and manage them all at once\n- Extensible \u2013 Add new database connectors by implementing the McpConnector interface<p>Built with TypeScript. Supports MySQL 5.7+, MongoDB 4.4+, and AWS Athena.<p>This is an open-source project \u2013 feedback, issues, and PRs are all welcome. If you try it out and have any\nsuggestions or ideas for improvement, please feel free to share!","title":"Show HN: MCP Storage Map \u2013 One MCP Server for MySQL, MongoDB, and Athena","updated_at":"2026-02-17T09:40:32Z","url":"https://github.com/cyhoon/mcp-storage-map"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"velmu"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Lessons learned from rebuilding a 19-year-old platform in one week with <em>Claude</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://gist.github.com/janit/6559e97ceb00e444b9aecb3c00dfdf16"}},"_tags":["story","author_velmu","story_47045052"],"author":"velmu","created_at":"2026-02-17T08:34:46Z","created_at_i":1771317286,"num_comments":0,"objectID":"47045052","points":2,"story_id":47045052,"title":"Lessons learned from rebuilding a 19-year-old platform in one week with Claude","updated_at":"2026-02-17T09:32:47Z","url":"https://gist.github.com/janit/6559e97ceb00e444b9aecb3c00dfdf16"}],"hitsPerPage":10,"nbHits":10217,"nbPages":100,"page":0,"params":"query=Claude&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":9,"processingTimingsMS":{"_request":{"roundTrip":21},"fetch":{"query":1,"scanning":6,"total":8},"total":9},"query":"Claude","serverTimeMS":10}
