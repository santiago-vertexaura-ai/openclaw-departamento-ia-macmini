{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"theaniketgiri"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"I realized something uncomfortable while running agents in production:<p>APIs authenticate the process making a request.<p>But with LLM agents, the process no longer decides the request \u2014 the <em>model</em> does.<p>So when an agent is prompt-injected or misaligned, authentication still succeeds.\nThe system verifies who executed the call, not who chose it.<p>Rotating keys or adding revocation checks doesn\u2019t fix this.\nYou\u2019re still trusting the wrapper while the decision lives inside the <em>model</em>.<p>The missing primitive isn\u2019t stronger identity \u2014 it\u2019s verifying the action itself.<p>In a typical backend system:<p>service \u2192 calls API\nauth verifies which process made the call<p>This works because the process contains the decision logic.<p>With agents:<p><em>model</em> decides the action \u2192 process just executes it<p>So authentication still proves who called\nbut no longer proves who decided<p>If an agent is compromised (prompt injection, tool misuse, leaked <em>context</em>), rotating API keys or checking revocation lists doesn\u2019t actually solve the problem \u2014 the system still trusts the process identity while the decision authority lives inside the <em>model</em>.<p>What we needed was verification of the action itself.<p>I built a small <em>protocol</em> where every side-effect requires a signed \u201cintent\u201d.<p>Each agent has a keypair.\nEvery tool call carries a signature over:<p>action<p>parameters<p>timestamp<p>nonce (replay protection)<p>declared capabilities<p>Verification is local (Ed25519, &lt;1ms).\nServices don\u2019t call an auth server \u2014 they verify the intent.<p>Revocation is async: services subscribe to key invalidation events, but verification still works offline.<p>Example:<p>from aip_<em>protocol</em> import shield<p>@shield(actions=[&quot;read_db&quot;,&quot;send_email&quot;])\nclass SupportAgent:\n    def handle_ticket(self, ticket_id):\n        ...<p>If the agent attempts an undeclared action, the call is rejected before execution.<p>Tradeoffs:<p>more complex than API keys (key management)<p>doesn\u2019t stop prompt injection, only limits consequences<p>requires thinking in capabilities instead of identities<p>I\u2019m trying to figure out if this is actually a missing primitive for agent systems or unnecessary complexity.<p>Repo:\n<a href=\"https://github.com/theaniketgiri/aip\" rel=\"nofollow\">https://github.com/theaniketgiri/aip</a><p>Spec:\n<a href=\"https://github.com/theaniketgiri/aip/blob/master/RFC-001.md\" rel=\"nofollow\">https://github.com/theaniketgiri/aip/blob/master/RFC-001.md</a><p>Would especially like feedback from people running agents beyond demos."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["protocol"],"value":"Show HN:AIP <em>Protocol</em>\u2013Solving the agent revocation problem in distributed systems"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/theaniketgiri/aip"}},"_tags":["story","author_theaniketgiri","story_47036121","show_hn"],"author":"theaniketgiri","created_at":"2026-02-16T15:19:19Z","created_at_i":1771255159,"num_comments":0,"objectID":"47036121","points":1,"story_id":47036121,"story_text":"I realized something uncomfortable while running agents in production:<p>APIs authenticate the process making a request.<p>But with LLM agents, the process no longer decides the request \u2014 the model does.<p>So when an agent is prompt-injected or misaligned, authentication still succeeds.\nThe system verifies who executed the call, not who chose it.<p>Rotating keys or adding revocation checks doesn\u2019t fix this.\nYou\u2019re still trusting the wrapper while the decision lives inside the model.<p>The missing primitive isn\u2019t stronger identity \u2014 it\u2019s verifying the action itself.<p>In a typical backend system:<p>service \u2192 calls API\nauth verifies which process made the call<p>This works because the process contains the decision logic.<p>With agents:<p>model decides the action \u2192 process just executes it<p>So authentication still proves who called\nbut no longer proves who decided<p>If an agent is compromised (prompt injection, tool misuse, leaked context), rotating API keys or checking revocation lists doesn\u2019t actually solve the problem \u2014 the system still trusts the process identity while the decision authority lives inside the model.<p>What we needed was verification of the action itself.<p>I built a small protocol where every side-effect requires a signed \u201cintent\u201d.<p>Each agent has a keypair.\nEvery tool call carries a signature over:<p>action<p>parameters<p>timestamp<p>nonce (replay protection)<p>declared capabilities<p>Verification is local (Ed25519, &lt;1ms).\nServices don\u2019t call an auth server \u2014 they verify the intent.<p>Revocation is async: services subscribe to key invalidation events, but verification still works offline.<p>Example:<p>from aip_protocol import shield<p>@shield(actions=[&quot;read_db&quot;,&quot;send_email&quot;])\nclass SupportAgent:\n    def handle_ticket(self, ticket_id):\n        ...<p>If the agent attempts an undeclared action, the call is rejected before execution.<p>Tradeoffs:<p>more complex than API keys (key management)<p>doesn\u2019t stop prompt injection, only limits consequences<p>requires thinking in capabilities instead of identities<p>I\u2019m trying to figure out if this is actually a missing primitive for agent systems or unnecessary complexity.<p>Repo:\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;theaniketgiri&#x2F;aip\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;theaniketgiri&#x2F;aip</a><p>Spec:\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;theaniketgiri&#x2F;aip&#x2F;blob&#x2F;master&#x2F;RFC-001.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;theaniketgiri&#x2F;aip&#x2F;blob&#x2F;master&#x2F;RFC-001.md</a><p>Would especially like feedback from people running agents beyond demos.","title":"Show HN:AIP Protocol\u2013Solving the agent revocation problem in distributed systems","updated_at":"2026-02-16T16:07:15Z","url":"https://github.com/theaniketgiri/aip"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"I\u2019ve been working on PolyMCP, an open-source framework designed to make it easier to build and coordinate agents using the <em>Model</em> <em>Context</em> <em>Protocol</em> (MCP).<p>Most MCP tooling today focuses primarily on exposing tools. PolyMCP instead targets the agent layer: how to structure agents properly, connect them to multiple MCP servers, and make them reliable in real-world workflows.<p>PolyMCP provides:\n \u2022 A clean way to implement MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for handling multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular architecture that makes it easier to compose skills and reuse components across projects<p>The goal is to reduce ad-hoc glue code between models and tools. Instead of manually wiring everything together for each new setup, PolyMCP offers a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Attach them to one or more agents\n \u2022 Explicitly manage execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and aimed at developers building production-grade automation, internal copilots, or multi-tool assistants.<p>Repository: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PolyMCP \u2013 A framework for structuring and orchestrating MCP agents"}},"_tags":["story","author_justvugg","story_47026179","show_hn"],"author":"justvugg","created_at":"2026-02-15T18:40:05Z","created_at_i":1771180805,"num_comments":0,"objectID":"47026179","points":1,"story_id":47026179,"story_text":"I\u2019ve been working on PolyMCP, an open-source framework designed to make it easier to build and coordinate agents using the Model Context Protocol (MCP).<p>Most MCP tooling today focuses primarily on exposing tools. PolyMCP instead targets the agent layer: how to structure agents properly, connect them to multiple MCP servers, and make them reliable in real-world workflows.<p>PolyMCP provides:\n \u2022 A clean way to implement MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for handling multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular architecture that makes it easier to compose skills and reuse components across projects<p>The goal is to reduce ad-hoc glue code between models and tools. Instead of manually wiring everything together for each new setup, PolyMCP offers a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Attach them to one or more agents\n \u2022 Explicitly manage execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and aimed at developers building production-grade automation, internal copilots, or multi-tool assistants.<p>Repository: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a>","title":"Show HN: PolyMCP \u2013 A framework for structuring and orchestrating MCP agents","updated_at":"2026-02-15T18:40:57Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"Hi everyone,<p>I\u2019ve been working on PolyMCP, an open-source framework for building and orchestrating agents using the <em>Model</em> <em>Context</em> <em>Protocol</em> (MCP).<p>Most of the tooling around MCP focuses on exposing tools. With PolyMCP, the focus this time is on agents: how to structure them, connect them to multiple MCP servers, and make them reliable in real workflows.<p>PolyMCP provides:\n \u2022 A clean way to define MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular structure that makes it easier to compose skills and reuse components across projects<p>The main goal is to make agent systems less ad-hoc. Instead of writing glue code around each <em>model</em> + tool combination, PolyMCP gives you a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Connect them to one or more agents\n \u2022 Control execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and intended for developers building real-world automation, internal copilots, or multi-tool assistants.<p>I\u2019d love feedback on:\n \u2022 The agent abstraction: is it too opinionated or not opinionated enough?\n \u2022 Orchestration patterns for multi-agent setups\n \u2022 Developer experience (CLI, inspector, project layout)<p>Happy to answer questions."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PolyMCP \u2013 A framework for building and orchestrating MCP agents"}},"_tags":["story","author_justvugg","story_47017912","show_hn"],"author":"justvugg","children":[47017997],"created_at":"2026-02-14T20:11:10Z","created_at_i":1771099870,"num_comments":2,"objectID":"47017912","points":3,"story_id":47017912,"story_text":"Hi everyone,<p>I\u2019ve been working on PolyMCP, an open-source framework for building and orchestrating agents using the Model Context Protocol (MCP).<p>Most of the tooling around MCP focuses on exposing tools. With PolyMCP, the focus this time is on agents: how to structure them, connect them to multiple MCP servers, and make them reliable in real workflows.<p>PolyMCP provides:\n \u2022 A clean way to define MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular structure that makes it easier to compose skills and reuse components across projects<p>The main goal is to make agent systems less ad-hoc. Instead of writing glue code around each model + tool combination, PolyMCP gives you a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Connect them to one or more agents\n \u2022 Control execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and intended for developers building real-world automation, internal copilots, or multi-tool assistants.<p>I\u2019d love feedback on:\n \u2022 The agent abstraction: is it too opinionated or not opinionated enough?\n \u2022 Orchestration patterns for multi-agent setups\n \u2022 Developer experience (CLI, inspector, project layout)<p>Happy to answer questions.","title":"Show HN: PolyMCP \u2013 A framework for building and orchestrating MCP agents","updated_at":"2026-02-16T17:09:32Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"L3nnox_Cc"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"Hey HN,<p>I built Engram because every time I started a new Claude Code session, it forgot everything. Same questions, same mistakes, zero <em>context</em>. AI agents have Alzheimer.<p>Engram is a memory layer for AI agents. Store facts, preferences, and decisions. Search them with full-text search. Recall the most important ones for <em>context</em> injection. 5 lines of Python, zero config.<p><pre><code>  from engram import Memory\n  mem = Memory()\n  mem.store(&quot;User prefers dark mode&quot;, importance=8)\n  results = mem.search(&quot;dark mode&quot;)\n  <em>context</em> = mem.recall(limit=10)\n</code></pre>\nWhat makes it different from Mem0/Letta/Zep:<p>Local-first: SQLite, runs on your machine. No cloud, no API keys, no telemetry.<p>Zero config: pip install engram-core and go. No Docker, no Postgres, no vector DB.<p>MCP native: First-class <em>Model</em> <em>Context</em> <em>Protocol</em> support \u2014 plug into Claude Code, Cursor, or any MCP client.<p>Privacy: Your data never leaves your machine. MIT licensed.<p>I use it daily with Claude Code via an auto-recall hook \u2014 every new session starts with my important memories pre-loaded. No more &quot;where were we?&quot;<p>Built with: Python, SQLite FTS5, FastAPI, MCP SDK.<p>Website: <a href=\"https://engram-ai.dev\" rel=\"nofollow\">https://engram-ai.dev</a><p>GitHub: <a href=\"https://github.com/engram-memory/engram\" rel=\"nofollow\">https://github.com/engram-memory/engram</a><p>PyPI: pip install engram-core<p>Would love feedback. What memory features would you want for your agents?"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Engram \u2013 Persistent memory for AI agents, local-first and open source"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://engram-ai.dev"}},"_tags":["story","author_L3nnox_Cc","story_47008274","show_hn"],"author":"L3nnox_Cc","created_at":"2026-02-13T21:46:53Z","created_at_i":1771019213,"num_comments":0,"objectID":"47008274","points":3,"story_id":47008274,"story_text":"Hey HN,<p>I built Engram because every time I started a new Claude Code session, it forgot everything. Same questions, same mistakes, zero context. AI agents have Alzheimer.<p>Engram is a memory layer for AI agents. Store facts, preferences, and decisions. Search them with full-text search. Recall the most important ones for context injection. 5 lines of Python, zero config.<p><pre><code>  from engram import Memory\n  mem = Memory()\n  mem.store(&quot;User prefers dark mode&quot;, importance=8)\n  results = mem.search(&quot;dark mode&quot;)\n  context = mem.recall(limit=10)\n</code></pre>\nWhat makes it different from Mem0&#x2F;Letta&#x2F;Zep:<p>Local-first: SQLite, runs on your machine. No cloud, no API keys, no telemetry.<p>Zero config: pip install engram-core and go. No Docker, no Postgres, no vector DB.<p>MCP native: First-class Model Context Protocol support \u2014 plug into Claude Code, Cursor, or any MCP client.<p>Privacy: Your data never leaves your machine. MIT licensed.<p>I use it daily with Claude Code via an auto-recall hook \u2014 every new session starts with my important memories pre-loaded. No more &quot;where were we?&quot;<p>Built with: Python, SQLite FTS5, FastAPI, MCP SDK.<p>Website: <a href=\"https:&#x2F;&#x2F;engram-ai.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;engram-ai.dev</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;engram-memory&#x2F;engram\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;engram-memory&#x2F;engram</a><p>PyPI: pip install engram-core<p>Would love feedback. What memory features would you want for your agents?","title":"Show HN: Engram \u2013 Persistent memory for AI agents, local-first and open source","updated_at":"2026-02-13T22:09:51Z","url":"https://engram-ai.dev"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"orbydx"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"I built 75 developer and AI tools as a single static site. Everything runs in the browser, no cookies, no ads, nothing gets sent to a server.<p>The tools range from the usual suspects (JSON formatter, base64 encoder, regex tester) to some AI-specific ones I couldn't find good free versions of bundled in one suite:<p>- LLM Token Counter (estimates tokens for GPT, Claude, Gemini, etc.)\n- AI <em>Model</em> Comparison (specs, pricing, <em>context</em> windows side by side)\n- AI Cost Estimator (plug in your usage, get monthly cost projections)\n- MCP Server Directory (browsable catalog of <em>Model</em> <em>Context</em> <em>Protocol</em> servers)\n- Agent Framework Comparison (LangChain vs CrewAI vs AutoGen vs...)\n- Prompt Template Builder (variables, conditionals, versioning)\n- Markdown Memory Generator (for OpenClaw)<p>Plus the standard dev toolkit: JWT decoder, cron expression builder, diff checker, SQL formatter, color converter, CSS flexbox playground, etc.<p>Tech stack: Astro 5 with React islands, Tailwind CSS 4, hosted on Cloudflare Pages. The whole site is static, so it loads fast everywhere. Largest JS bundle is 58 KB gzipped.<p>I built this with AI agent Rusty (OpenClaw). The AI handled most of the component code while I focused on architecture decisions, tool selection, and QA. Took about 2 days of evening sessions.<p>No login, no tracking cookies, no ads, no &quot;sign up for premium&quot;. Just tools.<p>Feedback welcome. What ai or dev tools do you wish existed that don't?"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: AI Dev Hub. 75 free AI and dev tools"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://aidevhub.io/"}},"_tags":["story","author_orbydx","story_47003685","show_hn"],"author":"orbydx","created_at":"2026-02-13T15:20:44Z","created_at_i":1770996044,"num_comments":0,"objectID":"47003685","points":1,"story_id":47003685,"story_text":"I built 75 developer and AI tools as a single static site. Everything runs in the browser, no cookies, no ads, nothing gets sent to a server.<p>The tools range from the usual suspects (JSON formatter, base64 encoder, regex tester) to some AI-specific ones I couldn&#x27;t find good free versions of bundled in one suite:<p>- LLM Token Counter (estimates tokens for GPT, Claude, Gemini, etc.)\n- AI Model Comparison (specs, pricing, context windows side by side)\n- AI Cost Estimator (plug in your usage, get monthly cost projections)\n- MCP Server Directory (browsable catalog of Model Context Protocol servers)\n- Agent Framework Comparison (LangChain vs CrewAI vs AutoGen vs...)\n- Prompt Template Builder (variables, conditionals, versioning)\n- Markdown Memory Generator (for OpenClaw)<p>Plus the standard dev toolkit: JWT decoder, cron expression builder, diff checker, SQL formatter, color converter, CSS flexbox playground, etc.<p>Tech stack: Astro 5 with React islands, Tailwind CSS 4, hosted on Cloudflare Pages. The whole site is static, so it loads fast everywhere. Largest JS bundle is 58 KB gzipped.<p>I built this with AI agent Rusty (OpenClaw). The AI handled most of the component code while I focused on architecture decisions, tool selection, and QA. Took about 2 days of evening sessions.<p>No login, no tracking cookies, no ads, no &quot;sign up for premium&quot;. Just tools.<p>Feedback welcome. What ai or dev tools do you wish existed that don&#x27;t?","title":"Show HN: AI Dev Hub. 75 free AI and dev tools","updated_at":"2026-02-13T15:22:05Z","url":"https://aidevhub.io/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"intheleantime"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"I built an MCP server that connects coding agents (Claude Code, Cursor, OpenCode, Codex) to a collaborative workspace where your team and other AI <em>models</em> can review what the agent is planning.<p>The problem: When Claude Code creates an implementation plan, it lives in your terminal session. Nobody else sees it until it becomes a PR. If you want GPT to check the architecture or a teammate to flag issues, you're copy-pasting between windows.<p>This MCP server fixes that. When your agent creates a plan, it gets shared as a collaborative thread in CoChat. Engineers comment on it, other AI <em>models</em> review it, and you pull all the feedback back into your agent's <em>context</em> with one command. Decisions can be saved as project memories that persist across sessions and are searchable by anyone.<p>What it does:<p>Plans: Auto-shared as collaborative threads. Pull feedback back into your terminal.\nCross-<em>model</em> review: Have GPT review your Claude plan, or vice versa.\nProject memories: Semantic memory that persists across sessions, <em>models</em>, and people.\nAsk: Query your project's knowledge base from the terminal.\nAuto-scoping: Detects your project from git remote. No config needed.\nSetup is one command per agent. Auto-share behavior is configurable (off/plan/all).<p>MIT licensed, available on npm: npx @cochatai/mcp-cochat<p>Happy to answer questions about the architecture or the MCP <em>protocol</em> integration."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: CoChat MCP \u2013 Let your team review what your coding agent is building"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/CoChatAI/mcp-cochat"}},"_tags":["story","author_intheleantime","story_47002924","show_hn"],"author":"intheleantime","created_at":"2026-02-13T14:11:40Z","created_at_i":1770991900,"num_comments":0,"objectID":"47002924","points":5,"story_id":47002924,"story_text":"I built an MCP server that connects coding agents (Claude Code, Cursor, OpenCode, Codex) to a collaborative workspace where your team and other AI models can review what the agent is planning.<p>The problem: When Claude Code creates an implementation plan, it lives in your terminal session. Nobody else sees it until it becomes a PR. If you want GPT to check the architecture or a teammate to flag issues, you&#x27;re copy-pasting between windows.<p>This MCP server fixes that. When your agent creates a plan, it gets shared as a collaborative thread in CoChat. Engineers comment on it, other AI models review it, and you pull all the feedback back into your agent&#x27;s context with one command. Decisions can be saved as project memories that persist across sessions and are searchable by anyone.<p>What it does:<p>Plans: Auto-shared as collaborative threads. Pull feedback back into your terminal.\nCross-model review: Have GPT review your Claude plan, or vice versa.\nProject memories: Semantic memory that persists across sessions, models, and people.\nAsk: Query your project&#x27;s knowledge base from the terminal.\nAuto-scoping: Detects your project from git remote. No config needed.\nSetup is one command per agent. Auto-share behavior is configurable (off&#x2F;plan&#x2F;all).<p>MIT licensed, available on npm: npx @cochatai&#x2F;mcp-cochat<p>Happy to answer questions about the architecture or the MCP protocol integration.","title":"Show HN: CoChat MCP \u2013 Let your team review what your coding agent is building","updated_at":"2026-02-13T19:20:05Z","url":"https://github.com/CoChatAI/mcp-cochat"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"hacker27369"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"I spent the last few years in High-Frequency Trading. In that world, &quot;probabilistic&quot; automation is a non-starter; if an AI hallucinations or clicks the wrong pixel, it's a compliance disaster.\nMost current AI agents rely on vision (pixels). It\u2019s slow, brittle, and introduces a massive margin of error. I built GodHands to treat desktop apps like structured APIs instead of screenshots. It\u2019s an MCP (<em>Model</em> <em>Context</em> <em>Protocol</em>) server that acts as a deterministic &quot;action layer.&quot;<p>The Approach:<p>Object <em>Model</em> &gt; Pixels: Instead of vision, the engine hooks into application object models directly. It maps data structures dynamically so the automation doesn't break when the UI changes.<p>Architect vs. Builder: The LLM acts only as the Architect (intent). A local execution engine acts as the Builder. The AI never &quot;guesses&quot; the math; it triggers verified code primitives.<p>Local-First: All data processing stays on your machine. The LLM handles the reasoning, but the GodHands engine handles the data locally.<p>The Workflow: It bridges siloed apps into a unified <em>protocol</em>\u2014e.g., scraping a Gmail statement, running a cross-sheet reconciliation in Excel, and piping anomalies to Slack or a Calendar invite.<p>I\u2019m looking for technical feedback on this architecture, specifically the deterministic vs. probabilistic trade-off in RPA. I\u2019ll be around to answer questions about the implementation or the MCP layer. If you are interested in trying out our beta version, please reach out to us at founders@godhands.dev"},"title":{"matchLevel":"none","matchedWords":[],"value":"GodHands \u2013 Deterministic Desktop Automation via MCP"}},"_tags":["story","author_hacker27369","story_46996023","ask_hn"],"author":"hacker27369","created_at":"2026-02-12T22:13:58Z","created_at_i":1770934438,"num_comments":0,"objectID":"46996023","points":1,"story_id":46996023,"story_text":"I spent the last few years in High-Frequency Trading. In that world, &quot;probabilistic&quot; automation is a non-starter; if an AI hallucinations or clicks the wrong pixel, it&#x27;s a compliance disaster.\nMost current AI agents rely on vision (pixels). It\u2019s slow, brittle, and introduces a massive margin of error. I built GodHands to treat desktop apps like structured APIs instead of screenshots. It\u2019s an MCP (Model Context Protocol) server that acts as a deterministic &quot;action layer.&quot;<p>The Approach:<p>Object Model &gt; Pixels: Instead of vision, the engine hooks into application object models directly. It maps data structures dynamically so the automation doesn&#x27;t break when the UI changes.<p>Architect vs. Builder: The LLM acts only as the Architect (intent). A local execution engine acts as the Builder. The AI never &quot;guesses&quot; the math; it triggers verified code primitives.<p>Local-First: All data processing stays on your machine. The LLM handles the reasoning, but the GodHands engine handles the data locally.<p>The Workflow: It bridges siloed apps into a unified protocol\u2014e.g., scraping a Gmail statement, running a cross-sheet reconciliation in Excel, and piping anomalies to Slack or a Calendar invite.<p>I\u2019m looking for technical feedback on this architecture, specifically the deterministic vs. probabilistic trade-off in RPA. I\u2019ll be around to answer questions about the implementation or the MCP layer. If you are interested in trying out our beta version, please reach out to us at founders@godhands.dev","title":"GodHands \u2013 Deterministic Desktop Automation via MCP","updated_at":"2026-02-13T04:43:48Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"lucamoretti"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"Comprehensive Secrets Management Guide for MCP (<em>Model</em> <em>Context</em> <em>Protocol</em>) Servers"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/rsdouglas/janee/blob/main/docs/mcp-secrets-guide.md"}},"_tags":["story","author_lucamoretti","story_46988171"],"author":"lucamoretti","children":[46988172],"created_at":"2026-02-12T12:50:50Z","created_at_i":1770900650,"num_comments":1,"objectID":"46988171","points":1,"story_id":46988171,"title":"Comprehensive Secrets Management Guide for MCP (Model Context Protocol) Servers","updated_at":"2026-02-12T12:52:31Z","url":"https://github.com/rsdouglas/janee/blob/main/docs/mcp-secrets-guide.md"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"pstryder"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"I built MemoryGate because I kept watching <em>context</em> vanish.\nI run multiple AI agents across Claude, ChatGPT, and Cursor. Every time a <em>model</em> updated, a platform changed its API, or a <em>context</em> window rolled over \u2014 everything the agent had learned was gone. Preferences, decisions, project history, relationship <em>context</em>. Just... wiped.\nThe fundamental problem: AI memory is trapped inside the platform that hosts the conversation. Your agent's knowledge dies with the session, the <em>model</em> version, or the provider's business decisions.\nMemoryGate is a persistent semantic memory layer that sits outside any single <em>model</em> or platform. It connects via MCP (<em>Model</em> <em>Context</em> <em>Protocol</em>), so any MCP-compatible agent \u2014 Claude Desktop, ChatGPT, Cursor, custom agents \u2014 can store and retrieve memories through a shared, durable knowledge store.\nWhat it actually does:<p>Semantic memory with vector embeddings \u2014 recall by meaning, not keywords\nConfidence-weighted observations that strengthen or decay based on evidence\nAutomatic lifecycle management \u2014 high-signal stays hot, noise fades to cold storage\nAppend-only architecture \u2014 memories are never overwritten, only superseded with lineage\nKnowledge graphs linking observations, patterns, concepts, and documents\nMulti-tenant with org isolation, roles, and shared memory stores\nOAuth 2.0, audit logs, rate limiting \u2014 production infrastructure, not a toy<p>What it's not:<p>Not a RAG pipeline. MemoryGate stores what the agent learns from interaction, not document chunks.\nNot prompt injection. Memory lives at the infrastructure layer, not stuffed into system prompts.\nNot tied to any <em>model</em> or provider. Switch from Claude to ChatGPT to a local <em>model</em> \u2014 memory persists.<p>Stack: Python/FastAPI, PostgreSQL + pgvector, Redis, deployed on Railway. MCP-native integration \u2014 your agent gets 33 memory tools on connection.\nThe real pitch: Platforms die. Models get deprecated. <em>Context</em> windows roll over. Your AI's memory shouldn't be hostage to your AI's provider.\nOpen source (Apache 2.0), self-hostable, with a hosted SaaS option if you don't want to run infrastructure.<p>GitHub: <a href=\"https://github.com/PStryder/MemoryGate\" rel=\"nofollow\">https://github.com/PStryder/MemoryGate</a>\nSaaS: <a href=\"https://memorygate.ai\" rel=\"nofollow\">https://memorygate.ai</a>\nDocs: <a href=\"https://memorygate.ai/docs/\" rel=\"nofollow\">https://memorygate.ai/docs/</a><p>I'm a solo founder \u2014 built this after leaving a decade in enterprise solutions engineering. Happy to answer questions about the architecture, the MCP integration, or why I think persistent memory is the missing infrastructure layer for AI agents."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: MemoryGate \u2013 Open-source persistent memory for AI agents via MCP"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.memorygate.ai"}},"_tags":["story","author_pstryder","story_46981840","show_hn"],"author":"pstryder","created_at":"2026-02-11T22:05:29Z","created_at_i":1770847529,"num_comments":0,"objectID":"46981840","points":1,"story_id":46981840,"story_text":"I built MemoryGate because I kept watching context vanish.\nI run multiple AI agents across Claude, ChatGPT, and Cursor. Every time a model updated, a platform changed its API, or a context window rolled over \u2014 everything the agent had learned was gone. Preferences, decisions, project history, relationship context. Just... wiped.\nThe fundamental problem: AI memory is trapped inside the platform that hosts the conversation. Your agent&#x27;s knowledge dies with the session, the model version, or the provider&#x27;s business decisions.\nMemoryGate is a persistent semantic memory layer that sits outside any single model or platform. It connects via MCP (Model Context Protocol), so any MCP-compatible agent \u2014 Claude Desktop, ChatGPT, Cursor, custom agents \u2014 can store and retrieve memories through a shared, durable knowledge store.\nWhat it actually does:<p>Semantic memory with vector embeddings \u2014 recall by meaning, not keywords\nConfidence-weighted observations that strengthen or decay based on evidence\nAutomatic lifecycle management \u2014 high-signal stays hot, noise fades to cold storage\nAppend-only architecture \u2014 memories are never overwritten, only superseded with lineage\nKnowledge graphs linking observations, patterns, concepts, and documents\nMulti-tenant with org isolation, roles, and shared memory stores\nOAuth 2.0, audit logs, rate limiting \u2014 production infrastructure, not a toy<p>What it&#x27;s not:<p>Not a RAG pipeline. MemoryGate stores what the agent learns from interaction, not document chunks.\nNot prompt injection. Memory lives at the infrastructure layer, not stuffed into system prompts.\nNot tied to any model or provider. Switch from Claude to ChatGPT to a local model \u2014 memory persists.<p>Stack: Python&#x2F;FastAPI, PostgreSQL + pgvector, Redis, deployed on Railway. MCP-native integration \u2014 your agent gets 33 memory tools on connection.\nThe real pitch: Platforms die. Models get deprecated. Context windows roll over. Your AI&#x27;s memory shouldn&#x27;t be hostage to your AI&#x27;s provider.\nOpen source (Apache 2.0), self-hostable, with a hosted SaaS option if you don&#x27;t want to run infrastructure.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;PStryder&#x2F;MemoryGate\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;PStryder&#x2F;MemoryGate</a>\nSaaS: <a href=\"https:&#x2F;&#x2F;memorygate.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;memorygate.ai</a>\nDocs: <a href=\"https:&#x2F;&#x2F;memorygate.ai&#x2F;docs&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;memorygate.ai&#x2F;docs&#x2F;</a><p>I&#x27;m a solo founder \u2014 built this after leaving a decade in enterprise solutions engineering. Happy to answer questions about the architecture, the MCP integration, or why I think persistent memory is the missing infrastructure layer for AI agents.","title":"Show HN: MemoryGate \u2013 Open-source persistent memory for AI agents via MCP","updated_at":"2026-02-11T22:08:46Z","url":"https://www.memorygate.ai"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["model","context","protocol"],"value":"Hi HN,<p>I built PolyMCP, an open-source framework around the <em>Model</em> <em>Context</em> <em>Protocol</em> (MCP) that lets you expose existing Python functions as AI-callable tools \u2014 without rewriting them or adopting a custom SDK.<p>The goal is simple:\nIf you already have working Python code, you should be able to make it accessible to LLM agents in minutes.<p>What it does<p>PolyMCP introspects regular Python functions and exposes them as MCP tools automatically. No decorators required. No framework lock-in.<p>It grew into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 Turn Python functions into MCP tools\n \u2022 PolyMCP Inspector \u2013 A visual UI to browse, test, and debug MCP servers\n \u2022 MCP SDK Apps \u2013 A lightweight way to build AI-powered apps with tools + UI resources<p>Why I built this<p>While experimenting with MCP and AI agents, I found that integrating existing codebases was often the painful part.\nMost solutions require rewriting logic around a specific SDK or heavily annotating functions.<p>PolyMCP focuses on:\n \u2022 Minimal intrusion into existing code\n \u2022 Clean separation between business logic and AI tooling\n \u2022 Easy debugging via a visual inspector<p>Example use cases\n \u2022 Expose internal APIs or legacy scripts to LLM agents\n \u2022 Automate operational workflows\n \u2022 Build internal copilots over real systems\n \u2022 Prototype AI agents that interact with production services<p>Works with OpenAI, Anthropic, and Ollama (including local models).<p>It\u2019s still evolving and I\u2019m actively iterating.\nI\u2019d really appreciate feedback \u2014 especially from people building agents or experimenting with MCP in production environments.<p>GitHub:\n \u2022 Core: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP</a>\n \u2022 Inspector: <a href=\"https://github.com/poly-mcp/PolyMCP-Inspector\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-Inspector</a>\n \u2022 SDK Apps: <a href=\"https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps</a><p>Happy to answer technical questions."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PolyMCP \u2013 Expose Python functions as MCP tools"}},"_tags":["story","author_justvugg","story_46980134","show_hn"],"author":"justvugg","created_at":"2026-02-11T20:06:17Z","created_at_i":1770840377,"num_comments":0,"objectID":"46980134","points":2,"story_id":46980134,"story_text":"Hi HN,<p>I built PolyMCP, an open-source framework around the Model Context Protocol (MCP) that lets you expose existing Python functions as AI-callable tools \u2014 without rewriting them or adopting a custom SDK.<p>The goal is simple:\nIf you already have working Python code, you should be able to make it accessible to LLM agents in minutes.<p>What it does<p>PolyMCP introspects regular Python functions and exposes them as MCP tools automatically. No decorators required. No framework lock-in.<p>It grew into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 Turn Python functions into MCP tools\n \u2022 PolyMCP Inspector \u2013 A visual UI to browse, test, and debug MCP servers\n \u2022 MCP SDK Apps \u2013 A lightweight way to build AI-powered apps with tools + UI resources<p>Why I built this<p>While experimenting with MCP and AI agents, I found that integrating existing codebases was often the painful part.\nMost solutions require rewriting logic around a specific SDK or heavily annotating functions.<p>PolyMCP focuses on:\n \u2022 Minimal intrusion into existing code\n \u2022 Clean separation between business logic and AI tooling\n \u2022 Easy debugging via a visual inspector<p>Example use cases\n \u2022 Expose internal APIs or legacy scripts to LLM agents\n \u2022 Automate operational workflows\n \u2022 Build internal copilots over real systems\n \u2022 Prototype AI agents that interact with production services<p>Works with OpenAI, Anthropic, and Ollama (including local models).<p>It\u2019s still evolving and I\u2019m actively iterating.\nI\u2019d really appreciate feedback \u2014 especially from people building agents or experimenting with MCP in production environments.<p>GitHub:\n \u2022 Core: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a>\n \u2022 Inspector: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector</a>\n \u2022 SDK Apps: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps</a><p>Happy to answer technical questions.","title":"Show HN: PolyMCP \u2013 Expose Python functions as MCP tools","updated_at":"2026-02-11T20:47:00Z"}],"hitsPerPage":10,"nbHits":529,"nbPages":53,"page":0,"params":"query=Model+Context+Protocol&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":30,"processingTimingsMS":{"_request":{"roundTrip":21},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":11,"scanning":17,"total":29},"total":30},"query":"Model Context Protocol","serverTimeMS":32}
