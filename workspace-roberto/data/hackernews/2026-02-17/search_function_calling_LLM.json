{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"supreeth_ravi"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["function","calling","llm"],"value":"Hi HN,<p>Been working on a way to get &quot;agent-per-row&quot; behavior in Postgres without actually running <em>LLMs</em> inside the database.<p>The problem: <em>Calling</em> <em>LLMs</em> from triggers/<em>functions</em> blocks transactions, exhausts connections, and breaks ACID. Saw some projects doing this and it felt dangerous for production.<p>The solution: DB-adjacent architecture. Lightweight triggers enqueue jobs to an outbox table. An external Python worker (agentd) polls, executes AI calls, and writes back safely with schema validation and CAS.<p>What you can build:<p>Auto-classify support tickets on INSERT<p>Content moderation that doesn't block your app<p>Lead scoring, fraud detection, and invoice extraction<p>Anything where data arrives and needs AI enrichment<p>Works with OpenAI, Anthropic, OpenRouter, or any Agent.<p>One SQL line to add AI to any table:<p>SELECT agent_runtime.agent_watch('tickets', 'id', 'classifier', 'v1', '{&quot;priority&quot;:&quot;$.priority&quot;}');<p>Includes 9 example use cases in the repo. Would love feedback on the architecture."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PgCortex \u2013 AI enrichment per Postgres row, zero transaction blocking"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/supreeth-ravi/pgcortex"}},"_tags":["story","author_supreeth_ravi","story_47045690","show_hn"],"author":"supreeth_ravi","created_at":"2026-02-17T10:14:41Z","created_at_i":1771323281,"num_comments":0,"objectID":"47045690","points":1,"story_id":47045690,"story_text":"Hi HN,<p>Been working on a way to get &quot;agent-per-row&quot; behavior in Postgres without actually running LLMs inside the database.<p>The problem: Calling LLMs from triggers&#x2F;functions blocks transactions, exhausts connections, and breaks ACID. Saw some projects doing this and it felt dangerous for production.<p>The solution: DB-adjacent architecture. Lightweight triggers enqueue jobs to an outbox table. An external Python worker (agentd) polls, executes AI calls, and writes back safely with schema validation and CAS.<p>What you can build:<p>Auto-classify support tickets on INSERT<p>Content moderation that doesn&#x27;t block your app<p>Lead scoring, fraud detection, and invoice extraction<p>Anything where data arrives and needs AI enrichment<p>Works with OpenAI, Anthropic, OpenRouter, or any Agent.<p>One SQL line to add AI to any table:<p>SELECT agent_runtime.agent_watch(&#x27;tickets&#x27;, &#x27;id&#x27;, &#x27;classifier&#x27;, &#x27;v1&#x27;, &#x27;{&quot;priority&quot;:&quot;$.priority&quot;}&#x27;);<p>Includes 9 example use cases in the repo. Would love feedback on the architecture.","title":"Show HN: PgCortex \u2013 AI enrichment per Postgres row, zero transaction blocking","updated_at":"2026-02-17T10:17:18Z","url":"https://github.com/supreeth-ravi/pgcortex"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"h4ch1"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["function","calling","llm"],"value":"Hi HN,<p>This is a new tab page I started building for myself close to 4 months ago, it started with a simple markdown editor with task extraction support and I kept expanding it depending on what I wanted.<p>I was sick of the current state of new tab pages, either they were very minimal (good morning, some quotes, etc) or were data collection agents.<p>I was also not really keen on downloading and using an electron note-taking app since my browser's already open and <em>falling</em> into configuration hell was a path I had taking numerous times.<p>There are quite a few features that people may find useful:<p>1. Timing <em>functions</em>: A clock and world clock with keyboard driven conversion - I was tired of Googling times in multiple timezones trying to co-ordinate between devs and clients.<p>2. Ambient Chaos: Upload your ambient sounds, use it as a central mixer - I usually listen to ambient music, nature sounds, fireplaces, etc while working. Having a youtube tab consume 400+MB while doing that wasn't very fun.<p>3. QuickLog: Not all thoughts need their dedicated note; a quick kb driven logging widget which rotates at the end of each day. Promotable to your main notes.<p>4. Notes &amp; Tasks: A CodeMirror based Markdown editor with nested task extraction to a separate widget - parses all your notes, extracts all tasks and gives a tree view of tasks across files or per-file.<p>5. Tab Debt: A nested tab widget which tracks what links were opened from where and how long they've been open. You can select and close/save them.<p>6. Weather: Just a detailed weather widget with forecasts and a <em>LLM</em> summary (if you add a key)<p>7. Discussions and Bookmark Chat - You can chat with HackerNews and Reddit discussions &amp; articles with the <em>LLM</em> of your choice (BYOK); supports OpenAI, Anthropic, Cerebras. It also has the ability to sync and parse your bookmarks with scraping support.<p>A little more on 7:<p>Sometimes when I use reddit to find product alternatives, the sheer volume of suggestions, often repeated with different usecases makes the process harder. The discussions chat supports proper backlinking to comments in the thread.\nWith bookmarks, I kept losing really cool stuff I had saved and never knew the gems I had just collecting dust. A quick &quot;find me bookmarks on 3d postprocessing&quot; really helps now.<p>It's up on the Chrome Web Store: <a href=\"https://chromewebstore.google.com/detail/pgfpnakgiejllklfaamjogeoamalobfp?utm_source=item-share-cb\" rel=\"nofollow\">https://chromewebstore.google.com/detail/pgfpnakgiejllklfaam...</a><p>The Firefox version is a little buggy so the publishing is delayed there but if you'd like to test it out you can download it here: <a href=\"https://deepflowdata.tech/commander-0.1.0-firefox.zip\" rel=\"nofollow\">https://deepflowdata.tech/commander-0.1.0-firefox.zip</a><p>Demo: <a href=\"https://www.youtube.com/watch?v=EAqbmOT_6wk\" rel=\"nofollow\">https://www.youtube.com/watch?v=EAqbmOT_6wk</a><p>This extension is something I personally use, doesn't collect any data and doesn't interact with the internet unless you use the <em>LLM</em> chat with your own key. Planning on making this OSS software after cleaning up the mess that the codebase is basically over 3-4 months of treating it like a sandbox.<p>Open to hearing feedback, critique and anything in between :) Have a great day/night!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Commander, an opinionated yet powerful new tab page"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://chromewebstore.google.com/detail/commander/pgfpnakgiejllklfaamjogeoamalobfp"}},"_tags":["story","author_h4ch1","story_46987439","show_hn"],"author":"h4ch1","created_at":"2026-02-12T11:27:22Z","created_at_i":1770895642,"num_comments":0,"objectID":"46987439","points":1,"story_id":46987439,"story_text":"Hi HN,<p>This is a new tab page I started building for myself close to 4 months ago, it started with a simple markdown editor with task extraction support and I kept expanding it depending on what I wanted.<p>I was sick of the current state of new tab pages, either they were very minimal (good morning, some quotes, etc) or were data collection agents.<p>I was also not really keen on downloading and using an electron note-taking app since my browser&#x27;s already open and falling into configuration hell was a path I had taking numerous times.<p>There are quite a few features that people may find useful:<p>1. Timing functions: A clock and world clock with keyboard driven conversion - I was tired of Googling times in multiple timezones trying to co-ordinate between devs and clients.<p>2. Ambient Chaos: Upload your ambient sounds, use it as a central mixer - I usually listen to ambient music, nature sounds, fireplaces, etc while working. Having a youtube tab consume 400+MB while doing that wasn&#x27;t very fun.<p>3. QuickLog: Not all thoughts need their dedicated note; a quick kb driven logging widget which rotates at the end of each day. Promotable to your main notes.<p>4. Notes &amp; Tasks: A CodeMirror based Markdown editor with nested task extraction to a separate widget - parses all your notes, extracts all tasks and gives a tree view of tasks across files or per-file.<p>5. Tab Debt: A nested tab widget which tracks what links were opened from where and how long they&#x27;ve been open. You can select and close&#x2F;save them.<p>6. Weather: Just a detailed weather widget with forecasts and a LLM summary (if you add a key)<p>7. Discussions and Bookmark Chat - You can chat with HackerNews and Reddit discussions &amp; articles with the LLM of your choice (BYOK); supports OpenAI, Anthropic, Cerebras. It also has the ability to sync and parse your bookmarks with scraping support.<p>A little more on 7:<p>Sometimes when I use reddit to find product alternatives, the sheer volume of suggestions, often repeated with different usecases makes the process harder. The discussions chat supports proper backlinking to comments in the thread.\nWith bookmarks, I kept losing really cool stuff I had saved and never knew the gems I had just collecting dust. A quick &quot;find me bookmarks on 3d postprocessing&quot; really helps now.<p>It&#x27;s up on the Chrome Web Store: <a href=\"https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;pgfpnakgiejllklfaamjogeoamalobfp?utm_source=item-share-cb\" rel=\"nofollow\">https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;pgfpnakgiejllklfaam...</a><p>The Firefox version is a little buggy so the publishing is delayed there but if you&#x27;d like to test it out you can download it here: <a href=\"https:&#x2F;&#x2F;deepflowdata.tech&#x2F;commander-0.1.0-firefox.zip\" rel=\"nofollow\">https:&#x2F;&#x2F;deepflowdata.tech&#x2F;commander-0.1.0-firefox.zip</a><p>Demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=EAqbmOT_6wk\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=EAqbmOT_6wk</a><p>This extension is something I personally use, doesn&#x27;t collect any data and doesn&#x27;t interact with the internet unless you use the LLM chat with your own key. Planning on making this OSS software after cleaning up the mess that the codebase is basically over 3-4 months of treating it like a sandbox.<p>Open to hearing feedback, critique and anything in between :) Have a great day&#x2F;night!","title":"Show HN: Commander, an opinionated yet powerful new tab page","updated_at":"2026-02-12T11:29:45Z","url":"https://chromewebstore.google.com/detail/commander/pgfpnakgiejllklfaamjogeoamalobfp"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"jared_stewart"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["function","calling","llm"],"value":"I've been building a tool that changes how <em>LLM</em> coding agents explore codebases, and I wanted to share it along with some early observations.<p>Typically claude code globs directories, greps for patterns, and reads files with minimal guidance. It works in kind of the same way you'd learn to navigate a city by <em>walking</em> every street. You'll eventually build a mental map, but claude never does - at least not any that persists across different contexts.<p>The Recursive Language Models paper from Zhang, Kraska, and Khattab at MIT CSAIL introduced a cleaner framing. Instead of cramming everything into context, the model gets a searchable environment. The model can then query just for what it needs and can drill deeper where needed.<p>coderlm is my implementation of that idea for codebases. A Rust server indexes a project with tree-sitter, builds a symbol table with cross-references, and exposes an API. The agent queries for structure, symbols, implementations, callers, and grep results \u2014 getting back exactly the code it needs instead of scanning for it.<p>The agent workflow looks like:<p>1. `init` \u2014 register the project, get the top-level structure<p>2. `structure` \u2014 drill into specific directories<p>3. `search` \u2014 find symbols by name across the codebase<p>4. `impl` \u2014 retrieve the exact source of a <em>function</em> or class<p>5. `callers` \u2014 find everything that calls a given symbol<p>6. `grep` \u2014 fall back to text search when you need it<p>This replaces the glob/grep/read cycle with index-backed lookups. The server currently supports Rust, Python, TypeScript, JavaScript, and Go for symbol parsing, though all file types show up in the tree and are searchable via grep.<p>It ships as a Claude Code plugin with hooks that guide the agent to use indexed lookups instead of native file tools, plus a Python CLI wrapper with zero dependencies.<p>For anecdotal results, I ran the same prompt against a codebase to &quot;explore and identify opportunities to clarify the existing structure&quot;.<p>Using coderlm, claude was able to generate a plan in about 3 minutes. The coderlm enabled instance found a genuine bug (duplicated code with identical names), orphaned code for cleanup, mismatched naming conventions crossing module boundaries, and overlapping vocabulary. These are all <i>semantic</i> issues which clearly benefit from the tree-sitter centric approach.<p>Using the native tools, claude was able to identify various file clutter in the root of the project, out of date references, and a migration timestamp collision. These findings are more consistent with methodical walks of the filesystem and took about 8 minutes to produce.<p>The indexed approach did better at catching semantic issues than native tools and had a key benefit in being faster to resolve.<p>I've spent some effort to streamline the installation process, but it isn't turnkey yet. You'll need the rust toolchain to build the server which runs as a separate process. Installing the plugin from a claude marketplace is possible, but the skill isn't being added to your .claude yet so there are some manual steps to just getting to a point where claude could use it.<p>Claude continues to demonstrate significant resistance to using CodeRLM in exploration tasks. Typically to use you will need to explicitly direct claude to use it.<p>---<p>Repo: github.com/JaredStewart/coderlm<p>Paper: Recursive Language Models <a href=\"https://arxiv.org/abs/2512.24601\" rel=\"nofollow\">https://arxiv.org/abs/2512.24601</a> \u2014 Zhang, Kraska, Khattab (MIT CSAIL, 2025)<p>Inspired by: <a href=\"https://github.com/brainqub3/claude_code_RLM\" rel=\"nofollow\">https://github.com/brainqub3/claude_code_RLM</a>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["llm"],"value":"Show HN: CodeRLM \u2013 Tree-sitter-backed code indexing for <em>LLM</em> agents"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/JaredStewart/coderlm/blob/main/server/REPL_to_API.md"}},"_tags":["story","author_jared_stewart","story_46974515","show_hn"],"author":"jared_stewart","children":[46984648,46984598,46987209,46985245,46986305,46984339,46984212,46983891,47013576,46983766],"created_at":"2026-02-11T13:10:23Z","created_at_i":1770815423,"num_comments":37,"objectID":"46974515","points":79,"story_id":46974515,"story_text":"I&#x27;ve been building a tool that changes how LLM coding agents explore codebases, and I wanted to share it along with some early observations.<p>Typically claude code globs directories, greps for patterns, and reads files with minimal guidance. It works in kind of the same way you&#x27;d learn to navigate a city by walking every street. You&#x27;ll eventually build a mental map, but claude never does - at least not any that persists across different contexts.<p>The Recursive Language Models paper from Zhang, Kraska, and Khattab at MIT CSAIL introduced a cleaner framing. Instead of cramming everything into context, the model gets a searchable environment. The model can then query just for what it needs and can drill deeper where needed.<p>coderlm is my implementation of that idea for codebases. A Rust server indexes a project with tree-sitter, builds a symbol table with cross-references, and exposes an API. The agent queries for structure, symbols, implementations, callers, and grep results \u2014 getting back exactly the code it needs instead of scanning for it.<p>The agent workflow looks like:<p>1. `init` \u2014 register the project, get the top-level structure<p>2. `structure` \u2014 drill into specific directories<p>3. `search` \u2014 find symbols by name across the codebase<p>4. `impl` \u2014 retrieve the exact source of a function or class<p>5. `callers` \u2014 find everything that calls a given symbol<p>6. `grep` \u2014 fall back to text search when you need it<p>This replaces the glob&#x2F;grep&#x2F;read cycle with index-backed lookups. The server currently supports Rust, Python, TypeScript, JavaScript, and Go for symbol parsing, though all file types show up in the tree and are searchable via grep.<p>It ships as a Claude Code plugin with hooks that guide the agent to use indexed lookups instead of native file tools, plus a Python CLI wrapper with zero dependencies.<p>For anecdotal results, I ran the same prompt against a codebase to &quot;explore and identify opportunities to clarify the existing structure&quot;.<p>Using coderlm, claude was able to generate a plan in about 3 minutes. The coderlm enabled instance found a genuine bug (duplicated code with identical names), orphaned code for cleanup, mismatched naming conventions crossing module boundaries, and overlapping vocabulary. These are all <i>semantic</i> issues which clearly benefit from the tree-sitter centric approach.<p>Using the native tools, claude was able to identify various file clutter in the root of the project, out of date references, and a migration timestamp collision. These findings are more consistent with methodical walks of the filesystem and took about 8 minutes to produce.<p>The indexed approach did better at catching semantic issues than native tools and had a key benefit in being faster to resolve.<p>I&#x27;ve spent some effort to streamline the installation process, but it isn&#x27;t turnkey yet. You&#x27;ll need the rust toolchain to build the server which runs as a separate process. Installing the plugin from a claude marketplace is possible, but the skill isn&#x27;t being added to your .claude yet so there are some manual steps to just getting to a point where claude could use it.<p>Claude continues to demonstrate significant resistance to using CodeRLM in exploration tasks. Typically to use you will need to explicitly direct claude to use it.<p>---<p>Repo: github.com&#x2F;JaredStewart&#x2F;coderlm<p>Paper: Recursive Language Models <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2512.24601\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2512.24601</a> \u2014 Zhang, Kraska, Khattab (MIT CSAIL, 2025)<p>Inspired by: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;brainqub3&#x2F;claude_code_RLM\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;brainqub3&#x2F;claude_code_RLM</a>","title":"Show HN: CodeRLM \u2013 Tree-sitter-backed code indexing for LLM agents","updated_at":"2026-02-17T02:32:46Z","url":"https://github.com/JaredStewart/coderlm/blob/main/server/REPL_to_API.md"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"simranmultani"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["function","calling","llm"],"value":"Hey HN,<p>I've been building <em>LLM</em>-based agents for a while and two things kept biting me.<p>1. Loops \u2014 an agent node would get stuck <em>calling</em> the same thing over and over, and I wouldn't notice until the API bill showed up. Lost $200+ on one run.\n2. <em>LLM</em> would return garbage that didn't match what downstream code expected, and everything would just crash.<p>I looked around and couldn't find something simple that handled both. Most frameworks assume your node <em>function</em> just works. In practice it doesn't \u2014 <em>LLM</em> calls fail, JSON comes back broken, state gets weird.<p>So I built AgentCircuit. It's a Python decorator that wraps your agent <em>functions</em> with circuit breaker-style protections:<p><pre><code>    from agentcircuit import reliable\n    from pydantic import BaseModel\n\n    class Output(BaseModel):\n        name: str\n        age: int\n\n    @reliable(sentinel_schema=Output)\n    def extract_data(state):\n        return call_<em>llm</em>(state[&quot;text&quot;])\n</code></pre>\nThat's it. Under the hood it:<p>- Fuse \u2014 detects when a node keeps seeing the same input and kills the loop\n- Sentinel \u2014 validates every output against a Pydantic schema\n- Medic \u2014 auto-repairs bad outputs using an <em>LLM</em>\n- Budget \u2014 per-node and global dollar/time limits so you never get a surprise bill\n- Pricing \u2014 built-in cost tracking for 40+ models (GPT-5, Claude 4.x, Gemini 3, Llama, etc.)<p>There's no server, no config files, no framework lock-in. It works at the <em>function</em> boundary so it composes with LangGraph, LangChain, CrewAI, AutoGen, or just plain <em>functions</em>.<p>GitHub: <a href=\"https://github.com/simranmultani197/AgentCircuit\" rel=\"nofollow\">https://github.com/simranmultani197/AgentCircuit</a>\nPyPI: <a href=\"https://pypi.org/project/agentcircuit/\" rel=\"nofollow\">https://pypi.org/project/agentcircuit/</a>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["function"],"value":"Show HN: AgentCircuit \u2013 Circuit breaker for AI agent <em>functions</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/simranmultani197/AgentCircuit"}},"_tags":["story","author_simranmultani","story_46899775","show_hn"],"author":"simranmultani","children":[46947900],"created_at":"2026-02-05T14:07:27Z","created_at_i":1770300447,"num_comments":1,"objectID":"46899775","points":1,"story_id":46899775,"story_text":"Hey HN,<p>I&#x27;ve been building LLM-based agents for a while and two things kept biting me.<p>1. Loops \u2014 an agent node would get stuck calling the same thing over and over, and I wouldn&#x27;t notice until the API bill showed up. Lost $200+ on one run.\n2. LLM would return garbage that didn&#x27;t match what downstream code expected, and everything would just crash.<p>I looked around and couldn&#x27;t find something simple that handled both. Most frameworks assume your node function just works. In practice it doesn&#x27;t \u2014 LLM calls fail, JSON comes back broken, state gets weird.<p>So I built AgentCircuit. It&#x27;s a Python decorator that wraps your agent functions with circuit breaker-style protections:<p><pre><code>    from agentcircuit import reliable\n    from pydantic import BaseModel\n\n    class Output(BaseModel):\n        name: str\n        age: int\n\n    @reliable(sentinel_schema=Output)\n    def extract_data(state):\n        return call_llm(state[&quot;text&quot;])\n</code></pre>\nThat&#x27;s it. Under the hood it:<p>- Fuse \u2014 detects when a node keeps seeing the same input and kills the loop\n- Sentinel \u2014 validates every output against a Pydantic schema\n- Medic \u2014 auto-repairs bad outputs using an LLM\n- Budget \u2014 per-node and global dollar&#x2F;time limits so you never get a surprise bill\n- Pricing \u2014 built-in cost tracking for 40+ models (GPT-5, Claude 4.x, Gemini 3, Llama, etc.)<p>There&#x27;s no server, no config files, no framework lock-in. It works at the function boundary so it composes with LangGraph, LangChain, CrewAI, AutoGen, or just plain functions.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;simranmultani197&#x2F;AgentCircuit\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;simranmultani197&#x2F;AgentCircuit</a>\nPyPI: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;agentcircuit&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;agentcircuit&#x2F;</a>","title":"Show HN: AgentCircuit \u2013 Circuit breaker for AI agent functions","updated_at":"2026-02-10T11:38:37Z","url":"https://github.com/simranmultani197/AgentCircuit"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Hannah203"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["function","calling","llm"],"value":"Over the past year, many SaaS products have added AI chatbots to answer questions and reduce support load. It helped initially, but most of these systems still live in a chat window with no awareness of what\u2019s happening inside the application.\nThey don\u2019t know the current page, selected data, user permissions, or workflow state. Users end up repeating context the product already has.\nI recently came across an open-source Copilot SDK that approaches this differently by injecting live application state directly into the AI and letting it execute real frontend and backend <em>functions</em> instead of just responding with text.\nWhat it does:\n- Understands application state including current page, selected data, and user permissions\n- Executes backend and frontend <em>functions</em> instead of only responding with text\n- Delivers richer product experiences through generative UI such as tables, forms, and interactive buttons\n- Understands user workflow and intent based on in-product context\n- Maintains session context so interactions remain consistent\nExample: Instead of the AI asking &quot;What do you need help with?&quot;, it understands the user context is viewing failed transactions from last week and can immediately offer to retry them, export the data, or investigate patterns.\nTechnical details:\n- Works with React, Next.js, Vite (Vue &amp; Angular coming soon)\n- <em>LLM</em>-agnostic (bring your own model)\n- State injection via context providers\n- Tool execution layer for safe <em>function</em> <em>calling</em>\n- Full data ownership (everything runs in your infrastructure)<p>Docs + examples: <a href=\"https://copilot-sdk.yourgpt.ai\" rel=\"nofollow\">https://copilot-sdk.yourgpt.ai</a><p>Happy to answer technical questions about implementation, or specific use cases."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: YourGPT Copilot SDK Open-source SDK for product-level intelligence"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://copilot-sdk.yourgpt.ai/docs"}},"_tags":["story","author_Hannah203","story_46885205","show_hn"],"author":"Hannah203","created_at":"2026-02-04T12:47:39Z","created_at_i":1770209259,"num_comments":0,"objectID":"46885205","points":2,"story_id":46885205,"story_text":"Over the past year, many SaaS products have added AI chatbots to answer questions and reduce support load. It helped initially, but most of these systems still live in a chat window with no awareness of what\u2019s happening inside the application.\nThey don\u2019t know the current page, selected data, user permissions, or workflow state. Users end up repeating context the product already has.\nI recently came across an open-source Copilot SDK that approaches this differently by injecting live application state directly into the AI and letting it execute real frontend and backend functions instead of just responding with text.\nWhat it does:\n- Understands application state including current page, selected data, and user permissions\n- Executes backend and frontend functions instead of only responding with text\n- Delivers richer product experiences through generative UI such as tables, forms, and interactive buttons\n- Understands user workflow and intent based on in-product context\n- Maintains session context so interactions remain consistent\nExample: Instead of the AI asking &quot;What do you need help with?&quot;, it understands the user context is viewing failed transactions from last week and can immediately offer to retry them, export the data, or investigate patterns.\nTechnical details:\n- Works with React, Next.js, Vite (Vue &amp; Angular coming soon)\n- LLM-agnostic (bring your own model)\n- State injection via context providers\n- Tool execution layer for safe function calling\n- Full data ownership (everything runs in your infrastructure)<p>Docs + examples: <a href=\"https:&#x2F;&#x2F;copilot-sdk.yourgpt.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;copilot-sdk.yourgpt.ai</a><p>Happy to answer technical questions about implementation, or specific use cases.","title":"Show HN: YourGPT Copilot SDK Open-source SDK for product-level intelligence","updated_at":"2026-02-04T13:18:11Z","url":"https://copilot-sdk.yourgpt.ai/docs"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Roshni1990r"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["function","calling","llm"],"value":"Over the past year, many SaaS products have added AI chatbots. They answer questions, guide users, and reduce some support load. That was a useful first step, but it is no longer enough.<p>Most AI still live in a chat window with no awareness of the application. They don't understand product state, selected data, user permissions, or the current workflow, so users end up restating context the system already has.<p>That approach does not scale well for real products.<p>We\u2019ve always believed copilots are the way to deliver the best customer experience\u2014not by answering questions, but by actually doing things<p>We are releasing Copilot SDK as an open-source toolkit to explore this idea and make context-aware, action-driven copilots for product teams.<p>What it does:<p>- Understands application state including current page, selected data, and user permissions<p>- Executes backend and frontend <em>functions</em> instead of only responding with text<p>- Delivers richer product experiences through generative UI such as tables, forms, and interactive buttons<p>- Understands user workflow and intent based on in-product context<p>- Maintains session context so interactions remain consistent<p>Example: Instead of the AI asking &quot;What do you need help with?&quot;, it understands the user context is viewing failed transactions from last week and can immediately offer to retry them, export the data, or investigate patterns.<p>Technical details:<p>- Works with React, Next.js, Vite (Vue &amp; Angular coming soon)<p>- <em>LLM</em>-agnostic (bring your own model)<p>- State injection via context providers<p>- Tool execution layer for safe <em>function</em> <em>calling</em><p>- Full data ownership (everything runs in your infrastructure)<p>Docs + examples: <a href=\"https://copilot-sdk.yourgpt.ai\" rel=\"nofollow\">https://copilot-sdk.yourgpt.ai</a><p>Happy to answer technical questions about implementation, or specific use cases."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: YourGPT Copilot SDK \u2013 Open-source toolkit for product-aware AI agents"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://copilot-sdk.yourgpt.ai/docs"}},"_tags":["story","author_Roshni1990r","story_46870742","show_hn"],"author":"Roshni1990r","created_at":"2026-02-03T13:31:12Z","created_at_i":1770125472,"num_comments":0,"objectID":"46870742","points":1,"story_id":46870742,"story_text":"Over the past year, many SaaS products have added AI chatbots. They answer questions, guide users, and reduce some support load. That was a useful first step, but it is no longer enough.<p>Most AI still live in a chat window with no awareness of the application. They don&#x27;t understand product state, selected data, user permissions, or the current workflow, so users end up restating context the system already has.<p>That approach does not scale well for real products.<p>We\u2019ve always believed copilots are the way to deliver the best customer experience\u2014not by answering questions, but by actually doing things<p>We are releasing Copilot SDK as an open-source toolkit to explore this idea and make context-aware, action-driven copilots for product teams.<p>What it does:<p>- Understands application state including current page, selected data, and user permissions<p>- Executes backend and frontend functions instead of only responding with text<p>- Delivers richer product experiences through generative UI such as tables, forms, and interactive buttons<p>- Understands user workflow and intent based on in-product context<p>- Maintains session context so interactions remain consistent<p>Example: Instead of the AI asking &quot;What do you need help with?&quot;, it understands the user context is viewing failed transactions from last week and can immediately offer to retry them, export the data, or investigate patterns.<p>Technical details:<p>- Works with React, Next.js, Vite (Vue &amp; Angular coming soon)<p>- LLM-agnostic (bring your own model)<p>- State injection via context providers<p>- Tool execution layer for safe function calling<p>- Full data ownership (everything runs in your infrastructure)<p>Docs + examples: <a href=\"https:&#x2F;&#x2F;copilot-sdk.yourgpt.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;copilot-sdk.yourgpt.ai</a><p>Happy to answer technical questions about implementation, or specific use cases.","title":"Show HN: YourGPT Copilot SDK \u2013 Open-source toolkit for product-aware AI agents","updated_at":"2026-02-03T13:35:54Z","url":"https://copilot-sdk.yourgpt.ai/docs"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"yol"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["function","calling"],"value":"How existing prompt management solutions work bothers me, it seems to go against programming best practices: the prompt templates are stored in completely separate system from its dependencies, and there\u2019s no interface definitions for using them. It\u2019s like <em>calling</em> a <em>function</em> (the prompt template) that takes ANY arguments and can silently return crap when the arguments don\u2019t align with its internal implementation.<p>So I made this project according to how I think prompt management should work - strongly typed interface, defined in the code; the prompt templates are co-located in the same codebase as their dependencies; and there\u2019s type-hint and validation for devEx. Doing this also brings additional benefit: because the variables are strong typed at compose time, it\u2019s save to support complex prompt templates with if/else/for control loops with full type safety.<p>I\u2019d love to know whether this resonate with others, or is it just my pet peeve."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["llm"],"value":"Show HN: Pixie-prompts \u2013 manage <em>LLM</em> prompt templates like code"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://gopixie.ai"}},"_tags":["story","author_yol","story_46781675","show_hn"],"author":"yol","created_at":"2026-01-27T15:55:40Z","created_at_i":1769529340,"num_comments":0,"objectID":"46781675","points":1,"story_id":46781675,"story_text":"How existing prompt management solutions work bothers me, it seems to go against programming best practices: the prompt templates are stored in completely separate system from its dependencies, and there\u2019s no interface definitions for using them. It\u2019s like calling a function (the prompt template) that takes ANY arguments and can silently return crap when the arguments don\u2019t align with its internal implementation.<p>So I made this project according to how I think prompt management should work - strongly typed interface, defined in the code; the prompt templates are co-located in the same codebase as their dependencies; and there\u2019s type-hint and validation for devEx. Doing this also brings additional benefit: because the variables are strong typed at compose time, it\u2019s save to support complex prompt templates with if&#x2F;else&#x2F;for control loops with full type safety.<p>I\u2019d love to know whether this resonate with others, or is it just my pet peeve.","title":"Show HN: Pixie-prompts \u2013 manage LLM prompt templates like code","updated_at":"2026-01-27T15:57:44Z","url":"https://gopixie.ai"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"iCeGaming"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["function","calling","llm"],"value":"Hey everyone,\nI built <em>llm</em>-schema-guard because LLMs are amazing at spitting out JSON... until they suddenly aren't. Even with JSON mode or <em>function</em> <em>calling</em>, you still get missing fields, wrong types, or just plain broken syntax that kills your agents, RAG flows, or any tool-<em>calling</em> setup.\nThis is a lightweight Rust HTTP proxy that sits in front of any OpenAI-compatible API (think Ollama, vLLM, LocalAI, OpenAI itself, Groq, you name it). It grabs the generated output, checks it against a JSON Schema you provide, and only lets it through if it's valid.\nIf it's invalid, strict mode kicks back a clean 400 with details. Permissive mode tries auto-retrying a few times by tweaking the prompt with a fix instruction and exponential backoff.\nEverything else stays the same: full streaming support (it buffers the response to validate), Prometheus metrics so you can monitor validation fails, retries, latency, and more. Config is simple YAML for upstreams, schemas per model, rate limiting, caching, etc. There's even an offline CLI if you just want to test schemas locally.\nIt's built with Axum and Tokio for really low latency and high throughput, plus jsonschema-rs under the hood. Docker compose makes it dead simple to spin up with Ollama.<p>This grew out of my earlier schema-gateway project, and I'm happy to add stuff like Anthropic support, tool <em>calling</em> validation, or better streaming fixes if people find it useful.\nStars or contributions are very welcome!<p>Thanks for taking a look :)"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["llm"],"value":"Show HN: <em>LLM</em>-schema-guard \u2013 Rust proxy enforcing JSON schemas on <em>LLM</em> outputs"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["llm"],"value":"https://github.com/AncientiCe/<em>llm</em>-schema-guard"}},"_tags":["story","author_iCeGaming","story_46778689","show_hn"],"author":"iCeGaming","created_at":"2026-01-27T11:39:24Z","created_at_i":1769513964,"num_comments":0,"objectID":"46778689","points":1,"story_id":46778689,"story_text":"Hey everyone,\nI built llm-schema-guard because LLMs are amazing at spitting out JSON... until they suddenly aren&#x27;t. Even with JSON mode or function calling, you still get missing fields, wrong types, or just plain broken syntax that kills your agents, RAG flows, or any tool-calling setup.\nThis is a lightweight Rust HTTP proxy that sits in front of any OpenAI-compatible API (think Ollama, vLLM, LocalAI, OpenAI itself, Groq, you name it). It grabs the generated output, checks it against a JSON Schema you provide, and only lets it through if it&#x27;s valid.\nIf it&#x27;s invalid, strict mode kicks back a clean 400 with details. Permissive mode tries auto-retrying a few times by tweaking the prompt with a fix instruction and exponential backoff.\nEverything else stays the same: full streaming support (it buffers the response to validate), Prometheus metrics so you can monitor validation fails, retries, latency, and more. Config is simple YAML for upstreams, schemas per model, rate limiting, caching, etc. There&#x27;s even an offline CLI if you just want to test schemas locally.\nIt&#x27;s built with Axum and Tokio for really low latency and high throughput, plus jsonschema-rs under the hood. Docker compose makes it dead simple to spin up with Ollama.<p>This grew out of my earlier schema-gateway project, and I&#x27;m happy to add stuff like Anthropic support, tool calling validation, or better streaming fixes if people find it useful.\nStars or contributions are very welcome!<p>Thanks for taking a look :)","title":"Show HN: LLM-schema-guard \u2013 Rust proxy enforcing JSON schemas on LLM outputs","updated_at":"2026-01-27T11:45:58Z","url":"https://github.com/AncientiCe/llm-schema-guard"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ashtadmir"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["function","calling"],"value":"I've been playing around with the new official GitHub Copilot SDK and realized it's a goldmine for building programmatic bridges to their models.<p>I built this server in Go to act as a OpenAI-compatible proxy. It essentially lets you treat your GitHub Copilot subscription as a standard OpenAI backend for any tool that supports it. I have tested it against OpenWebUI and Langchain.<p>Key Highlights:<p>- Official SDK: Built using the new Github Copilot SDK. It\u2019s much more robust than the reverse-engineered solutions floating around and does not use unpublished APIs.<p>- Tool <em>Calling</em> Support: It maps OpenAI <em>function</em> definitions to Copilot's agentic tools. You can use your own tools/functions through the Copilot without copilot needing access to the said tools just the definitions is enough.<p>The goal was to create a reliable &quot;bridge&quot; so I can use my subscription models in my preferred interfaces."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["llm"],"value":"Show HN: An OpenAI API compatible server that uses GitHub Copilot SDK for <em>LLMs</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/RajatGarga/copilot-openai-server"}},"_tags":["story","author_ashtadmir","story_46775889","show_hn"],"author":"ashtadmir","children":[46776731],"created_at":"2026-01-27T05:31:17Z","created_at_i":1769491877,"num_comments":1,"objectID":"46775889","points":2,"story_id":46775889,"story_text":"I&#x27;ve been playing around with the new official GitHub Copilot SDK and realized it&#x27;s a goldmine for building programmatic bridges to their models.<p>I built this server in Go to act as a OpenAI-compatible proxy. It essentially lets you treat your GitHub Copilot subscription as a standard OpenAI backend for any tool that supports it. I have tested it against OpenWebUI and Langchain.<p>Key Highlights:<p>- Official SDK: Built using the new Github Copilot SDK. It\u2019s much more robust than the reverse-engineered solutions floating around and does not use unpublished APIs.<p>- Tool Calling Support: It maps OpenAI function definitions to Copilot&#x27;s agentic tools. You can use your own tools&#x2F;functions through the Copilot without copilot needing access to the said tools just the definitions is enough.<p>The goal was to create a reliable &quot;bridge&quot; so I can use my subscription models in my preferred interfaces.","title":"Show HN: An OpenAI API compatible server that uses GitHub Copilot SDK for LLMs","updated_at":"2026-01-27T07:50:26Z","url":"https://github.com/RajatGarga/copilot-openai-server"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"charlielidbury"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["function"],"value":"If agent's tools are exposed as <em>functions</em>/objects in a Python REPL (as opposed to JSON schemas) they perform better, I linked the explainer article we wrote, but if you want to jump straight in check out the docs! <a href=\"https://docs.symbolica.ai/\" rel=\"nofollow\">https://docs.symbolica.ai/</a>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["calling","llm"],"value":"Show HN: <em>Calling</em> tools w/ Python improves <em>LLM</em> perf. vs MCP (77.1% on BrowseComp)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.symbolica.ai/blog/beyond-code-mode-agentica?theme=dark"}},"_tags":["story","author_charlielidbury","story_46287394","show_hn"],"author":"charlielidbury","created_at":"2025-12-16T11:41:34Z","created_at_i":1765885294,"num_comments":0,"objectID":"46287394","points":10,"story_id":46287394,"story_text":"If agent&#x27;s tools are exposed as functions&#x2F;objects in a Python REPL (as opposed to JSON schemas) they perform better, I linked the explainer article we wrote, but if you want to jump straight in check out the docs! <a href=\"https:&#x2F;&#x2F;docs.symbolica.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.symbolica.ai&#x2F;</a>","title":"Show HN: Calling tools w/ Python improves LLM perf. vs MCP (77.1% on BrowseComp)","updated_at":"2025-12-22T21:48:03Z","url":"https://www.symbolica.ai/blog/beyond-code-mode-agentica?theme=dark"}],"hitsPerPage":10,"nbHits":143,"nbPages":15,"page":0,"params":"query=function+calling+LLM&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":22,"processingTimingsMS":{"_request":{"queue":4,"roundTrip":18},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":7,"scanning":13,"total":21},"total":22},"query":"function calling LLM","serverTimeMS":27}
