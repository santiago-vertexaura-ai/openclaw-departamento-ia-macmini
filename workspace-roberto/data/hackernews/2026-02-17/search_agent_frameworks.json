{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"jhoxray"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"OneRingAI started as the internal engine of an enterprise agentic platform we've been building for 2+ years. After watching customers hit the same walls with auth, vendor lock-in, and context management over and over, we extracted the core into a standalone open-source library.\nThe two main alternatives didn't fit what we needed in production:<p>- LangChain: Great ecosystem, but the abstraction layers kept growing. By the time you wire up chains, runnables, callbacks, and <em>agents</em> across 50+ packages, you're fighting the <em>framework</em>\n  more than building your product.\n- CrewAI: Clean API, but Python-only and the role-based metaphor breaks down when you need fine-grained control over auth, context windows, or tool failures.<p>OneRingAI is a single TypeScript library (~62K LOC, 20 deps) that treats the boring production problems as first-class concerns:<p>Auth as architecture, not afterthought. A centralized connector registry with built-in OAuth (4 flows, AES-256-GCM storage, 43 vendor templates). This came directly from dealing with\nenterprise SSO and multi-tenant token isolation \u2014 no more scattered env vars or rolling your own token refresh.<p>Per-tool circuit breakers. One flaky Jira API shouldn't crash your entire <em>agent</em> loop. Each tool and connector gets independent failure isolation with retry/backoff. We learned this the\nhard way running <em>agents</em> against dozens of customer SaaS integrations simultaneously.<p>Context that doesn't blow up. Plugin-based context management with token budgeting. InContextMemory puts frequently-accessed state directly in the prompt instead of requiring a retrieval\ncall. Compaction removes tool call/result pairs together so the LLM never sees orphaned context.<p>Actually multi-vendor. 12 LLM providers native, 36 models in a typed registry with pricing and feature flags. Switch vendors by changing a connector name. Run openai-prod and\nopenai-backup side by side. Enterprise customers kept asking for this \u2014 nobody wants to be locked into one provider.<p>Multi-modal built in. Image gen (DALL-E 3, gpt-image-1, Imagen 4), video gen (Sora 2, Veo 3), TTS, STT \u2014 all in the same library. No extra packages.<p>Native MCP support with a registry pattern for managing multiple servers, health checks, and auto tool format conversion.<p>What it's not: it's not a no-code <em>agent</em> builder, and it's not trying to be a <em>framework</em> for every possible AI use case. It's an opinionated library for people building production <em>agent</em>\nsystems in TypeScript who want auth, resilience, and multi-vendor support without duct-taping 15 packages together.<p>2,285 tests, strict TypeScript throughout. The API surface is small on purpose \u2014 Connector.create(), <em>Agent</em>.create(), <em>agent</em>.run().<p>We also built Hosea, an open-source Electron desktop app on top of OneRingAI, if you want to see what a full <em>agent</em> system looks like in practice rather than just reading docs.<p>GitHub: <a href=\"https://github.com/Integrail/oneringai\" rel=\"nofollow\">https://github.com/Integrail/oneringai</a><p>npm: npm i @everworker/oneringai<p>Comparison with alternatives: <a href=\"https://oneringai.io/#comparison\" rel=\"nofollow\">https://oneringai.io/#comparison</a><p>Hosea: <a href=\"https://github.com/Integrail/oneringai/blob/main/apps/hosea/\" rel=\"nofollow\">https://github.com/Integrail/oneringai/blob/main/apps/hosea/</a>...<p>Happy to answer questions about the architecture decisions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: OneRingAI \u2013 Single TypeScript library for multi-vendor AI <em>agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://oneringai.io"}},"_tags":["story","author_jhoxray","story_47046494","show_hn"],"author":"jhoxray","created_at":"2026-02-17T11:48:29Z","created_at_i":1771328909,"num_comments":0,"objectID":"47046494","points":4,"story_id":47046494,"story_text":"OneRingAI started as the internal engine of an enterprise agentic platform we&#x27;ve been building for 2+ years. After watching customers hit the same walls with auth, vendor lock-in, and context management over and over, we extracted the core into a standalone open-source library.\nThe two main alternatives didn&#x27;t fit what we needed in production:<p>- LangChain: Great ecosystem, but the abstraction layers kept growing. By the time you wire up chains, runnables, callbacks, and agents across 50+ packages, you&#x27;re fighting the framework\n  more than building your product.\n- CrewAI: Clean API, but Python-only and the role-based metaphor breaks down when you need fine-grained control over auth, context windows, or tool failures.<p>OneRingAI is a single TypeScript library (~62K LOC, 20 deps) that treats the boring production problems as first-class concerns:<p>Auth as architecture, not afterthought. A centralized connector registry with built-in OAuth (4 flows, AES-256-GCM storage, 43 vendor templates). This came directly from dealing with\nenterprise SSO and multi-tenant token isolation \u2014 no more scattered env vars or rolling your own token refresh.<p>Per-tool circuit breakers. One flaky Jira API shouldn&#x27;t crash your entire agent loop. Each tool and connector gets independent failure isolation with retry&#x2F;backoff. We learned this the\nhard way running agents against dozens of customer SaaS integrations simultaneously.<p>Context that doesn&#x27;t blow up. Plugin-based context management with token budgeting. InContextMemory puts frequently-accessed state directly in the prompt instead of requiring a retrieval\ncall. Compaction removes tool call&#x2F;result pairs together so the LLM never sees orphaned context.<p>Actually multi-vendor. 12 LLM providers native, 36 models in a typed registry with pricing and feature flags. Switch vendors by changing a connector name. Run openai-prod and\nopenai-backup side by side. Enterprise customers kept asking for this \u2014 nobody wants to be locked into one provider.<p>Multi-modal built in. Image gen (DALL-E 3, gpt-image-1, Imagen 4), video gen (Sora 2, Veo 3), TTS, STT \u2014 all in the same library. No extra packages.<p>Native MCP support with a registry pattern for managing multiple servers, health checks, and auto tool format conversion.<p>What it&#x27;s not: it&#x27;s not a no-code agent builder, and it&#x27;s not trying to be a framework for every possible AI use case. It&#x27;s an opinionated library for people building production agent\nsystems in TypeScript who want auth, resilience, and multi-vendor support without duct-taping 15 packages together.<p>2,285 tests, strict TypeScript throughout. The API surface is small on purpose \u2014 Connector.create(), Agent.create(), agent.run().<p>We also built Hosea, an open-source Electron desktop app on top of OneRingAI, if you want to see what a full agent system looks like in practice rather than just reading docs.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Integrail&#x2F;oneringai\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Integrail&#x2F;oneringai</a><p>npm: npm i @everworker&#x2F;oneringai<p>Comparison with alternatives: <a href=\"https:&#x2F;&#x2F;oneringai.io&#x2F;#comparison\" rel=\"nofollow\">https:&#x2F;&#x2F;oneringai.io&#x2F;#comparison</a><p>Hosea: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;Integrail&#x2F;oneringai&#x2F;blob&#x2F;main&#x2F;apps&#x2F;hosea&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Integrail&#x2F;oneringai&#x2F;blob&#x2F;main&#x2F;apps&#x2F;hosea&#x2F;</a>...<p>Happy to answer questions about the architecture decisions.","title":"Show HN: OneRingAI \u2013 Single TypeScript library for multi-vendor AI agents","updated_at":"2026-02-17T12:43:18Z","url":"https://oneringai.io"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"manuelnd"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"We published the methodology we use for AI red team assessments. 48 hours, 4 phases, 6 attack priority areas.<p>This isn't theoretical \u2014 it's the <em>framework</em> we run against production AI agents with tool access. The core insight: AI red teaming requires different methodology than traditional penetration testing. The attack surface is different (natural language inputs, tool integrations, external data flows), and the exploitation patterns are different (attack chains that compose prompt injection into tool abuse, data exfiltration, or privilege escalation).<p>The 48-hour <em>framework</em>:<p>1. Reconnaissance (2h) \u2014 Map interfaces, tools, data flows, existing defenses. An <em>agent</em> with file system and database access is a fundamentally different target than a chatbot.<p>2. Automated Scanning (4h) \u2014 Systematic tests across 6 priorities: direct prompt injection, system prompt extraction, jailbreaks, tool abuse, indirect injection (RAG/web), and vision/multimodal attacks. Establishes a baseline.<p>3. Manual Exploitation (8h) \u2014 Confirm findings, build attack chains, test defense boundaries. Individual vulnerabilities compose: prompt injection -&gt; tool abuse -&gt; data exfiltration is a common chain.<p>4. Validation &amp; Reporting (2h) \u2014 Reproducibility, business impact, severity, resistance score.<p>Some observations from running these:<p>- 62 prompt injection techniques exist in our taxonomy. Most teams test for a handful. The basic ones (&quot;ignore previous instructions&quot;) are also the first to be blocked.<p>- Tool abuse is where the real damage happens. Parameter injection, scope escape, and tool chaining turn a successful prompt injection into unauthorized database queries, file access, or API calls.<p>- Indirect injection is underappreciated. If your AI reads external content (RAG, web search), that content is an attack surface. 5 poisoned documents among millions can achieve high attack success rates.<p>- Architecture determines priority. Chat-only apps need prompt injection testing first. RAG apps need indirect injection first. Agents with tools need tool abuse testing first.<p>The methodology references our open-source taxonomy of 122 attack vectors: https://github.com/tachyonicai/tachyonic-heuristics<p>Full post: https://tachyonicai.com/blog/how-to-red-team-ai-<em>agent</em>/<p>OWASP LLM Top 10 companion guide: https://tachyonicai.com/blog/owasp-llm-top-10-guide/"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"How to Red Team Your AI <em>Agent</em> in 48 Hours \u2013 A Practical Methodology"}},"_tags":["story","author_manuelnd","story_47045551","ask_hn"],"author":"manuelnd","created_at":"2026-02-17T09:53:19Z","created_at_i":1771321999,"num_comments":0,"objectID":"47045551","points":1,"story_id":47045551,"story_text":"We published the methodology we use for AI red team assessments. 48 hours, 4 phases, 6 attack priority areas.<p>This isn&#x27;t theoretical \u2014 it&#x27;s the framework we run against production AI agents with tool access. The core insight: AI red teaming requires different methodology than traditional penetration testing. The attack surface is different (natural language inputs, tool integrations, external data flows), and the exploitation patterns are different (attack chains that compose prompt injection into tool abuse, data exfiltration, or privilege escalation).<p>The 48-hour framework:<p>1. Reconnaissance (2h) \u2014 Map interfaces, tools, data flows, existing defenses. An agent with file system and database access is a fundamentally different target than a chatbot.<p>2. Automated Scanning (4h) \u2014 Systematic tests across 6 priorities: direct prompt injection, system prompt extraction, jailbreaks, tool abuse, indirect injection (RAG&#x2F;web), and vision&#x2F;multimodal attacks. Establishes a baseline.<p>3. Manual Exploitation (8h) \u2014 Confirm findings, build attack chains, test defense boundaries. Individual vulnerabilities compose: prompt injection -&gt; tool abuse -&gt; data exfiltration is a common chain.<p>4. Validation &amp; Reporting (2h) \u2014 Reproducibility, business impact, severity, resistance score.<p>Some observations from running these:<p>- 62 prompt injection techniques exist in our taxonomy. Most teams test for a handful. The basic ones (&quot;ignore previous instructions&quot;) are also the first to be blocked.<p>- Tool abuse is where the real damage happens. Parameter injection, scope escape, and tool chaining turn a successful prompt injection into unauthorized database queries, file access, or API calls.<p>- Indirect injection is underappreciated. If your AI reads external content (RAG, web search), that content is an attack surface. 5 poisoned documents among millions can achieve high attack success rates.<p>- Architecture determines priority. Chat-only apps need prompt injection testing first. RAG apps need indirect injection first. Agents with tools need tool abuse testing first.<p>The methodology references our open-source taxonomy of 122 attack vectors: https:&#x2F;&#x2F;github.com&#x2F;tachyonicai&#x2F;tachyonic-heuristics<p>Full post: https:&#x2F;&#x2F;tachyonicai.com&#x2F;blog&#x2F;how-to-red-team-ai-agent&#x2F;<p>OWASP LLM Top 10 companion guide: https:&#x2F;&#x2F;tachyonicai.com&#x2F;blog&#x2F;owasp-llm-top-10-guide&#x2F;","title":"How to Red Team Your AI Agent in 48 Hours \u2013 A Practical Methodology","updated_at":"2026-02-17T09:56:18Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"rittermax"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Start a task, grab a coffee, come back to production-grade code.  \nTests enforced. Context preserved. Quality automated.<p>Claude Code moves fast but without structure, it skips tests, loses context, and produces inconsistent results \u2014 especially on complex, established codebases. I tried other <em>frameworks</em> \u2014 they burned tokens on bloated prompts without adding real value. Some added process without enforcement. Others were prompt templates that Claude ignored when context got tight. None made Claude reliably produce production-grade code.<p>So I built Pilot. Instead of adding process on top, it bakes quality into every interaction. Linting, formatting, and type checking run as enforced hooks on every edit. TDD is mandatory, not suggested. Context is monitored and preserved across sessions. Every piece of work goes through verification before it's marked done.<p>Pilot optimizes for output quality, not system complexity. The rules are minimal and focused. There's no big learning curve, no project scaffolding to set up, no state files to manage. You install it in any existing project \u2014 no matter how complex \u2014 run `pilot`, then `/sync` to learn your codebase, and the quality guardrails are just there \u2014 hooks, TDD, type checking, formatting \u2014 enforced automatically on every edit, in every session.<p>The result: you can actually walk away. Start a `/spec` task, approve the plan, then go grab a coffee. When you come back, the work is done \u2014 tested, verified, formatted, and ready to ship. Hooks preserve state across compaction cycles, persistent memory carries context between sessions, quality hooks catch every mistake along the way, and verifier <em>agents</em> review the code before marking it complete. No babysitting required."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Claude Pilot \u2013 Claude Code is powerful. Pilot makes it reliable"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/maxritter/claude-pilot"}},"_tags":["story","author_rittermax","story_47043847","show_hn"],"author":"rittermax","created_at":"2026-02-17T04:55:29Z","created_at_i":1771304129,"num_comments":0,"objectID":"47043847","points":1,"story_id":47043847,"story_text":"Start a task, grab a coffee, come back to production-grade code.  \nTests enforced. Context preserved. Quality automated.<p>Claude Code moves fast but without structure, it skips tests, loses context, and produces inconsistent results \u2014 especially on complex, established codebases. I tried other frameworks \u2014 they burned tokens on bloated prompts without adding real value. Some added process without enforcement. Others were prompt templates that Claude ignored when context got tight. None made Claude reliably produce production-grade code.<p>So I built Pilot. Instead of adding process on top, it bakes quality into every interaction. Linting, formatting, and type checking run as enforced hooks on every edit. TDD is mandatory, not suggested. Context is monitored and preserved across sessions. Every piece of work goes through verification before it&#x27;s marked done.<p>Pilot optimizes for output quality, not system complexity. The rules are minimal and focused. There&#x27;s no big learning curve, no project scaffolding to set up, no state files to manage. You install it in any existing project \u2014 no matter how complex \u2014 run `pilot`, then `&#x2F;sync` to learn your codebase, and the quality guardrails are just there \u2014 hooks, TDD, type checking, formatting \u2014 enforced automatically on every edit, in every session.<p>The result: you can actually walk away. Start a `&#x2F;spec` task, approve the plan, then go grab a coffee. When you come back, the work is done \u2014 tested, verified, formatted, and ready to ship. Hooks preserve state across compaction cycles, persistent memory carries context between sessions, quality hooks catch every mistake along the way, and verifier agents review the code before marking it complete. No babysitting required.","title":"Show HN: Claude Pilot \u2013 Claude Code is powerful. Pilot makes it reliable","updated_at":"2026-02-17T04:57:01Z","url":"https://github.com/maxritter/claude-pilot"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"jxmorris12"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Forge: Scalable <em>Agent</em> RL <em>Framework</em> and Algorithm"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"https://www.minimax.io/news/forge-scalable-<em>agent</em>-rl-<em>framework</em>-and-algorithm"}},"_tags":["story","author_jxmorris12","story_47041601"],"author":"jxmorris12","created_at":"2026-02-16T23:09:54Z","created_at_i":1771283394,"num_comments":0,"objectID":"47041601","points":2,"story_id":47041601,"title":"Forge: Scalable Agent RL Framework and Algorithm","updated_at":"2026-02-16T23:15:46Z","url":"https://www.minimax.io/news/forge-scalable-agent-rl-framework-and-algorithm"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"dns"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"h3ll0 HN,<p>I\u2019ve spent the last 15 years in offensive security, and if there's one thing I've learned, it's that every new technology\u2014no matter how advanced\u2014brings its own unique breed of exploitable flaws. LLMs and autonomous <em>agents</em> are no exception. While they feel like &quot;magic,&quot; from a security perspective, they are just another attack surface with specific vulnerabilities in how they define and execute &quot;skills.&quot;<p>we built skillaudit.sh because I wanted a minimalist, lightweight tool to audit these new skill definitions without the overhead of heavy <em>frameworks</em>. It focuses on the practical, &quot;offensive&quot; side of LLM security.<p>What it audits:<p>- skillaudit-prompt-injection: Detects system prompt overrides and instructions hidden in HTML comments.<p>- skillaudit-data-exfiltration: Monitors for patterns used to leak session secrets to external endpoints.<p>- skillaudit-supply-chain-packages: Identifies hallucinated npm/pip package references (CWE-494).<p>- skillaudit-privilege-escalation: Checks for unauthorized tool execution or access level attempts.<p>- skillaudit-obfuscation: Flags Base64, Hex, or hidden URLs used to bypass filters.<p>It's still in the early stages, and I'm looking for feedback from this community on the detection patterns.<p>Security checks: <a href=\"https://skillaudit.sh/checks\" rel=\"nofollow\">https://skillaudit.sh/checks</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Skillaudit.sh \u2013 A minimalist security auditor for LLM skill definitions"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://skillaudit.sh/checks"}},"_tags":["story","author_dns","story_47039468","show_hn"],"author":"dns","created_at":"2026-02-16T19:54:39Z","created_at_i":1771271679,"num_comments":0,"objectID":"47039468","points":1,"story_id":47039468,"story_text":"h3ll0 HN,<p>I\u2019ve spent the last 15 years in offensive security, and if there&#x27;s one thing I&#x27;ve learned, it&#x27;s that every new technology\u2014no matter how advanced\u2014brings its own unique breed of exploitable flaws. LLMs and autonomous agents are no exception. While they feel like &quot;magic,&quot; from a security perspective, they are just another attack surface with specific vulnerabilities in how they define and execute &quot;skills.&quot;<p>we built skillaudit.sh because I wanted a minimalist, lightweight tool to audit these new skill definitions without the overhead of heavy frameworks. It focuses on the practical, &quot;offensive&quot; side of LLM security.<p>What it audits:<p>- skillaudit-prompt-injection: Detects system prompt overrides and instructions hidden in HTML comments.<p>- skillaudit-data-exfiltration: Monitors for patterns used to leak session secrets to external endpoints.<p>- skillaudit-supply-chain-packages: Identifies hallucinated npm&#x2F;pip package references (CWE-494).<p>- skillaudit-privilege-escalation: Checks for unauthorized tool execution or access level attempts.<p>- skillaudit-obfuscation: Flags Base64, Hex, or hidden URLs used to bypass filters.<p>It&#x27;s still in the early stages, and I&#x27;m looking for feedback from this community on the detection patterns.<p>Security checks: <a href=\"https:&#x2F;&#x2F;skillaudit.sh&#x2F;checks\" rel=\"nofollow\">https:&#x2F;&#x2F;skillaudit.sh&#x2F;checks</a>","title":"Show HN: Skillaudit.sh \u2013 A minimalist security auditor for LLM skill definitions","updated_at":"2026-02-16T20:02:16Z","url":"https://skillaudit.sh/checks"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"vseplet"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"A hackable AI <em>agent</em> <em>framework</em> for Telegram. ~4K lines of TypeScript, 6 LLM providers, 16 tools, full <em>agent</em> loop with memory"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Hackable Skinny Clawdbot for Telegram"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/vseplet/smith"}},"_tags":["story","author_vseplet","story_47037196","show_hn"],"author":"vseplet","created_at":"2026-02-16T16:45:49Z","created_at_i":1771260349,"num_comments":0,"objectID":"47037196","points":1,"story_id":47037196,"story_text":"A hackable AI agent framework for Telegram. ~4K lines of TypeScript, 6 LLM providers, 16 tools, full agent loop with memory","title":"Show HN: Hackable Skinny Clawdbot for Telegram","updated_at":"2026-02-16T16:48:01Z","url":"https://github.com/vseplet/smith"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"rnc000"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi! I\u2019m the creator of Rakenne and I built it because I noticed a recurring problem with LLMs in professional settings: chat-based document creation is unpredictable and hard to scale for domain experts.<p>Experts know the <i>process</i> of building a document (the questions to ask, the order of operations, the edge cases), but translating that into a long system prompt often leads to hallucinations or missed steps.<p>What is Rakenne? Rakenne is a multi-tenant SaaS that lets domain experts define &quot;Guided Workflows&quot; in Markdown. An LLM <em>agent</em> then runs these workflows server-side, conducting a structured dialogue with the user to produce a final, high-fidelity document.<p>The Tech Stack:<p>* Agentic Core: Built on the pi coding <em>agent</em> (<a href=\"https://github.com/badlogic/pi-mono\" rel=\"nofollow\">https://github.com/badlogic/pi-mono</a>) using RPC mode. This allows the <em>agent</em> to maintain state and follow complex logic branches defined in the Markdown files.<p>* Frontend: Built with Lit web components. I wanted something incredibly lightweight and <em>framework</em>-agnostic so the document &quot;interviews&quot; feel snappy and can eventually be embedded as widgets.<p>* Multi-tenancy: Designed to isolate <em>agent</em> environments server-side, ensuring that custom expert logic doesn't leak between tenants.<p>Why this approach? Instead of &quot;Chat with a PDF,&quot; it\u2019s &quot;The Logic of an Expert.&quot; If you\u2019re a lawyer or a compliance officer, you don\u2019t want a creative partner; you want a system that follows your proven methodology. By using Markdown, we make the &quot;expert logic&quot; version-controllable and easy for non-devs to edit.<p>I\u2019d love your feedback on:<p>1. The Agentic UX: Does the &quot;interview&quot; flow feel natural, or is it too rigid?\n2. Markdown as Logic: Is Markdown the right &quot;DSL&quot; for this, or should we move toward something like YAML or a custom schema?\n3. Latency: We're using RPC for the <em>agent</em>-browser communication\u2014is the response time acceptable for your use case?<p>Thanks! I'll be around to answer any technical questions."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Rakenne \u2013 Markdown-defined agentic workflows for structured documents"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://rakenne.app"}},"_tags":["story","author_rnc000","story_47034177","show_hn"],"author":"rnc000","created_at":"2026-02-16T12:26:31Z","created_at_i":1771244791,"num_comments":0,"objectID":"47034177","points":1,"story_id":47034177,"story_text":"Hi! I\u2019m the creator of Rakenne and I built it because I noticed a recurring problem with LLMs in professional settings: chat-based document creation is unpredictable and hard to scale for domain experts.<p>Experts know the <i>process</i> of building a document (the questions to ask, the order of operations, the edge cases), but translating that into a long system prompt often leads to hallucinations or missed steps.<p>What is Rakenne? Rakenne is a multi-tenant SaaS that lets domain experts define &quot;Guided Workflows&quot; in Markdown. An LLM agent then runs these workflows server-side, conducting a structured dialogue with the user to produce a final, high-fidelity document.<p>The Tech Stack:<p>* Agentic Core: Built on the pi coding agent (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;badlogic&#x2F;pi-mono\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;badlogic&#x2F;pi-mono</a>) using RPC mode. This allows the agent to maintain state and follow complex logic branches defined in the Markdown files.<p>* Frontend: Built with Lit web components. I wanted something incredibly lightweight and framework-agnostic so the document &quot;interviews&quot; feel snappy and can eventually be embedded as widgets.<p>* Multi-tenancy: Designed to isolate agent environments server-side, ensuring that custom expert logic doesn&#x27;t leak between tenants.<p>Why this approach? Instead of &quot;Chat with a PDF,&quot; it\u2019s &quot;The Logic of an Expert.&quot; If you\u2019re a lawyer or a compliance officer, you don\u2019t want a creative partner; you want a system that follows your proven methodology. By using Markdown, we make the &quot;expert logic&quot; version-controllable and easy for non-devs to edit.<p>I\u2019d love your feedback on:<p>1. The Agentic UX: Does the &quot;interview&quot; flow feel natural, or is it too rigid?\n2. Markdown as Logic: Is Markdown the right &quot;DSL&quot; for this, or should we move toward something like YAML or a custom schema?\n3. Latency: We&#x27;re using RPC for the agent-browser communication\u2014is the response time acceptable for your use case?<p>Thanks! I&#x27;ll be around to answer any technical questions.","title":"Show HN: Rakenne \u2013 Markdown-defined agentic workflows for structured documents","updated_at":"2026-02-16T12:31:00Z","url":"https://rakenne.app"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"madugula"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"The Agentic Shift: Peter Steinberger Joins OpenAI to Scale OpenClaw\nBy Sai Srikanth Madugula, PhD Research Scholar &amp; Product Manager | February 16, 2026<p>In a move that signals the definitive start of the &quot;Agentic Era,&quot; Peter Steinberger, the architect behind the viral open-source <em>framework</em> OpenClaw, has officially joined OpenAI. This transition isn't just a high-profile hire; it represents a fundamental change in how the industry views the intersection of proprietary intelligence and open-source orchestration.<p>As I continue my PhD research into AI-Blockchain models, I view this as a seminal moment. We are moving away from simple chatbots toward autonomous &quot;workers&quot; that can interact, reason, and execute. Steinberger\u2019s integration into OpenAI provides the missing bridge between world-class models and real-world execution <em>frameworks</em>.<p>In the Words of Sam Altman\nSam Altman, CEO of OpenAI, took to X (formerly Twitter) to welcome Steinberger and clarify the future of the <em>framework</em>. His statement highlights a newfound commitment to the open-source community as part of OpenAI's core product strategy:<p>&quot;Peter Steinberger is joining OpenAI to drive the next generation of personal <em>agents</em>. He is a genius with a lot of amazing ideas about the future of very smart <em>agents</em> interacting with each other to do very useful things for people... OpenClaw will live in a foundation as an open source project that OpenAI will continue to support.&quot;\nAltman\u2019s vision of a &quot;multi-<em>agent</em>&quot; future confirms what many of us in product management have suspected: the next billion-dollar startups won't be built on a single LLM, but on the orchestration of many specialized <em>agents</em> working in concert.<p>Why This Matters: The OpenClaw Foundation\nThe decision to house OpenClaw in an independent open-source foundation while receiving OpenAI\u2019s backing is a strategic masterstroke. It ensures that the <em>framework</em> remains a neutral ground for developers while benefiting from the massive compute and research resources of OpenAI. This helps solve several critical bottlenecks:<p>Interoperability: By standardizing how <em>agents</em> talk to each other, OpenClaw can become the &quot;HTTP of AI,&quot; allowing different models to collaborate seamlessly.\nReduced Friction: Developers can leverage pre-built &quot;<em>agent</em> personas&quot; (like the AI Engineer or AI Researcher) without reinventing the orchestration logic every time.\nTrust and Transparency: Keeping the foundation open-source helps demystify the &quot;black box&quot; of agentic decision-making, an area I am particularly focused on in my doctoral studies.\nA Catalyst for Solo Founders and Nano-Startups\nFor the solo founder, this news is transformative. When the creator of the most robust orchestration tool joins forces with the creator of the world's most capable models, the barriers to entry collapse. We are entering a phase where a single human can manage a &quot;digital corporation.&quot;<p>The implications for latency and data privacy are also significant. As OpenAI supports the foundation, we can expect more optimizations for on-device and edge-native <em>agents</em>\u2014a direction I recently analyzed through the lens of Karpathy\u2019s MicroGPT. Small, fast, and local <em>agents</em> are the future, and OpenClaw is the engine that will run them.<p>The Human in the Loop: The Conductor Role\nDoes this mean human roles are disappearing? Quite the opposite. As I\u2019ve argued in previous posts, our role is evolving into that of a Strategic Conductor. Peter Steinberger's move to OpenAI suggests that the industry is ready to provide us with a much more powerful orchestra. Our value now lies in the vision we set and the ethical guardrails we implement.<p>The workplace of tomorrow is no longer a collection of desks; it is a symphony of digital intelligence, and the baton is firmly in our hands."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Agentic Shift: Peter Steinberger Joins OpenAI"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://blog.saimadugula.com/posts/steinberger-openai-openclaw.html"}},"_tags":["story","author_madugula","story_47033865","show_hn"],"author":"madugula","created_at":"2026-02-16T11:42:16Z","created_at_i":1771242136,"num_comments":0,"objectID":"47033865","points":1,"story_id":47033865,"story_text":"The Agentic Shift: Peter Steinberger Joins OpenAI to Scale OpenClaw\nBy Sai Srikanth Madugula, PhD Research Scholar &amp; Product Manager | February 16, 2026<p>In a move that signals the definitive start of the &quot;Agentic Era,&quot; Peter Steinberger, the architect behind the viral open-source framework OpenClaw, has officially joined OpenAI. This transition isn&#x27;t just a high-profile hire; it represents a fundamental change in how the industry views the intersection of proprietary intelligence and open-source orchestration.<p>As I continue my PhD research into AI-Blockchain models, I view this as a seminal moment. We are moving away from simple chatbots toward autonomous &quot;workers&quot; that can interact, reason, and execute. Steinberger\u2019s integration into OpenAI provides the missing bridge between world-class models and real-world execution frameworks.<p>In the Words of Sam Altman\nSam Altman, CEO of OpenAI, took to X (formerly Twitter) to welcome Steinberger and clarify the future of the framework. His statement highlights a newfound commitment to the open-source community as part of OpenAI&#x27;s core product strategy:<p>&quot;Peter Steinberger is joining OpenAI to drive the next generation of personal agents. He is a genius with a lot of amazing ideas about the future of very smart agents interacting with each other to do very useful things for people... OpenClaw will live in a foundation as an open source project that OpenAI will continue to support.&quot;\nAltman\u2019s vision of a &quot;multi-agent&quot; future confirms what many of us in product management have suspected: the next billion-dollar startups won&#x27;t be built on a single LLM, but on the orchestration of many specialized agents working in concert.<p>Why This Matters: The OpenClaw Foundation\nThe decision to house OpenClaw in an independent open-source foundation while receiving OpenAI\u2019s backing is a strategic masterstroke. It ensures that the framework remains a neutral ground for developers while benefiting from the massive compute and research resources of OpenAI. This helps solve several critical bottlenecks:<p>Interoperability: By standardizing how agents talk to each other, OpenClaw can become the &quot;HTTP of AI,&quot; allowing different models to collaborate seamlessly.\nReduced Friction: Developers can leverage pre-built &quot;agent personas&quot; (like the AI Engineer or AI Researcher) without reinventing the orchestration logic every time.\nTrust and Transparency: Keeping the foundation open-source helps demystify the &quot;black box&quot; of agentic decision-making, an area I am particularly focused on in my doctoral studies.\nA Catalyst for Solo Founders and Nano-Startups\nFor the solo founder, this news is transformative. When the creator of the most robust orchestration tool joins forces with the creator of the world&#x27;s most capable models, the barriers to entry collapse. We are entering a phase where a single human can manage a &quot;digital corporation.&quot;<p>The implications for latency and data privacy are also significant. As OpenAI supports the foundation, we can expect more optimizations for on-device and edge-native agents\u2014a direction I recently analyzed through the lens of Karpathy\u2019s MicroGPT. Small, fast, and local agents are the future, and OpenClaw is the engine that will run them.<p>The Human in the Loop: The Conductor Role\nDoes this mean human roles are disappearing? Quite the opposite. As I\u2019ve argued in previous posts, our role is evolving into that of a Strategic Conductor. Peter Steinberger&#x27;s move to OpenAI suggests that the industry is ready to provide us with a much more powerful orchestra. Our value now lies in the vision we set and the ethical guardrails we implement.<p>The workplace of tomorrow is no longer a collection of desks; it is a symphony of digital intelligence, and the baton is firmly in our hands.","title":"Show HN: Agentic Shift: Peter Steinberger Joins OpenAI","updated_at":"2026-02-16T11:44:43Z","url":"https://blog.saimadugula.com/posts/steinberger-openai-openclaw.html"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"tanmay001"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"AI <em>agents</em> often generate inconsistent Playwright tests because they do not understand your application\u2019s specific workflows, UI patterns, or constraints.<p>The Playwright Skill provides more than 70 structured markdown guides that teach patterns for locators, authentication, visual testing, CI configuration, and <em>framework</em> migration so <em>agents</em> can apply consistent solutions instead of guessing.<p>You install it with: npx skills add testdino-hq/playwright-skill.<p>The material is organized into five packs: core testing (46 guides), Playwright CLI usage for token\u2011efficient automation (10), Page Object Model patterns (2), CI/CD setup for major providers (9), and migrations from Cypress or Selenium (2).<p>Each guide follows the same structure\u2014when to use a pattern, when to avoid it, quick reference code, and complete implementations\u2014so learners can move from concept to reliable tests step by step.<p>The skill works with tools such as Claude Code, GitHub Copilot, Cursor, and any <em>agent</em> that implements the skills protocol, and it is MIT\u2011licensed so teams can adapt the content to their own standards and practices.<p>For a deeper walkthrough of the guides and structure, see the full article at <a href=\"https://testdino.com/blog/playwright-skill/\" rel=\"nofollow\">https://testdino.com/blog/playwright-skill/</a>."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: Train AI <em>Agents</em> to Write Better Playwright Tests"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://testdino.com/blog/playwright-skill/"}},"_tags":["story","author_tanmay001","story_47032774","show_hn"],"author":"tanmay001","created_at":"2026-02-16T09:18:10Z","created_at_i":1771233490,"num_comments":0,"objectID":"47032774","points":2,"story_id":47032774,"story_text":"AI agents often generate inconsistent Playwright tests because they do not understand your application\u2019s specific workflows, UI patterns, or constraints.<p>The Playwright Skill provides more than 70 structured markdown guides that teach patterns for locators, authentication, visual testing, CI configuration, and framework migration so agents can apply consistent solutions instead of guessing.<p>You install it with: npx skills add testdino-hq&#x2F;playwright-skill.<p>The material is organized into five packs: core testing (46 guides), Playwright CLI usage for token\u2011efficient automation (10), Page Object Model patterns (2), CI&#x2F;CD setup for major providers (9), and migrations from Cypress or Selenium (2).<p>Each guide follows the same structure\u2014when to use a pattern, when to avoid it, quick reference code, and complete implementations\u2014so learners can move from concept to reliable tests step by step.<p>The skill works with tools such as Claude Code, GitHub Copilot, Cursor, and any agent that implements the skills protocol, and it is MIT\u2011licensed so teams can adapt the content to their own standards and practices.<p>For a deeper walkthrough of the guides and structure, see the full article at <a href=\"https:&#x2F;&#x2F;testdino.com&#x2F;blog&#x2F;playwright-skill&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;testdino.com&#x2F;blog&#x2F;playwright-skill&#x2F;</a>.","title":"Show HN: Train AI Agents to Write Better Playwright Tests","updated_at":"2026-02-16T09:24:28Z","url":"https://testdino.com/blog/playwright-skill/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"quinncom"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"<em>Agent</em> Zero AI: open-source agentic <em>framework</em> and computer assistant"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"https://www.<em>agent</em>-zero.ai/"}},"_tags":["story","author_quinncom","story_47027505"],"author":"quinncom","children":[47027823],"created_at":"2026-02-15T21:02:22Z","created_at_i":1771189342,"num_comments":1,"objectID":"47027505","points":1,"story_id":47027505,"title":"Agent Zero AI: open-source agentic framework and computer assistant","updated_at":"2026-02-15T22:07:28Z","url":"https://www.agent-zero.ai/"}],"hitsPerPage":10,"nbHits":1222,"nbPages":100,"page":0,"params":"query=agent+frameworks&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":34,"processingTimingsMS":{"_request":{"roundTrip":15},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":7,"scanning":26,"total":34},"total":34},"query":"agent frameworks","serverTimeMS":36}
