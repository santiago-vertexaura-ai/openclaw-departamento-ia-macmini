{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"dcellison"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"I built Kai because I wanted <em>Claude</em> <em>Code</em>'s full capabilities - shell access, file editing, git, web search - available from my phone, without being tied to a terminal.<p>Kai is a Telegram bot that wraps a persistent <em>Claude</em> <em>Code</em> process. You send messages in Telegram, and <em>Claude</em> responds with full tool access: it can read and edit files, run commands, manage git branches, search the web, and work across multiple projects. Responses stream back in real time. Everything runs on your own machine.<p>*How I actually <em>use</em> it:* I point Kai at a project workspace and <em>use</em> it as a dev assistant. It has the full context of whatever repo it's looking at - it can read and write <em>code</em>, check git status, run tests, make commits. Switching between projects is a Telegram command. I can be away from my desk and tell it &quot;fix the failing CI on the web repo&quot; or &quot;add input validation to the signup form&quot; and it just does it.<p>*Background:* I originally ran an instance of an open-source bot framework, but shut it down after a few days due to security concerns. I rebuilt from scratch on top of <em>Claude</em> <em>Code</em>'s CLI, which handles sandboxing and tool execution properly.<p>*No AI API keys required:* Kai doesn't call the Anthropic API directly - it wraps a logged-in <em>Claude</em> <em>Code</em> session, so there are no API keys to manage and no per-token costs beyond your existing <em>Claude</em> <em>Code</em> subscription. The original design eliminated all API keys after security problems with another bot framework that managed them insecurely. Now that Kai runs on a trustworthy local foundation, optional service integrations are safe.<p>*Privacy angle:* Kai runs locally - on a Mac mini in my <em>case</em>. Conversations, credentials, and project files never leave the machine. There's no server component, no cloud relay. Your Telegram messages go to your machine, and <em>Claude</em> <em>Code</em> handles the rest through Anthropic's API directly.<p>*External services without MCP:* Kai has a declarative HTTP service layer for connecting to any REST API. You define services in a YAML config - URL, method, auth type - and Kai makes the HTTP calls directly. No plugins, no third-party server processes, no executable <em>code</em>. API keys stay in your `.env` and are never touched by intermediary <em>code</em>. Ships with a Perplexity config for web search, but the same pattern works for weather APIs, notification services (Pushover, ntfy), home automation, translation, or anything else with a REST endpoint. Entirely optional - Kai works fine without it.<p>*Some things it can do:*<p>- Connect to external REST APIs via declarative config (search, weather, notifications, etc.)\n- Transcribe voice messages locally (whisper.cpp) and respond with voice (Piper TTS)\n- Run scheduled jobs and reminders\n- Receive GitHub webhooks (push, PR, issue notifications)\n- Stream responses in real time (message updates every 2s)\n- Switch between workspaces and models via Telegram commands<p>It's a single Python package, about 1700 lines across 11 modules. Runs as a launchd/systemd service. Setup is: clone, pip install, set two env vars (Telegram token + your user ID), and `make run`.<p>Repo: <a href=\"https://github.com/dcellison/kai\" rel=\"nofollow\">https://github.com/dcellison/kai</a><p>Happy to answer any questions about the setup or architecture."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude","code"],"value":"Show HN: Kai \u2013 A Telegram bot that turns <em>Claude</em> <em>Code</em> into a personal dev asst"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/dcellison/kai"}},"_tags":["story","author_dcellison","story_47034875","show_hn"],"author":"dcellison","children":[47037167],"created_at":"2026-02-16T13:47:46Z","created_at_i":1771249666,"num_comments":1,"objectID":"47034875","points":1,"story_id":47034875,"story_text":"I built Kai because I wanted Claude Code&#x27;s full capabilities - shell access, file editing, git, web search - available from my phone, without being tied to a terminal.<p>Kai is a Telegram bot that wraps a persistent Claude Code process. You send messages in Telegram, and Claude responds with full tool access: it can read and edit files, run commands, manage git branches, search the web, and work across multiple projects. Responses stream back in real time. Everything runs on your own machine.<p>*How I actually use it:* I point Kai at a project workspace and use it as a dev assistant. It has the full context of whatever repo it&#x27;s looking at - it can read and write code, check git status, run tests, make commits. Switching between projects is a Telegram command. I can be away from my desk and tell it &quot;fix the failing CI on the web repo&quot; or &quot;add input validation to the signup form&quot; and it just does it.<p>*Background:* I originally ran an instance of an open-source bot framework, but shut it down after a few days due to security concerns. I rebuilt from scratch on top of Claude Code&#x27;s CLI, which handles sandboxing and tool execution properly.<p>*No AI API keys required:* Kai doesn&#x27;t call the Anthropic API directly - it wraps a logged-in Claude Code session, so there are no API keys to manage and no per-token costs beyond your existing Claude Code subscription. The original design eliminated all API keys after security problems with another bot framework that managed them insecurely. Now that Kai runs on a trustworthy local foundation, optional service integrations are safe.<p>*Privacy angle:* Kai runs locally - on a Mac mini in my case. Conversations, credentials, and project files never leave the machine. There&#x27;s no server component, no cloud relay. Your Telegram messages go to your machine, and Claude Code handles the rest through Anthropic&#x27;s API directly.<p>*External services without MCP:* Kai has a declarative HTTP service layer for connecting to any REST API. You define services in a YAML config - URL, method, auth type - and Kai makes the HTTP calls directly. No plugins, no third-party server processes, no executable code. API keys stay in your `.env` and are never touched by intermediary code. Ships with a Perplexity config for web search, but the same pattern works for weather APIs, notification services (Pushover, ntfy), home automation, translation, or anything else with a REST endpoint. Entirely optional - Kai works fine without it.<p>*Some things it can do:*<p>- Connect to external REST APIs via declarative config (search, weather, notifications, etc.)\n- Transcribe voice messages locally (whisper.cpp) and respond with voice (Piper TTS)\n- Run scheduled jobs and reminders\n- Receive GitHub webhooks (push, PR, issue notifications)\n- Stream responses in real time (message updates every 2s)\n- Switch between workspaces and models via Telegram commands<p>It&#x27;s a single Python package, about 1700 lines across 11 modules. Runs as a launchd&#x2F;systemd service. Setup is: clone, pip install, set two env vars (Telegram token + your user ID), and `make run`.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dcellison&#x2F;kai\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dcellison&#x2F;kai</a><p>Happy to answer any questions about the setup or architecture.","title":"Show HN: Kai \u2013 A Telegram bot that turns Claude Code into a personal dev asst","updated_at":"2026-02-16T16:43:59Z","url":"https://github.com/dcellison/kai"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ChilinAI"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"Hi HN,\nI\u2019m a full-stack developer and I built a small tool that I now <em>use</em> every day.<p><em>Claude</em> <em>Code</em> from Anthropic is a very capable AI coding assistant, but it only runs locally on your computer. That means if you\u2019re away from your desk \u2014 commuting, walking, or just on the couch \u2014 you can\u2019t easily give it tasks.\nI wanted a simple way to send commands to <em>Claude</em> <em>Code</em> running on my home Mac from anywhere.\nSo I built <em>Claude</em> Remote \u2014 a free, open-source app that lets you control <em>Claude</em> <em>Code</em> through a browser.<p>How it works\nInstall a lightweight macOS app (menu bar app, ~5 MB, Apple Silicon).\nOpen a web chat from your phone or any device.\nSend a task \u2014 <em>Claude</em> <em>Code</em> executes it locally on your Mac and returns the result.\nThe Mac app acts as a bridge between the browser and <em>Claude</em> <em>Code</em>. All execution happens locally on your machine.<p>What I <em>use</em> it for\nFixing bugs or generating small features in side projects\nCreating or editing landing pages\nChecking or organizing files\nRunning scripts\nOpening websites in Chrome and interacting with them\nSummarizing or generating content\nPreparing quick reports\n<em>Claude</em> <em>Code</em> can control Chrome (open pages, read content, fill forms, take screenshots), so you can automate simple browser tasks remotely.\nResponses are returned as formatted markdown. I also added optional text-to-speech playback, which makes it usable while driving.\nPrivacy &amp; security\nOpen source (GitHub link below)\nNo subscriptions\nFirebase Auth (each user only sees their own sessions)\nAll AI execution happens on your machine\nThis is currently macOS (Apple Silicon) only.<p>I\u2019d really appreciate feedback \u2014 especially on security, architecture, and potential edge <em>cases</em>.<p>Website: <a href=\"https://clauderemote.web.app\" rel=\"nofollow\">https://clauderemote.web.app</a><p>GitHub: <a href=\"https://github.com/ChilinAI/claude-remote\" rel=\"nofollow\">https://github.com/ChilinAI/<em>claude</em>-remote</a><p>Thanks!"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude","code"],"value":"Show HN: <em>Claude</em> Remote \u2013 control <em>Claude</em> <em>Code</em> on your Mac from your phone"}},"_tags":["story","author_ChilinAI","story_47032993","show_hn"],"author":"ChilinAI","children":[47033354],"created_at":"2026-02-16T09:45:52Z","created_at_i":1771235152,"num_comments":1,"objectID":"47032993","points":2,"story_id":47032993,"story_text":"Hi HN,\nI\u2019m a full-stack developer and I built a small tool that I now use every day.<p>Claude Code from Anthropic is a very capable AI coding assistant, but it only runs locally on your computer. That means if you\u2019re away from your desk \u2014 commuting, walking, or just on the couch \u2014 you can\u2019t easily give it tasks.\nI wanted a simple way to send commands to Claude Code running on my home Mac from anywhere.\nSo I built Claude Remote \u2014 a free, open-source app that lets you control Claude Code through a browser.<p>How it works\nInstall a lightweight macOS app (menu bar app, ~5 MB, Apple Silicon).\nOpen a web chat from your phone or any device.\nSend a task \u2014 Claude Code executes it locally on your Mac and returns the result.\nThe Mac app acts as a bridge between the browser and Claude Code. All execution happens locally on your machine.<p>What I use it for\nFixing bugs or generating small features in side projects\nCreating or editing landing pages\nChecking or organizing files\nRunning scripts\nOpening websites in Chrome and interacting with them\nSummarizing or generating content\nPreparing quick reports\nClaude Code can control Chrome (open pages, read content, fill forms, take screenshots), so you can automate simple browser tasks remotely.\nResponses are returned as formatted markdown. I also added optional text-to-speech playback, which makes it usable while driving.\nPrivacy &amp; security\nOpen source (GitHub link below)\nNo subscriptions\nFirebase Auth (each user only sees their own sessions)\nAll AI execution happens on your machine\nThis is currently macOS (Apple Silicon) only.<p>I\u2019d really appreciate feedback \u2014 especially on security, architecture, and potential edge cases.<p>Website: <a href=\"https:&#x2F;&#x2F;clauderemote.web.app\" rel=\"nofollow\">https:&#x2F;&#x2F;clauderemote.web.app</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ChilinAI&#x2F;claude-remote\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ChilinAI&#x2F;claude-remote</a><p>Thanks!","title":"Show HN: Claude Remote \u2013 control Claude Code on your Mac from your phone","updated_at":"2026-02-16T10:30:14Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"server-lab"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"I built DoScript, a domain-specific language for file automation. The goal: make scripts readable by anyone.\nDesign Goal\nInstead of:\nbashfind . -type f -mtime +30 -exec rm {} \\;\nWrite:\nfor_each file_in here\n    if_older_than {file_name} 30 days\n        delete file {file_path}\n    end_if\nend_for\nTrade power for clarity. Optimize for maintenance over terseness.\nKey Design Decisions\n1. Natural Language Keywords\nmake folder not mkdir, copy file not cp. Self-documenting.\n2. Implicit Metadata\nWhen iterating files, auto-inject: {file_name}, {file_path}, {file_size}, {file_modified}, {file_is_old_days}\nfor_each file_in &quot;Documents&quot;\n    say &quot;{file_name} is {file_size} bytes&quot;\nend_for\n3. Built-in Time Handling\nif_older_than {file_name} 30 days\nmake folder &quot;backup_{today}&quot;\nNo date arithmetic needed.\n4. Expression Evaluation\nFunction-based for simplicity:\nif greater_than {file_size} 1000000\nif and(equals({type}, &quot;pdf&quot;), greater_than({size}, 10000))\nIntentionally awkward for complex logic - signals you should <em>use</em> Python.\nImplementation<p>Python interpreter (~2000 LOC)\nRecursive descent parser\nContext-aware error reporting\nCustom exception types with file/line info<p>Visual Component\nBuilt a browser-based node editor (single HTML file, 1200 LOC). Drag boxes, wire them, generate DoScript <em>code</em>.\nWhy? Different learning styles, workflow visualization, non-programmer accessibility.\nWhat Worked<p>Natural syntax is immediately understandable\nMetadata injection removes boilerplate\nTime handling makes common <em>cases</em> trivial\nVisual IDE differentiates from text-only<p>What Didn't<p>Complex conditionals get awkward fast\nNo user-defined functions (only macros)\nLimited data structures\nPerformance not optimized<p>The Challenge\nBuilt for non-programmers. But they don't hang out on dev forums. Developers say &quot;just <em>use</em> Python&quot; - which misses the point.\nHow do you market dev tools to non-developers?\nTechnical Transparency\nI designed syntax and architecture. Most Python implementation was AI-assisted (<em>Claude</em>, Copilot). Focus on design, <em>use</em> tools for implementation.\nOpen Questions<p>When does a DSL become too limited?\nHow to market to non-developers?\nType system worth the complexity?\nShould DSLs provide escape hatches to host language?<p>GitHub: <a href=\"https://github.com/TheServer-lab/DoScript\" rel=\"nofollow\">https://github.com/TheServer-lab/DoScript</a>\nv0.6.5, includes interpreter, visual IDE, VS <em>Code</em> extension, examples.\nBuilt because bash was too cryptic for my friend to organize files. Turns out lots of people have this problem.\nWould love feedback from people who've built DSLs or struggled with similar trade-offs."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: DoScript \u2013 DSL for file automation with natural language syntax"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/TheServer-lab/DoScript"}},"_tags":["story","author_server-lab","story_47032476","show_hn"],"author":"server-lab","created_at":"2026-02-16T08:37:57Z","created_at_i":1771231077,"num_comments":0,"objectID":"47032476","points":1,"story_id":47032476,"story_text":"I built DoScript, a domain-specific language for file automation. The goal: make scripts readable by anyone.\nDesign Goal\nInstead of:\nbashfind . -type f -mtime +30 -exec rm {} \\;\nWrite:\nfor_each file_in here\n    if_older_than {file_name} 30 days\n        delete file {file_path}\n    end_if\nend_for\nTrade power for clarity. Optimize for maintenance over terseness.\nKey Design Decisions\n1. Natural Language Keywords\nmake folder not mkdir, copy file not cp. Self-documenting.\n2. Implicit Metadata\nWhen iterating files, auto-inject: {file_name}, {file_path}, {file_size}, {file_modified}, {file_is_old_days}\nfor_each file_in &quot;Documents&quot;\n    say &quot;{file_name} is {file_size} bytes&quot;\nend_for\n3. Built-in Time Handling\nif_older_than {file_name} 30 days\nmake folder &quot;backup_{today}&quot;\nNo date arithmetic needed.\n4. Expression Evaluation\nFunction-based for simplicity:\nif greater_than {file_size} 1000000\nif and(equals({type}, &quot;pdf&quot;), greater_than({size}, 10000))\nIntentionally awkward for complex logic - signals you should use Python.\nImplementation<p>Python interpreter (~2000 LOC)\nRecursive descent parser\nContext-aware error reporting\nCustom exception types with file&#x2F;line info<p>Visual Component\nBuilt a browser-based node editor (single HTML file, 1200 LOC). Drag boxes, wire them, generate DoScript code.\nWhy? Different learning styles, workflow visualization, non-programmer accessibility.\nWhat Worked<p>Natural syntax is immediately understandable\nMetadata injection removes boilerplate\nTime handling makes common cases trivial\nVisual IDE differentiates from text-only<p>What Didn&#x27;t<p>Complex conditionals get awkward fast\nNo user-defined functions (only macros)\nLimited data structures\nPerformance not optimized<p>The Challenge\nBuilt for non-programmers. But they don&#x27;t hang out on dev forums. Developers say &quot;just use Python&quot; - which misses the point.\nHow do you market dev tools to non-developers?\nTechnical Transparency\nI designed syntax and architecture. Most Python implementation was AI-assisted (Claude, Copilot). Focus on design, use tools for implementation.\nOpen Questions<p>When does a DSL become too limited?\nHow to market to non-developers?\nType system worth the complexity?\nShould DSLs provide escape hatches to host language?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;TheServer-lab&#x2F;DoScript\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;TheServer-lab&#x2F;DoScript</a>\nv0.6.5, includes interpreter, visual IDE, VS Code extension, examples.\nBuilt because bash was too cryptic for my friend to organize files. Turns out lots of people have this problem.\nWould love feedback from people who&#x27;ve built DSLs or struggled with similar trade-offs.","title":"Show HN: DoScript \u2013 DSL for file automation with natural language syntax","updated_at":"2026-02-16T08:42:59Z","url":"https://github.com/TheServer-lab/DoScript"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"lordokami"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"My wife and I built and shipped a simple iOS app without writing a single line of <em>code</em> in the traditional sense.<p>She hates when I bring my laptop on trips. I love building things. This was our compromise.<p>I had been wanting to experiment with building an iOS app using <em>Claude</em> <em>Code</em>. I had never built for iOS before, and the idea of exploring it through AI-assisted development felt like a new frontier for me. But bringing a laptop to Japan again would not go unnoticed, and not in a good way.<p>So I made a plan.<p>Before leaving Spain, I configured my Mac so it would never sleep. I set up a VPN so I could SSH into it securely from my phone. I installed Zellij to maintain persistent terminal sessions in <em>case</em> the connection dropped. I also prepared a deployment pipeline to TestFlight, so I could trigger builds remotely and test them about 15 minutes later from the other side of the world, asynchronously.<p>This was our second time visiting Japan, and we have always wanted to learn more of the language. So we decided to build something we would actually <em>use</em>: a lightweight phrase app with useful tourist sentences and built-in text to speech. Things like ordering in restaurants, asking how much something costs, or navigating train stations.<p>The funny part is how it evolved.<p>While I was driving between cities, my wife would sit in the passenger seat dictating changes and features into Terminus on my iPhone, connected via SSH to my Mac back home. We used voice input to modify prompts, refine UI text, and generate new features. It became a shared game.<p>Development happened in short bursts, in parking lots, at rest stops, during train rides. We would ship a build, test it in real restaurants or shops, notice friction, and tweak it again that same evening from a ryokan or small hotel room.<p>The feedback loop was almost absurdly tight. We would <em>use</em> it in the real world, find awkward phrasing, improve it, redeploy, and test again the next day.<p>We never opened Xcode locally. We never touched the Mac physically during the trip. Everything happened remotely from a phone across continents.<p>What started as a workaround to avoid bringing a laptop turned into one of the most fun and lightweight building experiences I have ever had. It did not feel like working on vacation. It felt like co-creating something useful for the trip itself.<p>By the end of the journey, the app was not just a prototype. It was stable, usable, and something we genuinely relied on.<p>More than the app itself, the experiment was the interesting part: remote vibecoding, persistent sessions, AI-assisted iteration, and building in real-world feedback loops instead of simulated ones.<p>It made me rethink what a development environment even means.<p>Happy to answer questions about the setup, tooling, workflow, or what broke along the way."},"title":{"matchLevel":"none","matchedWords":[],"value":"Built and shipped an iOS app from my phone while traveling Japan"}},"_tags":["story","author_lordokami","story_47011100","ask_hn"],"author":"lordokami","children":[47011127,47012467,47011145],"created_at":"2026-02-14T03:00:57Z","created_at_i":1771038057,"num_comments":7,"objectID":"47011100","points":8,"story_id":47011100,"story_text":"My wife and I built and shipped a simple iOS app without writing a single line of code in the traditional sense.<p>She hates when I bring my laptop on trips. I love building things. This was our compromise.<p>I had been wanting to experiment with building an iOS app using Claude Code. I had never built for iOS before, and the idea of exploring it through AI-assisted development felt like a new frontier for me. But bringing a laptop to Japan again would not go unnoticed, and not in a good way.<p>So I made a plan.<p>Before leaving Spain, I configured my Mac so it would never sleep. I set up a VPN so I could SSH into it securely from my phone. I installed Zellij to maintain persistent terminal sessions in case the connection dropped. I also prepared a deployment pipeline to TestFlight, so I could trigger builds remotely and test them about 15 minutes later from the other side of the world, asynchronously.<p>This was our second time visiting Japan, and we have always wanted to learn more of the language. So we decided to build something we would actually use: a lightweight phrase app with useful tourist sentences and built-in text to speech. Things like ordering in restaurants, asking how much something costs, or navigating train stations.<p>The funny part is how it evolved.<p>While I was driving between cities, my wife would sit in the passenger seat dictating changes and features into Terminus on my iPhone, connected via SSH to my Mac back home. We used voice input to modify prompts, refine UI text, and generate new features. It became a shared game.<p>Development happened in short bursts, in parking lots, at rest stops, during train rides. We would ship a build, test it in real restaurants or shops, notice friction, and tweak it again that same evening from a ryokan or small hotel room.<p>The feedback loop was almost absurdly tight. We would use it in the real world, find awkward phrasing, improve it, redeploy, and test again the next day.<p>We never opened Xcode locally. We never touched the Mac physically during the trip. Everything happened remotely from a phone across continents.<p>What started as a workaround to avoid bringing a laptop turned into one of the most fun and lightweight building experiences I have ever had. It did not feel like working on vacation. It felt like co-creating something useful for the trip itself.<p>By the end of the journey, the app was not just a prototype. It was stable, usable, and something we genuinely relied on.<p>More than the app itself, the experiment was the interesting part: remote vibecoding, persistent sessions, AI-assisted iteration, and building in real-world feedback loops instead of simulated ones.<p>It made me rethink what a development environment even means.<p>Happy to answer questions about the setup, tooling, workflow, or what broke along the way.","title":"Built and shipped an iOS app from my phone while traveling Japan","updated_at":"2026-02-15T03:14:24Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"austinwang115"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"I've been working on CloudRouter, a skill + CLI that gives coding agents like <em>Claude</em> <em>Code</em> and Codex the ability to start cloud VMs and GPUs.<p>When an agent writes <em>code</em>, it usually needs to start a dev server, run tests, open a browser to verify its work. Today that all happens on your local machine. This works fine for a single task, but the agent is sharing your computer: your ports, RAM, screen. If you run multiple agents in parallel, it gets a bit chaotic. Docker helps with isolation, but it still <em>uses</em> your machine's resources, and doesn't give the agent a browser, a desktop, or a GPU to close the loop properly. The agent could handle all of this on its own if it had a primitive for starting VMs.<p>CloudRouter is that primitive \u2014 a skill that gives the agent its own machines. The agent can start a VM from your local project directory, upload the project files, run commands on the VM, and tear it down when it's done. If it needs a GPU, it can request one.<p><pre><code>  cloudrouter start ./my-project\n  cloudrouter start --gpu B200 ./my-project\n  cloudrouter ssh cr_abc123 &quot;npm install &amp;&amp; npm run dev&quot;\n</code></pre>\nEvery VM comes with a VNC desktop, VS <em>Code</em>, and Jupyter Lab, all behind auth-protected URLs. When the agent is doing browser automation on the VM, you can open the VNC URL and watch it in real time. CloudRouter wraps agent-browser [1] for browser automation.<p><pre><code>  cloudrouter browser open cr_abc123 &quot;http://localhost:3000&quot;\n  cloudrouter browser snapshot -i cr_abc123\n  # \u2192 @e1 [link] Home  @e2 [link] Settings  @e3 [button] Sign Out\n  cloudrouter browser click cr_abc123 @e2\n  cloudrouter browser screenshot cr_abc123 result.png\n</code></pre>\nHere's a short demo: <a href=\"https://youtu.be/SCkkzxKBcPE\" rel=\"nofollow\">https://youtu.be/SCkkzxKBcPE</a><p>What surprised me is how this inverted my workflow. Most cloud dev tooling starts from cloud (background agents, remote SSH, etc) to local for testing. But CloudRouter keeps your agents local and pushes the agent's work to the cloud. The agent does the same things it would do locally \u2014 running dev servers, operating browsers \u2014 but now on a VM. As I stopped watching agents work and worrying about local constraints, I started to run more tasks in parallel.<p>The GPU side is the part I'm most curious to see develop. Today if you want a coding agent to help with anything involving training or inference, there's a manual step where you go provision a machine. With CloudRouter the agent can just spin up a GPU sandbox, run the workload, and clean it up when it's done. Some of my friends have been using it to have agents run small experiments in parallel, but my ears are open to other <em>use</em> <em>cases</em>.<p>Would love your feedback and ideas. CloudRouter lives under packages/cloudrouter of our monorepo <a href=\"https://github.com/manaflow-ai/manaflow\" rel=\"nofollow\">https://github.com/manaflow-ai/manaflow</a>.<p>[1] <a href=\"https://github.com/vercel-labs/agent-browser\" rel=\"nofollow\">https://github.com/vercel-labs/agent-browser</a>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude","code"],"value":"Show HN: Skill that lets <em>Claude</em> <em>Code</em>/Codex spin up VMs and GPUs"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://cloudrouter.dev/"}},"_tags":["story","author_austinwang115","story_47006393","show_hn"],"author":"austinwang115","children":[47043150,47007903,47009560,47030709,47007062,47006997,47007968,47009305,47010651,47008435,47011287,47010069,47009829,47009412,47008069,47006972,47008191,47008582,47015567,47012057,47008546,47006851],"created_at":"2026-02-13T19:02:17Z","created_at_i":1771009337,"num_comments":36,"objectID":"47006393","points":137,"story_id":47006393,"story_text":"I&#x27;ve been working on CloudRouter, a skill + CLI that gives coding agents like Claude Code and Codex the ability to start cloud VMs and GPUs.<p>When an agent writes code, it usually needs to start a dev server, run tests, open a browser to verify its work. Today that all happens on your local machine. This works fine for a single task, but the agent is sharing your computer: your ports, RAM, screen. If you run multiple agents in parallel, it gets a bit chaotic. Docker helps with isolation, but it still uses your machine&#x27;s resources, and doesn&#x27;t give the agent a browser, a desktop, or a GPU to close the loop properly. The agent could handle all of this on its own if it had a primitive for starting VMs.<p>CloudRouter is that primitive \u2014 a skill that gives the agent its own machines. The agent can start a VM from your local project directory, upload the project files, run commands on the VM, and tear it down when it&#x27;s done. If it needs a GPU, it can request one.<p><pre><code>  cloudrouter start .&#x2F;my-project\n  cloudrouter start --gpu B200 .&#x2F;my-project\n  cloudrouter ssh cr_abc123 &quot;npm install &amp;&amp; npm run dev&quot;\n</code></pre>\nEvery VM comes with a VNC desktop, VS Code, and Jupyter Lab, all behind auth-protected URLs. When the agent is doing browser automation on the VM, you can open the VNC URL and watch it in real time. CloudRouter wraps agent-browser [1] for browser automation.<p><pre><code>  cloudrouter browser open cr_abc123 &quot;http:&#x2F;&#x2F;localhost:3000&quot;\n  cloudrouter browser snapshot -i cr_abc123\n  # \u2192 @e1 [link] Home  @e2 [link] Settings  @e3 [button] Sign Out\n  cloudrouter browser click cr_abc123 @e2\n  cloudrouter browser screenshot cr_abc123 result.png\n</code></pre>\nHere&#x27;s a short demo: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;SCkkzxKBcPE\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;SCkkzxKBcPE</a><p>What surprised me is how this inverted my workflow. Most cloud dev tooling starts from cloud (background agents, remote SSH, etc) to local for testing. But CloudRouter keeps your agents local and pushes the agent&#x27;s work to the cloud. The agent does the same things it would do locally \u2014 running dev servers, operating browsers \u2014 but now on a VM. As I stopped watching agents work and worrying about local constraints, I started to run more tasks in parallel.<p>The GPU side is the part I&#x27;m most curious to see develop. Today if you want a coding agent to help with anything involving training or inference, there&#x27;s a manual step where you go provision a machine. With CloudRouter the agent can just spin up a GPU sandbox, run the workload, and clean it up when it&#x27;s done. Some of my friends have been using it to have agents run small experiments in parallel, but my ears are open to other use cases.<p>Would love your feedback and ideas. CloudRouter lives under packages&#x2F;cloudrouter of our monorepo <a href=\"https:&#x2F;&#x2F;github.com&#x2F;manaflow-ai&#x2F;manaflow\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;manaflow-ai&#x2F;manaflow</a>.<p>[1] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vercel-labs&#x2F;agent-browser\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vercel-labs&#x2F;agent-browser</a>","title":"Show HN: Skill that lets Claude Code/Codex spin up VMs and GPUs","updated_at":"2026-02-17T12:22:17Z","url":"https://cloudrouter.dev/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Nlupus"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"I've been building lifecycle messaging systems for SaaS companies for 10+ years. Every company needs one (welcome emails, onboarding sequences, upgrade nudges, etc) but building one from scratch is tedious and most teams either copy generic templates or hire a consultant.<p>I took the approach I've battle-tested across dozens of projects and wrapped it into a CLI tool that runs on <em>Claude</em> <em>Code</em>.<p>Mango Lollipop runs entirely through <em>Claude</em> <em>Code</em> locally.<p>You give it your product URL, it analyzes your business, and walks you through building a complete messaging system using the AARRR pirate metrics framework.<p>It will take about 15 minutes from init to a complete v0.1 messaging system ready to implement and test.<p>What it produces:<p>- A structured messaging matrix with triggers, guards, suppressions, and timing for every message\n- Full message copy (email, in-app, SMS, push) written in your brand voice\n- An Excel workbook for your team's source of truth\n- An interactive HTML dashboard with journey maps and message previews\n- Developer hand-off docs with event specs and <em>code</em> examples<p>Demo with sample outputs here <a href=\"https://sr-kai.github.io/mango-lollipop/\" rel=\"nofollow\">https://sr-kai.github.io/mango-lollipop/</a><p>The whole thing is built as markdown skills (slash commands). Each step is independent so you can review, iterate, and course-correct before moving on.<p>I built it on <em>Claude</em> <em>Code</em>, but since the skills are just markdown files, it should work in any AI coding tool that supports them, like Cursor, OpenCode, Windsurf, etc.<p>Different models produce WILDLY different copy, I recommend trying a few to see what works best for your <em>use</em>-<em>case</em>.<p>npm install -g mango-lollipop<p>GitHub: <a href=\"https://github.com/sr-kai/mango-lollipop\" rel=\"nofollow\">https://github.com/sr-kai/mango-lollipop</a><p>I'd love feedback on the approach and how you build similar system.<p>The trigger/wait/guard/suppression model is not the most elegant solution, so if you have a better implementation please share your experience."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Mango Lollipop \u2013 AI-powered lifecycle messaging generator"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/sr-kai/mango-lollipop"}},"_tags":["story","author_Nlupus","story_46997378","show_hn"],"author":"Nlupus","created_at":"2026-02-13T00:38:00Z","created_at_i":1770943080,"num_comments":0,"objectID":"46997378","points":2,"story_id":46997378,"story_text":"I&#x27;ve been building lifecycle messaging systems for SaaS companies for 10+ years. Every company needs one (welcome emails, onboarding sequences, upgrade nudges, etc) but building one from scratch is tedious and most teams either copy generic templates or hire a consultant.<p>I took the approach I&#x27;ve battle-tested across dozens of projects and wrapped it into a CLI tool that runs on Claude Code.<p>Mango Lollipop runs entirely through Claude Code locally.<p>You give it your product URL, it analyzes your business, and walks you through building a complete messaging system using the AARRR pirate metrics framework.<p>It will take about 15 minutes from init to a complete v0.1 messaging system ready to implement and test.<p>What it produces:<p>- A structured messaging matrix with triggers, guards, suppressions, and timing for every message\n- Full message copy (email, in-app, SMS, push) written in your brand voice\n- An Excel workbook for your team&#x27;s source of truth\n- An interactive HTML dashboard with journey maps and message previews\n- Developer hand-off docs with event specs and code examples<p>Demo with sample outputs here <a href=\"https:&#x2F;&#x2F;sr-kai.github.io&#x2F;mango-lollipop&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;sr-kai.github.io&#x2F;mango-lollipop&#x2F;</a><p>The whole thing is built as markdown skills (slash commands). Each step is independent so you can review, iterate, and course-correct before moving on.<p>I built it on Claude Code, but since the skills are just markdown files, it should work in any AI coding tool that supports them, like Cursor, OpenCode, Windsurf, etc.<p>Different models produce WILDLY different copy, I recommend trying a few to see what works best for your use-case.<p>npm install -g mango-lollipop<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sr-kai&#x2F;mango-lollipop\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sr-kai&#x2F;mango-lollipop</a><p>I&#x27;d love feedback on the approach and how you build similar system.<p>The trigger&#x2F;wait&#x2F;guard&#x2F;suppression model is not the most elegant solution, so if you have a better implementation please share your experience.","title":"Show HN: Mango Lollipop \u2013 AI-powered lifecycle messaging generator","updated_at":"2026-02-13T08:58:49Z","url":"https://github.com/sr-kai/mango-lollipop"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mw1"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"tl;dr looking for any links, resources or tips around best practices for data security, privacy, and agent guardrails when using <em>Claude</em> (or others).<p>My journey over the past few years has been one of borderline AI skeptic for its <em>use</em> in coding to having tried <em>Claude</em> <em>Code</em> a month ago and being unlikely to ever go back to coding big changes without it. Most queries I would have used search for in the past are now done in AI models as a first step.<p>However, one thing that concerns me is whether I am using best practices around agent safety and <em>code</em> protection. I have turned off the \u201cHelp improve <em>Claude</em>\u201d toggle in the web panel for <em>Claude</em> settings. Do we believe that\u2019s enough to really stop them (the companies who took any data they could find to make this tool) from using or training on our <em>code</em>? Are all the companies and people using this product just entrusting their proprietary <em>code</em> bases to these AI companies? Is it enough for me to be on the $20/mo <em>Claude</em> Pro plan or do I have to pony up for a Teams plan to protect my data? Which companies do we trust more in this space?<p>In terms of agent guardrails, I have set up <em>Claude</em> CLI on a cloud VPS Ubuntu host, as its own user that has access to read and modify the <em>code</em>, but no commit ability or git credentials or access to data on my personal machines. The repos are in a directory with group write access and then my personal user account does all commits and pushes, to ensure that <em>Claude</em> has no tangible way to destroy any data that isn\u2019t backed up offsite in git. I don\u2019t provide any of the environment variable credentials necessary to actually run the software, or access to any real data, so testing and QA is still something I do manually and pushing the changes to another machine.<p>I <em>use</em> it iteratively on individual features or bug fixes. I still have to go back and forth with it (or drop into my editor) a decent amount when it makes mistakes or to encourage better architectural decisions, but it is overall quite fun and exciting for me to <em>use</em> (at this early stage of learning and exploration) and seems to speed up development for my <em>use</em> <em>case</em> in a major way (solo dev SaaS site with web, iOS, and Android native apps + many little, half-finished side projects and ideas).<p>Does HN have any links or resources that round up the state of the art best practices around AI <em>use</em> for those who are cautious and not wanting to give it the keys to kingdom, but trying to take advantage of this new coding frontier in a safe way? What commands or settings would be typically considered safe to always allow so it doesn\u2019t need to ask for permission as often? What security or privacy toggles do I want to consider in <em>Claude</em> (or other agents). Is it good to subscribe to a couple services and have one review the other\u2019s <em>code</em> as a first step? I hit usage limits on the $20 <em>Claude</em> Pro, should I go to Max or spread horizontally across different AI models? Thanks for any tips!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Ask HN: Best practices for AI agent safety and privacy"}},"_tags":["story","author_mw1","story_46996368","ask_hn"],"author":"mw1","children":[47006768,47032785],"created_at":"2026-02-12T22:47:39Z","created_at_i":1770936459,"num_comments":1,"objectID":"46996368","points":2,"story_id":46996368,"story_text":"tl;dr looking for any links, resources or tips around best practices for data security, privacy, and agent guardrails when using Claude (or others).<p>My journey over the past few years has been one of borderline AI skeptic for its use in coding to having tried Claude Code a month ago and being unlikely to ever go back to coding big changes without it. Most queries I would have used search for in the past are now done in AI models as a first step.<p>However, one thing that concerns me is whether I am using best practices around agent safety and code protection. I have turned off the \u201cHelp improve Claude\u201d toggle in the web panel for Claude settings. Do we believe that\u2019s enough to really stop them (the companies who took any data they could find to make this tool) from using or training on our code? Are all the companies and people using this product just entrusting their proprietary code bases to these AI companies? Is it enough for me to be on the $20&#x2F;mo Claude Pro plan or do I have to pony up for a Teams plan to protect my data? Which companies do we trust more in this space?<p>In terms of agent guardrails, I have set up Claude CLI on a cloud VPS Ubuntu host, as its own user that has access to read and modify the code, but no commit ability or git credentials or access to data on my personal machines. The repos are in a directory with group write access and then my personal user account does all commits and pushes, to ensure that Claude has no tangible way to destroy any data that isn\u2019t backed up offsite in git. I don\u2019t provide any of the environment variable credentials necessary to actually run the software, or access to any real data, so testing and QA is still something I do manually and pushing the changes to another machine.<p>I use it iteratively on individual features or bug fixes. I still have to go back and forth with it (or drop into my editor) a decent amount when it makes mistakes or to encourage better architectural decisions, but it is overall quite fun and exciting for me to use (at this early stage of learning and exploration) and seems to speed up development for my use case in a major way (solo dev SaaS site with web, iOS, and Android native apps + many little, half-finished side projects and ideas).<p>Does HN have any links or resources that round up the state of the art best practices around AI use for those who are cautious and not wanting to give it the keys to kingdom, but trying to take advantage of this new coding frontier in a safe way? What commands or settings would be typically considered safe to always allow so it doesn\u2019t need to ask for permission as often? What security or privacy toggles do I want to consider in Claude (or other agents). Is it good to subscribe to a couple services and have one review the other\u2019s code as a first step? I hit usage limits on the $20 Claude Pro, should I go to Max or spread horizontally across different AI models? Thanks for any tips!","title":"Ask HN: Best practices for AI agent safety and privacy","updated_at":"2026-02-16T09:20:44Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mushgev"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude","code","cases"],"value":"I built an AI executive assistant that works through iMessage.<p>Instead of creating another dashboard or agent interface, I wanted something that behaves more like messaging a real assistant.<p>Attach\u00e9 works entirely over iMessage.<p>You connect Gmail once and then you can send messages like:<p>give me a morning brief of what matters today\nsummarize important emails from the last 24 hours\ndraft a response to the investor thread and keep it concise\nfind a 30 minute slot next week for John and send options\nremind me if the contract is not signed by Friday<p>It manages inbox and calendar together and maintains persistent memory. It remembers your preferences and directives over time, so it adapts instead of starting from scratch each session.<p>It can also proactively summarize important emails as they arrive and prepare draft replies so you can approve or edit them quickly.<p>Security was critical because this touches real accounts. We do not store email credentials. Access is via OAuth and tokens are encrypted. During beta Google shows the unverified app warning because verification is still in progress.<p>Pricing is fixed so users do not have to think about LLM token usage or variable billing.<p>This was built in about a week using <em>Claude</em> <em>Code</em>.<p>I would really appreciate feedback, especially around edge <em>cases</em>, trust, and what you would or would not delegate to something like this."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["use"],"value":"Show HN: I built an AI executive assistant you <em>use</em> through iMessage"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://getattache.com/"}},"_tags":["story","author_mushgev","story_46976710","show_hn"],"author":"mushgev","created_at":"2026-02-11T16:09:05Z","created_at_i":1770826145,"num_comments":0,"objectID":"46976710","points":1,"story_id":46976710,"story_text":"I built an AI executive assistant that works through iMessage.<p>Instead of creating another dashboard or agent interface, I wanted something that behaves more like messaging a real assistant.<p>Attach\u00e9 works entirely over iMessage.<p>You connect Gmail once and then you can send messages like:<p>give me a morning brief of what matters today\nsummarize important emails from the last 24 hours\ndraft a response to the investor thread and keep it concise\nfind a 30 minute slot next week for John and send options\nremind me if the contract is not signed by Friday<p>It manages inbox and calendar together and maintains persistent memory. It remembers your preferences and directives over time, so it adapts instead of starting from scratch each session.<p>It can also proactively summarize important emails as they arrive and prepare draft replies so you can approve or edit them quickly.<p>Security was critical because this touches real accounts. We do not store email credentials. Access is via OAuth and tokens are encrypted. During beta Google shows the unverified app warning because verification is still in progress.<p>Pricing is fixed so users do not have to think about LLM token usage or variable billing.<p>This was built in about a week using Claude Code.<p>I would really appreciate feedback, especially around edge cases, trust, and what you would or would not delegate to something like this.","title":"Show HN: I built an AI executive assistant you use through iMessage","updated_at":"2026-02-11T16:11:59Z","url":"https://getattache.com/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"morog"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"A client needed their small team to pull deliverables and timelines out of RFPs\n- they wanted to chat with the documents instead of reading 200 page PDFs.\nThey were already on WordPress with team accounts so that was the obvious\nplatform. Can we make WordPress do this? Turns out yes, and its not as cursed\nas it sounds.<p>ChatProjects is a free GPL-licensed WordPress plugin for multi-provider AI chat\n(OpenAI, <em>Claude</em>, Gemini, DeepSeek, 100+ models via OpenRouter) and document\nRAG. Self-hosted, bring your own API keys, no middleware, no data leaving your\nserver except the API calls themselves.<p>The RAG <em>uses</em> OpenAI Vector Stores and the Responses API and honestly it works\nway better than I expected. Upload your docs (PDF, DOCX, <em>code</em>\nfiles etc), they get chunked and embedded into a Vector Store that's created per\nproject. Ask a question and file_search finds the relevant chunks, generates\nan answer with citations. You dont need to run your own vector db or mess with\nembeddings or chunk sizes - OpenAI handles all of it. For the &quot;I just need to\nsearch and summarize my documents&quot; <em>use</em>-<em>case</em> its remarkably good out of the box. Storage is\nabout $0.10/GB/day on OpenAIs side.<p>Some notes:<p>- Yes this was vibe-coded (what isn't nowadays?). Its been running in production and it works. I'm sure\n  there's things that would make a senior engineer wince. PRs welcome.<p>- WordPress isn't the cool choice, I know. But theres 800 million WordPress\n  sites out there and alot of them are run by people who need AI tools but\n  aren't going to spin up a Next.js app with Pinecone and LangChain and ChatGPT / <em>Claude</em> Teams is pricey for medium size teams when all they need is document analysis and basic chat. WordPress admin is the IDE for the rest of us.<p>- API keys encrypted with AES-256-CBC, messages stored locally in your WP\n  database. No 'server in between you and the AI providers.<p>GitHub: <a href=\"https://github.com/chatprojects-com/chatprojects\" rel=\"nofollow\">https://github.com/chatprojects-com/chatprojects</a>\nWordPress.org: <a href=\"https://wordpress.org/plugins/chatprojects/\" rel=\"nofollow\">https://wordpress.org/plugins/chatprojects/</a><p>Happy to answer questions, and appreciate any feedback!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: ChatProjects Open-source WordPress plugin for document RAG and chat"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/chatprojects-com/chatprojects"}},"_tags":["story","author_morog","story_46973738","show_hn"],"author":"morog","created_at":"2026-02-11T11:42:07Z","created_at_i":1770810127,"num_comments":0,"objectID":"46973738","points":1,"story_id":46973738,"story_text":"A client needed their small team to pull deliverables and timelines out of RFPs\n- they wanted to chat with the documents instead of reading 200 page PDFs.\nThey were already on WordPress with team accounts so that was the obvious\nplatform. Can we make WordPress do this? Turns out yes, and its not as cursed\nas it sounds.<p>ChatProjects is a free GPL-licensed WordPress plugin for multi-provider AI chat\n(OpenAI, Claude, Gemini, DeepSeek, 100+ models via OpenRouter) and document\nRAG. Self-hosted, bring your own API keys, no middleware, no data leaving your\nserver except the API calls themselves.<p>The RAG uses OpenAI Vector Stores and the Responses API and honestly it works\nway better than I expected. Upload your docs (PDF, DOCX, code\nfiles etc), they get chunked and embedded into a Vector Store that&#x27;s created per\nproject. Ask a question and file_search finds the relevant chunks, generates\nan answer with citations. You dont need to run your own vector db or mess with\nembeddings or chunk sizes - OpenAI handles all of it. For the &quot;I just need to\nsearch and summarize my documents&quot; use-case its remarkably good out of the box. Storage is\nabout $0.10&#x2F;GB&#x2F;day on OpenAIs side.<p>Some notes:<p>- Yes this was vibe-coded (what isn&#x27;t nowadays?). Its been running in production and it works. I&#x27;m sure\n  there&#x27;s things that would make a senior engineer wince. PRs welcome.<p>- WordPress isn&#x27;t the cool choice, I know. But theres 800 million WordPress\n  sites out there and alot of them are run by people who need AI tools but\n  aren&#x27;t going to spin up a Next.js app with Pinecone and LangChain and ChatGPT &#x2F; Claude Teams is pricey for medium size teams when all they need is document analysis and basic chat. WordPress admin is the IDE for the rest of us.<p>- API keys encrypted with AES-256-CBC, messages stored locally in your WP\n  database. No &#x27;server in between you and the AI providers.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;chatprojects-com&#x2F;chatprojects\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;chatprojects-com&#x2F;chatprojects</a>\nWordPress.org: <a href=\"https:&#x2F;&#x2F;wordpress.org&#x2F;plugins&#x2F;chatprojects&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;wordpress.org&#x2F;plugins&#x2F;chatprojects&#x2F;</a><p>Happy to answer questions, and appreciate any feedback!","title":"Show HN: ChatProjects Open-source WordPress plugin for document RAG and chat","updated_at":"2026-02-11T11:44:27Z","url":"https://github.com/chatprojects-com/chatprojects"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mattv8"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","use","cases"],"value":"RAGtime is a self-hosted MCP server and FAISS/PGVector manager that lets AI assistants run real operations on your infrastructure: SSH commands, SQL queries through SSH tunnels, git repo indexing, filesystem searches. It connects <em>Claude</em>, OpenAI, or Ollama to your environment via both MCP protocol and OpenAI-compatible chat completions API.<p>I originally built this over Christmas break as a &quot;self-serve business intelligence&quot; tool to stop fielding repetitive coworker questions (&quot;write me a query for X,&quot; &quot;where's the logic for Y?&quot;) but now it's morphed into a dev tool as well. I couldn't find anything that centralized these tools and served them over chat in one place.<p>I've been using it daily (via MCP) for work and it's been such a huge development accelerator for me. I want to share what I've built with the community, get feedback, or if you wish, contributions. Happy to answer questions about the architecture or <em>use</em> <em>cases</em>.<p>(You can stop here, unless you want more technical details...)<p>Tools: The agent gets access to configurable tools you define: SSH connections to servers (run commands, check logs, restart services), database queries via SSH tunnels (PostgreSQL, MySQL, MSSQL) with parameterized queries to prevent injection, and vector search over your indexed content. Each tool is defined in a config with connection details, and you can enable/disable them per <em>use</em> case. The database tools return structured results the LLM can reason about. SSH tools stream output for long-running commands. There's also a Python REPL tool for data manipulation when the LLM needs to transform query results.<p>On the RAG/indexing side: Chunking uses Chonkie's CodeChunker with Magika (Google's ML model) for automatic language detection, then tree-sitter for AST-aware splitting that respects semantic boundaries (functions, classes, blocks). Each <em>code</em> chunk gets a header with file path and import context so the LLM knows where it came from. Retrieval uses MMR (Maximal Marginal Relevance) to reduce near-duplicate results, balancing relevance with diversity via a configurable lambda parameter. FAISS indexes are portable and can be exported."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Self-hosted MCP server for SQL, SSH, and FAISS indexing"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/mattv8/ragtime"}},"_tags":["story","author_mattv8","story_46964772","show_hn"],"author":"mattv8","created_at":"2026-02-10T18:42:37Z","created_at_i":1770748957,"num_comments":0,"objectID":"46964772","points":3,"story_id":46964772,"story_text":"RAGtime is a self-hosted MCP server and FAISS&#x2F;PGVector manager that lets AI assistants run real operations on your infrastructure: SSH commands, SQL queries through SSH tunnels, git repo indexing, filesystem searches. It connects Claude, OpenAI, or Ollama to your environment via both MCP protocol and OpenAI-compatible chat completions API.<p>I originally built this over Christmas break as a &quot;self-serve business intelligence&quot; tool to stop fielding repetitive coworker questions (&quot;write me a query for X,&quot; &quot;where&#x27;s the logic for Y?&quot;) but now it&#x27;s morphed into a dev tool as well. I couldn&#x27;t find anything that centralized these tools and served them over chat in one place.<p>I&#x27;ve been using it daily (via MCP) for work and it&#x27;s been such a huge development accelerator for me. I want to share what I&#x27;ve built with the community, get feedback, or if you wish, contributions. Happy to answer questions about the architecture or use cases.<p>(You can stop here, unless you want more technical details...)<p>Tools: The agent gets access to configurable tools you define: SSH connections to servers (run commands, check logs, restart services), database queries via SSH tunnels (PostgreSQL, MySQL, MSSQL) with parameterized queries to prevent injection, and vector search over your indexed content. Each tool is defined in a config with connection details, and you can enable&#x2F;disable them per use case. The database tools return structured results the LLM can reason about. SSH tools stream output for long-running commands. There&#x27;s also a Python REPL tool for data manipulation when the LLM needs to transform query results.<p>On the RAG&#x2F;indexing side: Chunking uses Chonkie&#x27;s CodeChunker with Magika (Google&#x27;s ML model) for automatic language detection, then tree-sitter for AST-aware splitting that respects semantic boundaries (functions, classes, blocks). Each code chunk gets a header with file path and import context so the LLM knows where it came from. Retrieval uses MMR (Maximal Marginal Relevance) to reduce near-duplicate results, balancing relevance with diversity via a configurable lambda parameter. FAISS indexes are portable and can be exported.","title":"Show HN: Self-hosted MCP server for SQL, SSH, and FAISS indexing","updated_at":"2026-02-10T18:57:24Z","url":"https://github.com/mattv8/ragtime"}],"hitsPerPage":10,"nbHits":178,"nbPages":18,"page":0,"params":"query=Claude+Code+use+cases&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":33,"processingTimingsMS":{"_request":{"roundTrip":19},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":8,"scanning":24,"total":33},"total":33},"query":"Claude Code use cases","serverTimeMS":36}
