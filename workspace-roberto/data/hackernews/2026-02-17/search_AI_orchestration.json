{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"I built PolyClaw, an OpenClaw-inspired autonomous agent for the PolyMCP ecosystem.<p>PolyClaw doesn\u2019t just call tools.\nIt plans, executes, adapts \u2014 and creates MCP servers when needed.<p>It\u2019s designed for real multi-step, production workflows where agents must orchestrate tools, spin up infrastructure, recover from errors, and deliver complete results end-to-end.<p>\u2e3b<p>What PolyClaw Does\n \u2022 Plans complex multi-step tasks\n \u2022 Executes and orchestrates MCP tools dynamically\n \u2022 Adapts when steps fail or context changes\n \u2022 Creates and connects MCP servers on the fly\n \u2022 Runs Docker-first for safety and isolation\n \u2022 Built with Python and TypeScript<p>PolyClaw is not just a tool caller \u2014 it\u2019s an infrastructure-aware agent.<p>\u2e3b<p>Run PolyClaw with Ollama<p>You can launch PolyClaw directly from the PolyMCP CLI:<p>polymcp agent run \\\n  --type polyclaw \\\n  --query &quot;Build a sales reporting pipeline and test it end-to-end&quot; \\\n  --model minimax-m2.5:cloud \\\n  --verbose<p>What happens behind the scenes:\n 1. The agent decomposes the task.\n 2. It determines which MCP tools are required.\n 3. It spins up or connects to MCP servers.\n 4. It executes steps in sequence (or parallel when needed).\n 5. It validates outputs.\n 6. It adapts if something fails.\n 7. It returns a complete result.<p>All containerized. All isolated.<p>\u2e3b<p>Why This Matters<p>Most <em>AI</em> agents:\n \u2022 Call tools statically\n \u2022 Assume infrastructure already exists\n \u2022 Break on multi-step failure<p>PolyClaw:\n \u2022 Builds the infrastructure it needs\n \u2022 Orchestrates across multiple MCP servers\n \u2022 Handles retries and adaptive planning\n \u2022 Is safe to run in Dockerized environments<p>This makes it viable for:\n \u2022 Enterprise workflows\n \u2022 DevOps automation\n \u2022 Data pipelines\n \u2022 Internal tooling <em>orchestration</em>\n \u2022 Complex multi-tool reasoning tasks<p>PolyClaw turns PolyMCP from simple tool exposure only with Polyagent e unifiendpolyagent or codeagent but turn into full autonomous <em>orchestration</em> agent too.<p>Repo:\n<a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP</a><p>Happy to answer questions,"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PolyClaw \u2013 An Autonomous Docker-First MCP Agent for PolyMCP"}},"_tags":["story","author_justvugg","story_47036828","show_hn"],"author":"justvugg","created_at":"2026-02-16T16:13:08Z","created_at_i":1771258388,"num_comments":0,"objectID":"47036828","points":1,"story_id":47036828,"story_text":"I built PolyClaw, an OpenClaw-inspired autonomous agent for the PolyMCP ecosystem.<p>PolyClaw doesn\u2019t just call tools.\nIt plans, executes, adapts \u2014 and creates MCP servers when needed.<p>It\u2019s designed for real multi-step, production workflows where agents must orchestrate tools, spin up infrastructure, recover from errors, and deliver complete results end-to-end.<p>\u2e3b<p>What PolyClaw Does\n \u2022 Plans complex multi-step tasks\n \u2022 Executes and orchestrates MCP tools dynamically\n \u2022 Adapts when steps fail or context changes\n \u2022 Creates and connects MCP servers on the fly\n \u2022 Runs Docker-first for safety and isolation\n \u2022 Built with Python and TypeScript<p>PolyClaw is not just a tool caller \u2014 it\u2019s an infrastructure-aware agent.<p>\u2e3b<p>Run PolyClaw with Ollama<p>You can launch PolyClaw directly from the PolyMCP CLI:<p>polymcp agent run \\\n  --type polyclaw \\\n  --query &quot;Build a sales reporting pipeline and test it end-to-end&quot; \\\n  --model minimax-m2.5:cloud \\\n  --verbose<p>What happens behind the scenes:\n 1. The agent decomposes the task.\n 2. It determines which MCP tools are required.\n 3. It spins up or connects to MCP servers.\n 4. It executes steps in sequence (or parallel when needed).\n 5. It validates outputs.\n 6. It adapts if something fails.\n 7. It returns a complete result.<p>All containerized. All isolated.<p>\u2e3b<p>Why This Matters<p>Most AI agents:\n \u2022 Call tools statically\n \u2022 Assume infrastructure already exists\n \u2022 Break on multi-step failure<p>PolyClaw:\n \u2022 Builds the infrastructure it needs\n \u2022 Orchestrates across multiple MCP servers\n \u2022 Handles retries and adaptive planning\n \u2022 Is safe to run in Dockerized environments<p>This makes it viable for:\n \u2022 Enterprise workflows\n \u2022 DevOps automation\n \u2022 Data pipelines\n \u2022 Internal tooling orchestration\n \u2022 Complex multi-tool reasoning tasks<p>PolyClaw turns PolyMCP from simple tool exposure only with Polyagent e unifiendpolyagent or codeagent but turn into full autonomous orchestration agent too.<p>Repo:\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a><p>Happy to answer questions,","title":"Show HN: PolyClaw \u2013 An Autonomous Docker-First MCP Agent for PolyMCP","updated_at":"2026-02-16T16:16:31Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Romricci"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Maestro \u2013 Autonomous dev platform with multi-reviewer <em>AI</em> safety pipeline"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["orchestration"],"value":"https://www.maestro-<em>orchestrator</em>.dev"}},"_tags":["story","author_Romricci","story_47036538"],"author":"Romricci","created_at":"2026-02-16T15:51:02Z","created_at_i":1771257062,"num_comments":0,"objectID":"47036538","points":1,"story_id":47036538,"title":"Maestro \u2013 Autonomous dev platform with multi-reviewer AI safety pipeline","updated_at":"2026-02-16T15:55:30Z","url":"https://www.maestro-orchestrator.dev"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"madugula"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"The Agentic Shift: Peter Steinberger Joins OpenAI to Scale OpenClaw\nBy Sai Srikanth Madugula, PhD Research Scholar &amp; Product Manager | February 16, 2026<p>In a move that signals the definitive start of the &quot;Agentic Era,&quot; Peter Steinberger, the architect behind the viral open-source framework OpenClaw, has officially joined OpenAI. This transition isn't just a high-profile hire; it represents a fundamental change in how the industry views the intersection of proprietary intelligence and open-source <em>orchestration</em>.<p>As I continue my PhD research into <em>AI</em>-Blockchain models, I view this as a seminal moment. We are moving away from simple chatbots toward autonomous &quot;workers&quot; that can interact, reason, and execute. Steinberger\u2019s integration into OpenAI provides the missing bridge between world-class models and real-world execution frameworks.<p>In the Words of Sam Altman\nSam Altman, CEO of OpenAI, took to X (formerly Twitter) to welcome Steinberger and clarify the future of the framework. His statement highlights a newfound commitment to the open-source community as part of OpenAI's core product strategy:<p>&quot;Peter Steinberger is joining OpenAI to drive the next generation of personal agents. He is a genius with a lot of amazing ideas about the future of very smart agents interacting with each other to do very useful things for people... OpenClaw will live in a foundation as an open source project that OpenAI will continue to support.&quot;\nAltman\u2019s vision of a &quot;multi-agent&quot; future confirms what many of us in product management have suspected: the next billion-dollar startups won't be built on a single LLM, but on the <em>orchestration</em> of many specialized agents working in concert.<p>Why This Matters: The OpenClaw Foundation\nThe decision to house OpenClaw in an independent open-source foundation while receiving OpenAI\u2019s backing is a strategic masterstroke. It ensures that the framework remains a neutral ground for developers while benefiting from the massive compute and research resources of OpenAI. This helps solve several critical bottlenecks:<p>Interoperability: By standardizing how agents talk to each other, OpenClaw can become the &quot;HTTP of <em>AI</em>,&quot; allowing different models to collaborate seamlessly.\nReduced Friction: Developers can leverage pre-built &quot;agent personas&quot; (like the <em>AI</em> Engineer or <em>AI</em> Researcher) without reinventing the <em>orchestration</em> logic every time.\nTrust and Transparency: Keeping the foundation open-source helps demystify the &quot;black box&quot; of agentic decision-making, an area I am particularly focused on in my doctoral studies.\nA Catalyst for Solo Founders and Nano-Startups\nFor the solo founder, this news is transformative. When the creator of the most robust <em>orchestration</em> tool joins forces with the creator of the world's most capable models, the barriers to entry collapse. We are entering a phase where a single human can manage a &quot;digital corporation.&quot;<p>The implications for latency and data privacy are also significant. As OpenAI supports the foundation, we can expect more optimizations for on-device and edge-native agents\u2014a direction I recently analyzed through the lens of Karpathy\u2019s MicroGPT. Small, fast, and local agents are the future, and OpenClaw is the engine that will run them.<p>The Human in the Loop: The Conductor Role\nDoes this mean human roles are disappearing? Quite the opposite. As I\u2019ve argued in previous posts, our role is evolving into that of a Strategic Conductor. Peter Steinberger's move to OpenAI suggests that the industry is ready to provide us with a much more powerful orchestra. Our value now lies in the vision we set and the ethical guardrails we implement.<p>The workplace of tomorrow is no longer a collection of desks; it is a symphony of digital intelligence, and the baton is firmly in our hands."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Agentic Shift: Peter Steinberger Joins OpenAI"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://blog.saimadugula.com/posts/steinberger-openai-openclaw.html"}},"_tags":["story","author_madugula","story_47033865","show_hn"],"author":"madugula","created_at":"2026-02-16T11:42:16Z","created_at_i":1771242136,"num_comments":0,"objectID":"47033865","points":1,"story_id":47033865,"story_text":"The Agentic Shift: Peter Steinberger Joins OpenAI to Scale OpenClaw\nBy Sai Srikanth Madugula, PhD Research Scholar &amp; Product Manager | February 16, 2026<p>In a move that signals the definitive start of the &quot;Agentic Era,&quot; Peter Steinberger, the architect behind the viral open-source framework OpenClaw, has officially joined OpenAI. This transition isn&#x27;t just a high-profile hire; it represents a fundamental change in how the industry views the intersection of proprietary intelligence and open-source orchestration.<p>As I continue my PhD research into AI-Blockchain models, I view this as a seminal moment. We are moving away from simple chatbots toward autonomous &quot;workers&quot; that can interact, reason, and execute. Steinberger\u2019s integration into OpenAI provides the missing bridge between world-class models and real-world execution frameworks.<p>In the Words of Sam Altman\nSam Altman, CEO of OpenAI, took to X (formerly Twitter) to welcome Steinberger and clarify the future of the framework. His statement highlights a newfound commitment to the open-source community as part of OpenAI&#x27;s core product strategy:<p>&quot;Peter Steinberger is joining OpenAI to drive the next generation of personal agents. He is a genius with a lot of amazing ideas about the future of very smart agents interacting with each other to do very useful things for people... OpenClaw will live in a foundation as an open source project that OpenAI will continue to support.&quot;\nAltman\u2019s vision of a &quot;multi-agent&quot; future confirms what many of us in product management have suspected: the next billion-dollar startups won&#x27;t be built on a single LLM, but on the orchestration of many specialized agents working in concert.<p>Why This Matters: The OpenClaw Foundation\nThe decision to house OpenClaw in an independent open-source foundation while receiving OpenAI\u2019s backing is a strategic masterstroke. It ensures that the framework remains a neutral ground for developers while benefiting from the massive compute and research resources of OpenAI. This helps solve several critical bottlenecks:<p>Interoperability: By standardizing how agents talk to each other, OpenClaw can become the &quot;HTTP of AI,&quot; allowing different models to collaborate seamlessly.\nReduced Friction: Developers can leverage pre-built &quot;agent personas&quot; (like the AI Engineer or AI Researcher) without reinventing the orchestration logic every time.\nTrust and Transparency: Keeping the foundation open-source helps demystify the &quot;black box&quot; of agentic decision-making, an area I am particularly focused on in my doctoral studies.\nA Catalyst for Solo Founders and Nano-Startups\nFor the solo founder, this news is transformative. When the creator of the most robust orchestration tool joins forces with the creator of the world&#x27;s most capable models, the barriers to entry collapse. We are entering a phase where a single human can manage a &quot;digital corporation.&quot;<p>The implications for latency and data privacy are also significant. As OpenAI supports the foundation, we can expect more optimizations for on-device and edge-native agents\u2014a direction I recently analyzed through the lens of Karpathy\u2019s MicroGPT. Small, fast, and local agents are the future, and OpenClaw is the engine that will run them.<p>The Human in the Loop: The Conductor Role\nDoes this mean human roles are disappearing? Quite the opposite. As I\u2019ve argued in previous posts, our role is evolving into that of a Strategic Conductor. Peter Steinberger&#x27;s move to OpenAI suggests that the industry is ready to provide us with a much more powerful orchestra. Our value now lies in the vision we set and the ethical guardrails we implement.<p>The workplace of tomorrow is no longer a collection of desks; it is a symphony of digital intelligence, and the baton is firmly in our hands.","title":"Show HN: Agentic Shift: Peter Steinberger Joins OpenAI","updated_at":"2026-02-16T11:44:43Z","url":"https://blog.saimadugula.com/posts/steinberger-openai-openclaw.html"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"san-techie21"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Hi HN,<p>I'm a security engineer with 15+ years in enterprise security. After watching OpenClaw explode to 180K stars while binding to 0.0.0.0 by default, shipping no encryption, and accumulating 512 CVEs \u2014 I decided to build what I think a personal <em>AI</em> agent should look like when security comes first.<p>Gulama is an open-source personal <em>AI</em> agent with 15+ security mechanisms built into the core:<p>- AES-256-GCM encryption for all credentials and memories (never plaintext)\n- Sandboxed execution via bubblewrap/Docker (same sandbox Anthropic uses for Claude Code)\n- Ed25519-signed skills (no unsigned code runs \u2014 unlike ClawHub's 230+ malicious skills)\n- Cedar-inspired policy engine for deterministic authorization\n- Canary tokens for prompt injection detection\n- Egress filtering + DLP to prevent data exfiltration\n- Gateway binds 127.0.0.1 ONLY by default (not 0.0.0.0)\n- Cryptographic hash-chain audit trail<p>Beyond security, it's a full-featured agent:<p>- 100+ LLM providers via LiteLLM (Anthropic, OpenAI, DeepSeek, Ollama, etc.)\n- 19 built-in skills (files, shell, web, browser, email, calendar, GitHub, Notion, Spotify, voice, MCP bridge, and more)\n- 10 communication channels (CLI, Telegram, Discord, Slack, WhatsApp, Matrix, Teams, Web UI, Voice Wake)\n- Full MCP server + client support\n- Multi-agent <em>orchestration</em> with background sub-agents\n- RAG-powered memory via ChromaDB\n- Self-modifying: the agent writes its own new skills at runtime (sandboxed)\n- 5 autonomy levels from &quot;ask before everything&quot; to full autopilot<p>Install: pip install gulama &amp;&amp; gulama setup &amp;&amp; gulama chat<p>Stack: Python 3.12+, FastAPI, LiteLLM, SQLite, ChromaDB, Click\nPyPI: <a href=\"https://pypi.org/project/gulama/\" rel=\"nofollow\">https://pypi.org/project/gulama/</a><p>Happy to answer any questions about the security architecture or design decisions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: Gulama \u2013 Security-first open-source <em>AI</em> agent (OpenClaw alternative)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/san-techie21/gulama-bot"}},"_tags":["story","author_san-techie21","story_47031982","show_hn"],"author":"san-techie21","children":[47043547],"created_at":"2026-02-16T07:27:20Z","created_at_i":1771226840,"num_comments":1,"objectID":"47031982","points":1,"story_id":47031982,"story_text":"Hi HN,<p>I&#x27;m a security engineer with 15+ years in enterprise security. After watching OpenClaw explode to 180K stars while binding to 0.0.0.0 by default, shipping no encryption, and accumulating 512 CVEs \u2014 I decided to build what I think a personal AI agent should look like when security comes first.<p>Gulama is an open-source personal AI agent with 15+ security mechanisms built into the core:<p>- AES-256-GCM encryption for all credentials and memories (never plaintext)\n- Sandboxed execution via bubblewrap&#x2F;Docker (same sandbox Anthropic uses for Claude Code)\n- Ed25519-signed skills (no unsigned code runs \u2014 unlike ClawHub&#x27;s 230+ malicious skills)\n- Cedar-inspired policy engine for deterministic authorization\n- Canary tokens for prompt injection detection\n- Egress filtering + DLP to prevent data exfiltration\n- Gateway binds 127.0.0.1 ONLY by default (not 0.0.0.0)\n- Cryptographic hash-chain audit trail<p>Beyond security, it&#x27;s a full-featured agent:<p>- 100+ LLM providers via LiteLLM (Anthropic, OpenAI, DeepSeek, Ollama, etc.)\n- 19 built-in skills (files, shell, web, browser, email, calendar, GitHub, Notion, Spotify, voice, MCP bridge, and more)\n- 10 communication channels (CLI, Telegram, Discord, Slack, WhatsApp, Matrix, Teams, Web UI, Voice Wake)\n- Full MCP server + client support\n- Multi-agent orchestration with background sub-agents\n- RAG-powered memory via ChromaDB\n- Self-modifying: the agent writes its own new skills at runtime (sandboxed)\n- 5 autonomy levels from &quot;ask before everything&quot; to full autopilot<p>Install: pip install gulama &amp;&amp; gulama setup &amp;&amp; gulama chat<p>Stack: Python 3.12+, FastAPI, LiteLLM, SQLite, ChromaDB, Click\nPyPI: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;gulama&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;gulama&#x2F;</a><p>Happy to answer any questions about the security architecture or design decisions.","title":"Show HN: Gulama \u2013 Security-first open-source AI agent (OpenClaw alternative)","updated_at":"2026-02-17T04:00:01Z","url":"https://github.com/san-techie21/gulama-bot"},{"_highlightResult":{"author":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"bagula_<em>ai</em>"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"I was spending more time <em>orchestratin</em>g Claude Code and Cursor than actually coding. Run command \u2192 wait \u2192 check output \u2192 repeat.\nSo I built v16: persistent <em>AI</em> agents that work autonomously on my laptop.<p><pre><code>  - Each agent: ~40MB Go process                                                                                                                                                                                                                     \n  - Chat via Telegram (@devops, @research, @monitor)                                                                                                                                                                                                 \n  - Run cron jobs autonomously (git checks, research, monitoring)                                                                                                                                                                                    \n  - Multi-LLM support (Claude, GPT-4, Groq)                                                                                                                                                                                                          \n                                                                                                                                                                                                                                              </code></pre>\nMy MacBook runs 4 agents 24/7 at ~160MB RAM. They handle git commits, compile research, and alert on system issues.\nWritten in Go. Persistent memory via JSON. Battery-aware.\nOpen source: https://github.com/anup-singhai/v16\nBlog: https://v16.<em>ai</em>/blog/army-of-<em>ai</em>-agents"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"I got tired of babysitting Claude,so I built <em>AI</em> agent that run on my laptop 24/7"}},"_tags":["story","author_bagula_ai","story_47030623","ask_hn"],"author":"bagula_ai","created_at":"2026-02-16T03:40:37Z","created_at_i":1771213237,"num_comments":0,"objectID":"47030623","points":4,"story_id":47030623,"story_text":"I was spending more time orchestrating Claude Code and Cursor than actually coding. Run command \u2192 wait \u2192 check output \u2192 repeat.\nSo I built v16: persistent AI agents that work autonomously on my laptop.<p><pre><code>  - Each agent: ~40MB Go process                                                                                                                                                                                                                     \n  - Chat via Telegram (@devops, @research, @monitor)                                                                                                                                                                                                 \n  - Run cron jobs autonomously (git checks, research, monitoring)                                                                                                                                                                                    \n  - Multi-LLM support (Claude, GPT-4, Groq)                                                                                                                                                                                                          \n                                                                                                                                                                                                                                              </code></pre>\nMy MacBook runs 4 agents 24&#x2F;7 at ~160MB RAM. They handle git commits, compile research, and alert on system issues.\nWritten in Go. Persistent memory via JSON. Battery-aware.\nOpen source: https:&#x2F;&#x2F;github.com&#x2F;anup-singhai&#x2F;v16\nBlog: https:&#x2F;&#x2F;v16.ai&#x2F;blog&#x2F;army-of-ai-agents","title":"I got tired of babysitting Claude,so I built AI agent that run on my laptop 24/7","updated_at":"2026-02-16T07:01:43Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"crog"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"I built claude-relais to stop throwing expensive reasoning models at every line of code (I can't spend 500$/month on <em>AI</em> subs).<p>The idea: Claude acts as orchestrator: it plans tasks, breaks them into bounded units, and judges the output. Cursor agents (basic plan, almost unlimited and super fast) handle the actual code generation, which doesn't need frontier-level reasoning.<p>A guarded loop (PLAN -&gt; BUILD -&gt; JUDGE) enforces safety constraints between steps (no destructive ops, scoped file access, bounded iterations).<p>In practice, this brings my <em>AI</em>-assisted coding cost to ~$40/month while keeping the quality of having a strong model in the loop for architecture and review decisions.<p>The core tradeoff: you give up the simplicity of one model doing everything, but you gain cost control and a natural separation between &quot;thinking&quot; and &quot;typing.&quot;<p>Repo: <a href=\"https://github.com/clementrog/claude-relais\" rel=\"nofollow\">https://github.com/clementrog/claude-relais</a><p>Would love feedback on the <em>orchestration</em> approach, especially if others have tried similar multi-model setups and hit failure modes I haven't seen yet."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Claude-relais \u2013 A plan/build/judge loop mixing Claude with Cursor"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/clementrog/claude-relais"}},"_tags":["story","author_crog","story_47026886","show_hn"],"author":"crog","created_at":"2026-02-15T19:52:27Z","created_at_i":1771185147,"num_comments":0,"objectID":"47026886","points":1,"story_id":47026886,"story_text":"I built claude-relais to stop throwing expensive reasoning models at every line of code (I can&#x27;t spend 500$&#x2F;month on AI subs).<p>The idea: Claude acts as orchestrator: it plans tasks, breaks them into bounded units, and judges the output. Cursor agents (basic plan, almost unlimited and super fast) handle the actual code generation, which doesn&#x27;t need frontier-level reasoning.<p>A guarded loop (PLAN -&gt; BUILD -&gt; JUDGE) enforces safety constraints between steps (no destructive ops, scoped file access, bounded iterations).<p>In practice, this brings my AI-assisted coding cost to ~$40&#x2F;month while keeping the quality of having a strong model in the loop for architecture and review decisions.<p>The core tradeoff: you give up the simplicity of one model doing everything, but you gain cost control and a natural separation between &quot;thinking&quot; and &quot;typing.&quot;<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;clementrog&#x2F;claude-relais\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;clementrog&#x2F;claude-relais</a><p>Would love feedback on the orchestration approach, especially if others have tried similar multi-model setups and hit failure modes I haven&#x27;t seen yet.","title":"Show HN: Claude-relais \u2013 A plan/build/judge loop mixing Claude with Cursor","updated_at":"2026-02-15T19:54:12Z","url":"https://github.com/clementrog/claude-relais"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"firefoxd"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Many hn users often partially talk about their use case of <em>AI</em>. <em>Orchestratin</em>g agents, managing code and PRs. But they rarely talk about the project itself.<p>If you have any of those projects, or just heavily <em>AI</em> assisted project, please share it here."},"title":{"matchLevel":"none","matchedWords":[],"value":"Ask HN: Share your vibe coded project"}},"_tags":["story","author_firefoxd","story_47025879","ask_hn"],"author":"firefoxd","children":[47025995,47045232,47039043,47037620,47034054,47034436,47025918],"created_at":"2026-02-15T18:07:09Z","created_at_i":1771178829,"num_comments":8,"objectID":"47025879","points":5,"story_id":47025879,"story_text":"Many hn users often partially talk about their use case of AI. Orchestrating agents, managing code and PRs. But they rarely talk about the project itself.<p>If you have any of those projects, or just heavily AI assisted project, please share it here.","title":"Ask HN: Share your vibe coded project","updated_at":"2026-02-17T12:13:02Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"eftalyurtseven"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Hi everyone,<p>I run a generative <em>AI</em> infra company, unified API for 600+ models. Our team started deploying <em>AI</em> agents for our marketing and lead gen ops: content, engagement, analytics across multiple X accounts.<p>OpenClaw worked fine for single agents. But at ~14 agents across 6 accounts, the problem shifted from &quot;how do I build agents&quot; to &quot;how do I manage them.&quot;<p>Deployment, monitoring, team isolation, figuring out which agent broke what at 3am. Classic <em>orchestration</em> problem.<p>So I built klaw, modeled on Kubernetes:\nClusters \u2014 isolated environments per org/project\nNamespaces \u2014 team-level isolation (marketing, sales, support)\nChannels \u2014 connect agents to Slack, X, Discord\nSkills \u2014 reusable agent capabilities via a marketplace<p>CLI works like kubectl:\nklaw create cluster mycompany\nklaw create namespace marketing\nklaw deploy agent.yaml<p>I also rewrote from Node.js to Go \u2014 agents went from 800MB+ to under 10MB each.<p>Quick usage example: I run a &quot;content cluster&quot; where each X account is its own namespace. Agent misbehaving on one account can't affect others. Adding a new account is klaw create namespace [account] + deploy the same config. 30 seconds.<p>The key differentiator vs frameworks like CrewAI or LangGraph: those define how agents collaborate on tasks. klaw operates one layer above \u2014 managing fleets of agents across teams with isolation and operational tooling. You could run CrewAI agents inside klaw namespaces.<p>Happy to answer questions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: Klaw.sh \u2013\u00a0Kubernetes for <em>AI</em> agents"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/klawsh/klaw.sh"}},"_tags":["story","author_eftalyurtseven","story_47025478","show_hn"],"author":"eftalyurtseven","children":[47029558,47029395,47029241,47030814,47029973,47030304,47029319,47030228,47030777,47029262,47030929,47030168,47029667,47029331,47028493],"created_at":"2026-02-15T17:22:59Z","created_at_i":1771176179,"num_comments":44,"objectID":"47025478","points":60,"story_id":47025478,"story_text":"Hi everyone,<p>I run a generative AI infra company, unified API for 600+ models. Our team started deploying AI agents for our marketing and lead gen ops: content, engagement, analytics across multiple X accounts.<p>OpenClaw worked fine for single agents. But at ~14 agents across 6 accounts, the problem shifted from &quot;how do I build agents&quot; to &quot;how do I manage them.&quot;<p>Deployment, monitoring, team isolation, figuring out which agent broke what at 3am. Classic orchestration problem.<p>So I built klaw, modeled on Kubernetes:\nClusters \u2014 isolated environments per org&#x2F;project\nNamespaces \u2014 team-level isolation (marketing, sales, support)\nChannels \u2014 connect agents to Slack, X, Discord\nSkills \u2014 reusable agent capabilities via a marketplace<p>CLI works like kubectl:\nklaw create cluster mycompany\nklaw create namespace marketing\nklaw deploy agent.yaml<p>I also rewrote from Node.js to Go \u2014 agents went from 800MB+ to under 10MB each.<p>Quick usage example: I run a &quot;content cluster&quot; where each X account is its own namespace. Agent misbehaving on one account can&#x27;t affect others. Adding a new account is klaw create namespace [account] + deploy the same config. 30 seconds.<p>The key differentiator vs frameworks like CrewAI or LangGraph: those define how agents collaborate on tasks. klaw operates one layer above \u2014 managing fleets of agents across teams with isolation and operational tooling. You could run CrewAI agents inside klaw namespaces.<p>Happy to answer questions.","title":"Show HN: Klaw.sh \u2013\u00a0Kubernetes for AI agents","updated_at":"2026-02-17T11:06:17Z","url":"https://github.com/klawsh/klaw.sh"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mazilin"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Subject: My attempt at an &quot;OS-inspired&quot; <em>AI</em> architecture\nHi HN,\nI'm a Product Manager, not a systems engineer. I built <em>AI</em> Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using <em>AI</em> agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. <em>Orchestration</em> Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python/Node environment (no installation hell).\nThe Code: <a href=\"https://github.com/canishowtime/ai-station-navigator/\" rel=\"nofollow\">https://github.com/canishowtime/<em>ai</em>-station-navigator/</a>\nI'd love to hear your thoughts on this architectural approach."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: <em>AI</em> Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"https://github.com/canishowtime/<em>ai</em>-station-navigator"}},"_tags":["story","author_mazilin","story_47013274","show_hn"],"author":"mazilin","created_at":"2026-02-14T10:05:55Z","created_at_i":1771063555,"num_comments":0,"objectID":"47013274","points":2,"story_id":47013274,"story_text":"Subject: My attempt at an &quot;OS-inspired&quot; AI architecture\nHi HN,\nI&#x27;m a Product Manager, not a systems engineer. I built AI Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using AI agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. Orchestration Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python&#x2F;Node environment (no installation hell).\nThe Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;</a>\nI&#x27;d love to hear your thoughts on this architectural approach.","title":"Show HN: AI Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps","updated_at":"2026-02-14T10:09:52Z","url":"https://github.com/canishowtime/ai-station-navigator"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"hogwash"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"<em>AI</em> Agents Enable Human Communication at Unprecedented Scale"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"https://venturebeat.com/<em>orchestration</em>/<em>ai</em>-agents-turned-super-bowl-viewers-into-one-high-iq-team-now-imagine-this"}},"_tags":["story","author_hogwash","story_47006442"],"author":"hogwash","children":[47010122],"created_at":"2026-02-13T19:07:11Z","created_at_i":1771009631,"num_comments":1,"objectID":"47006442","points":10,"story_id":47006442,"title":"AI Agents Enable Human Communication at Unprecedented Scale","updated_at":"2026-02-15T09:15:25Z","url":"https://venturebeat.com/orchestration/ai-agents-turned-super-bowl-viewers-into-one-high-iq-team-now-imagine-this"}],"hitsPerPage":10,"nbHits":425,"nbPages":43,"page":0,"params":"query=AI+orchestration&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":11,"processingTimingsMS":{"_request":{"queue":30,"roundTrip":20},"afterFetch":{"format":{"total":1}},"fetch":{"query":6,"scanning":3,"total":10},"total":11},"query":"AI orchestration","serverTimeMS":42}
