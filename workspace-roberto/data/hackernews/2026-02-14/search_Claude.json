{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ashishra0"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Show HN: I built a personal news-curating AI using Ruby and <em>Claude</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/ashishra0/news-curator"}},"_tags":["story","author_ashishra0","story_47014122","show_hn"],"author":"ashishra0","created_at":"2026-02-14T12:40:15Z","created_at_i":1771072815,"num_comments":0,"objectID":"47014122","points":1,"story_id":47014122,"title":"Show HN: I built a personal news-curating AI using Ruby and Claude","updated_at":"2026-02-14T12:46:22Z","url":"https://github.com/ashishra0/news-curator"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"sbuttgereit"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Pentagon Used Anthropic's <em>Claude</em> in Maduro Venezuela Raid"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"https://www.wsj.com/politics/national-security/pentagon-used-anthropics-<em>claude</em>-in-maduro-venezuela-raid-583aff17"}},"_tags":["story","author_sbuttgereit","story_47014060"],"author":"sbuttgereit","created_at":"2026-02-14T12:29:10Z","created_at_i":1771072150,"num_comments":0,"objectID":"47014060","points":3,"story_id":47014060,"title":"Pentagon Used Anthropic's Claude in Maduro Venezuela Raid","updated_at":"2026-02-14T12:46:37Z","url":"https://www.wsj.com/politics/national-security/pentagon-used-anthropics-claude-in-maduro-venezuela-raid-583aff17"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"javiercr"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"<em>Claude</em> Agent in VS Code: no extension required, Copilot subscription supported"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"https://code.visualstudio.com/docs/copilot/agents/third-party-agents#_<em>claude</em>-agent-preview"}},"_tags":["story","author_javiercr","story_47014017"],"author":"javiercr","created_at":"2026-02-14T12:21:16Z","created_at_i":1771071676,"num_comments":0,"objectID":"47014017","points":2,"story_id":47014017,"title":"Claude Agent in VS Code: no extension required, Copilot subscription supported","updated_at":"2026-02-14T12:52:37Z","url":"https://code.visualstudio.com/docs/copilot/agents/third-party-agents#_claude-agent-preview"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"anistark"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"If you use <em>claude</em> with other coding agents like pi or opencode, you might not get the `/usage` skill that <em>claude</em> code comes with.<p>So, I made this small CLI tool `<em>claude</em>mon`.<p>Install with `npm install -g <em>claude</em>mon`<p>Setup once with `<em>claude</em>mon setup`<p>And then run it: `<em>claude</em>mon`<p>I keep it running on one small terminal window. It keeps track of usage. Refreshes every few seconds. Completely local and private. Also, open source, if someone wants to help add some new features.<p>Open to feedback."},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"<em>Claude</em> Usage Monitor"}},"_tags":["story","author_anistark","story_47013785","ask_hn"],"author":"anistark","created_at":"2026-02-14T11:48:23Z","created_at_i":1771069703,"num_comments":0,"objectID":"47013785","points":1,"story_id":47013785,"story_text":"If you use claude with other coding agents like pi or opencode, you might not get the `&#x2F;usage` skill that claude code comes with.<p>So, I made this small CLI tool `claudemon`.<p>Install with `npm install -g claudemon`<p>Setup once with `claudemon setup`<p>And then run it: `claudemon`<p>I keep it running on one small terminal window. It keeps track of usage. Refreshes every few seconds. Completely local and private. Also, open source, if someone wants to help add some new features.<p>Open to feedback.","title":"Claude Usage Monitor","updated_at":"2026-02-14T11:53:52Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mazilin"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Subject: My attempt at an &quot;OS-inspired&quot; AI architecture\nHi HN,\nI'm a Product Manager, not a systems engineer. I built AI Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using AI agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (<em>Claude</em>)\nThe raw computing power driving the capabilities.\n-- Kernel approx. Orchestration Layer (<em>Claude</em> Code + <em>CLAUDE</em>.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python/Node environment (no installation hell).\nThe Code: <a href=\"https://github.com/canishowtime/ai-station-navigator/\" rel=\"nofollow\">https://github.com/canishowtime/ai-station-navigator/</a>\nI'd love to hear your thoughts on this architectural approach."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: AI Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/canishowtime/ai-station-navigator"}},"_tags":["story","author_mazilin","story_47013274","show_hn"],"author":"mazilin","created_at":"2026-02-14T10:05:55Z","created_at_i":1771063555,"num_comments":0,"objectID":"47013274","points":2,"story_id":47013274,"story_text":"Subject: My attempt at an &quot;OS-inspired&quot; AI architecture\nHi HN,\nI&#x27;m a Product Manager, not a systems engineer. I built AI Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using AI agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. Orchestration Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python&#x2F;Node environment (no installation hell).\nThe Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;</a>\nI&#x27;d love to hear your thoughts on this architectural approach.","title":"Show HN: AI Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps","updated_at":"2026-02-14T10:09:52Z","url":"https://github.com/canishowtime/ai-station-navigator"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"meghendra"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Hi HN \u2014 I built cgrep, a local-first, code-aware search tool for AI coding agents (and humans).<p>The goal is to reduce noisy retrieval loops and token waste in real repositories.  \ncgrep combines BM25 + tree-sitter symbol awareness, with optional semantic/hybrid search, and returns deterministic JSON for agent workflows.<p>What it does:\n- Code navigation: definition, references, callers, dependents\n- Focused context tools: read, map\n- Agent flow: `agent locate` -&gt; `agent expand` (small payload first, expand only selected IDs)\n- MCP support: `cgrep mcp serve` + host install helpers\n- Agent install support: <em>claude</em>-code, codex, copilot, cursor, opencode<p>Benchmark snapshot (PyTorch, 6 implementation-tracing scenarios):\n- Baseline (`grep`) tokens-to-complete: 127,665\n- cgrep (`agent locate/expand`) tokens-to-complete: 6,153\n- 95.2% fewer tokens (20.75x smaller)\n- Avg retrieval latency to completion: 1321.3ms -&gt; 22.7ms (~58.2x faster after indexing)<p>Links:\n- Repo: <a href=\"https://github.com/meghendra6/cgrep\" rel=\"nofollow\">https://github.com/meghendra6/cgrep</a>\n- Docs: <a href=\"https://meghendra6.github.io/cgrep/\" rel=\"nofollow\">https://meghendra6.github.io/cgrep/</a>\n- Benchmark method/results: <a href=\"https://meghendra6.github.io/cgrep/benchmarks/pytorch-agent-token-efficiency/\" rel=\"nofollow\">https://meghendra6.github.io/cgrep/benchmarks/pytorch-agent-...</a><p>I\u2019d really appreciate feedback on:\n- Real-world agent workflows I should benchmark next\n- MCP/agent integrations I should add\n- Cases where cgrep retrieval quality still falls short"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: cgrep \u2013 local, code-aware search for AI coding agents"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/meghendra6/cgrep"}},"_tags":["story","author_meghendra","story_47013067","show_hn"],"author":"meghendra","created_at":"2026-02-14T09:30:37Z","created_at_i":1771061437,"num_comments":0,"objectID":"47013067","points":2,"story_id":47013067,"story_text":"Hi HN \u2014 I built cgrep, a local-first, code-aware search tool for AI coding agents (and humans).<p>The goal is to reduce noisy retrieval loops and token waste in real repositories.  \ncgrep combines BM25 + tree-sitter symbol awareness, with optional semantic&#x2F;hybrid search, and returns deterministic JSON for agent workflows.<p>What it does:\n- Code navigation: definition, references, callers, dependents\n- Focused context tools: read, map\n- Agent flow: `agent locate` -&gt; `agent expand` (small payload first, expand only selected IDs)\n- MCP support: `cgrep mcp serve` + host install helpers\n- Agent install support: claude-code, codex, copilot, cursor, opencode<p>Benchmark snapshot (PyTorch, 6 implementation-tracing scenarios):\n- Baseline (`grep`) tokens-to-complete: 127,665\n- cgrep (`agent locate&#x2F;expand`) tokens-to-complete: 6,153\n- 95.2% fewer tokens (20.75x smaller)\n- Avg retrieval latency to completion: 1321.3ms -&gt; 22.7ms (~58.2x faster after indexing)<p>Links:\n- Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;meghendra6&#x2F;cgrep\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;meghendra6&#x2F;cgrep</a>\n- Docs: <a href=\"https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;</a>\n- Benchmark method&#x2F;results: <a href=\"https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;benchmarks&#x2F;pytorch-agent-token-efficiency&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;benchmarks&#x2F;pytorch-agent-...</a><p>I\u2019d really appreciate feedback on:\n- Real-world agent workflows I should benchmark next\n- MCP&#x2F;agent integrations I should add\n- Cases where cgrep retrieval quality still falls short","title":"Show HN: cgrep \u2013 local, code-aware search for AI coding agents","updated_at":"2026-02-14T09:33:52Z","url":"https://github.com/meghendra6/cgrep"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"nojs"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Ads are coming to AI, but not to <em>Claude</em> [video]"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.youtube.com/watch?v=FBSam25u8O4"}},"_tags":["story","author_nojs","story_47012749"],"author":"nojs","children":[47012803],"created_at":"2026-02-14T08:28:40Z","created_at_i":1771057720,"num_comments":1,"objectID":"47012749","points":1,"story_id":47012749,"title":"Ads are coming to AI, but not to Claude [video]","updated_at":"2026-02-14T11:03:21Z","url":"https://www.youtube.com/watch?v=FBSam25u8O4"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"lingxiao10"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"Show HN: Long Mem code agent cut 95% costs for <em>Claude</em> with small model reading"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://marketplace.visualstudio.com/items?itemName=devokaicode.cosave"}},"_tags":["story","author_lingxiao10","story_47012614","show_hn"],"author":"lingxiao10","children":[47012719],"created_at":"2026-02-14T08:00:58Z","created_at_i":1771056058,"num_comments":1,"objectID":"47012614","points":26,"story_id":47012614,"title":"Show HN: Long Mem code agent cut 95% costs for Claude with small model reading","updated_at":"2026-02-14T12:10:22Z","url":"https://marketplace.visualstudio.com/items?itemName=devokaicode.cosave"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Paodim"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"MCP Card Gen, and Valentine Card from <em>Claude</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://starborn.github.io/MCP-Model-Card-Generator/"}},"_tags":["story","author_Paodim","story_47012323"],"author":"Paodim","children":[47012324],"created_at":"2026-02-14T07:02:46Z","created_at_i":1771052566,"num_comments":0,"objectID":"47012323","points":1,"story_id":47012323,"title":"MCP Card Gen, and Valentine Card from Claude","updated_at":"2026-02-14T07:05:37Z","url":"https://starborn.github.io/MCP-Model-Card-Generator/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"hoangnnguyen"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude"],"value":"After using Cursor and <em>Claude</em> Code daily, I\u2019ve noticed that when an AI coding agent drifts or forgets constraints, we assume it\u2019s a model limitation.<p>In many cases, it\u2019s context management.<p>A few observations:\n- Tokens are not just limits. They\u2019re attention competition.\n- Even before hitting the hard window limit, attention dilution happens.\n- Coding tasks degrade faster than chat because of dependency density and multi-representation juggling (diffs, logs, tests).<p>I started managing context deliberately:\n- Always write a contract\n- Chunk sessions by intent\n- Snapshot state and restart\n- Prefer on-demand CLI instead of preloading large MCP responses<p>It dramatically improved the stability of the agent.<p>Curious how others are handling context optimization."},"title":{"matchLevel":"none","matchedWords":[],"value":"Context management is the real bottleneck in AI-assisted coding"}},"_tags":["story","author_hoangnnguyen","story_47012302","ask_hn"],"author":"hoangnnguyen","children":[47012353],"created_at":"2026-02-14T06:58:16Z","created_at_i":1771052296,"num_comments":1,"objectID":"47012302","points":1,"story_id":47012302,"story_text":"After using Cursor and Claude Code daily, I\u2019ve noticed that when an AI coding agent drifts or forgets constraints, we assume it\u2019s a model limitation.<p>In many cases, it\u2019s context management.<p>A few observations:\n- Tokens are not just limits. They\u2019re attention competition.\n- Even before hitting the hard window limit, attention dilution happens.\n- Coding tasks degrade faster than chat because of dependency density and multi-representation juggling (diffs, logs, tests).<p>I started managing context deliberately:\n- Always write a contract\n- Chunk sessions by intent\n- Snapshot state and restart\n- Prefer on-demand CLI instead of preloading large MCP responses<p>It dramatically improved the stability of the agent.<p>Curious how others are handling context optimization.","title":"Context management is the real bottleneck in AI-assisted coding","updated_at":"2026-02-14T07:08:51Z"}],"hitsPerPage":10,"nbHits":9911,"nbPages":100,"page":0,"params":"query=Claude&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":11,"processingTimingsMS":{"_request":{"roundTrip":16},"fetch":{"query":3,"scanning":6,"total":10},"total":11},"query":"Claude","serverTimeMS":12}
