{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"jeremyace"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Bothive \u2013 An Operating System for <em>AI</em> <em>Agent</em> Swarms"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://bothive.cloud/"}},"_tags":["story","author_jeremyace","story_47013933"],"author":"jeremyace","created_at":"2026-02-14T12:08:35Z","created_at_i":1771070915,"num_comments":0,"objectID":"47013933","points":2,"story_id":47013933,"title":"Bothive \u2013 An Operating System for AI Agent Swarms","updated_at":"2026-02-14T12:11:22Z","url":"https://bothive.cloud/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"lewissheridan"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Show HN: Agentify - A Declarative, <em>AI</em> <em>agent</em> building toolkit"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/backplane-cloud/agentify-toolkit"}},"_tags":["story","author_lewissheridan","story_47013725","show_hn"],"author":"lewissheridan","children":[47013980,47013726],"created_at":"2026-02-14T11:38:26Z","created_at_i":1771069106,"num_comments":1,"objectID":"47013725","points":1,"story_id":47013725,"title":"Show HN: Agentify - A Declarative, AI agent building toolkit","updated_at":"2026-02-14T12:15:52Z","url":"https://github.com/backplane-cloud/agentify-toolkit"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"152334H"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Can <em>AI</em> <em>agents</em> write kernel exploits?"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://152334h.github.io/blog/kctf-eval/"}},"_tags":["story","author_152334H","story_47013656"],"author":"152334H","created_at":"2026-02-14T11:26:00Z","created_at_i":1771068360,"num_comments":0,"objectID":"47013656","points":2,"story_id":47013656,"title":"Can AI agents write kernel exploits?","updated_at":"2026-02-14T12:55:22Z","url":"https://152334h.github.io/blog/kctf-eval/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"kaycebasques"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"Automate repository tasks with GitHub <em>Agenti</em>c Workflows"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"https://github.blog/<em>ai</em>-and-ml/automate-repository-tasks-with-github-<em>agenti</em>c-workflows/"}},"_tags":["story","author_kaycebasques","story_47013597"],"author":"kaycebasques","created_at":"2026-02-14T11:16:41Z","created_at_i":1771067801,"num_comments":0,"objectID":"47013597","points":1,"story_id":47013597,"title":"Automate repository tasks with GitHub Agentic Workflows","updated_at":"2026-02-14T11:22:22Z","url":"https://github.blog/ai-and-ml/automate-repository-tasks-with-github-agentic-workflows/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mazilin"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Subject: My attempt at an &quot;OS-inspired&quot; <em>AI</em> architecture\nHi HN,\nI'm a Product Manager, not a systems engineer. I built <em>AI</em> Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using <em>AI</em> <em>agents</em> for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. Orchestration Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-<em>Agents</em>\nThe core feature: Execution runs in isolated sub-<em>agents</em>. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python/Node environment (no installation hell).\nThe Code: <a href=\"https://github.com/canishowtime/ai-station-navigator/\" rel=\"nofollow\">https://github.com/canishowtime/<em>ai</em>-station-navigator/</a>\nI'd love to hear your thoughts on this architectural approach."},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Show HN: <em>AI</em> Station Navigator \u2013 LLM=CPU, <em>Agents</em>=Processes, Skills=Apps"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"https://github.com/canishowtime/<em>ai</em>-station-navigator"}},"_tags":["story","author_mazilin","story_47013274","show_hn"],"author":"mazilin","created_at":"2026-02-14T10:05:55Z","created_at_i":1771063555,"num_comments":0,"objectID":"47013274","points":2,"story_id":47013274,"story_text":"Subject: My attempt at an &quot;OS-inspired&quot; AI architecture\nHi HN,\nI&#x27;m a Product Manager, not a systems engineer. I built AI Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using AI agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. Orchestration Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python&#x2F;Node environment (no installation hell).\nThe Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;</a>\nI&#x27;d love to hear your thoughts on this architectural approach.","title":"Show HN: AI Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps","updated_at":"2026-02-14T10:09:52Z","url":"https://github.com/canishowtime/ai-station-navigator"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"meghendra"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Hi HN \u2014 I built cgrep, a local-first, code-aware search tool for <em>AI</em> coding <em>agents</em> (and humans).<p>The goal is to reduce noisy retrieval loops and token waste in real repositories.  \ncgrep combines BM25 + tree-sitter symbol awareness, with optional semantic/hybrid search, and returns deterministic JSON for agent workflows.<p>What it does:\n- Code navigation: definition, references, callers, dependents\n- Focused context tools: read, map\n- Agent flow: `agent locate` -&gt; `agent expand` (small payload first, expand only selected IDs)\n- MCP support: `cgrep mcp serve` + host install helpers\n- Agent install support: claude-code, codex, copilot, cursor, opencode<p>Benchmark snapshot (PyTorch, 6 implementation-tracing scenarios):\n- Baseline (`grep`) tokens-to-complete: 127,665\n- cgrep (`agent locate/expand`) tokens-to-complete: 6,153\n- 95.2% fewer tokens (20.75x smaller)\n- Avg retrieval latency to completion: 1321.3ms -&gt; 22.7ms (~58.2x faster after indexing)<p>Links:\n- Repo: <a href=\"https://github.com/meghendra6/cgrep\" rel=\"nofollow\">https://github.com/meghendra6/cgrep</a>\n- Docs: <a href=\"https://meghendra6.github.io/cgrep/\" rel=\"nofollow\">https://meghendra6.github.io/cgrep/</a>\n- Benchmark method/results: <a href=\"https://meghendra6.github.io/cgrep/benchmarks/pytorch-agent-token-efficiency/\" rel=\"nofollow\">https://meghendra6.github.io/cgrep/benchmarks/pytorch-agent-...</a><p>I\u2019d really appreciate feedback on:\n- Real-world agent workflows I should benchmark next\n- MCP/agent integrations I should add\n- Cases where cgrep retrieval quality still falls short"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Show HN: cgrep \u2013 local, code-aware search for <em>AI</em> coding <em>agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/meghendra6/cgrep"}},"_tags":["story","author_meghendra","story_47013067","show_hn"],"author":"meghendra","created_at":"2026-02-14T09:30:37Z","created_at_i":1771061437,"num_comments":0,"objectID":"47013067","points":2,"story_id":47013067,"story_text":"Hi HN \u2014 I built cgrep, a local-first, code-aware search tool for AI coding agents (and humans).<p>The goal is to reduce noisy retrieval loops and token waste in real repositories.  \ncgrep combines BM25 + tree-sitter symbol awareness, with optional semantic&#x2F;hybrid search, and returns deterministic JSON for agent workflows.<p>What it does:\n- Code navigation: definition, references, callers, dependents\n- Focused context tools: read, map\n- Agent flow: `agent locate` -&gt; `agent expand` (small payload first, expand only selected IDs)\n- MCP support: `cgrep mcp serve` + host install helpers\n- Agent install support: claude-code, codex, copilot, cursor, opencode<p>Benchmark snapshot (PyTorch, 6 implementation-tracing scenarios):\n- Baseline (`grep`) tokens-to-complete: 127,665\n- cgrep (`agent locate&#x2F;expand`) tokens-to-complete: 6,153\n- 95.2% fewer tokens (20.75x smaller)\n- Avg retrieval latency to completion: 1321.3ms -&gt; 22.7ms (~58.2x faster after indexing)<p>Links:\n- Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;meghendra6&#x2F;cgrep\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;meghendra6&#x2F;cgrep</a>\n- Docs: <a href=\"https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;</a>\n- Benchmark method&#x2F;results: <a href=\"https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;benchmarks&#x2F;pytorch-agent-token-efficiency&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;meghendra6.github.io&#x2F;cgrep&#x2F;benchmarks&#x2F;pytorch-agent-...</a><p>I\u2019d really appreciate feedback on:\n- Real-world agent workflows I should benchmark next\n- MCP&#x2F;agent integrations I should add\n- Cases where cgrep retrieval quality still falls short","title":"Show HN: cgrep \u2013 local, code-aware search for AI coding agents","updated_at":"2026-02-14T09:33:52Z","url":"https://github.com/meghendra6/cgrep"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"sv-pro"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Author here. Built this after working on <em>AI</em> <em>agent</em> security at Radware, where we discovered ZombieAgent - persistent malicious instructions in <em>agent</em> memory.<p>The insight: Don't teach <em>agents</em> to resist attacks. Virtualize their perceived reality so attacks never enter their world. Like VMs hiding physical RAM \u2192 <em>agents</em> shouldn't see raw dangerous inputs.<p>ARCHITECTURE:\n- Input virtualization: Strip attacks at boundary (not after <em>agent</em> sees them)\n- Provenance tracking: Prevents contaminated learning (critical with continuous learning coming in 1-2 years per Amodei)\n- Taint propagation: Deterministic physics laws prevent data exfiltration\n- No LLM in critical path: Fully deterministic, testable<p>Working PoC demonstrates:\n- Prompt injection prevention (attacks stripped at virtualization boundary)\n- Taint containment (untrusted data can't escape system)\n- Deterministic decisions (same input = same output, always)<p>CRITICAL TIMING:\nDario Amodei (Anthropic CEO, Feb 13): Continuous learning in 1-2 years [1]\nProblem: Memory poisoning + continuous learning = permanent compromise\nSolution: Provenance tracking prevents untrusted data from entering learning loop<p>Research context:\n- OpenAI: &quot;unlikely to ever be fully solved&quot; [2]\n- Anthropic: 1% ASR = &quot;meaningful risk&quot;\n- Academic research: 90-100% bypass rates on published defenses [3]<p>Seeking feedback on whether ontological security (does X exist?) beats permission security (can <em>agent</em> do X?) for <em>agent</em> systems.<p>Practical workarounds available in repo for immediate use while PoC matures.<p>Disclaimer: Personal project, not Radware-endorsed. References to published work only.<p>Happy to answer questions!<p>[1] <a href=\"https://www.dwarkesh.com/p/dario-amodei-2\" rel=\"nofollow\">https://www.dwarkesh.com/p/dario-amodei-2</a>\n[2] <a href=\"https://simonwillison.net/2024/Dec/9/openai-prompt-injection/\" rel=\"nofollow\">https://simonwillison.net/2024/Dec/9/openai-prompt-injection...</a>\n[3] <a href=\"https://arxiv.org/abs/2310.12815\" rel=\"nofollow\">https://arxiv.org/abs/2310.12815</a>"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Show HN: <em>Agent</em> Hypervisor \u2013 Reality Virtualization for <em>AI</em> <em>Agents</em>"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"https://github.com/sv-pro/<em>agent</em>-hypervisor"}},"_tags":["story","author_sv-pro","story_47012965","show_hn"],"author":"sv-pro","created_at":"2026-02-14T09:10:18Z","created_at_i":1771060218,"num_comments":0,"objectID":"47012965","points":1,"story_id":47012965,"story_text":"Author here. Built this after working on AI agent security at Radware, where we discovered ZombieAgent - persistent malicious instructions in agent memory.<p>The insight: Don&#x27;t teach agents to resist attacks. Virtualize their perceived reality so attacks never enter their world. Like VMs hiding physical RAM \u2192 agents shouldn&#x27;t see raw dangerous inputs.<p>ARCHITECTURE:\n- Input virtualization: Strip attacks at boundary (not after agent sees them)\n- Provenance tracking: Prevents contaminated learning (critical with continuous learning coming in 1-2 years per Amodei)\n- Taint propagation: Deterministic physics laws prevent data exfiltration\n- No LLM in critical path: Fully deterministic, testable<p>Working PoC demonstrates:\n- Prompt injection prevention (attacks stripped at virtualization boundary)\n- Taint containment (untrusted data can&#x27;t escape system)\n- Deterministic decisions (same input = same output, always)<p>CRITICAL TIMING:\nDario Amodei (Anthropic CEO, Feb 13): Continuous learning in 1-2 years [1]\nProblem: Memory poisoning + continuous learning = permanent compromise\nSolution: Provenance tracking prevents untrusted data from entering learning loop<p>Research context:\n- OpenAI: &quot;unlikely to ever be fully solved&quot; [2]\n- Anthropic: 1% ASR = &quot;meaningful risk&quot;\n- Academic research: 90-100% bypass rates on published defenses [3]<p>Seeking feedback on whether ontological security (does X exist?) beats permission security (can agent do X?) for agent systems.<p>Practical workarounds available in repo for immediate use while PoC matures.<p>Disclaimer: Personal project, not Radware-endorsed. References to published work only.<p>Happy to answer questions!<p>[1] <a href=\"https:&#x2F;&#x2F;www.dwarkesh.com&#x2F;p&#x2F;dario-amodei-2\" rel=\"nofollow\">https:&#x2F;&#x2F;www.dwarkesh.com&#x2F;p&#x2F;dario-amodei-2</a>\n[2] <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;9&#x2F;openai-prompt-injection&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;9&#x2F;openai-prompt-injection...</a>\n[3] <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.12815\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.12815</a>","title":"Show HN: Agent Hypervisor \u2013 Reality Virtualization for AI Agents","updated_at":"2026-02-14T09:11:07Z","url":"https://github.com/sv-pro/agent-hypervisor"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"junon"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"<em>AI</em> <em>Agent</em> Lands PRs in Major OSS Projects"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"https://socket.dev/blog/<em>ai</em>-<em>agent</em>-lands-prs-in-major-oss-projects-targets-maintainers-via-cold-outreach"}},"_tags":["story","author_junon","story_47012841"],"author":"junon","created_at":"2026-02-14T08:46:08Z","created_at_i":1771058768,"num_comments":0,"objectID":"47012841","points":1,"story_id":47012841,"title":"AI Agent Lands PRs in Major OSS Projects","updated_at":"2026-02-14T08:50:07Z","url":"https://socket.dev/blog/ai-agent-lands-prs-in-major-oss-projects-targets-maintainers-via-cold-outreach"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"nevodavid10"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"Show HN: Schedule posts to social media with <em>AI</em> <em>Agent</em> CLI"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"https://github.com/gitroomhq/postiz-<em>agent</em>"}},"_tags":["story","author_nevodavid10","story_47012611","show_hn"],"author":"nevodavid10","created_at":"2026-02-14T08:00:31Z","created_at_i":1771056031,"num_comments":0,"objectID":"47012611","points":3,"story_id":47012611,"title":"Show HN: Schedule posts to social media with AI Agent CLI","updated_at":"2026-02-14T08:32:06Z","url":"https://github.com/gitroomhq/postiz-agent"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"hoangnnguyen"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agents"],"value":"After using Cursor and Claude Code daily, I\u2019ve noticed that when an <em>AI</em> coding <em>agent</em> drifts or forgets constraints, we assume it\u2019s a model limitation.<p>In many cases, it\u2019s context management.<p>A few observations:\n- Tokens are not just limits. They\u2019re attention competition.\n- Even before hitting the hard window limit, attention dilution happens.\n- Coding tasks degrade faster than chat because of dependency density and multi-representation juggling (diffs, logs, tests).<p>I started managing context deliberately:\n- Always write a contract\n- Chunk sessions by intent\n- Snapshot state and restart\n- Prefer on-demand CLI instead of preloading large MCP responses<p>It dramatically improved the stability of the <em>agent</em>.<p>Curious how others are handling context optimization."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Context management is the real bottleneck in <em>AI</em>-assisted coding"}},"_tags":["story","author_hoangnnguyen","story_47012302","ask_hn"],"author":"hoangnnguyen","children":[47012353],"created_at":"2026-02-14T06:58:16Z","created_at_i":1771052296,"num_comments":1,"objectID":"47012302","points":1,"story_id":47012302,"story_text":"After using Cursor and Claude Code daily, I\u2019ve noticed that when an AI coding agent drifts or forgets constraints, we assume it\u2019s a model limitation.<p>In many cases, it\u2019s context management.<p>A few observations:\n- Tokens are not just limits. They\u2019re attention competition.\n- Even before hitting the hard window limit, attention dilution happens.\n- Coding tasks degrade faster than chat because of dependency density and multi-representation juggling (diffs, logs, tests).<p>I started managing context deliberately:\n- Always write a contract\n- Chunk sessions by intent\n- Snapshot state and restart\n- Prefer on-demand CLI instead of preloading large MCP responses<p>It dramatically improved the stability of the agent.<p>Curious how others are handling context optimization.","title":"Context management is the real bottleneck in AI-assisted coding","updated_at":"2026-02-14T07:08:51Z"}],"hitsPerPage":10,"nbHits":8897,"nbPages":100,"page":0,"params":"query=AI+agents&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":23,"processingTimingsMS":{"_request":{"roundTrip":26},"fetch":{"query":3,"scanning":15,"total":19},"getIdx":{"load":{"gens":2,"total":2},"total":3},"total":23},"query":"AI agents","serverTimeMS":24}
