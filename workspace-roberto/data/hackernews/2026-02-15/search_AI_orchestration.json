{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mazilin"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Subject: My attempt at an &quot;OS-inspired&quot; <em>AI</em> architecture\nHi HN,\nI'm a Product Manager, not a systems engineer. I built <em>AI</em> Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using <em>AI</em> agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. <em>Orchestration</em> Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python/Node environment (no installation hell).\nThe Code: <a href=\"https://github.com/canishowtime/ai-station-navigator/\" rel=\"nofollow\">https://github.com/canishowtime/<em>ai</em>-station-navigator/</a>\nI'd love to hear your thoughts on this architectural approach."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: <em>AI</em> Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"https://github.com/canishowtime/<em>ai</em>-station-navigator"}},"_tags":["story","author_mazilin","story_47013274","show_hn"],"author":"mazilin","created_at":"2026-02-14T10:05:55Z","created_at_i":1771063555,"num_comments":0,"objectID":"47013274","points":2,"story_id":47013274,"story_text":"Subject: My attempt at an &quot;OS-inspired&quot; AI architecture\nHi HN,\nI&#x27;m a Product Manager, not a systems engineer. I built AI Station Navigator as a proof-of-concept to solve a specific problem I faced: Context Pollution.\nWhen using AI agents for complex tasks, the context window gets cluttered quickly, causing the model to hallucinate or get confused.\nTo solve this, I designed this project using a Computer Architecture Analogy. I treated the agent system like a traditional OS to better manage resources and isolation.\nHere is the mapping I used to design the system:\n-- CPU approx. LLM (Claude)\nThe raw computing power driving the capabilities.\n-- Kernel approx. Orchestration Layer (Claude Code + CLAUDE.md)\nHandles intent recognition, task scheduling, and context management.\n-- Processes approx. Sub-Agents\nThe core feature: Execution runs in isolated sub-agents. When a task is done, the sub-agent &quot;dies,&quot; freeing up context. This prevents the main thread from getting polluted.\n-- Applications approx. Skills (GitHub Repos)\n&quot;App Store-style&quot; installation of tools via GitHub links.\n-- Drivers approx. MCP + Hooks\nStandardized interfaces for external tools and system automation.\n-- Runtime approx. Portable Environment\nSelf-contained Python&#x2F;Node environment (no installation hell).\nThe Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;canishowtime&#x2F;ai-station-navigator&#x2F;</a>\nI&#x27;d love to hear your thoughts on this architectural approach.","title":"Show HN: AI Station Navigator \u2013 LLM=CPU, Agents=Processes, Skills=Apps","updated_at":"2026-02-14T10:09:52Z","url":"https://github.com/canishowtime/ai-station-navigator"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"hogwash"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"<em>AI</em> Agents Enable Human Communication at Unprecedented Scale"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"https://venturebeat.com/<em>orchestration</em>/<em>ai</em>-agents-turned-super-bowl-viewers-into-one-high-iq-team-now-imagine-this"}},"_tags":["story","author_hogwash","story_47006442"],"author":"hogwash","children":[47010122],"created_at":"2026-02-13T19:07:11Z","created_at_i":1771009631,"num_comments":1,"objectID":"47006442","points":10,"story_id":47006442,"title":"AI Agents Enable Human Communication at Unprecedented Scale","updated_at":"2026-02-15T09:15:25Z","url":"https://venturebeat.com/orchestration/ai-agents-turned-super-bowl-viewers-into-one-high-iq-team-now-imagine-this"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"zoudong376"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"OpenClaw is great, but it\u2019s fairly heavy to run 24/7 at home.<p>In practice it often needs &gt;1GB RAM and a small server or Mac mini, which makes \u201cpersonal <em>AI</em> agents\u201d surprisingly expensive.<p>I recently came across PicoClaw, an open-source project by Sipeed that takes a very different approach.<p>Instead of running large runtimes locally, it acts as a lightweight agent client and delegates reasoning to cloud LLM APIs (GLM/GPT/Claude), while keeping <em>orchestration</em> local.<p>The interesting part is the footprint:<p>&lt; 10MB memory usage<p>&lt; 1s cold start<p>single self-contained binary<p>no Node.js or Python<p>runs on ARM / x86 / RISC-V<p>So it can run on devices like Raspberry Pi 3B, cheap RISC-V boards (~$10), old Android TV boxes, etc.<p>Technically it\u2019s rebuilt from scratch in Go, which explains most of the startup and memory improvements. No dependency tree, no runtime environment \u2014 just one binary.<p>Despite the size, it still supports:<p>shell execution<p>file operations<p>web search<p>speech-to-text<p>Telegram / Discord / QQ / DingTalk integrations<p>Quick start is basically:<p>git clone <a href=\"https://github.com/sipeed/picoclaw.git\" rel=\"nofollow\">https://github.com/sipeed/picoclaw.git</a><p>cd picoclaw\nmake build\n./picoclaw agent<p>Feels more like a \u201cmicrokernel\u201d approach to agents compared to heavier stacks.<p>Interesting direction if you\u2019re experimenting with edge <em>AI</em> or home lab automation.<p>Repo: <a href=\"https://github.com/sipeed/picoclaw\" rel=\"nofollow\">https://github.com/sipeed/picoclaw</a><p>Site: <a href=\"https://picoclaw.org/\" rel=\"nofollow\">https://picoclaw.org/</a>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: PicoClaw 10MB OpenClaw alternative that runs <em>AI</em> agents on $10 hardware"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://picoclaw.org/"}},"_tags":["story","author_zoudong376","story_47004845","show_hn"],"author":"zoudong376","children":[47009520],"created_at":"2026-02-13T16:54:21Z","created_at_i":1771001661,"num_comments":1,"objectID":"47004845","points":1,"story_id":47004845,"story_text":"OpenClaw is great, but it\u2019s fairly heavy to run 24&#x2F;7 at home.<p>In practice it often needs &gt;1GB RAM and a small server or Mac mini, which makes \u201cpersonal AI agents\u201d surprisingly expensive.<p>I recently came across PicoClaw, an open-source project by Sipeed that takes a very different approach.<p>Instead of running large runtimes locally, it acts as a lightweight agent client and delegates reasoning to cloud LLM APIs (GLM&#x2F;GPT&#x2F;Claude), while keeping orchestration local.<p>The interesting part is the footprint:<p>&lt; 10MB memory usage<p>&lt; 1s cold start<p>single self-contained binary<p>no Node.js or Python<p>runs on ARM &#x2F; x86 &#x2F; RISC-V<p>So it can run on devices like Raspberry Pi 3B, cheap RISC-V boards (~$10), old Android TV boxes, etc.<p>Technically it\u2019s rebuilt from scratch in Go, which explains most of the startup and memory improvements. No dependency tree, no runtime environment \u2014 just one binary.<p>Despite the size, it still supports:<p>shell execution<p>file operations<p>web search<p>speech-to-text<p>Telegram &#x2F; Discord &#x2F; QQ &#x2F; DingTalk integrations<p>Quick start is basically:<p>git clone <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sipeed&#x2F;picoclaw.git\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sipeed&#x2F;picoclaw.git</a><p>cd picoclaw\nmake build\n.&#x2F;picoclaw agent<p>Feels more like a \u201cmicrokernel\u201d approach to agents compared to heavier stacks.<p>Interesting direction if you\u2019re experimenting with edge AI or home lab automation.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sipeed&#x2F;picoclaw\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sipeed&#x2F;picoclaw</a><p>Site: <a href=\"https:&#x2F;&#x2F;picoclaw.org&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;picoclaw.org&#x2F;</a>","title":"Show HN: PicoClaw 10MB OpenClaw alternative that runs AI agents on $10 hardware","updated_at":"2026-02-13T23:55:38Z","url":"https://picoclaw.org/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Hi everyone,<p>I am Vincenzo and i\u2019m working on PolyMCP, an open-source framework that not only exposes Python functions as <em>AI</em>-callable MCP tools but also lets you orchestrate agents across multiple MCP servers.<p>The idea: instead of rewriting code or wrapping every function with a special SDK, you can:\n 1. Publish your existing Python functions as MCP tools automatically\n 2. Spin up a UnifiedPolyAgent that coordinates multiple MCP servers\n 3. Ask your agent to perform complex workflows spanning different tools<p>Here\u2019s a quick example in Python:<p>from polymcp.polyagent import UnifiedPolyAgent, OpenAIProvider<p>agent = UnifiedPolyAgent(\n    llm_provider=OpenAIProvider(model=&quot;gpt-4o-mini&quot;),\n    mcp_servers=[\n        &quot;http://localhost:8000/mcp&quot;,\n        &quot;http://localhost:8001/mcp&quot;,\n    ],\n    verbose=True,\n)<p>answer = agent.run(&quot;Read sales data, compute totals, then summarize.&quot;)\nprint(answer)<p>Or TypeScript, combining HTTP and stdio-based MCP tools:<p>import { UnifiedPolyAgent, OpenAIProvider } from 'polymcp-ts';<p>const agent = new UnifiedPolyAgent({\n  llmProvider: new OpenAIProvider({\n    apiKey: process.env.OPENAI_API_KEY!,\n    model: 'gpt-4o-mini',\n  }),\n  mcpServers: ['http://localhost:3000/mcp'],\n  stdioServers: [{ command: 'npx', args: ['@playwright/mcp@latest'] }],\n  verbose: true,\n});<p>await agent.start();\nconst answer = await agent.run('Collect data and summarize.');\nconsole.log(answer);<p>Use cases:\n \u2022 Aggregate data from multiple internal services and scripts\n \u2022 Build <em>AI</em> copilots that span different tools and languages\n \u2022 Automate multi-step operational workflows\n \u2022 Prototype agents that interact with production systems safely<p>Works with OpenAI, Anthropic, and Ollama models, including local deployments.<p>GitHub links:\n \u2022 Core &amp; Agent: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP</a> \n \u2022 Inspector: <a href=\"https://github.com/poly-mcp/PolyMCP-Inspector\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-Inspector</a> \n \u2022 SDK Apps: <a href=\"https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps</a><p>I\u2019d love feedback from anyone exploring agent <em>orchestration</em> or building multi-tool <em>AI</em> pipelines."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: PolyMCP \u2013 Orchestrate <em>AI</em> agents across Python tools and MCP servers"}},"_tags":["story","author_justvugg","story_47004468","show_hn"],"author":"justvugg","created_at":"2026-02-13T16:23:05Z","created_at_i":1770999785,"num_comments":0,"objectID":"47004468","points":1,"story_id":47004468,"story_text":"Hi everyone,<p>I am Vincenzo and i\u2019m working on PolyMCP, an open-source framework that not only exposes Python functions as AI-callable MCP tools but also lets you orchestrate agents across multiple MCP servers.<p>The idea: instead of rewriting code or wrapping every function with a special SDK, you can:\n 1. Publish your existing Python functions as MCP tools automatically\n 2. Spin up a UnifiedPolyAgent that coordinates multiple MCP servers\n 3. Ask your agent to perform complex workflows spanning different tools<p>Here\u2019s a quick example in Python:<p>from polymcp.polyagent import UnifiedPolyAgent, OpenAIProvider<p>agent = UnifiedPolyAgent(\n    llm_provider=OpenAIProvider(model=&quot;gpt-4o-mini&quot;),\n    mcp_servers=[\n        &quot;http:&#x2F;&#x2F;localhost:8000&#x2F;mcp&quot;,\n        &quot;http:&#x2F;&#x2F;localhost:8001&#x2F;mcp&quot;,\n    ],\n    verbose=True,\n)<p>answer = agent.run(&quot;Read sales data, compute totals, then summarize.&quot;)\nprint(answer)<p>Or TypeScript, combining HTTP and stdio-based MCP tools:<p>import { UnifiedPolyAgent, OpenAIProvider } from &#x27;polymcp-ts&#x27;;<p>const agent = new UnifiedPolyAgent({\n  llmProvider: new OpenAIProvider({\n    apiKey: process.env.OPENAI_API_KEY!,\n    model: &#x27;gpt-4o-mini&#x27;,\n  }),\n  mcpServers: [&#x27;http:&#x2F;&#x2F;localhost:3000&#x2F;mcp&#x27;],\n  stdioServers: [{ command: &#x27;npx&#x27;, args: [&#x27;@playwright&#x2F;mcp@latest&#x27;] }],\n  verbose: true,\n});<p>await agent.start();\nconst answer = await agent.run(&#x27;Collect data and summarize.&#x27;);\nconsole.log(answer);<p>Use cases:\n \u2022 Aggregate data from multiple internal services and scripts\n \u2022 Build AI copilots that span different tools and languages\n \u2022 Automate multi-step operational workflows\n \u2022 Prototype agents that interact with production systems safely<p>Works with OpenAI, Anthropic, and Ollama models, including local deployments.<p>GitHub links:\n \u2022 Core &amp; Agent: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a> \n \u2022 Inspector: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector</a> \n \u2022 SDK Apps: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps</a><p>I\u2019d love feedback from anyone exploring agent orchestration or building multi-tool AI pipelines.","title":"Show HN: PolyMCP \u2013 Orchestrate AI agents across Python tools and MCP servers","updated_at":"2026-02-13T16:25:05Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"otavioc"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Our <em>AI</em> <em>Orchestration</em> Frameworks Are Reinventing Linda (1985)"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"https://otavio.cat/posts/<em>ai</em>-<em>orchestration</em>-reinventing-linda/"}},"_tags":["story","author_otavioc","story_47002178"],"author":"otavioc","created_at":"2026-02-13T12:54:14Z","created_at_i":1770987254,"num_comments":0,"objectID":"47002178","points":3,"story_id":47002178,"title":"Our AI Orchestration Frameworks Are Reinventing Linda (1985)","updated_at":"2026-02-13T16:29:20Z","url":"https://otavio.cat/posts/ai-orchestration-reinventing-linda/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"pavello"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Hi,<p>Throw-away account because my original one is easily identifiable.<p>Does any starts to feel depressed about <em>AI</em> push and hype? I'm around ~45 and have been happily hacking and delivering stuff for 25 years.<p>I use <em>AI</em> daily \u2014 it's a useful tool. But the gap between the marketing and reality for many of us is hard to describe. The people and corporations and all those LinkedIn gurus, podcasters declaring our obsolescence are overwhelmingly people who've never built or maintained anything complex in their lives. I'm sick of posts showing developers as awesome managers <em>orchestratin</em>g fleets of Codex and Claude Code instances \u2014 I don't know a single person who actually has access to unlimited quotas for that. I'm now scared to publish open source because some random <em>AI</em> agent might spam my repo with garbage PRs and issues. \nAre we really expected to deliver mediocre C compilers while emitting millions of tons of CO2 into the atmosphere just to make a handful of rich people even more rich? And suddenly we have something like Moltbook to pollute our planet even more. Where are we going with this?<p>Anybody feels something like that? I seriously thinking about leaving the industry to keep my mental health in control or switch to some tech that is hard for <em>AI</em>."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Ask HN: <em>AI</em> Depression"}},"_tags":["story","author_pavello","story_47001833","ask_hn"],"author":"pavello","children":[47006576,47005687,47002344,47011453,47005312,47012910,47007182,47004722,47004555,47003359,47003974,47002019,47001993,47001913,47002469,47019551,47003373],"created_at":"2026-02-13T12:12:59Z","created_at_i":1770984779,"num_comments":28,"objectID":"47001833","points":52,"story_id":47001833,"story_text":"Hi,<p>Throw-away account because my original one is easily identifiable.<p>Does any starts to feel depressed about AI push and hype? I&#x27;m around ~45 and have been happily hacking and delivering stuff for 25 years.<p>I use AI daily \u2014 it&#x27;s a useful tool. But the gap between the marketing and reality for many of us is hard to describe. The people and corporations and all those LinkedIn gurus, podcasters declaring our obsolescence are overwhelmingly people who&#x27;ve never built or maintained anything complex in their lives. I&#x27;m sick of posts showing developers as awesome managers orchestrating fleets of Codex and Claude Code instances \u2014 I don&#x27;t know a single person who actually has access to unlimited quotas for that. I&#x27;m now scared to publish open source because some random AI agent might spam my repo with garbage PRs and issues. \nAre we really expected to deliver mediocre C compilers while emitting millions of tons of CO2 into the atmosphere just to make a handful of rich people even more rich? And suddenly we have something like Moltbook to pollute our planet even more. Where are we going with this?<p>Anybody feels something like that? I seriously thinking about leaving the industry to keep my mental health in control or switch to some tech that is hard for AI.","title":"Ask HN: AI Depression","updated_at":"2026-02-15T12:42:11Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"roninjin10"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Smithers - Declarative <em>AI</em> <em>Orchestration</em> with React"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/evmts/smithers"}},"_tags":["story","author_roninjin10","story_46998448"],"author":"roninjin10","children":[46998455],"created_at":"2026-02-13T03:03:08Z","created_at_i":1770951788,"num_comments":1,"objectID":"46998448","points":3,"story_id":46998448,"title":"Smithers - Declarative AI Orchestration with React","updated_at":"2026-02-13T15:53:36Z","url":"https://github.com/evmts/smithers"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"knes"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: We got sick of juggling terminals for <em>AI</em> agents so we built a workspace"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["orchestration"],"value":"https://www.augmentcode.com/blog/intent-a-workspace-for-agent-<em>orchestration</em>"}},"_tags":["story","author_knes","story_46997059","show_hn"],"author":"knes","created_at":"2026-02-12T23:59:13Z","created_at_i":1770940753,"num_comments":0,"objectID":"46997059","points":1,"story_id":46997059,"title":"Show HN: We got sick of juggling terminals for AI agents so we built a workspace","updated_at":"2026-02-13T00:04:32Z","url":"https://www.augmentcode.com/blog/intent-a-workspace-for-agent-orchestration"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"PolyMCP now supports compiling Python MCP tools to WebAssembly using Pyodide.<p>This means any Python function exposed as an MCP tool can now run directly in the browser, Node.js, or edge workers, fully sandboxed, without a Python server.<p>Compile your tools, serve the bundle, and <em>AI</em> agents can call them instantly in WASM environments. Existing MCP features like input validation, error handling, and tool <em>orchestration</em> work seamlessly.<p>example:<p>from polymcp.polymcp_toolkit import expose_tools_wasm<p>def add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;\n    return a + b<p>compiler = expose_tools_wasm([add])\nbundle = compiler.compile(output_dir=&quot;./dist&quot;)<p>Open dist/demo.html in your browser \u2014 the add tool runs entirely in WASM.<p>Why it matters\n \u2022 No Python server required: runs client-side or on edge\n \u2022 Secure: sandboxed execution\n \u2022 Plug-and-play: multiple tools in one WASM bundle\n \u2022 Ideal for interactive demos, edge <em>AI</em> apps, or browser-based automation<p>Repo: <a href=\"https://github.com/poly-mcp/Polymcp\" rel=\"nofollow\">https://github.com/poly-mcp/Polymcp</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PolyMCP \u2013 Run MCP Python Tools in WASM via Pyodide"}},"_tags":["story","author_justvugg","story_46993832","show_hn"],"author":"justvugg","created_at":"2026-02-12T19:32:15Z","created_at_i":1770924735,"num_comments":0,"objectID":"46993832","points":2,"story_id":46993832,"story_text":"PolyMCP now supports compiling Python MCP tools to WebAssembly using Pyodide.<p>This means any Python function exposed as an MCP tool can now run directly in the browser, Node.js, or edge workers, fully sandboxed, without a Python server.<p>Compile your tools, serve the bundle, and AI agents can call them instantly in WASM environments. Existing MCP features like input validation, error handling, and tool orchestration work seamlessly.<p>example:<p>from polymcp.polymcp_toolkit import expose_tools_wasm<p>def add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;\n    return a + b<p>compiler = expose_tools_wasm([add])\nbundle = compiler.compile(output_dir=&quot;.&#x2F;dist&quot;)<p>Open dist&#x2F;demo.html in your browser \u2014 the add tool runs entirely in WASM.<p>Why it matters\n \u2022 No Python server required: runs client-side or on edge\n \u2022 Secure: sandboxed execution\n \u2022 Plug-and-play: multiple tools in one WASM bundle\n \u2022 Ideal for interactive demos, edge AI apps, or browser-based automation<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;Polymcp\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;Polymcp</a>","title":"Show HN: PolyMCP \u2013 Run MCP Python Tools in WASM via Pyodide","updated_at":"2026-02-13T07:57:03Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"gusmally"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"In a recent interview with The Pragmatic Engineer, Steve Yegge said he feels &quot;sorry for people&quot; who merely &quot;use Cursor, ask it questions sometimes, review its code really carefully, and then check it in.&quot;<p>Instead, he recommends engineers integrate LLMs into their workflow more and more, until they are  managing multiple agents at one time. The final level in his <em>AI</em> Coding chart reads: \n&quot;Level 8: you build your own <em>orchestrator</em> to coordinate more agents.&quot;<p>At my work, this wouldn't fly-- we're still doing things the sorry way. Are you using <em>orchestrator</em>s to manage multiple agents at work? Particularly interested in non-greenfield applications and how that's changed your SDLC."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["orchestration"],"value":"Ask HN: Are you using an agent <em>orchestrator</em> to write code?"}},"_tags":["story","author_gusmally","story_46993479","ask_hn"],"author":"gusmally","children":[46999194,46999241,46999562,46999714,46999178,46999316,47016387,47014179,47004614,46999286,46999279,47000042,46999804,46999385,47007380,46999411,47009739,47000345,46999560,46999578,46999369,46999229,46999505,47001872,46999193,46999218,46999089,46999438,46999253,46999622,46999501,46999127,46999406,46999132,46999906,47014934,47001197],"created_at":"2026-02-12T19:06:57Z","created_at_i":1770923217,"num_comments":57,"objectID":"46993479","points":37,"story_id":46993479,"story_text":"In a recent interview with The Pragmatic Engineer, Steve Yegge said he feels &quot;sorry for people&quot; who merely &quot;use Cursor, ask it questions sometimes, review its code really carefully, and then check it in.&quot;<p>Instead, he recommends engineers integrate LLMs into their workflow more and more, until they are  managing multiple agents at one time. The final level in his AI Coding chart reads: \n&quot;Level 8: you build your own orchestrator to coordinate more agents.&quot;<p>At my work, this wouldn&#x27;t fly-- we&#x27;re still doing things the sorry way. Are you using orchestrators to manage multiple agents at work? Particularly interested in non-greenfield applications and how that&#x27;s changed your SDLC.","title":"Ask HN: Are you using an agent orchestrator to write code?","updated_at":"2026-02-15T12:46:25Z"}],"hitsPerPage":10,"nbHits":337,"nbPages":34,"page":0,"params":"query=AI+orchestration&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":39,"processingTimingsMS":{"_request":{"roundTrip":20},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":6,"scanning":4,"total":11},"getIdx":{"load":{"gens":16,"synonyms":9,"total":27},"total":27},"total":40},"query":"AI orchestration","serverTimeMS":73}
