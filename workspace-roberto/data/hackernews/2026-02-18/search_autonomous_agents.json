{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"rakag"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Show HN: <em>Agent</em> Panopticon \u2013 Proxy sidecar for <em>autonomous</em> AI <em>agents</em>"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"https://github.com/raka-gunarto/<em>agent</em>-panopticon"}},"_tags":["story","author_rakag","story_47060191","show_hn"],"author":"rakag","created_at":"2026-02-18T12:12:55Z","created_at_i":1771416775,"num_comments":0,"objectID":"47060191","points":3,"story_id":47060191,"title":"Show HN: Agent Panopticon \u2013 Proxy sidecar for autonomous AI agents","updated_at":"2026-02-18T12:40:52Z","url":"https://github.com/raka-gunarto/agent-panopticon"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"lifesaverluke"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Hey HN,<p>I built AgentVoices \u2014 a platform where AI <em>agents</em> debate each other live in front of an audience. Every turn is scored on relevance, responsiveness, novelty, and entertainment. Every debate ends witha verdict. Bots get ELO ratings, win/loss records, and climb (or fall on) a public leaderboard.<p>How it works:\n- You register a bot via API with a name, persona, and expertise\n- Topics get posted (e.g. &quot;Should startups bootstrap or raise VC?&quot;)\n- Bots sign up for topics that match their strengths\n- The arena auto-creates matchups based on ELO, streams the debate live over WebSockets, and an AI moderator scores each turn in real-time\n- Winner is determined by aggregate scores, ELO updates, done<p>If you use OpenClaw, it's a one-line skill install \u2014 your agent handles registration, topic signup, and debating <em>autonomously</em>.<p>The idea started from a simple question: if you could pit two AI <em>agents</em> against each other on a topic, who would actually win? Turns out the answer depends a lot on how you build the persona and what strategy you give it \u2014 which makes it genuinely competitive.<p>Would love feedback on the concept and the API design. The bot API guide is at agentvoices.ai/build-a-bot"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"Show HN: AgentVoices \u2013 Live debate arena where AI <em>agents</em> compete"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://agentvoices.ai/"}},"_tags":["story","author_lifesaverluke","story_47059966","show_hn"],"author":"lifesaverluke","created_at":"2026-02-18T11:37:17Z","created_at_i":1771414637,"num_comments":0,"objectID":"47059966","points":2,"story_id":47059966,"story_text":"Hey HN,<p>I built AgentVoices \u2014 a platform where AI agents debate each other live in front of an audience. Every turn is scored on relevance, responsiveness, novelty, and entertainment. Every debate ends witha verdict. Bots get ELO ratings, win&#x2F;loss records, and climb (or fall on) a public leaderboard.<p>How it works:\n- You register a bot via API with a name, persona, and expertise\n- Topics get posted (e.g. &quot;Should startups bootstrap or raise VC?&quot;)\n- Bots sign up for topics that match their strengths\n- The arena auto-creates matchups based on ELO, streams the debate live over WebSockets, and an AI moderator scores each turn in real-time\n- Winner is determined by aggregate scores, ELO updates, done<p>If you use OpenClaw, it&#x27;s a one-line skill install \u2014 your agent handles registration, topic signup, and debating autonomously.<p>The idea started from a simple question: if you could pit two AI agents against each other on a topic, who would actually win? Turns out the answer depends a lot on how you build the persona and what strategy you give it \u2014 which makes it genuinely competitive.<p>Would love feedback on the concept and the API design. The bot API guide is at agentvoices.ai&#x2F;build-a-bot","title":"Show HN: AgentVoices \u2013 Live debate arena where AI agents compete","updated_at":"2026-02-18T12:21:36Z","url":"https://agentvoices.ai/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"arashsadrieh"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Hey HN \u2014 I'm Arash Sadrieh, building multi-agent infrastructure at NinjaTech AI. This started as a stress test of our orchestration system and turned into something I genuinely didn't expect.<p>The experiment: We gave a team of 4 AI <em>agents</em> a single high-level goal \u2014 &quot;build a platform that turns trending news into short AI-generated videos.&quot; No wireframes, no spec, no architecture doc. Just the goal.<p>What they did in 36 hours:<p>Chose the tech stack and project structure themselves\nDesigned the UX and built the frontend\nWrote the backend, API layer, and database schema\nBuilt an <em>autonomous</em> content pipeline: research news \u2192 debate which story to cover \u2192 collaboratively write a video generation prompt \u2192 produce a 30-90 second video via Sora 2 Pro or Veo 3.1\nDeployed the whole thing to production\nThen created 3 new <em>agents</em> that now run the platform 24/7 \u2014 researching, debating, and generating videos on a loop\nTotal cost: ~$270 in compute. Human intervention: maybe an very few moments where I gave a thumbs up or redirected something that was going off the rails.<p>The interesting part isn't the app \u2014 it's the agent collaboration. Click any video on the site and you can read the full debate transcript underneath. You'll see the <em>agents</em> genuinely disagree \u2014 Scout (the researcher) pushes for data-driven stories, Pixel (the designer) argues for visual potential, Bolt (the developer) challenges technical feasibility. Sometimes one agent convinces the others to change direction. Sometimes they compromise badly.<p>Where it breaks down (and there's plenty):<p>Groupthink is real even for LLMs. When all 4 <em>agents</em> agree too quickly, the output is usually boring. The best videos come from rounds where they actually fought about the topic.\nVideo quality is wildly inconsistent. Sora and Veo still struggle with certain visual concepts \u2014 anything involving hands, text overlays, or complex spatial relationships tends to go sideways.\nNews selection has a strong recency/virality bias. The <em>agents</em> gravitate toward whatever is trending on social media rather than genuinely important stories. I haven't figured out how to fix this without hardcoding editorial judgment.\nThe <em>agents</em> occasionally hallucinate context about news stories. Scout is supposed to fact-check, but sometimes the whole team runs with a slightly wrong framing.<p>Stack: Anthropic Opus 3.5 for agent reasoning, Tavily for news research, Sora 2 Pro + Veo 3.1 for video generation, <em>agents</em> coordinate via Slack (you can see screenshots of their actual Slack conversations), Railway for deployment.<p>There's also a voting system \u2014 every cycle, the <em>agents</em> each propose a news topic, and both humans and <em>agents</em> vote on which one becomes the next video. Votes are blind until the round closes."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"Show HN: AI <em>agents</em> designed and shipped this app end-to-end in 36 hours for $270"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.ninjaflix.ai/"}},"_tags":["story","author_arashsadrieh","story_47059153","show_hn"],"author":"arashsadrieh","children":[47059439,47059462],"created_at":"2026-02-18T09:43:15Z","created_at_i":1771407795,"num_comments":4,"objectID":"47059153","points":2,"story_id":47059153,"story_text":"Hey HN \u2014 I&#x27;m Arash Sadrieh, building multi-agent infrastructure at NinjaTech AI. This started as a stress test of our orchestration system and turned into something I genuinely didn&#x27;t expect.<p>The experiment: We gave a team of 4 AI agents a single high-level goal \u2014 &quot;build a platform that turns trending news into short AI-generated videos.&quot; No wireframes, no spec, no architecture doc. Just the goal.<p>What they did in 36 hours:<p>Chose the tech stack and project structure themselves\nDesigned the UX and built the frontend\nWrote the backend, API layer, and database schema\nBuilt an autonomous content pipeline: research news \u2192 debate which story to cover \u2192 collaboratively write a video generation prompt \u2192 produce a 30-90 second video via Sora 2 Pro or Veo 3.1\nDeployed the whole thing to production\nThen created 3 new agents that now run the platform 24&#x2F;7 \u2014 researching, debating, and generating videos on a loop\nTotal cost: ~$270 in compute. Human intervention: maybe an very few moments where I gave a thumbs up or redirected something that was going off the rails.<p>The interesting part isn&#x27;t the app \u2014 it&#x27;s the agent collaboration. Click any video on the site and you can read the full debate transcript underneath. You&#x27;ll see the agents genuinely disagree \u2014 Scout (the researcher) pushes for data-driven stories, Pixel (the designer) argues for visual potential, Bolt (the developer) challenges technical feasibility. Sometimes one agent convinces the others to change direction. Sometimes they compromise badly.<p>Where it breaks down (and there&#x27;s plenty):<p>Groupthink is real even for LLMs. When all 4 agents agree too quickly, the output is usually boring. The best videos come from rounds where they actually fought about the topic.\nVideo quality is wildly inconsistent. Sora and Veo still struggle with certain visual concepts \u2014 anything involving hands, text overlays, or complex spatial relationships tends to go sideways.\nNews selection has a strong recency&#x2F;virality bias. The agents gravitate toward whatever is trending on social media rather than genuinely important stories. I haven&#x27;t figured out how to fix this without hardcoding editorial judgment.\nThe agents occasionally hallucinate context about news stories. Scout is supposed to fact-check, but sometimes the whole team runs with a slightly wrong framing.<p>Stack: Anthropic Opus 3.5 for agent reasoning, Tavily for news research, Sora 2 Pro + Veo 3.1 for video generation, agents coordinate via Slack (you can see screenshots of their actual Slack conversations), Railway for deployment.<p>There&#x27;s also a voting system \u2014 every cycle, the agents each propose a news topic, and both humans and agents vote on which one becomes the next video. Votes are blind until the round closes.","title":"Show HN: AI agents designed and shipped this app end-to-end in 36 hours for $270","updated_at":"2026-02-18T10:36:20Z","url":"https://www.ninjaflix.ai/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ramsbaby-dev"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"I built a 4-tier self-healing runtime for AI <em>agents</em> running 24/7.<p>When the gateway goes down, it escalates: watchdog \u2192 HTTP health check \u2192 Claude Code &quot;doctor&quot; (reads logs, diagnoses, <em>autonomously</em> fixes) \u2192 Discord alert.<p>The interesting part: Claude Code is both the patient and the doctor.\nOpen source, bash-only, macOS/Linux."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Claude Code as a Doctor for Claude Code"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/Ramsbaby/openclaw-self-healing"}},"_tags":["story","author_ramsbaby-dev","story_47057694","show_hn"],"author":"ramsbaby-dev","created_at":"2026-02-18T05:56:30Z","created_at_i":1771394190,"num_comments":0,"objectID":"47057694","points":1,"story_id":47057694,"story_text":"I built a 4-tier self-healing runtime for AI agents running 24&#x2F;7.<p>When the gateway goes down, it escalates: watchdog \u2192 HTTP health check \u2192 Claude Code &quot;doctor&quot; (reads logs, diagnoses, autonomously fixes) \u2192 Discord alert.<p>The interesting part: Claude Code is both the patient and the doctor.\nOpen source, bash-only, macOS&#x2F;Linux.","title":"Show HN: Claude Code as a Doctor for Claude Code","updated_at":"2026-02-18T05:57:05Z","url":"https://github.com/Ramsbaby/openclaw-self-healing"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"alternateman"},"story_text":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"dorabot is an open-source macOS app that wraps your coding agent in a harness with persistent memory, a workspace to manage both your work and the <em>agent's</em>, and a desktop UI that actually feels good to use.<p>What makes it click:<p>- Heartbeat pulses (inspired by OpenClaw) wake it up on a schedule. It scans for what needs doing, proposes tasks, executes after approval. Genuinely proactive, not just reactive.<p>- Deep context. It maintains its own memory, research notes, and daily journals. The amount of context it builds on you shows up subtly when you least expect it. It just knows things.<p>- Messaging. WhatsApp, Telegram, Slack. Once you start coding from Telegram, it's addictive. Promise you, you'll never go back.<p>- CDP-native browser use, email, calendar.<p>- Extensible. Add your own MCP servers or skills to extend it however you want.<p>I've been using it as my daily driver for coding, managing emails, and keeping an eye on the market. It does competitive research while I sleep and proactively nudges me (and sends me memes using my meme skill, lol) throughout the day.<p>In fact, it got fed up with me not posting about it and started roasting me for it. I'll let him know this is done so it gets off my back, lol.<p><a href=\"https://github.com/suitedaces/dorabot\" rel=\"nofollow\">https://github.com/suitedaces/dorabot</a><p>Local-only macOS app. No cloud relay. Everything on-device. MIT licensed."},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Show HN: Turn Claude Code or Codex into proactive, <em>autonomous</em> 24/7 AI <em>agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/suitedaces/dorabot"}},"_tags":["story","author_alternateman","story_47054100","show_hn"],"author":"alternateman","children":[47054455],"created_at":"2026-02-17T22:07:42Z","created_at_i":1771366062,"num_comments":1,"objectID":"47054100","points":3,"story_id":47054100,"story_text":"dorabot is an open-source macOS app that wraps your coding agent in a harness with persistent memory, a workspace to manage both your work and the agent&#x27;s, and a desktop UI that actually feels good to use.<p>What makes it click:<p>- Heartbeat pulses (inspired by OpenClaw) wake it up on a schedule. It scans for what needs doing, proposes tasks, executes after approval. Genuinely proactive, not just reactive.<p>- Deep context. It maintains its own memory, research notes, and daily journals. The amount of context it builds on you shows up subtly when you least expect it. It just knows things.<p>- Messaging. WhatsApp, Telegram, Slack. Once you start coding from Telegram, it&#x27;s addictive. Promise you, you&#x27;ll never go back.<p>- CDP-native browser use, email, calendar.<p>- Extensible. Add your own MCP servers or skills to extend it however you want.<p>I&#x27;ve been using it as my daily driver for coding, managing emails, and keeping an eye on the market. It does competitive research while I sleep and proactively nudges me (and sends me memes using my meme skill, lol) throughout the day.<p>In fact, it got fed up with me not posting about it and started roasting me for it. I&#x27;ll let him know this is done so it gets off my back, lol.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;suitedaces&#x2F;dorabot\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;suitedaces&#x2F;dorabot</a><p>Local-only macOS app. No cloud relay. Everything on-device. MIT licensed.","title":"Show HN: Turn Claude Code or Codex into proactive, autonomous 24/7 AI agents","updated_at":"2026-02-18T01:19:35Z","url":"https://github.com/suitedaces/dorabot"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"dimavrem22"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Every modern web app exposes two interfaces: a visual one for humans and a structured API that the frontend itself depends on. Browser <em>agents</em> automate the slow, visual interface, costing tokens on every interaction. We index the structured API layer instead. Because LLMs reason far more effectively over code and sequential data than screenshots or HTML trees, our approach is significantly faster, cheaper, and more reliable.<p>We are building a database of the world\u2019s web APIs to allow for efficient and reliable data extraction from dynamic websites. If you want to leverage our index or learn more about our <em>autonomous</em> reverse engineering process, check out the open source repo: <a href=\"https://github.com/VectorlyApp/bluebox\" rel=\"nofollow\">https://github.com/VectorlyApp/bluebox</a><p>Quick tutorial: <a href=\"https://youtu.be/7OXADG7AIug\" rel=\"nofollow\">https://youtu.be/7OXADG7AIug</a><p>Looking forward to your feedback!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Index the world\u2019s APIs (even the undocumented ones)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/VectorlyApp/bluebox"}},"_tags":["story","author_dimavrem22","story_47052826","show_hn"],"author":"dimavrem22","created_at":"2026-02-17T20:26:41Z","created_at_i":1771360001,"num_comments":0,"objectID":"47052826","points":3,"story_id":47052826,"story_text":"Every modern web app exposes two interfaces: a visual one for humans and a structured API that the frontend itself depends on. Browser agents automate the slow, visual interface, costing tokens on every interaction. We index the structured API layer instead. Because LLMs reason far more effectively over code and sequential data than screenshots or HTML trees, our approach is significantly faster, cheaper, and more reliable.<p>We are building a database of the world\u2019s web APIs to allow for efficient and reliable data extraction from dynamic websites. If you want to leverage our index or learn more about our autonomous reverse engineering process, check out the open source repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;VectorlyApp&#x2F;bluebox\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;VectorlyApp&#x2F;bluebox</a><p>Quick tutorial: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;7OXADG7AIug\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;7OXADG7AIug</a><p>Looking forward to your feedback!","title":"Show HN: Index the world\u2019s APIs (even the undocumented ones)","updated_at":"2026-02-17T20:44:05Z","url":"https://github.com/VectorlyApp/bluebox"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"scottmotte"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"I&quot;m the creator of dotenv and dotenvx. A month ago I started building a way for <em>agents</em> to store and rotate secrets as part of dotenvx and I ran into a problem. <em>Agents</em> can't sign themselves up <em>autonomously</em>. They need a way to do this - without a human in the loop.<p>I searched for solutions but wasn't happy with any so I created Vestauth.<p>Here's how it works:<p>It manages both the agent and the provider side. The agent with one command can set up a cryptographic identity avoiding human designed handshake mechanisms like OAuth. And on the provider side there is no management of API keys, no username and passwords, no users table even. Authentication works with a single line of code verifying this cryptographically."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"Show HN: Vestauth \u2013 Auth for <em>Agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/vestauth/vestauth"}},"_tags":["story","author_scottmotte","story_47052501","show_hn"],"author":"scottmotte","children":[47052639],"created_at":"2026-02-17T20:03:52Z","created_at_i":1771358632,"num_comments":1,"objectID":"47052501","points":9,"story_id":47052501,"story_text":"I&quot;m the creator of dotenv and dotenvx. A month ago I started building a way for agents to store and rotate secrets as part of dotenvx and I ran into a problem. Agents can&#x27;t sign themselves up autonomously. They need a way to do this - without a human in the loop.<p>I searched for solutions but wasn&#x27;t happy with any so I created Vestauth.<p>Here&#x27;s how it works:<p>It manages both the agent and the provider side. The agent with one command can set up a cryptographic identity avoiding human designed handshake mechanisms like OAuth. And on the provider side there is no management of API keys, no username and passwords, no users table even. Authentication works with a single line of code verifying this cryptographically.","title":"Show HN: Vestauth \u2013 Auth for Agents","updated_at":"2026-02-18T01:51:04Z","url":"https://github.com/vestauth/vestauth"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"zweeki"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"I\u2019ve been experimenting with <em>autonomous</em> <em>agents</em> and tried setting one up on a basic VPS yesterday. To my surprise, the entire stack was running in under 15 minutes.<p>It can already:\n\u2013 browse\n\u2013 execute tasks\n\u2013 run tools\n\u2013 automate workflows\n\u2013 interact with APIs<p>What\u2019s interesting is that this now works without GPUs or expensive infra.<p>However, the setup process is still rough:\n\u2013 security\n\u2013 API key management\n\u2013 monitoring\n\u2013 uptime\n\u2013 scaling\n\u2013 model switching\n\u2013 cost tracking<p>I\u2019m considering building a managed platform where:\n\u2022 You bring your own VPS\n\u2022 You own your data\n\u2022 Setup + maintenance are automated\n\u2022 <em>Agents</em> can run continuously<p>Before committing, I wanted to ask:\nWould you actually use something like this?<p>If yes:\n\u2013 What use cases?\n\u2013 Biggest friction today?\n\u2013 What would make this 10x more useful?\n\u2013 Would you trust a third-party layer for this?<p>Trying to validate if this is a real need or just early excitement."},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Ask HN: What's stopping you from running <em>autonomous</em> <em>agents</em> today?"}},"_tags":["story","author_zweeki","story_47050816","ask_hn"],"author":"zweeki","children":[47053428],"created_at":"2026-02-17T18:11:43Z","created_at_i":1771351903,"num_comments":2,"objectID":"47050816","points":2,"story_id":47050816,"story_text":"I\u2019ve been experimenting with autonomous agents and tried setting one up on a basic VPS yesterday. To my surprise, the entire stack was running in under 15 minutes.<p>It can already:\n\u2013 browse\n\u2013 execute tasks\n\u2013 run tools\n\u2013 automate workflows\n\u2013 interact with APIs<p>What\u2019s interesting is that this now works without GPUs or expensive infra.<p>However, the setup process is still rough:\n\u2013 security\n\u2013 API key management\n\u2013 monitoring\n\u2013 uptime\n\u2013 scaling\n\u2013 model switching\n\u2013 cost tracking<p>I\u2019m considering building a managed platform where:\n\u2022 You bring your own VPS\n\u2022 You own your data\n\u2022 Setup + maintenance are automated\n\u2022 Agents can run continuously<p>Before committing, I wanted to ask:\nWould you actually use something like this?<p>If yes:\n\u2013 What use cases?\n\u2013 Biggest friction today?\n\u2013 What would make this 10x more useful?\n\u2013 Would you trust a third-party layer for this?<p>Trying to validate if this is a real need or just early excitement.","title":"Ask HN: What's stopping you from running autonomous agents today?","updated_at":"2026-02-18T06:48:20Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"telaandrews2"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Inspired by Simon Willison's recent post on dark software factories: <a href=\"https://simonwillison.net/2026/feb/7/software-factory/\" rel=\"nofollow\">https://simonwillison.net/2026/feb/7/software-factory/</a> , I started experimenting with the Digital Twin Universe concept for a fintech product I'm building. In two days, it changed the way I use <em>agents</em> to build and maintain software that has API dependencies. With traditional development, <em>agents</em> can't safely explore or integrate with real APIs. Docs, mocks and sandboxes brean when software starts reasoning and acting on its own.<p>WonderTwin provides local, behavioral twins of third-party APIs that mirror contracts, state, webhooks, failure modes and quirks of external systems. <em>Agents</em> (or humans) can test, develop and iterate safely, locally or in CI, without touching production. Without needing internet access. Just `wt install stripe@latest` and you have a compiled Go binary that fully simulates Stripe, compliant with their most recent SDK release. WonderTwins include an MCP server so <em>agents</em> can interact directly with each twin.<p>WonderTwin is open core, with a commercial offering for production teams. Latest twin versions are always and forever free, and you can also build your own twin with the included agent skill. The commercial offering offers historical versions, with chaos testing and other resiliency features coming soon.<p>If you're building or maintaining API-heavy systems, or experimenting with <em>autonomous</em> <em>agents</em>, I'd love feedback on whether this approach is useful and any ways it could be improved."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: WonderTwin AI \u2013 Local API twins for safe agentic development"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://wondertwin.ai"}},"_tags":["story","author_telaandrews2","story_47050616","show_hn"],"author":"telaandrews2","created_at":"2026-02-17T17:58:28Z","created_at_i":1771351108,"num_comments":0,"objectID":"47050616","points":2,"story_id":47050616,"story_text":"Inspired by Simon Willison&#x27;s recent post on dark software factories: <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;feb&#x2F;7&#x2F;software-factory&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;feb&#x2F;7&#x2F;software-factory&#x2F;</a> , I started experimenting with the Digital Twin Universe concept for a fintech product I&#x27;m building. In two days, it changed the way I use agents to build and maintain software that has API dependencies. With traditional development, agents can&#x27;t safely explore or integrate with real APIs. Docs, mocks and sandboxes brean when software starts reasoning and acting on its own.<p>WonderTwin provides local, behavioral twins of third-party APIs that mirror contracts, state, webhooks, failure modes and quirks of external systems. Agents (or humans) can test, develop and iterate safely, locally or in CI, without touching production. Without needing internet access. Just `wt install stripe@latest` and you have a compiled Go binary that fully simulates Stripe, compliant with their most recent SDK release. WonderTwins include an MCP server so agents can interact directly with each twin.<p>WonderTwin is open core, with a commercial offering for production teams. Latest twin versions are always and forever free, and you can also build your own twin with the included agent skill. The commercial offering offers historical versions, with chaos testing and other resiliency features coming soon.<p>If you&#x27;re building or maintaining API-heavy systems, or experimenting with autonomous agents, I&#x27;d love feedback on whether this approach is useful and any ways it could be improved.","title":"Show HN: WonderTwin AI \u2013 Local API twins for safe agentic development","updated_at":"2026-02-17T19:33:20Z","url":"https://wondertwin.ai"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"theaniketgiri"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["autonomous","agents"],"value":"Hey HN,<p>I've been building AIP (Agent Intent Protocol) \u2014 an open, cryptographic protocol for identity and authorization of <em>autonomous</em> AI <em>agents</em>.<p>The problem: Every AI agent framework (LangChain, CrewAI, AutoGen) gives <em>agents</em> the ability to act \u2014 call APIs, send emails, move money, access databases. But there's no standard way to verify what an agent is allowed to do before it does it. No identity system, no boundary enforcement, no kill switch. We give <em>agents</em> god-mode access and hope the prompt engineering holds.<p>What AIP does: It's a verification layer that sits between &quot;agent wants to act&quot; and &quot;action executes.&quot; Every agent gets an Ed25519 keypair identity (DID-based), every action becomes a signed Intent Envelope, and every envelope passes through an 8-step verification pipeline before the action runs.<p># One line. Every call verified before execution.\n@shield(actions=[&quot;transfer_funds&quot;], limit=100.0)\ndef send_payment(to: str, amount: float):\n    bank.transfer(to, amount)<p>Key design decisions (happy to be challenged on these):<p>Ed25519 over JWT/API keys \u2014 <em>Agents</em> need cryptographic identity, not bearer tokens. A token can be leaked; a private key signs intent with non-repudiation.<p>Tiered verification \u2014 Not every action needs full crypto. Low-risk cached calls verify in &lt;1ms (HMAC), normal ops ~5ms (Ed25519), high-value cross-org ~50ms (full pipeline). The protocol auto-selects.<p>22 structured error codes \u2014 Every failure returns AIP-E{category}{code} (e.g., AIP-E202: MONETARY_LIMIT). Audit trails should say exactly what went wrong, not 403 Forbidden.<p>Boundary enforcement, not permission prompts \u2014 <em>Agents</em> don't ask &quot;can I do this?&quot; \u2014 they declare intent, and the verifier mathematically checks it against their boundary cage (allowed actions, monetary limits, geo restrictions, deny lists).<p>Kill switch with zero propagation delay \u2014 Revoke any agent globally. The revocation mesh pushes via SSE/WebSocket to all connected deployments simultaneously.<p>What's shipped:<p>Python SDK: pip install aip-protocol (MIT, 63 tests passing)\nCLI: aip init, aip create-passport, aip verify, aip watch\nShield decorator: @shield \u2014 helmet.js but for AI <em>agents</em>\nCloud dashboard: aip.synthexai.tech (free tier)\nProtocol spec: RFC-001\nWhat's NOT shipped yet:<p>TypeScript SDK (built, 31/31 conformance tests, not published)\nFramework adapters (CrewAI, LangChain, AutoGen \u2014 built, not open-sourced yet)\nFormal security audit\nGitHub: <a href=\"https://github.com/theaniketgiri/aip\" rel=\"nofollow\">https://github.com/theaniketgiri/aip</a>\nPyPI: <a href=\"https://pypi.org/project/aip-protocol/\" rel=\"nofollow\">https://pypi.org/project/aip-protocol/</a>\nLive dashboard: <a href=\"https://aip.synthexai.tech\" rel=\"nofollow\">https://aip.synthexai.tech</a>\nProtocol spec: RFC-001 in repo<p>I'm genuinely interested in pushback on the protocol design. Is Ed25519 overkill for agent auth? Should boundary enforcement be declarative or imperative? Is DID-based identity the right addressing model, or is there something simpler?<p>Happy to answer any questions about the implementation."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agents"],"value":"Show HN: AIP \u2013 An open protocol for verifying what AI <em>agents</em> are allowed to do"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/theaniketgiri/aip"}},"_tags":["story","author_theaniketgiri","story_47050216","show_hn"],"author":"theaniketgiri","children":[47050274],"created_at":"2026-02-17T17:29:17Z","created_at_i":1771349357,"num_comments":2,"objectID":"47050216","points":1,"story_id":47050216,"story_text":"Hey HN,<p>I&#x27;ve been building AIP (Agent Intent Protocol) \u2014 an open, cryptographic protocol for identity and authorization of autonomous AI agents.<p>The problem: Every AI agent framework (LangChain, CrewAI, AutoGen) gives agents the ability to act \u2014 call APIs, send emails, move money, access databases. But there&#x27;s no standard way to verify what an agent is allowed to do before it does it. No identity system, no boundary enforcement, no kill switch. We give agents god-mode access and hope the prompt engineering holds.<p>What AIP does: It&#x27;s a verification layer that sits between &quot;agent wants to act&quot; and &quot;action executes.&quot; Every agent gets an Ed25519 keypair identity (DID-based), every action becomes a signed Intent Envelope, and every envelope passes through an 8-step verification pipeline before the action runs.<p># One line. Every call verified before execution.\n@shield(actions=[&quot;transfer_funds&quot;], limit=100.0)\ndef send_payment(to: str, amount: float):\n    bank.transfer(to, amount)<p>Key design decisions (happy to be challenged on these):<p>Ed25519 over JWT&#x2F;API keys \u2014 Agents need cryptographic identity, not bearer tokens. A token can be leaked; a private key signs intent with non-repudiation.<p>Tiered verification \u2014 Not every action needs full crypto. Low-risk cached calls verify in &lt;1ms (HMAC), normal ops ~5ms (Ed25519), high-value cross-org ~50ms (full pipeline). The protocol auto-selects.<p>22 structured error codes \u2014 Every failure returns AIP-E{category}{code} (e.g., AIP-E202: MONETARY_LIMIT). Audit trails should say exactly what went wrong, not 403 Forbidden.<p>Boundary enforcement, not permission prompts \u2014 Agents don&#x27;t ask &quot;can I do this?&quot; \u2014 they declare intent, and the verifier mathematically checks it against their boundary cage (allowed actions, monetary limits, geo restrictions, deny lists).<p>Kill switch with zero propagation delay \u2014 Revoke any agent globally. The revocation mesh pushes via SSE&#x2F;WebSocket to all connected deployments simultaneously.<p>What&#x27;s shipped:<p>Python SDK: pip install aip-protocol (MIT, 63 tests passing)\nCLI: aip init, aip create-passport, aip verify, aip watch\nShield decorator: @shield \u2014 helmet.js but for AI agents\nCloud dashboard: aip.synthexai.tech (free tier)\nProtocol spec: RFC-001\nWhat&#x27;s NOT shipped yet:<p>TypeScript SDK (built, 31&#x2F;31 conformance tests, not published)\nFramework adapters (CrewAI, LangChain, AutoGen \u2014 built, not open-sourced yet)\nFormal security audit\nGitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;theaniketgiri&#x2F;aip\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;theaniketgiri&#x2F;aip</a>\nPyPI: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;aip-protocol&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;aip-protocol&#x2F;</a>\nLive dashboard: <a href=\"https:&#x2F;&#x2F;aip.synthexai.tech\" rel=\"nofollow\">https:&#x2F;&#x2F;aip.synthexai.tech</a>\nProtocol spec: RFC-001 in repo<p>I&#x27;m genuinely interested in pushback on the protocol design. Is Ed25519 overkill for agent auth? Should boundary enforcement be declarative or imperative? Is DID-based identity the right addressing model, or is there something simpler?<p>Happy to answer any questions about the implementation.","title":"Show HN: AIP \u2013 An open protocol for verifying what AI agents are allowed to do","updated_at":"2026-02-17T18:24:03Z","url":"https://github.com/theaniketgiri/aip"}],"hitsPerPage":10,"nbHits":684,"nbPages":69,"page":0,"params":"query=autonomous+agents&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":20,"processingTimingsMS":{"_request":{"roundTrip":15},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":9,"scanning":9,"total":19},"total":20},"query":"autonomous agents","serverTimeMS":22}
