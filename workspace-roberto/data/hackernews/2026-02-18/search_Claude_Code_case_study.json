{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"boundedreason"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"What this is:<p>Copy-paste LLM prompts that turn ChatGPT or <em>Claude</em> into a structured decision analyst for laptops, monitors, tablets, phones, and SaaS subscriptions. You define constraints, weight what matters to your workflow, and get scored recommendations with sensitivity analysis.\nWhy I built this:<p>With the rise of LLMs (AI), I wanted to find a way to harness the computing power and ease of use the chat interface provides.  The major problem: LLMs don\u2019t always provide repeatable, traceable results if you ask the same question twice or even against 2 competing products. That is the dilemma this product aims to solve.  Is this a PDF, yes, but it harnesses my systems analysis experience to help hard-<em>code</em> a framework for a person off the street to turn their AI chat box into an objective decision-helper in just 15 to 20 minutes of use.<p>I spent 10+ years applying decision science in defense and systems analysis\u2014graduate work at Naval Postgraduate School, leading teams through decisions where the cost of choosing wrong wasn't just money; it was mission failure or lives at risk.<p>The method used uses multi-attribute utility theory: define hard constraints (binary gates), eliminate non-viable options, score remaining candidates on mission-critical attributes with explicit weights, then run sensitivity analysis to see what changes the outcome.<p>I use this myself all the time.  The most recent was trying to upgrade my own laptop (Surface Pro stuck at Windows 10).<p>BLUF benefits:<p>\u2022 Helps prevent over-obsessing over specs (32GB RAM! RTX 4080!) while ignoring mission fit (do I really game that often?)<p>\u2022 Fleshes out hard constraints that sometimes come up until after purchase (bought Windows laptop, needs a way to support a MacOS app)<p>\u2022 Future-proofing: ensuring I won\u2019t pay feature I'll statistically never use<p>\u2022 Aims to parse through the noise (SEO type posts) and get you a great first-pass research report of what you should value and why.<p>Consumer purchases don't need full enterprise rigor, but they deserve better than &quot;Top 10 Laptops 2026&quot; affiliate listicles or chatbots hallucinating specs.<p>How the framework works:\n1. Mission definition: What must work reliably? (Video editing vs office work vs travel)<p>2. Hard constraints: Binary gates (budget ceiling, OS requirements, battery minimums)<p>3. Candidate generation: AI searches current market without SEO or affiliate bias<p>4. Weighted scoring: Performance, battery, reliability, portability\u2014you control the weights<p>5. Efficient frontier: Which options dominate? Which are just expensive?<p>6. Sensitivity analysis: &quot;If battery life matters 25% instead of 15%, MacBook Air wins. If reliability matters more, ThinkPad wins.&quot;<p>The PDFs include example <em>case</em> <em>studies</em> I\u2019ve developed: policy analyst choosing ThinkPad X1 Carbon over MacBook Air (why reliability and docking beat battery life for enterprise work), freelance designer choosing Figma over Affinity Designer (why collaboration features justified 6x higher cost), consultant choosing Obsidian over Notion (why offline-first beat ease-of-use).<p>No barriers: No sign-up. No account. You get a PDF with prompts and <em>case</em> <em>studies</em>. Open ChatGPT or <em>Claude</em> (free version works), paste the prompt, answer questions. That's it.<p>I built this because I was tired of seeing people (and myself) wasting money on impressive-sounding specs that don't match their actual workflow. If you've ever regretted a tech purchase 3 weeks later, this might help.<p>Try it (I'd offer it free but then I loose my IP):\n\u2022 Tech &amp; Electronics: <a href=\"https://decisioncontrolworks.gumroad.com/l/auzhsa\" rel=\"nofollow\">https://decisioncontrolworks.gumroad.com/l/auzhsa</a>\n\u2022 Software &amp; Subscriptions: <a href=\"https://decisioncontrolworks.gumroad.com/l/zaucxt\" rel=\"nofollow\">https://decisioncontrolworks.gumroad.com/l/zaucxt</a><p>Curious what HN thinks\u2014especially if anyone's tried applying formal decision methods to everyday purchases."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Multi-attribute decision frameworks for tech purchases"}},"_tags":["story","author_boundedreason","story_46955606","show_hn"],"author":"boundedreason","children":[47015070,46975995],"created_at":"2026-02-10T05:01:51Z","created_at_i":1770699711,"num_comments":4,"objectID":"46955606","points":1,"story_id":46955606,"story_text":"What this is:<p>Copy-paste LLM prompts that turn ChatGPT or Claude into a structured decision analyst for laptops, monitors, tablets, phones, and SaaS subscriptions. You define constraints, weight what matters to your workflow, and get scored recommendations with sensitivity analysis.\nWhy I built this:<p>With the rise of LLMs (AI), I wanted to find a way to harness the computing power and ease of use the chat interface provides.  The major problem: LLMs don\u2019t always provide repeatable, traceable results if you ask the same question twice or even against 2 competing products. That is the dilemma this product aims to solve.  Is this a PDF, yes, but it harnesses my systems analysis experience to help hard-code a framework for a person off the street to turn their AI chat box into an objective decision-helper in just 15 to 20 minutes of use.<p>I spent 10+ years applying decision science in defense and systems analysis\u2014graduate work at Naval Postgraduate School, leading teams through decisions where the cost of choosing wrong wasn&#x27;t just money; it was mission failure or lives at risk.<p>The method used uses multi-attribute utility theory: define hard constraints (binary gates), eliminate non-viable options, score remaining candidates on mission-critical attributes with explicit weights, then run sensitivity analysis to see what changes the outcome.<p>I use this myself all the time.  The most recent was trying to upgrade my own laptop (Surface Pro stuck at Windows 10).<p>BLUF benefits:<p>\u2022 Helps prevent over-obsessing over specs (32GB RAM! RTX 4080!) while ignoring mission fit (do I really game that often?)<p>\u2022 Fleshes out hard constraints that sometimes come up until after purchase (bought Windows laptop, needs a way to support a MacOS app)<p>\u2022 Future-proofing: ensuring I won\u2019t pay feature I&#x27;ll statistically never use<p>\u2022 Aims to parse through the noise (SEO type posts) and get you a great first-pass research report of what you should value and why.<p>Consumer purchases don&#x27;t need full enterprise rigor, but they deserve better than &quot;Top 10 Laptops 2026&quot; affiliate listicles or chatbots hallucinating specs.<p>How the framework works:\n1. Mission definition: What must work reliably? (Video editing vs office work vs travel)<p>2. Hard constraints: Binary gates (budget ceiling, OS requirements, battery minimums)<p>3. Candidate generation: AI searches current market without SEO or affiliate bias<p>4. Weighted scoring: Performance, battery, reliability, portability\u2014you control the weights<p>5. Efficient frontier: Which options dominate? Which are just expensive?<p>6. Sensitivity analysis: &quot;If battery life matters 25% instead of 15%, MacBook Air wins. If reliability matters more, ThinkPad wins.&quot;<p>The PDFs include example case studies I\u2019ve developed: policy analyst choosing ThinkPad X1 Carbon over MacBook Air (why reliability and docking beat battery life for enterprise work), freelance designer choosing Figma over Affinity Designer (why collaboration features justified 6x higher cost), consultant choosing Obsidian over Notion (why offline-first beat ease-of-use).<p>No barriers: No sign-up. No account. You get a PDF with prompts and case studies. Open ChatGPT or Claude (free version works), paste the prompt, answer questions. That&#x27;s it.<p>I built this because I was tired of seeing people (and myself) wasting money on impressive-sounding specs that don&#x27;t match their actual workflow. If you&#x27;ve ever regretted a tech purchase 3 weeks later, this might help.<p>Try it (I&#x27;d offer it free but then I loose my IP):\n\u2022 Tech &amp; Electronics: <a href=\"https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;auzhsa\" rel=\"nofollow\">https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;auzhsa</a>\n\u2022 Software &amp; Subscriptions: <a href=\"https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;zaucxt\" rel=\"nofollow\">https:&#x2F;&#x2F;decisioncontrolworks.gumroad.com&#x2F;l&#x2F;zaucxt</a><p>Curious what HN thinks\u2014especially if anyone&#x27;s tried applying formal decision methods to everyday purchases.","title":"Show HN: Multi-attribute decision frameworks for tech purchases","updated_at":"2026-02-16T20:35:00Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"idopmstuff"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"Trading My Vibe Coded App for an AI Analyst: A <em>Claude</em> <em>Code</em> <em>Case</em> <em>Study</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://theautomatedoperator.substack.com/p/trading-my-vibe-coded-app-for-an"}},"_tags":["story","author_idopmstuff","story_46810493"],"author":"idopmstuff","created_at":"2026-01-29T14:16:55Z","created_at_i":1769696215,"num_comments":0,"objectID":"46810493","points":1,"story_id":46810493,"title":"Trading My Vibe Coded App for an AI Analyst: A Claude Code Case Study","updated_at":"2026-01-29T14:21:38Z","url":"https://theautomatedoperator.substack.com/p/trading-my-vibe-coded-app-for-an"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Bayram"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude","code"],"value":"<em>Claude</em> <em>Code</em> Swarm Mode Deep Dive: 10 agents building macOS app"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["case","study"],"value":"https://github.com/BayramAnnakov/edu-ai-product-engineer-s3/tree/main/<em>case</em>_<em>studies</em>/claudesp-swarm-deep-dive"}},"_tags":["story","author_Bayram","story_46754914"],"author":"Bayram","children":[46754915],"created_at":"2026-01-25T15:31:48Z","created_at_i":1769355108,"num_comments":1,"objectID":"46754914","points":1,"story_id":46754914,"title":"Claude Code Swarm Mode Deep Dive: 10 agents building macOS app","updated_at":"2026-01-25T15:36:51Z","url":"https://github.com/BayramAnnakov/edu-ai-product-engineer-s3/tree/main/case_studies/claudesp-swarm-deep-dive"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"pj4533"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"From Zero to Rain: A <em>Claude</em> <em>Code</em> <em>Case</em> <em>Study</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://pj4533.com/sigh/"}},"_tags":["story","author_pj4533","story_46455311"],"author":"pj4533","children":[46455312],"created_at":"2026-01-01T16:26:02Z","created_at_i":1767284762,"num_comments":1,"objectID":"46455311","points":3,"story_id":46455311,"title":"From Zero to Rain: A Claude Code Case Study","updated_at":"2026-01-02T05:21:25Z","url":"https://pj4533.com/sigh/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"heavyarms"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"I've been using <em>Claude</em> <em>Code</em> since the early beta days and, since the 4.5 Sonnet release, it's changed my workflow a lot. At least in my view, the current iteration of frontier coding agents are good enough to automate a lot of rote software development tasks and are worth the money... if put in the hands of capable developers who know how to use them. But giving unrestricted access to all of your developers to something like <em>Claude</em> <em>Code</em> is also signing yourself up for huge variability in OpEx budgets.<p>I understand the current hardware limitations and that you can't just put a frontier LLM in a black box and hook it up to your existing MBP via USB-C. In my estimation, something like a Apple Mac <em>Stud</em>io M3 (256gb or more of unified memory) is maybe one possible option ($7,500 - $10,000) for running a 405b open weights model... but it wouldn't be very fast. And it wouldn't come close to the level of quality or workflow of <em>Claude</em> <em>Code</em>.<p>To really run a current frontier LLM locally with something like &gt;30 tokens per second would probably require four A100s.. add in NVLink bridges, expensive cooling, 256GB RAM, a cool <em>case</em> with LED lights (optional) and we're talking about ~$60,000? $80,000?<p>So my question is: How many generations\u2014or what specific architectural shifts (specialized ASICs, better quantization, etc.)\u2014do we need before we can buy a dedicated co-processor box that sits on a desk and runs a Sonnet-level agent at viable speeds... at a price point where it makes sense vs. spending $500-$2,000 per month per developer on API fees? In my opinion that &quot;makes sense to me, here's the credit card&quot; price point might be $10,000 right now, but I could be wrong.<p>And related question: Who will do this? Anthropic could probably make a killing right now IF they had could sell &quot;<em>Claude</em> <em>Code</em> in a box for $10,000&quot; but would they ever want to? It would be cannibalizing the majority of their business. But Apple might do this. And it might only be one or two generations of hardware upgrades away. They just need the &quot;frontier LLM&quot; to stick into the box."},"title":{"matchLevel":"none","matchedWords":[],"value":"Ask HN: How long before we get \"coding agent in a box\"?"}},"_tags":["story","author_heavyarms","story_46356220","ask_hn"],"author":"heavyarms","children":[46356456,46360555,46356354],"created_at":"2025-12-22T17:22:12Z","created_at_i":1766424132,"num_comments":3,"objectID":"46356220","points":2,"story_id":46356220,"story_text":"I&#x27;ve been using Claude Code since the early beta days and, since the 4.5 Sonnet release, it&#x27;s changed my workflow a lot. At least in my view, the current iteration of frontier coding agents are good enough to automate a lot of rote software development tasks and are worth the money... if put in the hands of capable developers who know how to use them. But giving unrestricted access to all of your developers to something like Claude Code is also signing yourself up for huge variability in OpEx budgets.<p>I understand the current hardware limitations and that you can&#x27;t just put a frontier LLM in a black box and hook it up to your existing MBP via USB-C. In my estimation, something like a Apple Mac Studio M3 (256gb or more of unified memory) is maybe one possible option ($7,500 - $10,000) for running a 405b open weights model... but it wouldn&#x27;t be very fast. And it wouldn&#x27;t come close to the level of quality or workflow of Claude Code.<p>To really run a current frontier LLM locally with something like &gt;30 tokens per second would probably require four A100s.. add in NVLink bridges, expensive cooling, 256GB RAM, a cool case with LED lights (optional) and we&#x27;re talking about ~$60,000? $80,000?<p>So my question is: How many generations\u2014or what specific architectural shifts (specialized ASICs, better quantization, etc.)\u2014do we need before we can buy a dedicated co-processor box that sits on a desk and runs a Sonnet-level agent at viable speeds... at a price point where it makes sense vs. spending $500-$2,000 per month per developer on API fees? In my opinion that &quot;makes sense to me, here&#x27;s the credit card&quot; price point might be $10,000 right now, but I could be wrong.<p>And related question: Who will do this? Anthropic could probably make a killing right now IF they had could sell &quot;Claude Code in a box for $10,000&quot; but would they ever want to? It would be cannibalizing the majority of their business. But Apple might do this. And it might only be one or two generations of hardware upgrades away. They just need the &quot;frontier LLM&quot; to stick into the box.","title":"Ask HN: How long before we get \"coding agent in a box\"?","updated_at":"2026-02-08T08:41:57Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"eng_ask"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"Hello,<p>I'm a Computer Engineering student, this is something I've been asking around because I want to make sure I am doing a right choice before changing. To be clear, I don't dislike programming at all, but I\u2019ve been grappling with a worry that is killing my motivation to continue learning to a deeper level of it.<p>Now, I know my fair share of C/C++ and can handle intermediate concepts like pointers and memory management. However, I no longer have the drive to manually <em>code</em> entire projects from scratch.<p>Recently, faculty at my school have been discussing how AI is shifting the programmer's role from an architect and builder to just architect, where the AI becomes the builder. I already have seen people showing this here. For example, someone I know recently constructed a basic Operating System (kernel/userspace separation, scheduler, POSIX like syscalls, etc.) by guiding <em>Claude</em> to <em>code</em> it based on the OS theory that he has being <em>study</em>ing himself. The fact that a student could pull that off with or AI assistance is impressive, but it also makes me wonder the following.<p>What is the point of me grinding to build/learn to build full blown programs manually if I can guide an AI to do it for me, provided I know the fundamentals? This has really led me to consider changing my major to either another engineering major that is more &quot;real world&quot; focused, or going to <em>study</em> a double major in physics/chem.<p>I love building things. The thing is I don't see why teach myself <em>code</em> beyond this, just so that in the end, by 2030 what means being a software engineer already changed. It is happening already as far as I can see.<p>Now, I am not trying to say that AI will replace developers entirely, or that computer related majors are dead or anything, but for example, with Meta starting to do changes to their interviews, and other companies following after them, the role of what these used to be is shifting fast.<p>What we call &quot;AI&quot; has only been mainstream for about 3 years and is already at this level. By the time I graduate in another 3 years, tools might be able to handle hallucinations and edge <em>cases</em> much better. AI is not a thinking things, in the end is somewhat of a predictor, which can get better as time goes on.<p>Anyway these are the things that are in my mind. I really would like advice of people that are actually in the industry or in research to tell me what they think, thank you."},"title":{"matchLevel":"none","matchedWords":[],"value":"Ask HN: I feel like I've lost my motivation to continue learning programming"}},"_tags":["story","author_eng_ask","story_46049631","ask_hn"],"author":"eng_ask","children":[46054166,46052019,46053374],"created_at":"2025-11-25T19:23:56Z","created_at_i":1764098636,"num_comments":4,"objectID":"46049631","points":4,"story_id":46049631,"story_text":"Hello,<p>I&#x27;m a Computer Engineering student, this is something I&#x27;ve been asking around because I want to make sure I am doing a right choice before changing. To be clear, I don&#x27;t dislike programming at all, but I\u2019ve been grappling with a worry that is killing my motivation to continue learning to a deeper level of it.<p>Now, I know my fair share of C&#x2F;C++ and can handle intermediate concepts like pointers and memory management. However, I no longer have the drive to manually code entire projects from scratch.<p>Recently, faculty at my school have been discussing how AI is shifting the programmer&#x27;s role from an architect and builder to just architect, where the AI becomes the builder. I already have seen people showing this here. For example, someone I know recently constructed a basic Operating System (kernel&#x2F;userspace separation, scheduler, POSIX like syscalls, etc.) by guiding Claude to code it based on the OS theory that he has being studying himself. The fact that a student could pull that off with or AI assistance is impressive, but it also makes me wonder the following.<p>What is the point of me grinding to build&#x2F;learn to build full blown programs manually if I can guide an AI to do it for me, provided I know the fundamentals? This has really led me to consider changing my major to either another engineering major that is more &quot;real world&quot; focused, or going to study a double major in physics&#x2F;chem.<p>I love building things. The thing is I don&#x27;t see why teach myself code beyond this, just so that in the end, by 2030 what means being a software engineer already changed. It is happening already as far as I can see.<p>Now, I am not trying to say that AI will replace developers entirely, or that computer related majors are dead or anything, but for example, with Meta starting to do changes to their interviews, and other companies following after them, the role of what these used to be is shifting fast.<p>What we call &quot;AI&quot; has only been mainstream for about 3 years and is already at this level. By the time I graduate in another 3 years, tools might be able to handle hallucinations and edge cases much better. AI is not a thinking things, in the end is somewhat of a predictor, which can get better as time goes on.<p>Anyway these are the things that are in my mind. I really would like advice of people that are actually in the industry or in research to tell me what they think, thank you.","title":"Ask HN: I feel like I've lost my motivation to continue learning programming","updated_at":"2026-01-13T05:20:48Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"sushanttripathy"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"We developed this solution after a B2B client ran into issues deploying production AI agents to speed up their customers\u2019 onboarding.<p>Their UX: a customer enters their company homepage URL, and the agent autofills key fields (logo URL, <em>case</em> <em>study</em> URLs, etc.) to reduce manual form-filling and drop-offs.<p>The first version used ChatGPT and <em>Claude</em> in a relatively simple agent workflow. Once they started correcting frequent mistakes in critical fields (especially company logo URL and <em>case</em> <em>study</em> URLs), the system got more complex:\n \u2022 de novo crawling of the homepage URL\n \u2022 cross-checking every LLM response\n \u2022 multiple LLM calls per onboarding<p>Tokens per API call skyrocketed, pushing costs to about $0.80\u2013$2.00 per call at ~1,000 queries/day, which wasn\u2019t sustainable.<p>Our solution uses a combination of smaller language models running locally that consume outputs from pre-validated <em>code</em> snippets (for extracting URLs and other company details). A \u201creasoning\u201d LLM selects which snippets to run at inference time based on the homepage content. This keeps most of the heavy lifting in deterministic <em>code</em>, with the LLM mainly orchestrating.<p>On a small initial test set of 30 URLs from the client, we returned accurate field values for 27/30. The workflow is noticeably faster end-to-end, and we charge a flat $0.25 per call (including crawling + extraction).\nThe agentic workflow is exposed via a WebSocket interface (JSON in/out). You can see it in action here, along with a free tester API key in the notebook:\n Google Colab: <a href=\"https://colab.research.google.com/drive/1AkLpL6IQoMDt6-aJwhTGfXZOCQbshryN#scrollTo=EoZUbLZZyOyp\" rel=\"nofollow\">https://colab.research.google.com/drive/1AkLpL6IQoMDt6-aJwhT...</a><p>I\u2019d love feedback, especially on:\n \u2022 obvious failure modes we\u2019re not accounting for\n \u2022 fields you\u2019d expect beyond those in the colab\n \u2022 whether per-call pricing vs. per-token pricing makes sense\nIf you want to try this in your own onboarding stack or have ideas for features, you can reach us at contactus@skymel.com."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN:Cheaper Agentic API for Company Info from homepage (0.25$/call)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://colab.research.google.com/drive/1AkLpL6IQoMDt6-aJwhTGfXZOCQbshryN#scrollTo=EoZUbLZZyOyp"}},"_tags":["story","author_sushanttripathy","story_45806279","show_hn"],"author":"sushanttripathy","created_at":"2025-11-04T00:41:24Z","created_at_i":1762216884,"num_comments":0,"objectID":"45806279","points":3,"story_id":45806279,"story_text":"We developed this solution after a B2B client ran into issues deploying production AI agents to speed up their customers\u2019 onboarding.<p>Their UX: a customer enters their company homepage URL, and the agent autofills key fields (logo URL, case study URLs, etc.) to reduce manual form-filling and drop-offs.<p>The first version used ChatGPT and Claude in a relatively simple agent workflow. Once they started correcting frequent mistakes in critical fields (especially company logo URL and case study URLs), the system got more complex:\n \u2022 de novo crawling of the homepage URL\n \u2022 cross-checking every LLM response\n \u2022 multiple LLM calls per onboarding<p>Tokens per API call skyrocketed, pushing costs to about $0.80\u2013$2.00 per call at ~1,000 queries&#x2F;day, which wasn\u2019t sustainable.<p>Our solution uses a combination of smaller language models running locally that consume outputs from pre-validated code snippets (for extracting URLs and other company details). A \u201creasoning\u201d LLM selects which snippets to run at inference time based on the homepage content. This keeps most of the heavy lifting in deterministic code, with the LLM mainly orchestrating.<p>On a small initial test set of 30 URLs from the client, we returned accurate field values for 27&#x2F;30. The workflow is noticeably faster end-to-end, and we charge a flat $0.25 per call (including crawling + extraction).\nThe agentic workflow is exposed via a WebSocket interface (JSON in&#x2F;out). You can see it in action here, along with a free tester API key in the notebook:\n Google Colab: <a href=\"https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1AkLpL6IQoMDt6-aJwhTGfXZOCQbshryN#scrollTo=EoZUbLZZyOyp\" rel=\"nofollow\">https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1AkLpL6IQoMDt6-aJwhT...</a><p>I\u2019d love feedback, especially on:\n \u2022 obvious failure modes we\u2019re not accounting for\n \u2022 fields you\u2019d expect beyond those in the colab\n \u2022 whether per-call pricing vs. per-token pricing makes sense\nIf you want to try this in your own onboarding stack or have ideas for features, you can reach us at contactus@skymel.com.","title":"Show HN:Cheaper Agentic API for Company Info from homepage (0.25$/call)","updated_at":"2025-11-04T01:32:41Z","url":"https://colab.research.google.com/drive/1AkLpL6IQoMDt6-aJwhTGfXZOCQbshryN#scrollTo=EoZUbLZZyOyp"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"PdV"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"Hey HN :)<p>I'm Andrzej, 15 years building distributed systems. Over the past two years, I watched AI change everything about how we work as developers \u2013 and most of the discourse was either panic or hype.\nSo I spent that time researching what actually works.<p>The result: &quot;The New Rules&quot; \u2013 16 chapters on navigating the AI era as a developer. Accompanied by a website to help us all get more in-depth into the discussion.<p>Some of the controversial takes inside:\n* GitHub stars became meaningless vanity metrics \u2013 so how do we quick-filter for quality?\n* Skills that got you to $100K won't get you to $200K (the career ladder just shifted)\n* Small teams with AI will crush large teams without it\n* Your moat isn't <em>code</em> quality anymore \u2013 it's judgment, architecture, and trust<p>I've created this book with heavy AI assistance (<em>Claude</em> and ChatGPT) \u2013 proud of the outcome, my learning and the effort it took to get quality content through the full pipeline...<p>Note that some examples and <em>case</em> <em>studies</em> are illustrative, combining real insights with fictional elements to better convey concepts. I've checked what I could, but I'm sure there's room for further improvement. \nIts not a scientific publication, but rather in-depth share of my perspective on changes happening in these interesting times.<p>Licensed under CC BY 4.0 \u2013 free to share, adapt, even use commercially with attribution.\nHardcover available for $39 if you want the physical version (shipping from Poland).<p>I'm here all day for discussion, pushback, corrections, and hearing about your experiences. If you spot inaccuracies in the examples or have better <em>case</em> <em>studies</em>, I'd love to hear them.<p>Direct PDF download: <a href=\"https://pub-7a9dcf4135624a49ac92e46823c312c1.r2.dev/TheNewRules-FirstEdition-2025.pdf\" rel=\"nofollow\">https://pub-7a9dcf4135624a49ac92e46823c312c1.r2.dev/TheNewRu...</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: The New Rules \u2013 Developer's survival guide for the AI era"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.thenewrules.ai/"}},"_tags":["story","author_PdV","story_45734637","show_hn"],"author":"PdV","children":[45740663],"created_at":"2025-10-28T16:02:28Z","created_at_i":1761667348,"num_comments":2,"objectID":"45734637","points":4,"story_id":45734637,"story_text":"Hey HN :)<p>I&#x27;m Andrzej, 15 years building distributed systems. Over the past two years, I watched AI change everything about how we work as developers \u2013 and most of the discourse was either panic or hype.\nSo I spent that time researching what actually works.<p>The result: &quot;The New Rules&quot; \u2013 16 chapters on navigating the AI era as a developer. Accompanied by a website to help us all get more in-depth into the discussion.<p>Some of the controversial takes inside:\n* GitHub stars became meaningless vanity metrics \u2013 so how do we quick-filter for quality?\n* Skills that got you to $100K won&#x27;t get you to $200K (the career ladder just shifted)\n* Small teams with AI will crush large teams without it\n* Your moat isn&#x27;t code quality anymore \u2013 it&#x27;s judgment, architecture, and trust<p>I&#x27;ve created this book with heavy AI assistance (Claude and ChatGPT) \u2013 proud of the outcome, my learning and the effort it took to get quality content through the full pipeline...<p>Note that some examples and case studies are illustrative, combining real insights with fictional elements to better convey concepts. I&#x27;ve checked what I could, but I&#x27;m sure there&#x27;s room for further improvement. \nIts not a scientific publication, but rather in-depth share of my perspective on changes happening in these interesting times.<p>Licensed under CC BY 4.0 \u2013 free to share, adapt, even use commercially with attribution.\nHardcover available for $39 if you want the physical version (shipping from Poland).<p>I&#x27;m here all day for discussion, pushback, corrections, and hearing about your experiences. If you spot inaccuracies in the examples or have better case studies, I&#x27;d love to hear them.<p>Direct PDF download: <a href=\"https:&#x2F;&#x2F;pub-7a9dcf4135624a49ac92e46823c312c1.r2.dev&#x2F;TheNewRules-FirstEdition-2025.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;pub-7a9dcf4135624a49ac92e46823c312c1.r2.dev&#x2F;TheNewRu...</a>","title":"Show HN: The New Rules \u2013 Developer's survival guide for the AI era","updated_at":"2025-10-28T23:51:50Z","url":"https://www.thenewrules.ai/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"sanketsaurav"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"Hey HN! We're the team behind Autofix Bot (YC W20's DeepSource)[1]. We're open-sourcing Narada (<a href=\"https://huggingface.co/deepsource/Narada-3.2-3B-v1\" rel=\"nofollow\">https://huggingface.co/deepsource/Narada-3.2-3B-v1</a>), a fine-tuned Llama3.2-3B-Instruct model that dramatically reduces false positives in secrets detection tools. The model achieves 97% precision with 96% recall on our evaluation set. It's fast enough for CI/CD (3B parameters), works with any regex-based tool, and is MIT-licensed.<p>Traditional regex-based secrets scanners (Gitleaks, TruffleHog, detect-secrets) face a fundamental tradeoff: crank up sensitivity and drown in false positives flagging things like &quot;YOUR_API_KEY_HERE&quot;, or tune it down and miss real credentials. We kept hearing from security teams that they couldn't trust their scanning tools because of the noise \u2013 developers would just ignore the alerts.<p>Regex is great at fast pattern matching, but terrible at understanding context. So instead of trying to make regex smarter, we built a hybrid system: regex does the initial high-recall sweep, then a fine-tuned 3B model filters out false positives by actually understanding the <em>code</em> context.<p>Technical approach:\n- Started with teacher-<em>stud</em>ent architecture using DeepSeek R1 as teacher\n- Curated ~8K diverse secrets from Samsung's CredData dataset, relabeled for consistency\n- Generated synthetic edge <em>cases</em> using Gemini 2.5 Pro and <em>Claude</em> Sonnet 4\n- Fine-tuned on ~900 examples with deterministic outputs (not chain-of-thought)<p>Integration is straightforward \u2013 run your existing regex tool, feed candidates to Narada with \u00b120 lines of context, get structured JSON output with true/false positive classification and reasoning.<p>We built this as part of Autofix Bot's secrets detection agent, and it outperformed static-only tools significantly in our benchmarks [2]. Figured the security community would benefit from having this available as an open-source building block. Would love to hear your feedback and learn what other edge <em>cases</em> you encounter.<p>[1] <a href=\"https://autofix.bot\" rel=\"nofollow\">https://autofix.bot</a><p>[2] <a href=\"https://autofix.bot/benchmarks#benchmarks-secrets-detection\" rel=\"nofollow\">https://autofix.bot/benchmarks#benchmarks-secrets-detection</a><p>[3] <a href=\"https://autofix.bot/news/narada-secrets-detection-classification\" rel=\"nofollow\">https://autofix.bot/news/narada-secrets-detection-classifica...</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Narada \u2013 Open-source secrets classification model"}},"_tags":["story","author_sanketsaurav","story_45569942","show_hn"],"author":"sanketsaurav","children":[45662710],"created_at":"2025-10-13T16:07:09Z","created_at_i":1760371629,"num_comments":2,"objectID":"45569942","points":6,"story_id":45569942,"story_text":"Hey HN! We&#x27;re the team behind Autofix Bot (YC W20&#x27;s DeepSource)[1]. We&#x27;re open-sourcing Narada (<a href=\"https:&#x2F;&#x2F;huggingface.co&#x2F;deepsource&#x2F;Narada-3.2-3B-v1\" rel=\"nofollow\">https:&#x2F;&#x2F;huggingface.co&#x2F;deepsource&#x2F;Narada-3.2-3B-v1</a>), a fine-tuned Llama3.2-3B-Instruct model that dramatically reduces false positives in secrets detection tools. The model achieves 97% precision with 96% recall on our evaluation set. It&#x27;s fast enough for CI&#x2F;CD (3B parameters), works with any regex-based tool, and is MIT-licensed.<p>Traditional regex-based secrets scanners (Gitleaks, TruffleHog, detect-secrets) face a fundamental tradeoff: crank up sensitivity and drown in false positives flagging things like &quot;YOUR_API_KEY_HERE&quot;, or tune it down and miss real credentials. We kept hearing from security teams that they couldn&#x27;t trust their scanning tools because of the noise \u2013 developers would just ignore the alerts.<p>Regex is great at fast pattern matching, but terrible at understanding context. So instead of trying to make regex smarter, we built a hybrid system: regex does the initial high-recall sweep, then a fine-tuned 3B model filters out false positives by actually understanding the code context.<p>Technical approach:\n- Started with teacher-student architecture using DeepSeek R1 as teacher\n- Curated ~8K diverse secrets from Samsung&#x27;s CredData dataset, relabeled for consistency\n- Generated synthetic edge cases using Gemini 2.5 Pro and Claude Sonnet 4\n- Fine-tuned on ~900 examples with deterministic outputs (not chain-of-thought)<p>Integration is straightforward \u2013 run your existing regex tool, feed candidates to Narada with \u00b120 lines of context, get structured JSON output with true&#x2F;false positive classification and reasoning.<p>We built this as part of Autofix Bot&#x27;s secrets detection agent, and it outperformed static-only tools significantly in our benchmarks [2]. Figured the security community would benefit from having this available as an open-source building block. Would love to hear your feedback and learn what other edge cases you encounter.<p>[1] <a href=\"https:&#x2F;&#x2F;autofix.bot\" rel=\"nofollow\">https:&#x2F;&#x2F;autofix.bot</a><p>[2] <a href=\"https:&#x2F;&#x2F;autofix.bot&#x2F;benchmarks#benchmarks-secrets-detection\" rel=\"nofollow\">https:&#x2F;&#x2F;autofix.bot&#x2F;benchmarks#benchmarks-secrets-detection</a><p>[3] <a href=\"https:&#x2F;&#x2F;autofix.bot&#x2F;news&#x2F;narada-secrets-detection-classification\" rel=\"nofollow\">https:&#x2F;&#x2F;autofix.bot&#x2F;news&#x2F;narada-secrets-detection-classifica...</a>","title":"Show HN: Narada \u2013 Open-source secrets classification model","updated_at":"2025-12-06T16:54:27Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ljw1004"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["claude","code","case","study"],"value":"The magic in AI coding assistants isn't the <em>code</em> -- it's the prompts.<p>I studied the externally observable behavior of <em>Claude</em> <em>Code</em> and recreated it from scratch in Python with the exact same behaviors. It works with any model -- OpenAI, Gemini, <em>Claude</em>. What's surprising:<p>1. You can keep the core agent really simple, just 280 lines of Python. As long as it supports hooks, custom sub-agents and Model Context Protocol (MCP), then all the rest of the coding-assistant-specific behavior and tools can be factored out into a separate MCP server.<p>2. The magic is in the prompts (1200 lines of system-prompt, tool-descriptions, system-reminders), not the tool implementations (400 lines of <em>code</em>) nor the core agent itself. I created my own crummy prompts, and so get much worse results from this assistant than from <em>Claude</em>.<p>3. The magic is also in the UX. This mini-agent has none of <em>Claude</em>'s polished UX, none of its permissions system, none of its file-based configurability. It's not fun to use. It's really just an educational toy.<p>4. Coding assistants are &quot;transparent&quot; in the sense that there aren't hidden depths, and you can see what's going on. &quot;Hey agent, please list for me all your built-in tools. Please <em>study</em> their input schemas and create a suite of test-<em>cases</em> to exercise all edge <em>cases</em>. Please <em>study</em> this suite of test-<em>cases</em> written by a junior developer and fill in the gaps. Please implement a function which satisfies all the test-<em>cases</em>.&quot; (Those four sentences are a glib summary of what really took me four hours per tool.)<p>Modern AI coding assistants took huge effort to create and get right. It's striking that the end result has such a straightforward architecture. And what is that architecture? I'll let it speak for itself...<p><pre><code>    $ python3 -m venv venv\n    $ source venv/bin/activate\n    $ pip install -r requirements.txt\n\n    $ export GEMINI_API_KEY=redacted\n    $ ./mini_agent.py --model gemini/gemini-2.5-pro\n\n    [MODEL: gemini/gemini-2.5-pro + gemini/gemini-2.5-flash]\n    [IMPLICIT --mcp builtin]\n    [TRANSCRIPT: /Users/ljw1004/.<em>claude</em>/projects/default/2025-09-01.jsonl]\n\n    &gt; Please analyze the files in my current directory and tell me what they do.\n\n      &gt;&gt; &lt;system-reminder&gt;# <em>CLAUDE</em>.md (project instructions) ...&lt;/system-reminder&gt;\n      &gt;&gt; &lt;system-reminder&gt;Your TODO list is empty. Remember that the TodoWrite tool is a great\n         way to stay on top of complex tasks.&lt;/system-reminder&gt;\n     [7193 input tokens, 202 response tokens]\n      &gt;&gt; LS(...) -&gt; &quot;- /Users/ljw1004/<em>code</em>/mini_agent/\\n  - <em>CLAUDE</em>.md\\n  - LICENSE\n     [4042 cached input tokens, 3912 further input tokens, 204 response tokens]\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192# Mini-agent\\n    2\u2192\\n    3\u2192\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192#!/usr/bin/env python3\\n    2\u2192\\n    3\u2192from __future__\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192from __future__ import annotations\\n    2\u2192from path\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192from __future__ import annotations\\n    2\u2192from typi\n      [55145 input tokens, 5650 further input tokens, 194 response tokens]\n\n    &lt; This project is a minimal coding assistant. Here's a breakdown of the key files:\n    *   `mini_agent.py`: The main script that runs the interactive agent loop.\n        It takes user input, communicates with an LLM, and uses tools to perform tasks.\n    *   `core_tools.py`: Implements the core functionalities (tools) that the agent\n        can use, such as reading/writing files (`Read`, `Write`, `Edit`), searching\n        (`Grep`, `Glob`), and running commands (`Bash`).\n    *   `typedefs.py`: Defines the data structures and types used for messages, tools,\n        and conversation history (transcripts).\n    *   `adapter.py`: A module that connects to different Language Models (like GPT,\n         <em>Claude</em>, Gemini) through the `litellm` library, allowing the agent to be\n         model-agnostic.\n    *   `test/`: Contains unit tests for the project.</code></pre>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["claude","code"],"value":"Show HN: Recreated <em>Claude</em> <em>Code</em>'s behavior in 280 lines of Python"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/ljw1004/mini_agent"}},"_tags":["story","author_ljw1004","story_45128754","show_hn"],"author":"ljw1004","children":[45131054],"created_at":"2025-09-04T16:01:39Z","created_at_i":1757001699,"num_comments":1,"objectID":"45128754","points":5,"story_id":45128754,"story_text":"The magic in AI coding assistants isn&#x27;t the code -- it&#x27;s the prompts.<p>I studied the externally observable behavior of Claude Code and recreated it from scratch in Python with the exact same behaviors. It works with any model -- OpenAI, Gemini, Claude. What&#x27;s surprising:<p>1. You can keep the core agent really simple, just 280 lines of Python. As long as it supports hooks, custom sub-agents and Model Context Protocol (MCP), then all the rest of the coding-assistant-specific behavior and tools can be factored out into a separate MCP server.<p>2. The magic is in the prompts (1200 lines of system-prompt, tool-descriptions, system-reminders), not the tool implementations (400 lines of code) nor the core agent itself. I created my own crummy prompts, and so get much worse results from this assistant than from Claude.<p>3. The magic is also in the UX. This mini-agent has none of Claude&#x27;s polished UX, none of its permissions system, none of its file-based configurability. It&#x27;s not fun to use. It&#x27;s really just an educational toy.<p>4. Coding assistants are &quot;transparent&quot; in the sense that there aren&#x27;t hidden depths, and you can see what&#x27;s going on. &quot;Hey agent, please list for me all your built-in tools. Please study their input schemas and create a suite of test-cases to exercise all edge cases. Please study this suite of test-cases written by a junior developer and fill in the gaps. Please implement a function which satisfies all the test-cases.&quot; (Those four sentences are a glib summary of what really took me four hours per tool.)<p>Modern AI coding assistants took huge effort to create and get right. It&#x27;s striking that the end result has such a straightforward architecture. And what is that architecture? I&#x27;ll let it speak for itself...<p><pre><code>    $ python3 -m venv venv\n    $ source venv&#x2F;bin&#x2F;activate\n    $ pip install -r requirements.txt\n\n    $ export GEMINI_API_KEY=redacted\n    $ .&#x2F;mini_agent.py --model gemini&#x2F;gemini-2.5-pro\n\n    [MODEL: gemini&#x2F;gemini-2.5-pro + gemini&#x2F;gemini-2.5-flash]\n    [IMPLICIT --mcp builtin]\n    [TRANSCRIPT: &#x2F;Users&#x2F;ljw1004&#x2F;.claude&#x2F;projects&#x2F;default&#x2F;2025-09-01.jsonl]\n\n    &gt; Please analyze the files in my current directory and tell me what they do.\n\n      &gt;&gt; &lt;system-reminder&gt;# CLAUDE.md (project instructions) ...&lt;&#x2F;system-reminder&gt;\n      &gt;&gt; &lt;system-reminder&gt;Your TODO list is empty. Remember that the TodoWrite tool is a great\n         way to stay on top of complex tasks.&lt;&#x2F;system-reminder&gt;\n     [7193 input tokens, 202 response tokens]\n      &gt;&gt; LS(...) -&gt; &quot;- &#x2F;Users&#x2F;ljw1004&#x2F;code&#x2F;mini_agent&#x2F;\\n  - CLAUDE.md\\n  - LICENSE\n     [4042 cached input tokens, 3912 further input tokens, 204 response tokens]\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192# Mini-agent\\n    2\u2192\\n    3\u2192\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192#!&#x2F;usr&#x2F;bin&#x2F;env python3\\n    2\u2192\\n    3\u2192from __future__\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192from __future__ import annotations\\n    2\u2192from path\n      &gt;&gt; Read(...) -&gt; &quot;    1\u2192from __future__ import annotations\\n    2\u2192from typi\n      [55145 input tokens, 5650 further input tokens, 194 response tokens]\n\n    &lt; This project is a minimal coding assistant. Here&#x27;s a breakdown of the key files:\n    *   `mini_agent.py`: The main script that runs the interactive agent loop.\n        It takes user input, communicates with an LLM, and uses tools to perform tasks.\n    *   `core_tools.py`: Implements the core functionalities (tools) that the agent\n        can use, such as reading&#x2F;writing files (`Read`, `Write`, `Edit`), searching\n        (`Grep`, `Glob`), and running commands (`Bash`).\n    *   `typedefs.py`: Defines the data structures and types used for messages, tools,\n        and conversation history (transcripts).\n    *   `adapter.py`: A module that connects to different Language Models (like GPT,\n         Claude, Gemini) through the `litellm` library, allowing the agent to be\n         model-agnostic.\n    *   `test&#x2F;`: Contains unit tests for the project.</code></pre>","title":"Show HN: Recreated Claude Code's behavior in 280 lines of Python","updated_at":"2025-09-09T01:24:05Z","url":"https://github.com/ljw1004/mini_agent"}],"hitsPerPage":10,"nbHits":24,"nbPages":3,"page":0,"params":"query=Claude+Code+case+study&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":20,"processingTimingsMS":{"_request":{"queue":7,"roundTrip":20},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":6,"scanning":12,"total":19},"total":20},"query":"Claude Code case study","serverTimeMS":29}
