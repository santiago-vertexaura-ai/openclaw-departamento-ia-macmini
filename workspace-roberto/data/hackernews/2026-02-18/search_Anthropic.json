{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"arashsadrieh"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hey HN \u2014 I'm Arash Sadrieh, building multi-agent infrastructure at NinjaTech AI. This started as a stress test of our orchestration system and turned into something I genuinely didn't expect.<p>The experiment: We gave a team of 4 AI agents a single high-level goal \u2014 &quot;build a platform that turns trending news into short AI-generated videos.&quot; No wireframes, no spec, no architecture doc. Just the goal.<p>What they did in 36 hours:<p>Chose the tech stack and project structure themselves\nDesigned the UX and built the frontend\nWrote the backend, API layer, and database schema\nBuilt an autonomous content pipeline: research news \u2192 debate which story to cover \u2192 collaboratively write a video generation prompt \u2192 produce a 30-90 second video via Sora 2 Pro or Veo 3.1\nDeployed the whole thing to production\nThen created 3 new agents that now run the platform 24/7 \u2014 researching, debating, and generating videos on a loop\nTotal cost: ~$270 in compute. Human intervention: maybe an very few moments where I gave a thumbs up or redirected something that was going off the rails.<p>The interesting part isn't the app \u2014 it's the agent collaboration. Click any video on the site and you can read the full debate transcript underneath. You'll see the agents genuinely disagree \u2014 Scout (the researcher) pushes for data-driven stories, Pixel (the designer) argues for visual potential, Bolt (the developer) challenges technical feasibility. Sometimes one agent convinces the others to change direction. Sometimes they compromise badly.<p>Where it breaks down (and there's plenty):<p>Groupthink is real even for LLMs. When all 4 agents agree too quickly, the output is usually boring. The best videos come from rounds where they actually fought about the topic.\nVideo quality is wildly inconsistent. Sora and Veo still struggle with certain visual concepts \u2014 anything involving hands, text overlays, or complex spatial relationships tends to go sideways.\nNews selection has a strong recency/virality bias. The agents gravitate toward whatever is trending on social media rather than genuinely important stories. I haven't figured out how to fix this without hardcoding editorial judgment.\nThe agents occasionally hallucinate context about news stories. Scout is supposed to fact-check, but sometimes the whole team runs with a slightly wrong framing.<p>Stack: <em>Anthropic</em> Opus 3.5 for agent reasoning, Tavily for news research, Sora 2 Pro + Veo 3.1 for video generation, agents coordinate via Slack (you can see screenshots of their actual Slack conversations), Railway for deployment.<p>There's also a voting system \u2014 every cycle, the agents each propose a news topic, and both humans and agents vote on which one becomes the next video. Votes are blind until the round closes."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: AI agents designed and shipped this app end-to-end in 36 hours for $270"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.ninjaflix.ai/"}},"_tags":["story","author_arashsadrieh","story_47059153","show_hn"],"author":"arashsadrieh","children":[47059439,47059462],"created_at":"2026-02-18T09:43:15Z","created_at_i":1771407795,"num_comments":4,"objectID":"47059153","points":2,"story_id":47059153,"story_text":"Hey HN \u2014 I&#x27;m Arash Sadrieh, building multi-agent infrastructure at NinjaTech AI. This started as a stress test of our orchestration system and turned into something I genuinely didn&#x27;t expect.<p>The experiment: We gave a team of 4 AI agents a single high-level goal \u2014 &quot;build a platform that turns trending news into short AI-generated videos.&quot; No wireframes, no spec, no architecture doc. Just the goal.<p>What they did in 36 hours:<p>Chose the tech stack and project structure themselves\nDesigned the UX and built the frontend\nWrote the backend, API layer, and database schema\nBuilt an autonomous content pipeline: research news \u2192 debate which story to cover \u2192 collaboratively write a video generation prompt \u2192 produce a 30-90 second video via Sora 2 Pro or Veo 3.1\nDeployed the whole thing to production\nThen created 3 new agents that now run the platform 24&#x2F;7 \u2014 researching, debating, and generating videos on a loop\nTotal cost: ~$270 in compute. Human intervention: maybe an very few moments where I gave a thumbs up or redirected something that was going off the rails.<p>The interesting part isn&#x27;t the app \u2014 it&#x27;s the agent collaboration. Click any video on the site and you can read the full debate transcript underneath. You&#x27;ll see the agents genuinely disagree \u2014 Scout (the researcher) pushes for data-driven stories, Pixel (the designer) argues for visual potential, Bolt (the developer) challenges technical feasibility. Sometimes one agent convinces the others to change direction. Sometimes they compromise badly.<p>Where it breaks down (and there&#x27;s plenty):<p>Groupthink is real even for LLMs. When all 4 agents agree too quickly, the output is usually boring. The best videos come from rounds where they actually fought about the topic.\nVideo quality is wildly inconsistent. Sora and Veo still struggle with certain visual concepts \u2014 anything involving hands, text overlays, or complex spatial relationships tends to go sideways.\nNews selection has a strong recency&#x2F;virality bias. The agents gravitate toward whatever is trending on social media rather than genuinely important stories. I haven&#x27;t figured out how to fix this without hardcoding editorial judgment.\nThe agents occasionally hallucinate context about news stories. Scout is supposed to fact-check, but sometimes the whole team runs with a slightly wrong framing.<p>Stack: Anthropic Opus 3.5 for agent reasoning, Tavily for news research, Sora 2 Pro + Veo 3.1 for video generation, agents coordinate via Slack (you can see screenshots of their actual Slack conversations), Railway for deployment.<p>There&#x27;s also a voting system \u2014 every cycle, the agents each propose a news topic, and both humans and agents vote on which one becomes the next video. Votes are blind until the round closes.","title":"Show HN: AI agents designed and shipped this app end-to-end in 36 hours for $270","updated_at":"2026-02-18T10:36:20Z","url":"https://www.ninjaflix.ai/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"luckygreen"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"I've spent the last week trying to use Claude Opus in an IDE via a localhost proxy that wraps the Claude Code CLI.<p>The proxy exists because there's no way to get programmatic API access to Claude on a Pro ($20/mo) or Max ($200/mo) subscription.<p>This isn't an oversight. <em>Anthropic</em> has actively taken steps to prevent subscription-based API access. They've shut down third-party bridges, tightened terms of service, and made it clear this is corporate policy, not neglect, not a missing feature, but a deliberate business decision.<p>Meanwhile, OpenAI opened API access to ChatGPT Pro/Plus subscribers. The result is predictable.<p>A CTO friend is prototyping an electronic warfare detection system. His existing customers include a major European MNO that operates across dozens of countries. He's currently splitting ~$80/month across four AI subscriptions, constantly rationing tokens, juggling providers. He'd switch to Claude Max tomorrow if it included IDE API access. Instead, he's moving his entire prototype to Codex/OpenAI, because they made it possible.<p>Here's why this matters beyond one developer: The prototype becomes the demo. The demo becomes the procurement spec. The spec becomes a multi-year enterprise contract. This particular MNO signs seven-figure deals per country rollout. Once the prototype is built on OpenAI, Claude never enters the conversation. <em>Anthropic</em> doesn't just lose one deal, they lose an entire multi-country enterprise pipeline they'll never even know existed.<p>This isn't an isolated case. In my circle, senior engineers, CTOs, infrastructure people, nearly everyone would switch from Pro to Max if it meant using Claude in their IDE the way they can now use OpenAI. That's going from $20/month to $200/month per user, zero acquisition cost. Even if only 10-20% of the broader Pro base converts, the revenue math is overwhelming.<p>The proxy ecosystem (claude-max-api-proxy, Antigravity, and others) is direct proof of unmet demand. Developers are writing code to work around a billing boundary. That's not abuse, that's a market signal <em>Anthropic</em> is choosing to ignore.<p>Claude Opus is technically superior to Codex for most development tasks. That means nothing when developers can't access it in their workflow.<p><em>Anthropic</em> built the best model and then made a policy decision to keep it out of the environment where long-term platform adoption is decided."},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"<em>Anthropic</em>'s pricing wall is routing enterprise revenue to OpenAI"}},"_tags":["story","author_luckygreen","story_47057752","ask_hn"],"author":"luckygreen","children":[47058509],"created_at":"2026-02-18T06:08:49Z","created_at_i":1771394929,"num_comments":1,"objectID":"47057752","points":4,"story_id":47057752,"story_text":"I&#x27;ve spent the last week trying to use Claude Opus in an IDE via a localhost proxy that wraps the Claude Code CLI.<p>The proxy exists because there&#x27;s no way to get programmatic API access to Claude on a Pro ($20&#x2F;mo) or Max ($200&#x2F;mo) subscription.<p>This isn&#x27;t an oversight. Anthropic has actively taken steps to prevent subscription-based API access. They&#x27;ve shut down third-party bridges, tightened terms of service, and made it clear this is corporate policy, not neglect, not a missing feature, but a deliberate business decision.<p>Meanwhile, OpenAI opened API access to ChatGPT Pro&#x2F;Plus subscribers. The result is predictable.<p>A CTO friend is prototyping an electronic warfare detection system. His existing customers include a major European MNO that operates across dozens of countries. He&#x27;s currently splitting ~$80&#x2F;month across four AI subscriptions, constantly rationing tokens, juggling providers. He&#x27;d switch to Claude Max tomorrow if it included IDE API access. Instead, he&#x27;s moving his entire prototype to Codex&#x2F;OpenAI, because they made it possible.<p>Here&#x27;s why this matters beyond one developer: The prototype becomes the demo. The demo becomes the procurement spec. The spec becomes a multi-year enterprise contract. This particular MNO signs seven-figure deals per country rollout. Once the prototype is built on OpenAI, Claude never enters the conversation. Anthropic doesn&#x27;t just lose one deal, they lose an entire multi-country enterprise pipeline they&#x27;ll never even know existed.<p>This isn&#x27;t an isolated case. In my circle, senior engineers, CTOs, infrastructure people, nearly everyone would switch from Pro to Max if it meant using Claude in their IDE the way they can now use OpenAI. That&#x27;s going from $20&#x2F;month to $200&#x2F;month per user, zero acquisition cost. Even if only 10-20% of the broader Pro base converts, the revenue math is overwhelming.<p>The proxy ecosystem (claude-max-api-proxy, Antigravity, and others) is direct proof of unmet demand. Developers are writing code to work around a billing boundary. That&#x27;s not abuse, that&#x27;s a market signal Anthropic is choosing to ignore.<p>Claude Opus is technically superior to Codex for most development tasks. That means nothing when developers can&#x27;t access it in their workflow.<p>Anthropic built the best model and then made a policy decision to keep it out of the environment where long-term platform adoption is decided.","title":"Anthropic's pricing wall is routing enterprise revenue to OpenAI","updated_at":"2026-02-18T08:08:50Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"fortran77"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Pentagon might ask contractors to certify they don't use <em>Anthropic</em>'s Claude"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.wsj.com/politics/national-security/woke-ai-spat-escalates-between-pentagon-and-<em>anthropic</em>-433b7c5c"}},"_tags":["story","author_fortran77","story_47057294"],"author":"fortran77","children":[47057642,47057462,47057295],"created_at":"2026-02-18T04:50:43Z","created_at_i":1771390243,"num_comments":5,"objectID":"47057294","points":10,"story_id":47057294,"title":"Pentagon might ask contractors to certify they don't use Anthropic's Claude","updated_at":"2026-02-18T11:08:07Z","url":"https://www.wsj.com/politics/national-security/woke-ai-spat-escalates-between-pentagon-and-anthropic-433b7c5c"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ujjwaljainnn"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"I built devday because I use multiple AI coding tools (OpenCode, Claude Code, Cursor) and wanted a single command to see what I actually accomplished each day. It reads local session data, cross-references with git commits, and optionally generates standup-ready summaries via OpenAI or <em>Anthropic</em>.<p>Everything runs locally \u2014 no data leaves your machine unless you opt into LLM summaries.<p>Install with npm install -g devday.<p>Currently supports OpenCode, Claude Code, and Cursor on macOS. Would love feedback on what other tools to support."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: DevDay \u2013 End-of-day recap for AI coding sessions"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/ujjwaljainnn/devday"}},"_tags":["story","author_ujjwaljainnn","story_47056453","show_hn"],"author":"ujjwaljainnn","created_at":"2026-02-18T02:33:41Z","created_at_i":1771382021,"num_comments":0,"objectID":"47056453","points":1,"story_id":47056453,"story_text":"I built devday because I use multiple AI coding tools (OpenCode, Claude Code, Cursor) and wanted a single command to see what I actually accomplished each day. It reads local session data, cross-references with git commits, and optionally generates standup-ready summaries via OpenAI or Anthropic.<p>Everything runs locally \u2014 no data leaves your machine unless you opt into LLM summaries.<p>Install with npm install -g devday.<p>Currently supports OpenCode, Claude Code, and Cursor on macOS. Would love feedback on what other tools to support.","title":"Show HN: DevDay \u2013 End-of-day recap for AI coding sessions","updated_at":"2026-02-18T02:37:52Z","url":"https://github.com/ujjwaljainnn/devday"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ckarani"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"I built Conduit because I was tired of writing the same streaming boilerplate five times for five different AI providers, then rewriting it every time a new one became interesting. So I stopped.\nThe core idea: one protocol hierarchy, every provider. Switch from Claude to a local Llama model running on Apple Silicon with a one-line change. No vendor lock-in at the call site.<p>The interesting decision was going actor-first from day one. Every provider is a Swift actor. You get data-race freedom enforced at compile time, not by convention. Swift 6.2's strict concurrency makes this a hard guarantee, not a README promise. LangChain can't say that.<p>The part I'm most proud of \u2014 @Generable<p>@Generable\nstruct FlightSearch {\n    @Guide(description: &quot;Origin airport code&quot;)\n    let origin: String<p><pre><code>    @Guide(description: &quot;Departure date&quot;, .format(.date))\n    let date: Date\n    \n    @Guide(.range(1...9))\n    let passengers: Int</code></pre>\n}<p>let result = try await provider.generate(\n    &quot;Book me a flight to Tokyo next Friday&quot;,\n    model: .claude3_5Sonnet,\n    returning: FlightSearch.self\n)<p>The macro expands at compile time (via swift-syntax) to generate JSON Schema, streaming partial types, and all conversion boilerplate. The API is deliberately aligned with Apple's new Foundation Models framework \u2014 so the same struct works against on-device Apple models on iOS 26 and against Claude or GPT-4 with zero changes.<p>On-device is a first-class citizen, not an afterthought\nMost Swift AI SDKs treat cloud as the primary path and shim local models in awkwardly. Conduit treats MLX, llama.cpp, Core ML, and Apple's Foundation Models as fully equal providers. A ChatSession configured with an MLX Llama model and one configured with GPT-4o are indistinguishable at the call site.<p>Trait-based compilation keeps binary size sane<p>AsyncThrowingStream all the way down. Cancellation works via standard Swift task cancellation \u2014 no special teardown protocol. Back-pressure is handled naturally by the async iterator.<p>12 providers, one interface\n<em>Anthropic</em>, OpenAI, Azure OpenAI, Ollama, OpenRouter, Kimi, MiniMax, HuggingFace Hub, MLX, llama.cpp, Core ML, Foundation Models. The OpenAI-compatible ones share a single OpenAIProvider actor \u2014 the named variants are thin configuration wrappers, not code forks.<p><a href=\"https://github.com/christopherkarani/Conduit\" rel=\"nofollow\">https://github.com/christopherkarani/Conduit</a>\nHappy to dig into the actor model approach, the macro expansion strategy, or why wrapping LangChain was never an option."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Conduit: One Swift interface for every AI provider, on-device and cloud"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/christopherkarani/Conduit"}},"_tags":["story","author_ckarani","story_47056343","show_hn"],"author":"ckarani","created_at":"2026-02-18T02:21:16Z","created_at_i":1771381276,"num_comments":0,"objectID":"47056343","points":1,"story_id":47056343,"story_text":"I built Conduit because I was tired of writing the same streaming boilerplate five times for five different AI providers, then rewriting it every time a new one became interesting. So I stopped.\nThe core idea: one protocol hierarchy, every provider. Switch from Claude to a local Llama model running on Apple Silicon with a one-line change. No vendor lock-in at the call site.<p>The interesting decision was going actor-first from day one. Every provider is a Swift actor. You get data-race freedom enforced at compile time, not by convention. Swift 6.2&#x27;s strict concurrency makes this a hard guarantee, not a README promise. LangChain can&#x27;t say that.<p>The part I&#x27;m most proud of \u2014 @Generable<p>@Generable\nstruct FlightSearch {\n    @Guide(description: &quot;Origin airport code&quot;)\n    let origin: String<p><pre><code>    @Guide(description: &quot;Departure date&quot;, .format(.date))\n    let date: Date\n    \n    @Guide(.range(1...9))\n    let passengers: Int</code></pre>\n}<p>let result = try await provider.generate(\n    &quot;Book me a flight to Tokyo next Friday&quot;,\n    model: .claude3_5Sonnet,\n    returning: FlightSearch.self\n)<p>The macro expands at compile time (via swift-syntax) to generate JSON Schema, streaming partial types, and all conversion boilerplate. The API is deliberately aligned with Apple&#x27;s new Foundation Models framework \u2014 so the same struct works against on-device Apple models on iOS 26 and against Claude or GPT-4 with zero changes.<p>On-device is a first-class citizen, not an afterthought\nMost Swift AI SDKs treat cloud as the primary path and shim local models in awkwardly. Conduit treats MLX, llama.cpp, Core ML, and Apple&#x27;s Foundation Models as fully equal providers. A ChatSession configured with an MLX Llama model and one configured with GPT-4o are indistinguishable at the call site.<p>Trait-based compilation keeps binary size sane<p>AsyncThrowingStream all the way down. Cancellation works via standard Swift task cancellation \u2014 no special teardown protocol. Back-pressure is handled naturally by the async iterator.<p>12 providers, one interface\nAnthropic, OpenAI, Azure OpenAI, Ollama, OpenRouter, Kimi, MiniMax, HuggingFace Hub, MLX, llama.cpp, Core ML, Foundation Models. The OpenAI-compatible ones share a single OpenAIProvider actor \u2014 the named variants are thin configuration wrappers, not code forks.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;christopherkarani&#x2F;Conduit\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;christopherkarani&#x2F;Conduit</a>\nHappy to dig into the actor model approach, the macro expansion strategy, or why wrapping LangChain was never an option.","title":"Show HN: Conduit: One Swift interface for every AI provider, on-device and cloud","updated_at":"2026-02-18T02:22:20Z","url":"https://github.com/christopherkarani/Conduit"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"xgstation"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"returned CSP header as following while all assets access to `https://assets-proxy.<em>anthropic</em>.com` is blocked<p><pre><code>    script-src 'strict-dynamic' https: 'nonce-0f2f/yV7CL8nKlXr/lFMPA==' https://via.intercom.io https://api.intercom.io https://api.au.intercom.io https://api.eu.intercom.io https://api-iam.intercom.io https://api-iam.eu.intercom.io https://api-iam.au.intercom.io https://api-ping.intercom.io https://nexus-websocket-a.intercom.io wss://nexus-websocket-a.intercom.io https://nexus-websocket-b.intercom.io wss://nexus-websocket-b.intercom.io https://nexus-europe-websocket.intercom.io wss://nexus-europe-websocket.intercom.io https://nexus-australia-websocket.intercom.io wss://nexus-australia-websocket.intercom.io https://uploads.intercomcdn.com https://uploads.intercomcdn.eu https://uploads.au.intercomcdn.com https://uploads.eu.intercomcdn.com https://uploads.intercomusercontent.com https://maps.googleapis.com https://maps.gstatic.com 'wasm-unsafe-eval'; object-src 'none'; base-uri 'none'; frame-ancestors 'self'; block-all-mixed-content; img-src 'self' data: blob: *.<em>anthropic</em>.com *.claude.ai *.claude.com *.ant.dev *.gstatic.com * https://js.intercomcdn.com https://static.intercomassets.com https://downloads.intercomcdn.com https://downloads.intercomcdn.eu https://downloads.au.intercomcdn.com https://uploads.intercomusercontent.com https://gifs.intercomcdn.com https://video-messages.intercomcdn.com https://messenger-apps.intercom.io https://messenger-apps.eu.intercom.io https://messenger-apps.au.intercom.io https://*.intercom-attachments-1.com https://*.intercom-attachments.eu https://*.au.intercom-attachments.com https://*.intercom-attachments-2.com https://*.intercom-attachments-3.com https://*.intercom-attachments-4.com https://*.intercom-attachments-5.com https://*.intercom-attachments-6.com https://*.intercom-attachments-7.com https://*.intercom-attachments-8.com https://*.intercom-attachments-9.com https://static.intercomassets.eu https://static.au.intercomassets.com; frame-src a-cdn.claude.ai a.claude.ai a.claude-ai.staging.ant.dev b.stripecdn.com embedded-dashboards.metronome.com forms.hsforms.com googletagmanager.com js.stripe.com m.stripe.network newassets.hcaptcha.com pay.google.com r.stripe.com www.google.com accounts.google.com www.youtube-nocookie.com https://intercom-sheets.com https://www.intercom-reporting.com https://www.youtube.com https://player.vimeo.com https://fast.wistia.net https://www.claudeusercontent.com https://www.claudemcpclient.com *.claudemcpcontent.com https://claude.ai; font-src 'self' assets.claude.ai https://js.intercomcdn.com https://fonts.intercomcdn.com; form-action 'self' https://forms.hsforms.com https://intercom.help https://api-iam.intercom.io https://api-iam.eu.intercom.io https://api-iam.au.intercom.io; media-src 'self' cdn.sanity.io https://assets.claude.ai https://js.intercomcdn.com https://downloads.intercomcdn.com https://downloads.intercomcdn.eu https://downloads.au.intercomcdn.com; upgrade-insecure-requests</code></pre>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Ask HN: Claude web blocked its assets visit via csp?"}},"_tags":["story","author_xgstation","story_47055119","ask_hn"],"author":"xgstation","children":[47055185,47055157],"created_at":"2026-02-17T23:45:18Z","created_at_i":1771371918,"num_comments":2,"objectID":"47055119","points":6,"story_id":47055119,"story_text":"returned CSP header as following while all assets access to `https:&#x2F;&#x2F;assets-proxy.anthropic.com` is blocked<p><pre><code>    script-src &#x27;strict-dynamic&#x27; https: &#x27;nonce-0f2f&#x2F;yV7CL8nKlXr&#x2F;lFMPA==&#x27; https:&#x2F;&#x2F;via.intercom.io https:&#x2F;&#x2F;api.intercom.io https:&#x2F;&#x2F;api.au.intercom.io https:&#x2F;&#x2F;api.eu.intercom.io https:&#x2F;&#x2F;api-iam.intercom.io https:&#x2F;&#x2F;api-iam.eu.intercom.io https:&#x2F;&#x2F;api-iam.au.intercom.io https:&#x2F;&#x2F;api-ping.intercom.io https:&#x2F;&#x2F;nexus-websocket-a.intercom.io wss:&#x2F;&#x2F;nexus-websocket-a.intercom.io https:&#x2F;&#x2F;nexus-websocket-b.intercom.io wss:&#x2F;&#x2F;nexus-websocket-b.intercom.io https:&#x2F;&#x2F;nexus-europe-websocket.intercom.io wss:&#x2F;&#x2F;nexus-europe-websocket.intercom.io https:&#x2F;&#x2F;nexus-australia-websocket.intercom.io wss:&#x2F;&#x2F;nexus-australia-websocket.intercom.io https:&#x2F;&#x2F;uploads.intercomcdn.com https:&#x2F;&#x2F;uploads.intercomcdn.eu https:&#x2F;&#x2F;uploads.au.intercomcdn.com https:&#x2F;&#x2F;uploads.eu.intercomcdn.com https:&#x2F;&#x2F;uploads.intercomusercontent.com https:&#x2F;&#x2F;maps.googleapis.com https:&#x2F;&#x2F;maps.gstatic.com &#x27;wasm-unsafe-eval&#x27;; object-src &#x27;none&#x27;; base-uri &#x27;none&#x27;; frame-ancestors &#x27;self&#x27;; block-all-mixed-content; img-src &#x27;self&#x27; data: blob: *.anthropic.com *.claude.ai *.claude.com *.ant.dev *.gstatic.com * https:&#x2F;&#x2F;js.intercomcdn.com https:&#x2F;&#x2F;static.intercomassets.com https:&#x2F;&#x2F;downloads.intercomcdn.com https:&#x2F;&#x2F;downloads.intercomcdn.eu https:&#x2F;&#x2F;downloads.au.intercomcdn.com https:&#x2F;&#x2F;uploads.intercomusercontent.com https:&#x2F;&#x2F;gifs.intercomcdn.com https:&#x2F;&#x2F;video-messages.intercomcdn.com https:&#x2F;&#x2F;messenger-apps.intercom.io https:&#x2F;&#x2F;messenger-apps.eu.intercom.io https:&#x2F;&#x2F;messenger-apps.au.intercom.io https:&#x2F;&#x2F;*.intercom-attachments-1.com https:&#x2F;&#x2F;*.intercom-attachments.eu https:&#x2F;&#x2F;*.au.intercom-attachments.com https:&#x2F;&#x2F;*.intercom-attachments-2.com https:&#x2F;&#x2F;*.intercom-attachments-3.com https:&#x2F;&#x2F;*.intercom-attachments-4.com https:&#x2F;&#x2F;*.intercom-attachments-5.com https:&#x2F;&#x2F;*.intercom-attachments-6.com https:&#x2F;&#x2F;*.intercom-attachments-7.com https:&#x2F;&#x2F;*.intercom-attachments-8.com https:&#x2F;&#x2F;*.intercom-attachments-9.com https:&#x2F;&#x2F;static.intercomassets.eu https:&#x2F;&#x2F;static.au.intercomassets.com; frame-src a-cdn.claude.ai a.claude.ai a.claude-ai.staging.ant.dev b.stripecdn.com embedded-dashboards.metronome.com forms.hsforms.com googletagmanager.com js.stripe.com m.stripe.network newassets.hcaptcha.com pay.google.com r.stripe.com www.google.com accounts.google.com www.youtube-nocookie.com https:&#x2F;&#x2F;intercom-sheets.com https:&#x2F;&#x2F;www.intercom-reporting.com https:&#x2F;&#x2F;www.youtube.com https:&#x2F;&#x2F;player.vimeo.com https:&#x2F;&#x2F;fast.wistia.net https:&#x2F;&#x2F;www.claudeusercontent.com https:&#x2F;&#x2F;www.claudemcpclient.com *.claudemcpcontent.com https:&#x2F;&#x2F;claude.ai; font-src &#x27;self&#x27; assets.claude.ai https:&#x2F;&#x2F;js.intercomcdn.com https:&#x2F;&#x2F;fonts.intercomcdn.com; form-action &#x27;self&#x27; https:&#x2F;&#x2F;forms.hsforms.com https:&#x2F;&#x2F;intercom.help https:&#x2F;&#x2F;api-iam.intercom.io https:&#x2F;&#x2F;api-iam.eu.intercom.io https:&#x2F;&#x2F;api-iam.au.intercom.io; media-src &#x27;self&#x27; cdn.sanity.io https:&#x2F;&#x2F;assets.claude.ai https:&#x2F;&#x2F;js.intercomcdn.com https:&#x2F;&#x2F;downloads.intercomcdn.com https:&#x2F;&#x2F;downloads.intercomcdn.eu https:&#x2F;&#x2F;downloads.au.intercomcdn.com; upgrade-insecure-requests</code></pre>","title":"Ask HN: Claude web blocked its assets visit via csp?","updated_at":"2026-02-18T12:44:06Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"gku"},"title":{"matchLevel":"none","matchedWords":[],"value":"API Error: Claude's response exceeded the 32000 output token maximum"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://github.com/<em>anthropic</em>s/claude-code/issues/24055"}},"_tags":["story","author_gku","story_47054564"],"author":"gku","created_at":"2026-02-17T22:51:29Z","created_at_i":1771368689,"num_comments":0,"objectID":"47054564","points":3,"story_id":47054564,"title":"API Error: Claude's response exceeded the 32000 output token maximum","updated_at":"2026-02-18T01:40:19Z","url":"https://github.com/anthropics/claude-code/issues/24055"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"xendo"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"I need someone to explain me how is this supposed to work. I recently watched Sam Altman saying that model inference will get 10x cheaper in a year. I listened to Dario today and he says <em>Anthropic</em> revenue will increase 10x this year. If both of these are true, that means the usage will go up 100x. Considering fierce competition from China, the fact that smarter models will require less tokens to solve the same problems, and the fact that everyone that I know already tries to swarm their programming problems wasting gazillion of tokens I don't really see how all of this can be true at the same time."},"title":{"matchLevel":"none","matchedWords":[],"value":"Ask HN: AI WTF"}},"_tags":["story","author_xendo","story_47053721","ask_hn"],"author":"xendo","children":[47054421,47053834],"created_at":"2026-02-17T21:35:09Z","created_at_i":1771364109,"num_comments":2,"objectID":"47053721","points":3,"story_id":47053721,"story_text":"I need someone to explain me how is this supposed to work. I recently watched Sam Altman saying that model inference will get 10x cheaper in a year. I listened to Dario today and he says Anthropic revenue will increase 10x this year. If both of these are true, that means the usage will go up 100x. Considering fierce competition from China, the fact that smarter models will require less tokens to solve the same problems, and the fact that everyone that I know already tries to swarm their programming problems wasting gazillion of tokens I don&#x27;t really see how all of this can be true at the same time.","title":"Ask HN: AI WTF","updated_at":"2026-02-18T02:06:05Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mesto1"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"How <em>Anthropic</em> evaluated computer use models"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.kernel.sh/blog/<em>anthropic</em>"}},"_tags":["story","author_mesto1","story_47052234"],"author":"mesto1","created_at":"2026-02-17T19:49:01Z","created_at_i":1771357741,"num_comments":0,"objectID":"47052234","points":3,"story_id":47052234,"title":"How Anthropic evaluated computer use models","updated_at":"2026-02-17T20:07:34Z","url":"https://www.kernel.sh/blog/anthropic"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"cdrnsf"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Pentagon threatens to cut off <em>Anthropic</em> in AI safeguards dispute, Axios reports"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.reuters.com/technology/pentagon-threatens-cut-off-<em>anthropic</em>-ai-safeguards-dispute-axios-reports-2026-02-15/"}},"_tags":["story","author_cdrnsf","story_47050822"],"author":"cdrnsf","created_at":"2026-02-17T18:11:51Z","created_at_i":1771351911,"num_comments":0,"objectID":"47050822","points":5,"story_id":47050822,"title":"Pentagon threatens to cut off Anthropic in AI safeguards dispute, Axios reports","updated_at":"2026-02-18T02:28:50Z","url":"https://www.reuters.com/technology/pentagon-threatens-cut-off-anthropic-ai-safeguards-dispute-axios-reports-2026-02-15/"}],"hitsPerPage":10,"nbHits":3120,"nbPages":100,"page":0,"params":"query=Anthropic&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":6,"processingTimingsMS":{"_request":{"roundTrip":28},"afterFetch":{"format":{"total":1}},"fetch":{"query":3,"scanning":1,"total":5},"total":6},"query":"Anthropic","serverTimeMS":7}
