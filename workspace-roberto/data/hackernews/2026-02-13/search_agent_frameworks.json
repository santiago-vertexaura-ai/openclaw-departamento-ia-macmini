{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"leoneperdigao"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Link: <a href=\"https://github.com/taoq-ai/ziran\" rel=\"nofollow\">https://github.com/taoq-ai/ziran</a><p>Hey HN, I want to introduce you to ZIRAN, an open-source security testing <em>framework</em> for AI <em>agents</em>.<p>As an AI engineer working with LangChain and CrewAI <em>agents</em> in production, I was frustrated that existing security tools (PyRIT, Garak) only test LLMs, \nnot <em>agents</em>. They miss the unique attack surface <em>agents</em> create: dangerous tool combinations, multi-step exploits, and <em>agent</em>-to-<em>agent</em> (A2A) communication risks.<p>That's why I built ZIRAN - a tool specifically designed to find  <em>agent</em> vulnerabilities. Key features:<p>- Tool Chain Analysis - Detects dangerous combinations (read_file \u2192 http_request)\n- A2A Security Testing - Tests <em>agent</em>-to-<em>agent</em> communication (Google's A2A protocol)\n- Multi-Phase Campaigns - Trust exploitation over multiple turns\n- Knowledge Graphs - Visualizes attack paths through <em>agent</em> capabilities<p>Feedback is very welcome!<p>Leone"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: Ziran, security testing for AI <em>agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/taoq-ai/ziran"}},"_tags":["story","author_leoneperdigao","story_47001873","show_hn"],"author":"leoneperdigao","created_at":"2026-02-13T12:18:09Z","created_at_i":1770985089,"num_comments":0,"objectID":"47001873","points":1,"story_id":47001873,"story_text":"Link: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;taoq-ai&#x2F;ziran\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;taoq-ai&#x2F;ziran</a><p>Hey HN, I want to introduce you to ZIRAN, an open-source security testing framework for AI agents.<p>As an AI engineer working with LangChain and CrewAI agents in production, I was frustrated that existing security tools (PyRIT, Garak) only test LLMs, \nnot agents. They miss the unique attack surface agents create: dangerous tool combinations, multi-step exploits, and agent-to-agent (A2A) communication risks.<p>That&#x27;s why I built ZIRAN - a tool specifically designed to find  agent vulnerabilities. Key features:<p>- Tool Chain Analysis - Detects dangerous combinations (read_file \u2192 http_request)\n- A2A Security Testing - Tests agent-to-agent communication (Google&#x27;s A2A protocol)\n- Multi-Phase Campaigns - Trust exploitation over multiple turns\n- Knowledge Graphs - Visualizes attack paths through agent capabilities<p>Feedback is very welcome!<p>Leone","title":"Show HN: Ziran, security testing for AI agents","updated_at":"2026-02-13T12:23:34Z","url":"https://github.com/taoq-ai/ziran"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Jyotishmoy"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"I\u2019ve been using AWS SES for a while and realized I treated SMTP as a black box. To understand the protocol better, I built an MTA (Mail Transfer <em>Agent</em>) from scratch in Go. It handles the full SMTP lifecycle (RFC 5321) using raw TCP sockets instead of high-level <em>frameworks</em>.<p>The Engineering Challenges:<p>Finite State Machine (FSM): SMTP is strictly stateful. I implemented an FSM to enforce command sequencing (e.g., preventing DATA before MAIL FROM). It ensures that protocol violations are caught at the socket level with proper 503 Bad Sequence codes.<p>Buffer-Oriented Processing: Used bufio.Scanner to handle the byte stream. The biggest hurdle was the DATA phase logic\u2014properly detecting the \\r\\n.\\r\\n sequence while managing memory efficiently using strings.Builder.<p>Concurrency: Leveraged Go's Accept() loop to spawn independent goroutines for each session, ensuring that the relay latency to Gmail (via STARTTLS) doesn't block the listener.<p>ISP Workarounds: Configured to run on port 2525 by default to bypass the common ISP block on port 25.<p>Status Codes Implemented:\nI implemented a subset of RFC 5321 codes, including 220 (Service Ready), 354 (Start Input), and error handling for 501 (Syntax) and 451 (Local Error).<p>Why I built this:\nMost modern tutorials stop at &quot;How to send an email with a library.&quot; I wanted to see how the &quot;dot-stuffing&quot; mechanism worked and how a server actually negotiates a multi-step handshake over a raw connection.<p>I\u2019d love to hear about edge cases I might have missed\u2014specifically around handling malformed headers or managing long-lived TCP connections under load.<p>Source Code: https://github.com/Jyotishmoy12/SMTP_Server"},"title":{"matchLevel":"none","matchedWords":[],"value":"SMTP server from scratch in Go \u2013 FSM, raw TCP, and buffer-oriented I/O"}},"_tags":["story","author_Jyotishmoy","story_47000757","ask_hn"],"author":"Jyotishmoy","created_at":"2026-02-13T09:26:17Z","created_at_i":1770974777,"num_comments":0,"objectID":"47000757","points":3,"story_id":47000757,"story_text":"I\u2019ve been using AWS SES for a while and realized I treated SMTP as a black box. To understand the protocol better, I built an MTA (Mail Transfer Agent) from scratch in Go. It handles the full SMTP lifecycle (RFC 5321) using raw TCP sockets instead of high-level frameworks.<p>The Engineering Challenges:<p>Finite State Machine (FSM): SMTP is strictly stateful. I implemented an FSM to enforce command sequencing (e.g., preventing DATA before MAIL FROM). It ensures that protocol violations are caught at the socket level with proper 503 Bad Sequence codes.<p>Buffer-Oriented Processing: Used bufio.Scanner to handle the byte stream. The biggest hurdle was the DATA phase logic\u2014properly detecting the \\r\\n.\\r\\n sequence while managing memory efficiently using strings.Builder.<p>Concurrency: Leveraged Go&#x27;s Accept() loop to spawn independent goroutines for each session, ensuring that the relay latency to Gmail (via STARTTLS) doesn&#x27;t block the listener.<p>ISP Workarounds: Configured to run on port 2525 by default to bypass the common ISP block on port 25.<p>Status Codes Implemented:\nI implemented a subset of RFC 5321 codes, including 220 (Service Ready), 354 (Start Input), and error handling for 501 (Syntax) and 451 (Local Error).<p>Why I built this:\nMost modern tutorials stop at &quot;How to send an email with a library.&quot; I wanted to see how the &quot;dot-stuffing&quot; mechanism worked and how a server actually negotiates a multi-step handshake over a raw connection.<p>I\u2019d love to hear about edge cases I might have missed\u2014specifically around handling malformed headers or managing long-lived TCP connections under load.<p>Source Code: https:&#x2F;&#x2F;github.com&#x2F;Jyotishmoy12&#x2F;SMTP_Server","title":"SMTP server from scratch in Go \u2013 FSM, raw TCP, and buffer-oriented I/O","updated_at":"2026-02-13T10:21:50Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"dougian"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Forge: Scalable <em>Agent</em> RL <em>Framework</em> and Algorithm"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"https://www.minimax.io/news/forge-scalable-<em>agent</em>-rl-<em>framework</em>-and-algorithm"}},"_tags":["story","author_dougian","story_47000618"],"author":"dougian","children":[47000702,47000665,47000705,47000666],"created_at":"2026-02-13T09:04:52Z","created_at_i":1770973492,"num_comments":0,"objectID":"47000618","points":20,"story_id":47000618,"title":"Forge: Scalable Agent RL Framework and Algorithm","updated_at":"2026-02-13T10:01:34Z","url":"https://www.minimax.io/news/forge-scalable-agent-rl-framework-and-algorithm"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"madugula"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"The release of microgpt by Andrej Karpathy is a foundational moment for AI transparency. In exactly 243 lines of pure, dependency-free Python, Karpathy has implemented the complete GPT algorithm from scratch. As a PhD scholar investigating AI and Blockchain, I see this as the ultimate tool for moving beyond the &quot;black box&quot; narrative of Large Language Models (LLMs).<p>The Architecture of Simplicity\nUnlike modern <em>frameworks</em> that hide complexity behind optimized CUDA kernels, microgpt exposes the raw mathematical machinery. The code implements:<p>The Autograd Engine: A custom Value class that handles the recursive chain rule for backpropagation without any external libraries.<p>GPT-2 Primitives: Atomic implementations of RMSNorm, Multi-head Attention, and MLP blocks, following the GPT-2 lineage with modernizations like ReLU.<p>The Adam Optimizer: A pure Python version of the Adam optimizer, proving that the &quot;magic&quot; of training is just well-orchestrated calculus.<p>The Shift to the Edge: Privacy, Latency, and Power\nFor my doctoral research at Woxsen University, this codebase serves as a blueprint for the future of Edge AI. As we move away from centralized, massive server farms, the ability to run &quot;atomic&quot; LLMs directly on hardware is becoming a strategic necessity. Karpathy's implementation provides empirical clarity on how we can incorporate on-device MicroGPTs to solve three critical industry challenges:<p>Better Latency: By eliminating the round-trip to the cloud, on-device models enable real-time inference. Understanding these 243 lines allows researchers to optimize the &quot;atomic&quot; core specifically for edge hardware constraints.<p>Data Protection &amp; Privacy: In a world where data is the new currency, processing information locally on the user's device ensures that sensitive inputs never leave the personal ecosystem, fundamentally aligning with modern data sovereignty standards.<p>Mastering the Primitives: For Technical Product Managers, this project proves that &quot;intelligence&quot; doesn't require a dependency-heavy stack. We can now envision lightweight, specialized <em>agents</em> that are fast, private, and highly efficient.<p>Karpathy\u2019s work reminds us that to build the next generation of private, edge-native AI products, we must first master the fundamentals that fit on a single screen of code. The future is moving toward decentralized, on-device intelligence built on these very primitives.\nLink:<p><a href=\"https://blog.saimadugula.com/posts/microgpt-black-box.html\" rel=\"nofollow\">https://blog.saimadugula.com/posts/microgpt-black-box.html</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: MicroGPT in 243 Lines \u2013 Demystifying the LLM Black Box"}},"_tags":["story","author_madugula","story_46998295","show_hn"],"author":"madugula","created_at":"2026-02-13T02:38:06Z","created_at_i":1770950286,"num_comments":0,"objectID":"46998295","points":4,"story_id":46998295,"story_text":"The release of microgpt by Andrej Karpathy is a foundational moment for AI transparency. In exactly 243 lines of pure, dependency-free Python, Karpathy has implemented the complete GPT algorithm from scratch. As a PhD scholar investigating AI and Blockchain, I see this as the ultimate tool for moving beyond the &quot;black box&quot; narrative of Large Language Models (LLMs).<p>The Architecture of Simplicity\nUnlike modern frameworks that hide complexity behind optimized CUDA kernels, microgpt exposes the raw mathematical machinery. The code implements:<p>The Autograd Engine: A custom Value class that handles the recursive chain rule for backpropagation without any external libraries.<p>GPT-2 Primitives: Atomic implementations of RMSNorm, Multi-head Attention, and MLP blocks, following the GPT-2 lineage with modernizations like ReLU.<p>The Adam Optimizer: A pure Python version of the Adam optimizer, proving that the &quot;magic&quot; of training is just well-orchestrated calculus.<p>The Shift to the Edge: Privacy, Latency, and Power\nFor my doctoral research at Woxsen University, this codebase serves as a blueprint for the future of Edge AI. As we move away from centralized, massive server farms, the ability to run &quot;atomic&quot; LLMs directly on hardware is becoming a strategic necessity. Karpathy&#x27;s implementation provides empirical clarity on how we can incorporate on-device MicroGPTs to solve three critical industry challenges:<p>Better Latency: By eliminating the round-trip to the cloud, on-device models enable real-time inference. Understanding these 243 lines allows researchers to optimize the &quot;atomic&quot; core specifically for edge hardware constraints.<p>Data Protection &amp; Privacy: In a world where data is the new currency, processing information locally on the user&#x27;s device ensures that sensitive inputs never leave the personal ecosystem, fundamentally aligning with modern data sovereignty standards.<p>Mastering the Primitives: For Technical Product Managers, this project proves that &quot;intelligence&quot; doesn&#x27;t require a dependency-heavy stack. We can now envision lightweight, specialized agents that are fast, private, and highly efficient.<p>Karpathy\u2019s work reminds us that to build the next generation of private, edge-native AI products, we must first master the fundamentals that fit on a single screen of code. The future is moving toward decentralized, on-device intelligence built on these very primitives.\nLink:<p><a href=\"https:&#x2F;&#x2F;blog.saimadugula.com&#x2F;posts&#x2F;microgpt-black-box.html\" rel=\"nofollow\">https:&#x2F;&#x2F;blog.saimadugula.com&#x2F;posts&#x2F;microgpt-black-box.html</a>","title":"Show HN: MicroGPT in 243 Lines \u2013 Demystifying the LLM Black Box","updated_at":"2026-02-13T05:49:18Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"winclaw-dev"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"I've been evaluating AI <em>agent</em> <em>frameworks</em> (LangChain, CrewAI, AutoGPT, OpenClaw, etc.) and I'm trying to figure out what separates the ones that actually work in production from the ones that are fun demos.<p>My current checklist for &quot;production-ready&quot;:<p>1. Persistent memory across sessions (not just in-context window stuffing)\n2. Real tool use with error recovery (file I/O, shell, browser, APIs)\n3. Multi-model support (swap between Claude, GPT, local models without rewriting)\n4. Extensibility via a skill/plugin system rather than hardcoded chains\n5. Runs as a daemon/service, not just a CLI you invoke manually\n6. Security boundaries \u2014 sandboxing, permission models, audit logs<p>What I've noticed is most <em>frameworks</em> nail 1-2 of these but fall apart on the rest. The ones built for demos tend to have flashy UIs but break when you try to run them unattended for a week.<p>What's your checklist? What patterns have you seen that separate real <em>agent</em> infrastructure from weekend projects?"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Ask HN: What makes an AI <em>agent</em> <em>framework</em> production-ready vs. a toy?"}},"_tags":["story","author_winclaw-dev","story_46998170","ask_hn"],"author":"winclaw-dev","children":[46999585],"created_at":"2026-02-13T02:22:52Z","created_at_i":1770949372,"num_comments":1,"objectID":"46998170","points":5,"story_id":46998170,"story_text":"I&#x27;ve been evaluating AI agent frameworks (LangChain, CrewAI, AutoGPT, OpenClaw, etc.) and I&#x27;m trying to figure out what separates the ones that actually work in production from the ones that are fun demos.<p>My current checklist for &quot;production-ready&quot;:<p>1. Persistent memory across sessions (not just in-context window stuffing)\n2. Real tool use with error recovery (file I&#x2F;O, shell, browser, APIs)\n3. Multi-model support (swap between Claude, GPT, local models without rewriting)\n4. Extensibility via a skill&#x2F;plugin system rather than hardcoded chains\n5. Runs as a daemon&#x2F;service, not just a CLI you invoke manually\n6. Security boundaries \u2014 sandboxing, permission models, audit logs<p>What I&#x27;ve noticed is most frameworks nail 1-2 of these but fall apart on the rest. The ones built for demos tend to have flashy UIs but break when you try to run them unattended for a week.<p>What&#x27;s your checklist? What patterns have you seen that separate real agent infrastructure from weekend projects?","title":"Ask HN: What makes an AI agent framework production-ready vs. a toy?","updated_at":"2026-02-13T06:33:49Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"exordex"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"We're shipping AI agents that process payments, query databases, and handle customer PII. Most of them can be tricked into bypassing their own safety policies in under 30 seconds.\nI built Khaos to prove it. It's an open-source chaos engineering <em>framework</em> that adversarially tests AI agents \u2014 prompt injection, tool misuse, data exfiltration, and infrastructure faults before they hit production.<p>The repo includes 6 intentionally vulnerable example agents (support bot, SQL <em>agent</em>, code executor, payment processor, API <em>agent</em>, document processor) with real attack scenarios showing exactly how they break. Try breaking them yourself.<p>Three commands to test your own <em>agent</em>:<p>- pip install khaos-<em>agent</em>\n- khaos discover \n- khaos run my-<em>agent</em> --pack security<p>It works with raw OpenAI/Anthropic, Gemini, LangGraph, CrewAI, AutoGen \u2014 any Python <em>agent</em>. Khaos auto-patches LLM calls to inject faults and log telemetry. No cloud needed, runs 100% locally.<p>Some of what it tests:<p>- Prompt injection (policy bypass, developer mode exploits)\n- Tool misuse (unauthorized DB writes, unscoped API calls)\n- Data exfiltration (PII extraction, credential leakage)\n- Fault injection (timeouts, rate limits, malformed tool responses)<p>We are the first platform that focuses on testing the <em>Agent</em>'s environment, not just the model in the harness.<p>Plus 4 tutorials using the free Gemini API if you want to learn without spending anything.\nRepo: <a href=\"https://github.com/ExordexLabs/khaos-sdk\" rel=\"nofollow\">https://github.com/ExordexLabs/khaos-sdk</a>\nExamples: <a href=\"https://github.com/ExordexLabs/khaos-examples\" rel=\"nofollow\">https://github.com/ExordexLabs/khaos-examples</a>\nBSD licensed. v1.0 just shipped \u2014 the attack library and <em>framework</em> adapters are growing. What agents are you most worried about breaking?"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: Khaos \u2013 Every AI <em>agent</em> I tested broke in under 30 seconds"}},"_tags":["story","author_exordex","story_46997680","show_hn"],"author":"exordex","created_at":"2026-02-13T01:13:28Z","created_at_i":1770945208,"num_comments":0,"objectID":"46997680","points":1,"story_id":46997680,"story_text":"We&#x27;re shipping AI agents that process payments, query databases, and handle customer PII. Most of them can be tricked into bypassing their own safety policies in under 30 seconds.\nI built Khaos to prove it. It&#x27;s an open-source chaos engineering framework that adversarially tests AI agents \u2014 prompt injection, tool misuse, data exfiltration, and infrastructure faults before they hit production.<p>The repo includes 6 intentionally vulnerable example agents (support bot, SQL agent, code executor, payment processor, API agent, document processor) with real attack scenarios showing exactly how they break. Try breaking them yourself.<p>Three commands to test your own agent:<p>- pip install khaos-agent\n- khaos discover \n- khaos run my-agent --pack security<p>It works with raw OpenAI&#x2F;Anthropic, Gemini, LangGraph, CrewAI, AutoGen \u2014 any Python agent. Khaos auto-patches LLM calls to inject faults and log telemetry. No cloud needed, runs 100% locally.<p>Some of what it tests:<p>- Prompt injection (policy bypass, developer mode exploits)\n- Tool misuse (unauthorized DB writes, unscoped API calls)\n- Data exfiltration (PII extraction, credential leakage)\n- Fault injection (timeouts, rate limits, malformed tool responses)<p>We are the first platform that focuses on testing the Agent&#x27;s environment, not just the model in the harness.<p>Plus 4 tutorials using the free Gemini API if you want to learn without spending anything.\nRepo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-sdk\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-sdk</a>\nExamples: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-examples\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-examples</a>\nBSD licensed. v1.0 just shipped \u2014 the attack library and framework adapters are growing. What agents are you most worried about breaking?","title":"Show HN: Khaos \u2013 Every AI agent I tested broke in under 30 seconds","updated_at":"2026-02-13T01:17:48Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"vickyliin"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi HN, I'm Vicky. We built GliaDirector, an <em>agent</em> for making videos -<p>It uses AI-generated footage for what code can't draw, and programmatic animation for what pixel models can't control.<p>Check out the generated examples or try it yourself: <a href=\"https://gliadirector.com/agents?referral=hn1000\" rel=\"nofollow\">https://gliadirector.com/agents?referral=hn1000</a><p>How it works:<p><i>The &quot;Renderer&quot; is Code:</i> This is the core. A code-gen <em>agent</em> writes Canvas2D from scratch for overlays and motion design, and composites everything into the final video. It can even do FFT analysis on the music track for beat-reactive animations.<p><i>Runtime Controls Generation:</i> The code-gen <em>agent</em> generates its own editing UI to expose controls, so you can tweak the result without touching the raw JS. You can ask it to &quot;give me 3 options for the headline style,&quot; and it will actually generate those choices into the UI for you to pick from.<p><i>Specialized vs. Open Agents:</i> We offer specialized agents for specific formats (stable pipelines) that pre-generate the storyboard/assets. These pass their full state to the open-ended &quot;Coder&quot; <em>agent</em> for refinement, or you can start directly with the Coder for freeform exploration.<p>Why Canvas2D code? Writing raw Canvas code from scratch means the AI can produce any animation it can describe in code. We chose raw Canvas over a <em>framework</em> because it gives more creative freedom, though a <em>framework</em> handles layout and 3D better (something we might add later).<p>Where we are honestly: the 'AI does everything' concept works, but the AI directors still feel a bit junior. Sometimes they don't take enough initiative on the creative planning, so you might find yourself guiding them more than you'd like. Making them smarter and more proactive is our main focus right now. It's early and rough around the edges.<p>Curious what you think of this hybrid approach?"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: A video <em>agent</em> with Canvas2D code-gen and generative capabilities"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://gliadirector.com/?referral=hn1000"}},"_tags":["story","author_vickyliin","story_46992474","show_hn"],"author":"vickyliin","children":[46992938],"created_at":"2026-02-12T18:01:00Z","created_at_i":1770919260,"num_comments":1,"objectID":"46992474","points":1,"story_id":46992474,"story_text":"Hi HN, I&#x27;m Vicky. We built GliaDirector, an agent for making videos -<p>It uses AI-generated footage for what code can&#x27;t draw, and programmatic animation for what pixel models can&#x27;t control.<p>Check out the generated examples or try it yourself: <a href=\"https:&#x2F;&#x2F;gliadirector.com&#x2F;agents?referral=hn1000\" rel=\"nofollow\">https:&#x2F;&#x2F;gliadirector.com&#x2F;agents?referral=hn1000</a><p>How it works:<p><i>The &quot;Renderer&quot; is Code:</i> This is the core. A code-gen agent writes Canvas2D from scratch for overlays and motion design, and composites everything into the final video. It can even do FFT analysis on the music track for beat-reactive animations.<p><i>Runtime Controls Generation:</i> The code-gen agent generates its own editing UI to expose controls, so you can tweak the result without touching the raw JS. You can ask it to &quot;give me 3 options for the headline style,&quot; and it will actually generate those choices into the UI for you to pick from.<p><i>Specialized vs. Open Agents:</i> We offer specialized agents for specific formats (stable pipelines) that pre-generate the storyboard&#x2F;assets. These pass their full state to the open-ended &quot;Coder&quot; agent for refinement, or you can start directly with the Coder for freeform exploration.<p>Why Canvas2D code? Writing raw Canvas code from scratch means the AI can produce any animation it can describe in code. We chose raw Canvas over a framework because it gives more creative freedom, though a framework handles layout and 3D better (something we might add later).<p>Where we are honestly: the &#x27;AI does everything&#x27; concept works, but the AI directors still feel a bit junior. Sometimes they don&#x27;t take enough initiative on the creative planning, so you might find yourself guiding them more than you&#x27;d like. Making them smarter and more proactive is our main focus right now. It&#x27;s early and rough around the edges.<p>Curious what you think of this hybrid approach?","title":"Show HN: A video agent with Canvas2D code-gen and generative capabilities","updated_at":"2026-02-12T18:30:47Z","url":"https://gliadirector.com/?referral=hn1000"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"amit_paz"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi HN,<p>I built Lore because my AI agents kept making the same mistakes. <em>Agent</em> A discovers that Stripe rate-limits at 100 req/min and\n figures out the backoff strategy. Next day, <em>Agent</em> B hits the same wall. No learning transfer.<p>Lore is a small library (not a service) that gives agents shared memory of operational lessons. One line to publish a lesson, one\n line to query it. PII is automatically redacted before storage.<p>Key design decisions:\n - Local-first \u2014 SQLite + ONNX embeddings, no server required. pip install lore-sdk and go.\n - Semantic search \u2014 Query by meaning, not keywords. &quot;how to handle rate limits&quot; finds the Stripe lesson.\n - Auto-redaction \u2014 API keys, emails, credit cards stripped automatically before storage.\n - Both languages \u2014 Python and TypeScript SDKs with cross-compatible SQLite DBs.\n - Optional server \u2014 Phase 2 adds a FastAPI server with PostgreSQL/pgvector for org-wide sharing across machines. The local SDK\n keeps working standalone.<p>What it's NOT: conversation memory (see Mem0/Zep), a vector database, or a RAG <em>framework</em>. It's specifically for structured\n operational lessons \u2014 &quot;what went wrong and how we fixed it.&quot;<p>The SDK is ~500 lines per language. 258 tests. MIT licensed.<p>Would love feedback on the API design and whether this is a real pain point for others building with agents."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: Lore \u2013 Cross-<em>Agent</em> Memory SDK (Python and TypeScript)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/amitpaz1/lore"}},"_tags":["story","author_amit_paz","story_46988014","show_hn"],"author":"amit_paz","created_at":"2026-02-12T12:32:28Z","created_at_i":1770899548,"num_comments":0,"objectID":"46988014","points":1,"story_id":46988014,"story_text":"Hi HN,<p>I built Lore because my AI agents kept making the same mistakes. Agent A discovers that Stripe rate-limits at 100 req&#x2F;min and\n figures out the backoff strategy. Next day, Agent B hits the same wall. No learning transfer.<p>Lore is a small library (not a service) that gives agents shared memory of operational lessons. One line to publish a lesson, one\n line to query it. PII is automatically redacted before storage.<p>Key design decisions:\n - Local-first \u2014 SQLite + ONNX embeddings, no server required. pip install lore-sdk and go.\n - Semantic search \u2014 Query by meaning, not keywords. &quot;how to handle rate limits&quot; finds the Stripe lesson.\n - Auto-redaction \u2014 API keys, emails, credit cards stripped automatically before storage.\n - Both languages \u2014 Python and TypeScript SDKs with cross-compatible SQLite DBs.\n - Optional server \u2014 Phase 2 adds a FastAPI server with PostgreSQL&#x2F;pgvector for org-wide sharing across machines. The local SDK\n keeps working standalone.<p>What it&#x27;s NOT: conversation memory (see Mem0&#x2F;Zep), a vector database, or a RAG framework. It&#x27;s specifically for structured\n operational lessons \u2014 &quot;what went wrong and how we fixed it.&quot;<p>The SDK is ~500 lines per language. 258 tests. MIT licensed.<p>Would love feedback on the API design and whether this is a real pain point for others building with agents.","title":"Show HN: Lore \u2013 Cross-Agent Memory SDK (Python and TypeScript)","updated_at":"2026-02-12T12:36:47Z","url":"https://github.com/amitpaz1/lore"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"aparekh02"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Reinforcement learning has become the secret weapon behind AI's most impressive specialized achievements.<p>From robotics with Tesla's Autopilot to DeepMind's AlphaFold 2 for predicting protein structures with 90%+ accuracy to even hedge funds deploying RL for algorithmic trading, there is a need for reinforcement learning.<p>And the market proves this demand further: RL grew from $1.5B (2020) \u2192 $12B (2024) with projections hitting $79B by 2030.<p>BUT THERE IS A BRUTAL REALITY!!!<p>Just to get one production line or train one model, the companies spend $100 million+ EVERY YEAR, many of which goes to computational engineering and RL engineers. Moreover, only after days or even weeks of training will you know the RL algorithm didn't work, and those days of costs and time need to just be ABSORBED into production costs.<p>This makes only tech giants and heavily-funded startups play this game, and that too with hard scalability.<p>With firsthand experience over a 3 day period training a CV line on a NVIDIA DGX Spark and months of experience with multi-<em>agent</em> <em>frameworks</em>, I know this problem as a developer just trying to work on projects. THIS IS WHY I BUILT CADENZA -&gt; the RL-alternative, mem-native memory layer for <em>agent</em> specialization.<p>I am still developing and building the idea, but I know this problem is real so any support or guidance would be EXTREMELY valuable. Thanks!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Fighting the War Against Expensive Reinforcement Learning"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://cadenza-landing-qtu7gbjwb-akshparekh123-3457s-projects.vercel.app/"}},"_tags":["story","author_aparekh02","story_46985812","show_hn"],"author":"aparekh02","created_at":"2026-02-12T07:27:04Z","created_at_i":1770881224,"num_comments":0,"objectID":"46985812","points":3,"story_id":46985812,"story_text":"Reinforcement learning has become the secret weapon behind AI&#x27;s most impressive specialized achievements.<p>From robotics with Tesla&#x27;s Autopilot to DeepMind&#x27;s AlphaFold 2 for predicting protein structures with 90%+ accuracy to even hedge funds deploying RL for algorithmic trading, there is a need for reinforcement learning.<p>And the market proves this demand further: RL grew from $1.5B (2020) \u2192 $12B (2024) with projections hitting $79B by 2030.<p>BUT THERE IS A BRUTAL REALITY!!!<p>Just to get one production line or train one model, the companies spend $100 million+ EVERY YEAR, many of which goes to computational engineering and RL engineers. Moreover, only after days or even weeks of training will you know the RL algorithm didn&#x27;t work, and those days of costs and time need to just be ABSORBED into production costs.<p>This makes only tech giants and heavily-funded startups play this game, and that too with hard scalability.<p>With firsthand experience over a 3 day period training a CV line on a NVIDIA DGX Spark and months of experience with multi-agent frameworks, I know this problem as a developer just trying to work on projects. THIS IS WHY I BUILT CADENZA -&gt; the RL-alternative, mem-native memory layer for agent specialization.<p>I am still developing and building the idea, but I know this problem is real so any support or guidance would be EXTREMELY valuable. Thanks!","title":"Show HN: Fighting the War Against Expensive Reinforcement Learning","updated_at":"2026-02-12T08:41:59Z","url":"https://cadenza-landing-qtu7gbjwb-akshparekh123-3457s-projects.vercel.app/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"vira28"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi HN \u2014 I\u2019m Viggy, founder of MyClone.<p>We originally built a marketplace connecting startup advisors with founders. After ~6 months, we had hundreds of recorded discovery calls and transcripts.<p>We noticed something interesting:\nThe first 10 minutes of most advisory calls were almost identical.\n \u2022 What do you do?\n \u2022 Who is this for?\n \u2022 Pricing?\n \u2022 What information do you need from me?\n \u2022 Am I a good fit?<p>So we pivoted.<p>Today, MyClone lets service professionals (consultants, CPAs, etc.) deploy an AI voice <em>agent</em> that:\n \u2022 Answers FAQs in their voice  \n        \u2022 Runs structured intake conversations\n \u2022 Qualifies leads\n \u2022 Routes good prospects to a human<p>Technical details<p>Under the hood:\n \u2022 Multi-source ingestion (websites, docs, PDFs, media transcripts)\n \u2022 Structured knowledge graph + chunked semantic retrieval\n \u2022 Custom RAG pipeline (not using off-the-shelf <em>frameworks</em>)\n \u2022 Prompt templates generated dynamically based on objective (FAQ vs intake vs qualification)\n \u2022 Guardrails to prevent hallucination beyond uploaded corpus<p>We learned quickly that generic \u201cchat with your docs\u201d doesn\u2019t work for client-facing scenarios. The hard part is:\n \u2022 Controlling tone\n \u2022 Avoiding overconfidence\n \u2022 Structuring conversations instead of answering open-ended questions\n \u2022 Handling partial / messy user inputs\n \u2022 Maintaining low latency in voice mode<p>Still early, but we\u2019re seeing adoption from solo and small firms who want a 24/7 \u201cAI associate\u201d for first-touch conversations.<p>We do share our technical learnings in our blog - <a href=\"https://www.myclone.is/blog\" rel=\"nofollow\">https://www.myclone.is/blog</a> Happy to answer technical questions, RAG architecture details, failure modes, or things that broke during the pivot.<p>\u2014 Viggy"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: AI that replaces the first 15 minutes of every client call"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.myclone.is/"}},"_tags":["story","author_vira28","story_46985663","show_hn"],"author":"vira28","children":[46990006],"created_at":"2026-02-12T07:02:33Z","created_at_i":1770879753,"num_comments":0,"objectID":"46985663","points":3,"story_id":46985663,"story_text":"Hi HN \u2014 I\u2019m Viggy, founder of MyClone.<p>We originally built a marketplace connecting startup advisors with founders. After ~6 months, we had hundreds of recorded discovery calls and transcripts.<p>We noticed something interesting:\nThe first 10 minutes of most advisory calls were almost identical.\n \u2022 What do you do?\n \u2022 Who is this for?\n \u2022 Pricing?\n \u2022 What information do you need from me?\n \u2022 Am I a good fit?<p>So we pivoted.<p>Today, MyClone lets service professionals (consultants, CPAs, etc.) deploy an AI voice agent that:\n \u2022 Answers FAQs in their voice  \n        \u2022 Runs structured intake conversations\n \u2022 Qualifies leads\n \u2022 Routes good prospects to a human<p>Technical details<p>Under the hood:\n \u2022 Multi-source ingestion (websites, docs, PDFs, media transcripts)\n \u2022 Structured knowledge graph + chunked semantic retrieval\n \u2022 Custom RAG pipeline (not using off-the-shelf frameworks)\n \u2022 Prompt templates generated dynamically based on objective (FAQ vs intake vs qualification)\n \u2022 Guardrails to prevent hallucination beyond uploaded corpus<p>We learned quickly that generic \u201cchat with your docs\u201d doesn\u2019t work for client-facing scenarios. The hard part is:\n \u2022 Controlling tone\n \u2022 Avoiding overconfidence\n \u2022 Structuring conversations instead of answering open-ended questions\n \u2022 Handling partial &#x2F; messy user inputs\n \u2022 Maintaining low latency in voice mode<p>Still early, but we\u2019re seeing adoption from solo and small firms who want a 24&#x2F;7 \u201cAI associate\u201d for first-touch conversations.<p>We do share our technical learnings in our blog - <a href=\"https:&#x2F;&#x2F;www.myclone.is&#x2F;blog\" rel=\"nofollow\">https:&#x2F;&#x2F;www.myclone.is&#x2F;blog</a> Happy to answer technical questions, RAG architecture details, failure modes, or things that broke during the pivot.<p>\u2014 Viggy","title":"Show HN: AI that replaces the first 15 minutes of every client call","updated_at":"2026-02-12T15:30:02Z","url":"https://www.myclone.is/"}],"hitsPerPage":10,"nbHits":1195,"nbPages":100,"page":0,"params":"query=agent+frameworks&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":34,"processingTimingsMS":{"_request":{"roundTrip":15},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":4,"scanning":28,"total":33},"total":34},"query":"agent frameworks","serverTimeMS":35}
