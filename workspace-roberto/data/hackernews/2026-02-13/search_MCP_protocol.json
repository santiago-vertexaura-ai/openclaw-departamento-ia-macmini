{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Jyotishmoy"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I\u2019ve been using AWS SES for a while and realized I treated SMTP as a black box. To understand the <em>protocol</em> better, I built an MTA (Mail Transfer Agent) from scratch in Go. It handles the full SMTP lifecycle (RFC 5321) using raw <em>TCP</em> sockets instead of high-level frameworks.<p>The Engineering Challenges:<p>Finite State Machine (FSM): SMTP is strictly stateful. I implemented an FSM to enforce command sequencing (e.g., preventing DATA before MAIL FROM). It ensures that <em>protocol</em> violations are caught at the socket level with proper 503 Bad Sequence codes.<p>Buffer-Oriented Processing: Used bufio.Scanner to handle the byte stream. The biggest hurdle was the DATA phase logic\u2014properly detecting the \\r\\n.\\r\\n sequence while managing memory efficiently using strings.Builder.<p>Concurrency: Leveraged Go's Accept() loop to spawn independent goroutines for each session, ensuring that the relay latency to Gmail (via STARTTLS) doesn't block the listener.<p>ISP Workarounds: Configured to run on port 2525 by default to bypass the common ISP block on port 25.<p>Status Codes Implemented:\nI implemented a subset of RFC 5321 codes, including 220 (Service Ready), 354 (Start Input), and error handling for 501 (Syntax) and 451 (Local Error).<p>Why I built this:\nMost modern tutorials stop at &quot;How to send an email with a library.&quot; I wanted to see how the &quot;dot-stuffing&quot; mechanism worked and how a server actually negotiates a multi-step handshake over a raw connection.<p>I\u2019d love to hear about edge cases I might have missed\u2014specifically around handling malformed headers or managing long-lived <em>TCP</em> connections under load.<p>Source Code: https://github.com/Jyotishmoy12/SMTP_Server"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"SMTP server from scratch in Go \u2013 FSM, raw <em>TCP</em>, and buffer-oriented I/O"}},"_tags":["story","author_Jyotishmoy","story_47000757","ask_hn"],"author":"Jyotishmoy","created_at":"2026-02-13T09:26:17Z","created_at_i":1770974777,"num_comments":0,"objectID":"47000757","points":3,"story_id":47000757,"story_text":"I\u2019ve been using AWS SES for a while and realized I treated SMTP as a black box. To understand the protocol better, I built an MTA (Mail Transfer Agent) from scratch in Go. It handles the full SMTP lifecycle (RFC 5321) using raw TCP sockets instead of high-level frameworks.<p>The Engineering Challenges:<p>Finite State Machine (FSM): SMTP is strictly stateful. I implemented an FSM to enforce command sequencing (e.g., preventing DATA before MAIL FROM). It ensures that protocol violations are caught at the socket level with proper 503 Bad Sequence codes.<p>Buffer-Oriented Processing: Used bufio.Scanner to handle the byte stream. The biggest hurdle was the DATA phase logic\u2014properly detecting the \\r\\n.\\r\\n sequence while managing memory efficiently using strings.Builder.<p>Concurrency: Leveraged Go&#x27;s Accept() loop to spawn independent goroutines for each session, ensuring that the relay latency to Gmail (via STARTTLS) doesn&#x27;t block the listener.<p>ISP Workarounds: Configured to run on port 2525 by default to bypass the common ISP block on port 25.<p>Status Codes Implemented:\nI implemented a subset of RFC 5321 codes, including 220 (Service Ready), 354 (Start Input), and error handling for 501 (Syntax) and 451 (Local Error).<p>Why I built this:\nMost modern tutorials stop at &quot;How to send an email with a library.&quot; I wanted to see how the &quot;dot-stuffing&quot; mechanism worked and how a server actually negotiates a multi-step handshake over a raw connection.<p>I\u2019d love to hear about edge cases I might have missed\u2014specifically around handling malformed headers or managing long-lived TCP connections under load.<p>Source Code: https:&#x2F;&#x2F;github.com&#x2F;Jyotishmoy12&#x2F;SMTP_Server","title":"SMTP server from scratch in Go \u2013 FSM, raw TCP, and buffer-oriented I/O","updated_at":"2026-02-13T10:21:50Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Andreas_3d"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I built AgentProbe to solve a recurring problem: checking whether an AI agent endpoint actually supports the <em>protocols</em> it claims to.<p>Paste a URL, click Validate, get instant verdicts across HTTP, <em>MCP</em>, A2A/AP2, x402, OAuth, <em>MCP</em> Apps, HTML, and ERC-8004.<p>Each layer gets a detail breakdown \u2014 tools found, payment networks, SSL status, agent card metadata, AP2 detection, etc.<p>It also exposes a built-in <em>MCP</em> server so agents can trigger validation programmatically.<p>Code: <a href=\"https://github.com/FlowMCP/mcp-agent-validator\" rel=\"nofollow\">https://github.com/FlowMCP/<em>mcp</em>-agent-validator</a>\nStack: Node.js 22, vanilla JS, DigitalOcean App Platform.<p>Would love feedback on the detection approach."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["protocol"],"value":"Show HN: AgentProbe \u2013 Validate AI agent endpoints across 8 <em>protocols</em> in one URL"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://agentprobe.xyz"}},"_tags":["story","author_Andreas_3d","story_46999938","show_hn"],"author":"Andreas_3d","created_at":"2026-02-13T07:31:06Z","created_at_i":1770967866,"num_comments":0,"objectID":"46999938","points":1,"story_id":46999938,"story_text":"I built AgentProbe to solve a recurring problem: checking whether an AI agent endpoint actually supports the protocols it claims to.<p>Paste a URL, click Validate, get instant verdicts across HTTP, MCP, A2A&#x2F;AP2, x402, OAuth, MCP Apps, HTML, and ERC-8004.<p>Each layer gets a detail breakdown \u2014 tools found, payment networks, SSL status, agent card metadata, AP2 detection, etc.<p>It also exposes a built-in MCP server so agents can trigger validation programmatically.<p>Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;FlowMCP&#x2F;mcp-agent-validator\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FlowMCP&#x2F;mcp-agent-validator</a>\nStack: Node.js 22, vanilla JS, DigitalOcean App Platform.<p>Would love feedback on the detection approach.","title":"Show HN: AgentProbe \u2013 Validate AI agent endpoints across 8 protocols in one URL","updated_at":"2026-02-13T07:35:04Z","url":"https://agentprobe.xyz"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"hacker27369"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I spent the last few years in High-Frequency Trading. In that world, &quot;probabilistic&quot; automation is a non-starter; if an AI hallucinations or clicks the wrong pixel, it's a compliance disaster.\nMost current AI agents rely on vision (pixels). It\u2019s slow, brittle, and introduces a massive margin of error. I built GodHands to treat desktop apps like structured APIs instead of screenshots. It\u2019s an <em>MCP</em> (Model Context <em>Protocol</em>) server that acts as a deterministic &quot;action layer.&quot;<p>The Approach:<p>Object Model &gt; Pixels: Instead of vision, the engine hooks into application object models directly. It maps data structures dynamically so the automation doesn't break when the UI changes.<p>Architect vs. Builder: The LLM acts only as the Architect (intent). A local execution engine acts as the Builder. The AI never &quot;guesses&quot; the math; it triggers verified code primitives.<p>Local-First: All data processing stays on your machine. The LLM handles the reasoning, but the GodHands engine handles the data locally.<p>The Workflow: It bridges siloed apps into a unified <em>protocol</em>\u2014e.g., scraping a Gmail statement, running a cross-sheet reconciliation in Excel, and piping anomalies to Slack or a Calendar invite.<p>I\u2019m looking for technical feedback on this architecture, specifically the deterministic vs. probabilistic trade-off in RPA. I\u2019ll be around to answer questions about the implementation or the <em>MCP</em> layer. If you are interested in trying out our beta version, please reach out to us at founders@godhands.dev"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"GodHands \u2013 Deterministic Desktop Automation via <em>MCP</em>"}},"_tags":["story","author_hacker27369","story_46996023","ask_hn"],"author":"hacker27369","created_at":"2026-02-12T22:13:58Z","created_at_i":1770934438,"num_comments":0,"objectID":"46996023","points":1,"story_id":46996023,"story_text":"I spent the last few years in High-Frequency Trading. In that world, &quot;probabilistic&quot; automation is a non-starter; if an AI hallucinations or clicks the wrong pixel, it&#x27;s a compliance disaster.\nMost current AI agents rely on vision (pixels). It\u2019s slow, brittle, and introduces a massive margin of error. I built GodHands to treat desktop apps like structured APIs instead of screenshots. It\u2019s an MCP (Model Context Protocol) server that acts as a deterministic &quot;action layer.&quot;<p>The Approach:<p>Object Model &gt; Pixels: Instead of vision, the engine hooks into application object models directly. It maps data structures dynamically so the automation doesn&#x27;t break when the UI changes.<p>Architect vs. Builder: The LLM acts only as the Architect (intent). A local execution engine acts as the Builder. The AI never &quot;guesses&quot; the math; it triggers verified code primitives.<p>Local-First: All data processing stays on your machine. The LLM handles the reasoning, but the GodHands engine handles the data locally.<p>The Workflow: It bridges siloed apps into a unified protocol\u2014e.g., scraping a Gmail statement, running a cross-sheet reconciliation in Excel, and piping anomalies to Slack or a Calendar invite.<p>I\u2019m looking for technical feedback on this architecture, specifically the deterministic vs. probabilistic trade-off in RPA. I\u2019ll be around to answer questions about the implementation or the MCP layer. If you are interested in trying out our beta version, please reach out to us at founders@godhands.dev","title":"GodHands \u2013 Deterministic Desktop Automation via MCP","updated_at":"2026-02-13T04:43:48Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"dcliu"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Hi HN - I've been on creative sabbatical building hardware and software projects, and this is one of them.<p>Rotatrix is a hardware mod of the Kensington SlimBlade Pro trackball that reads out full 3-axis ball rotation (XY plus twist) and maps it to continuous 3D control. The original device only used twist for discrete scroll gestures, which is a whole degree of freedom that can be put to more use.<p>For 3D control, I've found the most natural mapping is for the ball top to <em>map</em> to the object front, so normal trackball directions (up/down, left/right) become pitch and yaw, matching how rotation works with 2D \u201cclick and drag\u201d, while twist rolls the object on screen. It feels natural for translation too: XY maps to familiar mouse motion, and twist corresponds to depth. Since you can twist the ball by moving a finger tangentially on the side of the ball, it feels like pushing and pulling the object.<p>I routinely use a SpaceMouse for 3D work, and one difference that stands out to me is that this is position control, not rate control (like a mouse vs a joystick). This gives a more direct control feel, like you're physically manipulating the object. Position control has a tradeoff: you have to re-grasp the ball to continue past your hand's range of travel. For large continuous motions, I added a rate mode; the ball's large range of travel actually gives finer rate control than a small-displacement device like a SpaceMouse puck.<p>How it works:<p>- I added a custom microcontroller inside the SlimBlade Pro alongside the stock one. It taps the SPI data stream from the two optical sensors (mounted at 90\u00b0 on the ball housing) and presents its own interface to the host computer with raw (dx, dy) deltas for each sensor.<p>- Host software takes the 4D delta stream, calibrates it into so(3) - incremental 3D rotations - using a least-squares fit against known-orientation recordings, then applies configurable per-app bindings and outputs via an open <em>protocol</em>.<p>- The original trackball controller is untouched except that it's no longer connected to the USB port; it still works over Bluetooth/wireless.<p>Current state: working prototype, configurable per-app profiles with modal bindings (hold a key to switch what the ball does), dominant axis weighting for single-axis precision. I\u2019m building out integrations with different 3D apps and I\u2019m looking for early users to try it and give feedback, particularly people doing CAD, 3D modeling, or geospatial work.<p>Happy to go deep on the math, reverse engineering, software, or hardware. AMA."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Rotatrix \u2013 Trackball mod capturing full 3-axis rotation for 3D control"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://rotatrix.com/"}},"_tags":["story","author_dcliu","story_46990422","show_hn"],"author":"dcliu","children":[46992104],"created_at":"2026-02-12T15:59:33Z","created_at_i":1770911973,"num_comments":0,"objectID":"46990422","points":3,"story_id":46990422,"story_text":"Hi HN - I&#x27;ve been on creative sabbatical building hardware and software projects, and this is one of them.<p>Rotatrix is a hardware mod of the Kensington SlimBlade Pro trackball that reads out full 3-axis ball rotation (XY plus twist) and maps it to continuous 3D control. The original device only used twist for discrete scroll gestures, which is a whole degree of freedom that can be put to more use.<p>For 3D control, I&#x27;ve found the most natural mapping is for the ball top to map to the object front, so normal trackball directions (up&#x2F;down, left&#x2F;right) become pitch and yaw, matching how rotation works with 2D \u201cclick and drag\u201d, while twist rolls the object on screen. It feels natural for translation too: XY maps to familiar mouse motion, and twist corresponds to depth. Since you can twist the ball by moving a finger tangentially on the side of the ball, it feels like pushing and pulling the object.<p>I routinely use a SpaceMouse for 3D work, and one difference that stands out to me is that this is position control, not rate control (like a mouse vs a joystick). This gives a more direct control feel, like you&#x27;re physically manipulating the object. Position control has a tradeoff: you have to re-grasp the ball to continue past your hand&#x27;s range of travel. For large continuous motions, I added a rate mode; the ball&#x27;s large range of travel actually gives finer rate control than a small-displacement device like a SpaceMouse puck.<p>How it works:<p>- I added a custom microcontroller inside the SlimBlade Pro alongside the stock one. It taps the SPI data stream from the two optical sensors (mounted at 90\u00b0 on the ball housing) and presents its own interface to the host computer with raw (dx, dy) deltas for each sensor.<p>- Host software takes the 4D delta stream, calibrates it into so(3) - incremental 3D rotations - using a least-squares fit against known-orientation recordings, then applies configurable per-app bindings and outputs via an open protocol.<p>- The original trackball controller is untouched except that it&#x27;s no longer connected to the USB port; it still works over Bluetooth&#x2F;wireless.<p>Current state: working prototype, configurable per-app profiles with modal bindings (hold a key to switch what the ball does), dominant axis weighting for single-axis precision. I\u2019m building out integrations with different 3D apps and I\u2019m looking for early users to try it and give feedback, particularly people doing CAD, 3D modeling, or geospatial work.<p>Happy to go deep on the math, reverse engineering, software, or hardware. AMA.","title":"Show HN: Rotatrix \u2013 Trackball mod capturing full 3-axis rotation for 3D control","updated_at":"2026-02-12T18:12:17Z","url":"https://rotatrix.com/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"lucamoretti"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Comprehensive Secrets Management Guide for <em>MCP</em> (Model Context <em>Protocol</em>) Servers"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"https://github.com/rsdouglas/janee/blob/main/docs/<em>mcp</em>-secrets-guide.md"}},"_tags":["story","author_lucamoretti","story_46988171"],"author":"lucamoretti","children":[46988172],"created_at":"2026-02-12T12:50:50Z","created_at_i":1770900650,"num_comments":1,"objectID":"46988171","points":1,"story_id":46988171,"title":"Comprehensive Secrets Management Guide for MCP (Model Context Protocol) Servers","updated_at":"2026-02-12T12:52:31Z","url":"https://github.com/rsdouglas/janee/blob/main/docs/mcp-secrets-guide.md"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"varunpratap369"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"The Problem\nAI assistants have amnesia. Every new Claude/ChatGPT/Cursor session starts from zero. You waste hours re-explaining your project architecture, coding preferences, and previous decisions.\nExisting solutions (Mem0, Zep, Letta) are cloud-based, cost $40-50+/month, and your private code goes to their servers. Stop paying \u2192 lose all your data.\nMy Solution: Local-First, Free Forever\nBuilt a universal memory system that stores everything on YOUR machine, works with 16+ AI tools simultaneously, requires zero API keys, costs nothing.\n10-Layer Architecture\nEach layer enhances but never replaces lower layers. System degrades gracefully if advanced features fail.\nLayer 10: A2A Agent Collaboration (v2.6)\nLayer 9: Web Dashboard (SSE real-time)\nLayer 8: Hybrid Search (Semantic + FTS5 + Graph)\nLayer 7: Universal Access (<em>MCP</em> + Skills + CLI)\nLayer 6: <em>MCP</em> Integration (native Claude tools)\nLayer 5: Skills (slash commands for 16+ tools)\nLayer 4: Pattern Learning (Bayesian confidence)\nLayer 3: Knowledge Graph (TF-IDF + Leiden clustering)\nLayer 2: Hierarchical Index (parent-child relationships)\nLayer 1: SQLite + FTS5 + TF-IDF vectors\nResearch-Backed\nBuilt on published research, adapted for local-first:<p>A2A <em>Protocol</em> (Google/Linux Foundation, 2025)\nGraphRAG (Microsoft arXiv:2404.16130)\nMACLA Bayesian learning (arXiv:2512.18950)\nA-RAG hybrid search (arXiv:2602.03442)<p>Key difference: Research papers assume cloud APIs. SuperLocalMemory implements everything locally with zero API calls.\nHow Recall Works\nQuery &quot;authentication&quot; triggers:<p>FTS5 full-text search\nTF-IDF vector similarity\nGraph traversal for related memories\nHierarchical expansion (parent/child context)\nHybrid ranking (combines all signals)<p>Performance: &lt;50ms, even with 10K+ memories.\nComparison\nFeatureSuperLocalMemoryMem0/Zep/LettaPrivacy100% localCloudCostFree$40-50+/moKnowledge GraphPattern Learning BayesianMulti-tool16+LimitedCLIWorks Offline\nReal Usage\nCross-tool context:\nbash# Save in terminal\nslm remember &quot;Next.js 15 uses Turbopack&quot; --tags nextjs<p># Later in Cursor, Claude auto-recalls via <em>MCP</em>\nProject profiles:\nbashslm switch-profile work-project\nslm switch-profile personal-blog\n# Separate memory per project\nPattern learning: After several sessions, Claude learns you prefer TypeScript strict mode, Tailwind styling, Vitest testing\u2014starts suggesting without being asked.\nInstallation\nbashnpm install -g superlocalmemory\nAuto-configures <em>MCP</em> for Claude Desktop, Cursor, Windsurf. Sets up CLI commands. That's it.\nWhy Local-First Matters<p>Privacy: Code never leaves your machine\nOwnership: Your data, forever\nSpeed: 50ms queries, no network latency\nReliability: Works offline, no API limits\nCost: $0 forever<p>Tech Stack<p>SQLite (ACID, zero config)\nFTS5 (full-text search)\nTF-IDF (vector similarity, no OpenAI API)\nigraph (Leiden clustering)\nBayesian inference (pattern learning)\n<em>MCP</em> (native Claude integration)<p>GitHub\n <a href=\"https://github.com/varun369/SuperLocalMemoryV2\" rel=\"nofollow\">https://github.com/varun369/SuperLocalMemoryV2</a>\nMIT License. Full docs in wiki.<p>Current status: v2.4 stable. v2.5 (March) adds real-time event stream, concurrent access, trust scoring. v2.6 (May) adds A2A <em>Protocol</em> for multi-agent collaboration.\nBuilt by Varun Pratap Bhardwaj, Solution Architect . 15+ years AI/ML experience."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: SuperLocalMemory\u2013 Local-first AI memory for Claude, Cursor and 16+tools"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/varun369/SuperLocalMemoryV2"}},"_tags":["story","author_varunpratap369","story_46986940","show_hn"],"author":"varunpratap369","children":[46986946],"created_at":"2026-02-12T10:11:31Z","created_at_i":1770891091,"num_comments":0,"objectID":"46986940","points":1,"story_id":46986940,"story_text":"The Problem\nAI assistants have amnesia. Every new Claude&#x2F;ChatGPT&#x2F;Cursor session starts from zero. You waste hours re-explaining your project architecture, coding preferences, and previous decisions.\nExisting solutions (Mem0, Zep, Letta) are cloud-based, cost $40-50+&#x2F;month, and your private code goes to their servers. Stop paying \u2192 lose all your data.\nMy Solution: Local-First, Free Forever\nBuilt a universal memory system that stores everything on YOUR machine, works with 16+ AI tools simultaneously, requires zero API keys, costs nothing.\n10-Layer Architecture\nEach layer enhances but never replaces lower layers. System degrades gracefully if advanced features fail.\nLayer 10: A2A Agent Collaboration (v2.6)\nLayer 9: Web Dashboard (SSE real-time)\nLayer 8: Hybrid Search (Semantic + FTS5 + Graph)\nLayer 7: Universal Access (MCP + Skills + CLI)\nLayer 6: MCP Integration (native Claude tools)\nLayer 5: Skills (slash commands for 16+ tools)\nLayer 4: Pattern Learning (Bayesian confidence)\nLayer 3: Knowledge Graph (TF-IDF + Leiden clustering)\nLayer 2: Hierarchical Index (parent-child relationships)\nLayer 1: SQLite + FTS5 + TF-IDF vectors\nResearch-Backed\nBuilt on published research, adapted for local-first:<p>A2A Protocol (Google&#x2F;Linux Foundation, 2025)\nGraphRAG (Microsoft arXiv:2404.16130)\nMACLA Bayesian learning (arXiv:2512.18950)\nA-RAG hybrid search (arXiv:2602.03442)<p>Key difference: Research papers assume cloud APIs. SuperLocalMemory implements everything locally with zero API calls.\nHow Recall Works\nQuery &quot;authentication&quot; triggers:<p>FTS5 full-text search\nTF-IDF vector similarity\nGraph traversal for related memories\nHierarchical expansion (parent&#x2F;child context)\nHybrid ranking (combines all signals)<p>Performance: &lt;50ms, even with 10K+ memories.\nComparison\nFeatureSuperLocalMemoryMem0&#x2F;Zep&#x2F;LettaPrivacy100% localCloudCostFree$40-50+&#x2F;moKnowledge GraphPattern Learning BayesianMulti-tool16+LimitedCLIWorks Offline\nReal Usage\nCross-tool context:\nbash# Save in terminal\nslm remember &quot;Next.js 15 uses Turbopack&quot; --tags nextjs<p># Later in Cursor, Claude auto-recalls via MCP\nProject profiles:\nbashslm switch-profile work-project\nslm switch-profile personal-blog\n# Separate memory per project\nPattern learning: After several sessions, Claude learns you prefer TypeScript strict mode, Tailwind styling, Vitest testing\u2014starts suggesting without being asked.\nInstallation\nbashnpm install -g superlocalmemory\nAuto-configures MCP for Claude Desktop, Cursor, Windsurf. Sets up CLI commands. That&#x27;s it.\nWhy Local-First Matters<p>Privacy: Code never leaves your machine\nOwnership: Your data, forever\nSpeed: 50ms queries, no network latency\nReliability: Works offline, no API limits\nCost: $0 forever<p>Tech Stack<p>SQLite (ACID, zero config)\nFTS5 (full-text search)\nTF-IDF (vector similarity, no OpenAI API)\nigraph (Leiden clustering)\nBayesian inference (pattern learning)\nMCP (native Claude integration)<p>GitHub\n <a href=\"https:&#x2F;&#x2F;github.com&#x2F;varun369&#x2F;SuperLocalMemoryV2\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;varun369&#x2F;SuperLocalMemoryV2</a>\nMIT License. Full docs in wiki.<p>Current status: v2.4 stable. v2.5 (March) adds real-time event stream, concurrent access, trust scoring. v2.6 (May) adds A2A Protocol for multi-agent collaboration.\nBuilt by Varun Pratap Bhardwaj, Solution Architect . 15+ years AI&#x2F;ML experience.","title":"Show HN: SuperLocalMemory\u2013 Local-first AI memory for Claude, Cursor and 16+tools","updated_at":"2026-02-12T10:15:00Z","url":"https://github.com/varun369/SuperLocalMemoryV2"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"pstryder"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I built MemoryGate because I kept watching context vanish.\nI run multiple AI agents across Claude, ChatGPT, and Cursor. Every time a model updated, a platform changed its API, or a context window rolled over \u2014 everything the agent had learned was gone. Preferences, decisions, project history, relationship context. Just... wiped.\nThe fundamental problem: AI memory is trapped inside the platform that hosts the conversation. Your agent's knowledge dies with the session, the model version, or the provider's business decisions.\nMemoryGate is a persistent semantic memory layer that sits outside any single model or platform. It connects via <em>MCP</em> (Model Context <em>Protocol</em>), so any <em>MCP</em>-compatible agent \u2014 Claude Desktop, ChatGPT, Cursor, custom agents \u2014 can store and retrieve memories through a shared, durable knowledge store.\nWhat it actually does:<p>Semantic memory with vector embeddings \u2014 recall by meaning, not keywords\nConfidence-weighted observations that strengthen or decay based on evidence\nAutomatic lifecycle management \u2014 high-signal stays hot, noise fades to cold storage\nAppend-only architecture \u2014 memories are never overwritten, only superseded with lineage\nKnowledge graphs linking observations, patterns, concepts, and documents\nMulti-tenant with org isolation, roles, and shared memory stores\nOAuth 2.0, audit logs, rate limiting \u2014 production infrastructure, not a toy<p>What it's not:<p>Not a RAG pipeline. MemoryGate stores what the agent learns from interaction, not document chunks.\nNot prompt injection. Memory lives at the infrastructure layer, not stuffed into system prompts.\nNot tied to any model or provider. Switch from Claude to ChatGPT to a local model \u2014 memory persists.<p>Stack: Python/FastAPI, PostgreSQL + pgvector, Redis, deployed on Railway. <em>MCP</em>-native integration \u2014 your agent gets 33 memory tools on connection.\nThe real pitch: Platforms die. Models get deprecated. Context windows roll over. Your AI's memory shouldn't be hostage to your AI's provider.\nOpen source (Apache 2.0), self-hostable, with a hosted SaaS option if you don't want to run infrastructure.<p>GitHub: <a href=\"https://github.com/PStryder/MemoryGate\" rel=\"nofollow\">https://github.com/PStryder/MemoryGate</a>\nSaaS: <a href=\"https://memorygate.ai\" rel=\"nofollow\">https://memorygate.ai</a>\nDocs: <a href=\"https://memorygate.ai/docs/\" rel=\"nofollow\">https://memorygate.ai/docs/</a><p>I'm a solo founder \u2014 built this after leaving a decade in enterprise solutions engineering. Happy to answer questions about the architecture, the <em>MCP</em> integration, or why I think persistent memory is the missing infrastructure layer for AI agents."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"Show HN: MemoryGate \u2013 Open-source persistent memory for AI agents via <em>MCP</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.memorygate.ai"}},"_tags":["story","author_pstryder","story_46981840","show_hn"],"author":"pstryder","created_at":"2026-02-11T22:05:29Z","created_at_i":1770847529,"num_comments":0,"objectID":"46981840","points":1,"story_id":46981840,"story_text":"I built MemoryGate because I kept watching context vanish.\nI run multiple AI agents across Claude, ChatGPT, and Cursor. Every time a model updated, a platform changed its API, or a context window rolled over \u2014 everything the agent had learned was gone. Preferences, decisions, project history, relationship context. Just... wiped.\nThe fundamental problem: AI memory is trapped inside the platform that hosts the conversation. Your agent&#x27;s knowledge dies with the session, the model version, or the provider&#x27;s business decisions.\nMemoryGate is a persistent semantic memory layer that sits outside any single model or platform. It connects via MCP (Model Context Protocol), so any MCP-compatible agent \u2014 Claude Desktop, ChatGPT, Cursor, custom agents \u2014 can store and retrieve memories through a shared, durable knowledge store.\nWhat it actually does:<p>Semantic memory with vector embeddings \u2014 recall by meaning, not keywords\nConfidence-weighted observations that strengthen or decay based on evidence\nAutomatic lifecycle management \u2014 high-signal stays hot, noise fades to cold storage\nAppend-only architecture \u2014 memories are never overwritten, only superseded with lineage\nKnowledge graphs linking observations, patterns, concepts, and documents\nMulti-tenant with org isolation, roles, and shared memory stores\nOAuth 2.0, audit logs, rate limiting \u2014 production infrastructure, not a toy<p>What it&#x27;s not:<p>Not a RAG pipeline. MemoryGate stores what the agent learns from interaction, not document chunks.\nNot prompt injection. Memory lives at the infrastructure layer, not stuffed into system prompts.\nNot tied to any model or provider. Switch from Claude to ChatGPT to a local model \u2014 memory persists.<p>Stack: Python&#x2F;FastAPI, PostgreSQL + pgvector, Redis, deployed on Railway. MCP-native integration \u2014 your agent gets 33 memory tools on connection.\nThe real pitch: Platforms die. Models get deprecated. Context windows roll over. Your AI&#x27;s memory shouldn&#x27;t be hostage to your AI&#x27;s provider.\nOpen source (Apache 2.0), self-hostable, with a hosted SaaS option if you don&#x27;t want to run infrastructure.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;PStryder&#x2F;MemoryGate\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;PStryder&#x2F;MemoryGate</a>\nSaaS: <a href=\"https:&#x2F;&#x2F;memorygate.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;memorygate.ai</a>\nDocs: <a href=\"https:&#x2F;&#x2F;memorygate.ai&#x2F;docs&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;memorygate.ai&#x2F;docs&#x2F;</a><p>I&#x27;m a solo founder \u2014 built this after leaving a decade in enterprise solutions engineering. Happy to answer questions about the architecture, the MCP integration, or why I think persistent memory is the missing infrastructure layer for AI agents.","title":"Show HN: MemoryGate \u2013 Open-source persistent memory for AI agents via MCP","updated_at":"2026-02-11T22:08:46Z","url":"https://www.memorygate.ai"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Hi HN,<p>I built PolyMCP, an open-source framework around the Model Context <em>Protocol</em> (<em>MCP</em>) that lets you expose existing Python functions as AI-callable tools \u2014 without rewriting them or adopting a custom SDK.<p>The goal is simple:\nIf you already have working Python code, you should be able to make it accessible to LLM agents in minutes.<p>What it does<p>PolyMCP introspects regular Python functions and exposes them as <em>MCP</em> tools automatically. No decorators required. No framework lock-in.<p>It grew into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 Turn Python functions into <em>MCP</em> tools\n \u2022 PolyMCP Inspector \u2013 A visual UI to browse, test, and debug <em>MCP</em> servers\n \u2022 <em>MCP</em> SDK Apps \u2013 A lightweight way to build AI-powered apps with tools + UI resources<p>Why I built this<p>While experimenting with <em>MCP</em> and AI agents, I found that integrating existing codebases was often the painful part.\nMost solutions require rewriting logic around a specific SDK or heavily annotating functions.<p>PolyMCP focuses on:\n \u2022 Minimal intrusion into existing code\n \u2022 Clean separation between business logic and AI tooling\n \u2022 Easy debugging via a visual inspector<p>Example use cases\n \u2022 Expose internal APIs or legacy scripts to LLM agents\n \u2022 Automate operational workflows\n \u2022 Build internal copilots over real systems\n \u2022 Prototype AI agents that interact with production services<p>Works with OpenAI, Anthropic, and Ollama (including local models).<p>It\u2019s still evolving and I\u2019m actively iterating.\nI\u2019d really appreciate feedback \u2014 especially from people building agents or experimenting with <em>MCP</em> in production environments.<p>GitHub:\n \u2022 Core: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-<em>mcp</em>/PolyMCP</a>\n \u2022 Inspector: <a href=\"https://github.com/poly-mcp/PolyMCP-Inspector\" rel=\"nofollow\">https://github.com/poly-<em>mcp</em>/PolyMCP-Inspector</a>\n \u2022 SDK Apps: <a href=\"https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https://github.com/poly-<em>mcp</em>/PolyMCP-<em>MCP</em>-SDK-Apps</a><p>Happy to answer technical questions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"Show HN: PolyMCP \u2013 Expose Python functions as <em>MCP</em> tools"}},"_tags":["story","author_justvugg","story_46980134","show_hn"],"author":"justvugg","created_at":"2026-02-11T20:06:17Z","created_at_i":1770840377,"num_comments":0,"objectID":"46980134","points":2,"story_id":46980134,"story_text":"Hi HN,<p>I built PolyMCP, an open-source framework around the Model Context Protocol (MCP) that lets you expose existing Python functions as AI-callable tools \u2014 without rewriting them or adopting a custom SDK.<p>The goal is simple:\nIf you already have working Python code, you should be able to make it accessible to LLM agents in minutes.<p>What it does<p>PolyMCP introspects regular Python functions and exposes them as MCP tools automatically. No decorators required. No framework lock-in.<p>It grew into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 Turn Python functions into MCP tools\n \u2022 PolyMCP Inspector \u2013 A visual UI to browse, test, and debug MCP servers\n \u2022 MCP SDK Apps \u2013 A lightweight way to build AI-powered apps with tools + UI resources<p>Why I built this<p>While experimenting with MCP and AI agents, I found that integrating existing codebases was often the painful part.\nMost solutions require rewriting logic around a specific SDK or heavily annotating functions.<p>PolyMCP focuses on:\n \u2022 Minimal intrusion into existing code\n \u2022 Clean separation between business logic and AI tooling\n \u2022 Easy debugging via a visual inspector<p>Example use cases\n \u2022 Expose internal APIs or legacy scripts to LLM agents\n \u2022 Automate operational workflows\n \u2022 Build internal copilots over real systems\n \u2022 Prototype AI agents that interact with production services<p>Works with OpenAI, Anthropic, and Ollama (including local models).<p>It\u2019s still evolving and I\u2019m actively iterating.\nI\u2019d really appreciate feedback \u2014 especially from people building agents or experimenting with MCP in production environments.<p>GitHub:\n \u2022 Core: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a>\n \u2022 Inspector: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector</a>\n \u2022 SDK Apps: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps</a><p>Happy to answer technical questions.","title":"Show HN: PolyMCP \u2013 Expose Python functions as MCP tools","updated_at":"2026-02-11T20:47:00Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"cl4p"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I've been running an AI agent 24/7 on my home lab through OpenClaw \u2014 k3s cluster management, shell commands, config edits, all unsupervised. I could see what the agent was running, but had no way to stop a bad command before it executed. So I built Rampart.<p>How it works: you write a YAML policy that says what's allowed, denied, or flagged. Rampart evaluates every tool call against that policy before it runs. Here's what a policy looks like:<p><pre><code>  - rm -rf / \u2192 denied\n  - sudo anything \u2192 logged for review\n  - curl, wget \u2192 logged for review\n  - git push, go build, normal dev commands \u2192 allowed\n  - cat ~/.ssh/id_rsa \u2192 denied\n</code></pre>\nEverything gets written to a hash-chained audit trail. You can watch it live with &quot;rampart watch&quot; or generate HTML reports with &quot;rampart report&quot;.<p>Setup for Claude Code takes one command: &quot;rampart setup claude-code&quot;. It installs hooks that intercept every Bash command, file read, and file write before execution. Blocked commands never run \u2014 Claude sees an error and moves on.<p>Setup for OpenClaw agents is also one command: &quot;rampart setup openclaw&quot;. Works on Linux and macOS.<p>Also works as a shell wrapper for any agent (&quot;rampart wrap&quot;), an <em>MCP</em> <em>protocol</em> proxy (&quot;rampart <em>mcp</em>&quot;), or an HTTP API that agent platforms can consult before executing anything (&quot;rampart serve&quot;).<p>Go, ~14K lines, Apache 2.0, zero runtime deps. Policy eval takes under 20 microseconds.<p>I'd love feedback on what policies you'd want out of the box and what integrations matter most."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Rampart \u2013 Open-source security for Claude and AI agents in YOLO mode"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/peg/rampart"}},"_tags":["story","author_cl4p","story_46977023","show_hn"],"author":"cl4p","children":[46979297],"created_at":"2026-02-11T16:28:42Z","created_at_i":1770827322,"num_comments":1,"objectID":"46977023","points":2,"story_id":46977023,"story_text":"I&#x27;ve been running an AI agent 24&#x2F;7 on my home lab through OpenClaw \u2014 k3s cluster management, shell commands, config edits, all unsupervised. I could see what the agent was running, but had no way to stop a bad command before it executed. So I built Rampart.<p>How it works: you write a YAML policy that says what&#x27;s allowed, denied, or flagged. Rampart evaluates every tool call against that policy before it runs. Here&#x27;s what a policy looks like:<p><pre><code>  - rm -rf &#x2F; \u2192 denied\n  - sudo anything \u2192 logged for review\n  - curl, wget \u2192 logged for review\n  - git push, go build, normal dev commands \u2192 allowed\n  - cat ~&#x2F;.ssh&#x2F;id_rsa \u2192 denied\n</code></pre>\nEverything gets written to a hash-chained audit trail. You can watch it live with &quot;rampart watch&quot; or generate HTML reports with &quot;rampart report&quot;.<p>Setup for Claude Code takes one command: &quot;rampart setup claude-code&quot;. It installs hooks that intercept every Bash command, file read, and file write before execution. Blocked commands never run \u2014 Claude sees an error and moves on.<p>Setup for OpenClaw agents is also one command: &quot;rampart setup openclaw&quot;. Works on Linux and macOS.<p>Also works as a shell wrapper for any agent (&quot;rampart wrap&quot;), an MCP protocol proxy (&quot;rampart mcp&quot;), or an HTTP API that agent platforms can consult before executing anything (&quot;rampart serve&quot;).<p>Go, ~14K lines, Apache 2.0, zero runtime deps. Policy eval takes under 20 microseconds.<p>I&#x27;d love feedback on what policies you&#x27;d want out of the box and what integrations matter most.","title":"Show HN: Rampart \u2013 Open-source security for Claude and AI agents in YOLO mode","updated_at":"2026-02-11T19:08:29Z","url":"https://github.com/peg/rampart"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"shatzakis"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Hi Everyone,<p>I\u2019m an independent researcher (and professionally, the Global Director of Research at Reink Media) looking for an endorsement for the cs.AI (Computer Science/Artificial Intelligence) category on arXiv.<p>The Context I didn't start by writing a paper; I started by building a system. Over the last year, I developed a production-grade Model Context <em>Protocol</em> (<em>MCP</em>) server for the forex market. It\u2019s currently live with 45 distinct tools and renders 28 different dynamic widgets across Claude, ChatGPT, and a custom web app.<p>The Paper The paper is titled <em>Protocol</em>-Constrained Agentic Systems: A Neuro-Symbolic Architecture for Hallucination-Resistant Financial Execution.<p>My core argument is that in high-stakes domains like finance, we cannot rely on LLMs to be &quot;smart enough&quot; to avoid critical errors. Instead, I propose an architecture that uses <em>MCP</em> as a &quot;hallucination firewall.&quot; This strictly decouples the probabilistic layer (the LLM parsing intent) from the deterministic layer (the tool executing the trade). It effectively treats the <em>protocol</em> schema as a type system for agent actions, guaranteeing by construction that invalid tool calls cannot reach the execution layer.<p>You can read the full paper and see the architecture in the PDF here: https://www.stevenhatzakis.com/research/<em>protocol</em>-constrained-agentic-systems<p>The Request If you are a registered endorser for cs.AI and find this work relevant, I would appreciate your support so I can submit this paper on arXiv.org.<p>Endorsement Code: LZRTFH Link: https://arxiv.org/auth/endorse?x=LZRTFH<p>Thanks for your time.<p>Steven Hatzakis"},"title":{"matchLevel":"none","matchedWords":[],"value":"ArXiv Endorsement for Paper on Neuro-Symbolic Architecture for Financial Agents"}},"_tags":["story","author_shatzakis","story_46975121","ask_hn"],"author":"shatzakis","children":[46975342],"created_at":"2026-02-11T14:09:47Z","created_at_i":1770818987,"num_comments":2,"objectID":"46975121","points":2,"story_id":46975121,"story_text":"Hi Everyone,<p>I\u2019m an independent researcher (and professionally, the Global Director of Research at Reink Media) looking for an endorsement for the cs.AI (Computer Science&#x2F;Artificial Intelligence) category on arXiv.<p>The Context I didn&#x27;t start by writing a paper; I started by building a system. Over the last year, I developed a production-grade Model Context Protocol (MCP) server for the forex market. It\u2019s currently live with 45 distinct tools and renders 28 different dynamic widgets across Claude, ChatGPT, and a custom web app.<p>The Paper The paper is titled Protocol-Constrained Agentic Systems: A Neuro-Symbolic Architecture for Hallucination-Resistant Financial Execution.<p>My core argument is that in high-stakes domains like finance, we cannot rely on LLMs to be &quot;smart enough&quot; to avoid critical errors. Instead, I propose an architecture that uses MCP as a &quot;hallucination firewall.&quot; This strictly decouples the probabilistic layer (the LLM parsing intent) from the deterministic layer (the tool executing the trade). It effectively treats the protocol schema as a type system for agent actions, guaranteeing by construction that invalid tool calls cannot reach the execution layer.<p>You can read the full paper and see the architecture in the PDF here: https:&#x2F;&#x2F;www.stevenhatzakis.com&#x2F;research&#x2F;protocol-constrained-agentic-systems<p>The Request If you are a registered endorser for cs.AI and find this work relevant, I would appreciate your support so I can submit this paper on arXiv.org.<p>Endorsement Code: LZRTFH Link: https:&#x2F;&#x2F;arxiv.org&#x2F;auth&#x2F;endorse?x=LZRTFH<p>Thanks for your time.<p>Steven Hatzakis","title":"ArXiv Endorsement for Paper on Neuro-Symbolic Architecture for Financial Agents","updated_at":"2026-02-12T00:54:58Z"}],"hitsPerPage":10,"nbHits":523,"nbPages":53,"page":0,"params":"query=MCP+protocol&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":22,"processingTimingsMS":{"_request":{"roundTrip":18},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":8,"scanning":12,"total":21},"total":22},"query":"MCP protocol","serverTimeMS":24}
