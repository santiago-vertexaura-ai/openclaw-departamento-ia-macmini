{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"otavioc"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Our <em>AI</em> <em>Orchestration</em> Frameworks Are Reinventing Linda (1985)"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"https://otavio.cat/posts/<em>ai</em>-<em>orchestration</em>-reinventing-linda/"}},"_tags":["story","author_otavioc","story_47002178"],"author":"otavioc","created_at":"2026-02-13T12:54:14Z","created_at_i":1770987254,"num_comments":0,"objectID":"47002178","points":1,"story_id":47002178,"title":"Our AI Orchestration Frameworks Are Reinventing Linda (1985)","updated_at":"2026-02-13T12:55:05Z","url":"https://otavio.cat/posts/ai-orchestration-reinventing-linda/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"pavello"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Hi,<p>Throw-away account because my original one is easily identifiable.<p>Does any starts to feel depressed about <em>AI</em> push and hype? I'm around ~45 and have been happily hacking and delivering stuff for 25 years.<p>I use <em>AI</em> daily \u2014 it's a useful tool. But the gap between the marketing and reality for many of us is hard to describe. The people and corporations and all those LinkedIn gurus, podcasters declaring our obsolescence are overwhelmingly people who've never built or maintained anything complex in their lives. I'm sick of posts showing developers as awesome managers <em>orchestratin</em>g fleets of Codex and Claude Code instances \u2014 I don't know a single person who actually has access to unlimited quotas for that. I'm now scared to publish open source because some random <em>AI</em> agent might spam my repo with garbage PRs and issues. \nAre we really expected to deliver mediocre C compilers while emitting millions of tons of CO2 into the atmosphere just to make a handful of rich people even more rich? And suddenly we have something like Moltbook to pollute our planet even more. Where are we going with this?<p>Anybody feels something like that? I seriously thinking about leaving the industry to keep my mental health in control or switch to some tech that is hard for <em>AI</em>."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Ask HN: <em>AI</em> Depression"}},"_tags":["story","author_pavello","story_47001833","ask_hn"],"author":"pavello","children":[47001993,47001913,47002019],"created_at":"2026-02-13T12:12:59Z","created_at_i":1770984779,"num_comments":3,"objectID":"47001833","points":8,"story_id":47001833,"story_text":"Hi,<p>Throw-away account because my original one is easily identifiable.<p>Does any starts to feel depressed about AI push and hype? I&#x27;m around ~45 and have been happily hacking and delivering stuff for 25 years.<p>I use AI daily \u2014 it&#x27;s a useful tool. But the gap between the marketing and reality for many of us is hard to describe. The people and corporations and all those LinkedIn gurus, podcasters declaring our obsolescence are overwhelmingly people who&#x27;ve never built or maintained anything complex in their lives. I&#x27;m sick of posts showing developers as awesome managers orchestrating fleets of Codex and Claude Code instances \u2014 I don&#x27;t know a single person who actually has access to unlimited quotas for that. I&#x27;m now scared to publish open source because some random AI agent might spam my repo with garbage PRs and issues. \nAre we really expected to deliver mediocre C compilers while emitting millions of tons of CO2 into the atmosphere just to make a handful of rich people even more rich? And suddenly we have something like Moltbook to pollute our planet even more. Where are we going with this?<p>Anybody feels something like that? I seriously thinking about leaving the industry to keep my mental health in control or switch to some tech that is hard for AI.","title":"Ask HN: AI Depression","updated_at":"2026-02-13T12:50:19Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"roninjin10"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Smithers - Declarative <em>AI</em> <em>Orchestration</em> with React"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/evmts/smithers"}},"_tags":["story","author_roninjin10","story_46998448"],"author":"roninjin10","children":[46998455],"created_at":"2026-02-13T03:03:08Z","created_at_i":1770951788,"num_comments":1,"objectID":"46998448","points":2,"story_id":46998448,"title":"Smithers - Declarative AI Orchestration with React","updated_at":"2026-02-13T06:27:48Z","url":"https://github.com/evmts/smithers"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"knes"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: We got sick of juggling terminals for <em>AI</em> agents so we built a workspace"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["orchestration"],"value":"https://www.augmentcode.com/blog/intent-a-workspace-for-agent-<em>orchestration</em>"}},"_tags":["story","author_knes","story_46997059","show_hn"],"author":"knes","created_at":"2026-02-12T23:59:13Z","created_at_i":1770940753,"num_comments":0,"objectID":"46997059","points":1,"story_id":46997059,"title":"Show HN: We got sick of juggling terminals for AI agents so we built a workspace","updated_at":"2026-02-13T00:04:32Z","url":"https://www.augmentcode.com/blog/intent-a-workspace-for-agent-orchestration"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"PolyMCP now supports compiling Python MCP tools to WebAssembly using Pyodide.<p>This means any Python function exposed as an MCP tool can now run directly in the browser, Node.js, or edge workers, fully sandboxed, without a Python server.<p>Compile your tools, serve the bundle, and <em>AI</em> agents can call them instantly in WASM environments. Existing MCP features like input validation, error handling, and tool <em>orchestration</em> work seamlessly.<p>example:<p>from polymcp.polymcp_toolkit import expose_tools_wasm<p>def add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;\n    return a + b<p>compiler = expose_tools_wasm([add])\nbundle = compiler.compile(output_dir=&quot;./dist&quot;)<p>Open dist/demo.html in your browser \u2014 the add tool runs entirely in WASM.<p>Why it matters\n \u2022 No Python server required: runs client-side or on edge\n \u2022 Secure: sandboxed execution\n \u2022 Plug-and-play: multiple tools in one WASM bundle\n \u2022 Ideal for interactive demos, edge <em>AI</em> apps, or browser-based automation<p>Repo: <a href=\"https://github.com/poly-mcp/Polymcp\" rel=\"nofollow\">https://github.com/poly-mcp/Polymcp</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: PolyMCP \u2013 Run MCP Python Tools in WASM via Pyodide"}},"_tags":["story","author_justvugg","story_46993832","show_hn"],"author":"justvugg","created_at":"2026-02-12T19:32:15Z","created_at_i":1770924735,"num_comments":0,"objectID":"46993832","points":2,"story_id":46993832,"story_text":"PolyMCP now supports compiling Python MCP tools to WebAssembly using Pyodide.<p>This means any Python function exposed as an MCP tool can now run directly in the browser, Node.js, or edge workers, fully sandboxed, without a Python server.<p>Compile your tools, serve the bundle, and AI agents can call them instantly in WASM environments. Existing MCP features like input validation, error handling, and tool orchestration work seamlessly.<p>example:<p>from polymcp.polymcp_toolkit import expose_tools_wasm<p>def add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;\n    return a + b<p>compiler = expose_tools_wasm([add])\nbundle = compiler.compile(output_dir=&quot;.&#x2F;dist&quot;)<p>Open dist&#x2F;demo.html in your browser \u2014 the add tool runs entirely in WASM.<p>Why it matters\n \u2022 No Python server required: runs client-side or on edge\n \u2022 Secure: sandboxed execution\n \u2022 Plug-and-play: multiple tools in one WASM bundle\n \u2022 Ideal for interactive demos, edge AI apps, or browser-based automation<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;Polymcp\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;Polymcp</a>","title":"Show HN: PolyMCP \u2013 Run MCP Python Tools in WASM via Pyodide","updated_at":"2026-02-13T07:57:03Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"gusmally"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"In a recent interview with The Pragmatic Engineer, Steve Yegge said he feels &quot;sorry for people&quot; who merely &quot;use Cursor, ask it questions sometimes, review its code really carefully, and then check it in.&quot;<p>Instead, he recommends engineers integrate LLMs into their workflow more and more, until they are  managing multiple agents at one time. The final level in his <em>AI</em> Coding chart reads: \n&quot;Level 8: you build your own <em>orchestrator</em> to coordinate more agents.&quot;<p>At my work, this wouldn't fly-- we're still doing things the sorry way. Are you using <em>orchestrator</em>s to manage multiple agents at work? Particularly interested in non-greenfield applications and how that's changed your SDLC."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["orchestration"],"value":"Ask HN: Are you using an agent <em>orchestrator</em> to write code?"}},"_tags":["story","author_gusmally","story_46993479","ask_hn"],"author":"gusmally","children":[46999194,46999241,46999562,47001872,46999714,46999178,46999316,47000042,46999804,46999286,47000345,46999385,46999411,46999560,46999369,46999279,46999193,46999218,46999438,46999505,46999622,46999501,46999089,46999406,46999578,46999906,46999253,46999229,46999132,46999127,47001197],"created_at":"2026-02-12T19:06:57Z","created_at_i":1770923217,"num_comments":46,"objectID":"46993479","points":32,"story_id":46993479,"story_text":"In a recent interview with The Pragmatic Engineer, Steve Yegge said he feels &quot;sorry for people&quot; who merely &quot;use Cursor, ask it questions sometimes, review its code really carefully, and then check it in.&quot;<p>Instead, he recommends engineers integrate LLMs into their workflow more and more, until they are  managing multiple agents at one time. The final level in his AI Coding chart reads: \n&quot;Level 8: you build your own orchestrator to coordinate more agents.&quot;<p>At my work, this wouldn&#x27;t fly-- we&#x27;re still doing things the sorry way. Are you using orchestrators to manage multiple agents at work? Particularly interested in non-greenfield applications and how that&#x27;s changed your SDLC.","title":"Ask HN: Are you using an agent orchestrator to write code?","updated_at":"2026-02-13T12:47:04Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"pablituuu"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Hi HN, I'm the developer behind Pablituuu. I spent the last few months solving the &quot;heavy lifting&quot; of browser-based video editing. \nIt uses a custom <em>orchestration</em> layer with Fabric.js, WebGL-accelerated rendering (via OpenVideo), and FFmpeg/WASM for client-side processing to eliminate server costs and latency.\nI just added:\n- *<em>AI</em> Analytics (Gemini):* To automatically detect highlights from raw footage.\n- *FFmpeg WASM:* For native browser processing.\n- *Optimized Timeline:* Handles precision state sync between canvas and layers.\nI'm looking for technical feedback on memory management for large assets and I'm open to new professional challenges/collaborations in the media tech space.\nHappy to answer any technical questions!"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: Pablituuu \u2013 Web Video Editor with <em>AI</em> Highlights (WebGL, FFmpeg WASM)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://pablituuu.space/login"}},"_tags":["story","author_pablituuu","story_46987655","show_hn"],"author":"pablituuu","created_at":"2026-02-12T11:57:42Z","created_at_i":1770897462,"num_comments":0,"objectID":"46987655","points":1,"story_id":46987655,"story_text":"Hi HN, I&#x27;m the developer behind Pablituuu. I spent the last few months solving the &quot;heavy lifting&quot; of browser-based video editing. \nIt uses a custom orchestration layer with Fabric.js, WebGL-accelerated rendering (via OpenVideo), and FFmpeg&#x2F;WASM for client-side processing to eliminate server costs and latency.\nI just added:\n- *AI Analytics (Gemini):* To automatically detect highlights from raw footage.\n- *FFmpeg WASM:* For native browser processing.\n- *Optimized Timeline:* Handles precision state sync between canvas and layers.\nI&#x27;m looking for technical feedback on memory management for large assets and I&#x27;m open to new professional challenges&#x2F;collaborations in the media tech space.\nHappy to answer any technical questions!","title":"Show HN: Pablituuu \u2013 Web Video Editor with AI Highlights (WebGL, FFmpeg WASM)","updated_at":"2026-02-12T12:00:00Z","url":"https://pablituuu.space/login"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ariansyah"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"I've been building <em>AI</em> agents at work and the hardest part isn't the prompts or <em>orchestration</em> \u2013 it's answering &quot;is this agent actually good?&quot; in production.<p>Tracing tells you what happened. But I wanted to know how well it happened. So I built Auditi \u2013 it captures your LLM traces and spans and automatically evaluates them with LLM-as-a-judge + human annotation workflows.<p>Two lines to get started:<p><pre><code>  auditi.init(api_key=&quot;...&quot;)\n  auditi.instrument()  # monkey-patches OpenAI/Anthropic/Gemini\n</code></pre>\nEvery API call is captured with full span trees, token usage, and costs. No code changes to your existing LLM calls.<p>The interesting technical bit: the SDK monkey-patches client.chat.completions.create() at runtime (similar to how OpenTelemetry auto-instruments HTTP libraries). It wraps streaming responses with proxy iterators that accumulate content and extract usage from the final chunk \u2013 so even streamed responses get full cost tracking without the user doing anything.<p>What makes this different from just tracing:\n  - Built-in evaluators \u2013 7 managed LLM judges (hallucination, relevance, correctness, toxicity, etc.) run automatically on every trace\n  - Span-level evaluation \u2013 scores each step in a multi-step agent, not just the final output\n  - Human annotation queues \u2013 when you need ground truth, not just vibes\n  - Dataset export \u2013 annotated traces export as JSONL/CSV/Parquet for fine-tuning<p>Self-host with docker compose up.<p>I'd love feedback from anyone running <em>AI</em> agents or LLMs in production. What metrics do you actually look at? How do you decide if an agent response is &quot;good enough&quot;?<p>GitHub: <a href=\"https://github.com/deduu/auditi\" rel=\"nofollow\">https://github.com/deduu/auditi</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Auditi \u2013 open-source LLM tracing and evaluation platform"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/deduu/auditi"}},"_tags":["story","author_ariansyah","story_46974783","show_hn"],"author":"ariansyah","created_at":"2026-02-11T13:37:02Z","created_at_i":1770817022,"num_comments":0,"objectID":"46974783","points":3,"story_id":46974783,"story_text":"I&#x27;ve been building AI agents at work and the hardest part isn&#x27;t the prompts or orchestration \u2013 it&#x27;s answering &quot;is this agent actually good?&quot; in production.<p>Tracing tells you what happened. But I wanted to know how well it happened. So I built Auditi \u2013 it captures your LLM traces and spans and automatically evaluates them with LLM-as-a-judge + human annotation workflows.<p>Two lines to get started:<p><pre><code>  auditi.init(api_key=&quot;...&quot;)\n  auditi.instrument()  # monkey-patches OpenAI&#x2F;Anthropic&#x2F;Gemini\n</code></pre>\nEvery API call is captured with full span trees, token usage, and costs. No code changes to your existing LLM calls.<p>The interesting technical bit: the SDK monkey-patches client.chat.completions.create() at runtime (similar to how OpenTelemetry auto-instruments HTTP libraries). It wraps streaming responses with proxy iterators that accumulate content and extract usage from the final chunk \u2013 so even streamed responses get full cost tracking without the user doing anything.<p>What makes this different from just tracing:\n  - Built-in evaluators \u2013 7 managed LLM judges (hallucination, relevance, correctness, toxicity, etc.) run automatically on every trace\n  - Span-level evaluation \u2013 scores each step in a multi-step agent, not just the final output\n  - Human annotation queues \u2013 when you need ground truth, not just vibes\n  - Dataset export \u2013 annotated traces export as JSONL&#x2F;CSV&#x2F;Parquet for fine-tuning<p>Self-host with docker compose up.<p>I&#x27;d love feedback from anyone running AI agents or LLMs in production. What metrics do you actually look at? How do you decide if an agent response is &quot;good enough&quot;?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;deduu&#x2F;auditi\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;deduu&#x2F;auditi</a>","title":"Show HN: Auditi \u2013 open-source LLM tracing and evaluation platform","updated_at":"2026-02-11T14:53:28Z","url":"https://github.com/deduu/auditi"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"I built PolyMCP, an open-source framework around the Model Context Protocol (MCP) that lets you turn any existing Python function into an MCP tool usable by <em>AI</em> agents \u2014 with no rewrites, no glue code, no custom wrappers.<p>Over the last weeks, PolyMCP has grown into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 expose Python functions as MCP tools\n \u2022 PolyMCP Inspector \u2013 visual UI to explore, test, and debug MCP servers\n \u2022 PolyMCP MCP SDK Apps \u2013 build MCP-powered apps with tools + UI resources<p>\u2e3b<p>1) Turn any Python function into an MCP tool<p>Basic example:<p>from polymcp import expose_tools_http<p>def add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;\n    return a + b<p>app = expose_tools_http(\n    tools=[add],\n    title=&quot;Math Tools&quot;\n)<p>Run it:<p>uvicorn server_mcp:app --reload<p>Now add is an MCP-compliant tool that any <em>AI</em> agent can discover and call.<p>No decorators, no schema files, no agent-specific SDKs.<p>\u2e3b<p>2) Real APIs, not toy examples<p>Existing API code works as-is:<p>import requests\nfrom polymcp import expose_tools_http<p>def get_weather(city: str):\n    &quot;&quot;&quot;Return current weather data for a city&quot;&quot;&quot;\n    response = requests.get(\n        f&quot;<a href=\"https://api.weatherapi.com/v1/current.json?q={city}\" rel=\"nofollow\">https://api.weatherapi.com/v1/current.json?q={city}</a>&quot;\n    )\n    return response.json()<p>app = expose_tools_http([get_weather], title=&quot;Weather Tools&quot;)<p>Agents can now call:<p>get_weather(&quot;London&quot;)<p>and receive real-time data.<p>\u2e3b<p>3) Business &amp; internal workflows<p>Example: internal reporting logic reused directly by agents.<p>import pandas as pd\nfrom polymcp import expose_tools_http<p>def calculate_commissions(sales_data: list[dict]):\n    &quot;&quot;&quot;Calculate sales commissions from sales data&quot;&quot;&quot;\n    df = pd.DataFrame(sales_data)\n    df[&quot;commission&quot;] = df[&quot;sales_amount&quot;] * 0.05\n    return df.to_dict(orient=&quot;records&quot;)<p>app = expose_tools_http([calculate_commissions], title=&quot;Business Tools&quot;)<p>No rewriting legacy logic.<p>4) PolyMCP Inspector (visual debugging)<p>To make MCP development usable in practice, I added PolyMCP Inspector:\n \u2022 Visual UI to browse tools, prompts, and resources\n \u2022 Call MCP tools interactively\n \u2022 Inspect schemas, inputs, outputs, and errors\n \u2022 Multi-server support (HTTP + stdio)\n \u2022 Built-in chat playground (OpenAI / Anthropic / Ollama)<p>Think \u201cPostman + DevTools\u201d for MCP servers.<p>Repo: <a href=\"https://github.com/poly-mcp/PolyMCP-Inspector\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-Inspector</a><p>\u2e3b<p>5) MCP SDK Apps (tools + UI)<p>The latest addition is PolyMCP MCP SDK Apps:\n \u2022 Build MCP apps, not just tools\n \u2022 Expose:\n \u2022 tools\n \u2022 UI resources (HTML/JS dashboards)\n \u2022 app-level workflows\n \u2022 Let agents interact with both tools and UIs<p>This is useful for:\n \u2022 internal copilots\n \u2022 ops dashboards\n \u2022 support tools\n \u2022 enterprise <em>AI</em> frontends<p>Repo: <a href=\"https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps</a><p>\u2e3b<p>Why this matters (especially for companies)\n \u2022 Reuse existing code immediately (scripts, APIs, internal libs)\n \u2022 Standard MCP interface instead of vendor-specific agent SDKs\n \u2022 Multiple tools, one server\n \u2022 Agent-driven <em>orchestration</em>, not hardcoded flows\n \u2022 Faster <em>AI</em> adoption without refactoring everything<p>PolyMCP treats <em>AI</em> agents as clients of your software, not magic wrappers around it.<p>\u2e3b<p>Repos\n \u2022 Core framework: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP</a>\n \u2022 Inspector UI: <a href=\"https://github.com/poly-mcp/PolyMCP-Inspector\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-Inspector</a>\n \u2022 MCP SDK Apps: <a href=\"https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP-MCP-SDK-Apps</a><p>Happy to hear feedback from people building MCP servers, agents, or internal <em>AI</em> tools."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: PolyMCP \u2013 <em>AI</em>-Callable Python and TS Tools with Inspector and Apps"}},"_tags":["story","author_justvugg","story_46966000","show_hn"],"author":"justvugg","created_at":"2026-02-10T20:03:43Z","created_at_i":1770753823,"num_comments":0,"objectID":"46966000","points":2,"story_id":46966000,"story_text":"I built PolyMCP, an open-source framework around the Model Context Protocol (MCP) that lets you turn any existing Python function into an MCP tool usable by AI agents \u2014 with no rewrites, no glue code, no custom wrappers.<p>Over the last weeks, PolyMCP has grown into a small ecosystem:\n \u2022 PolyMCP (core) \u2013 expose Python functions as MCP tools\n \u2022 PolyMCP Inspector \u2013 visual UI to explore, test, and debug MCP servers\n \u2022 PolyMCP MCP SDK Apps \u2013 build MCP-powered apps with tools + UI resources<p>\u2e3b<p>1) Turn any Python function into an MCP tool<p>Basic example:<p>from polymcp import expose_tools_http<p>def add(a: int, b: int) -&gt; int:\n    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;\n    return a + b<p>app = expose_tools_http(\n    tools=[add],\n    title=&quot;Math Tools&quot;\n)<p>Run it:<p>uvicorn server_mcp:app --reload<p>Now add is an MCP-compliant tool that any AI agent can discover and call.<p>No decorators, no schema files, no agent-specific SDKs.<p>\u2e3b<p>2) Real APIs, not toy examples<p>Existing API code works as-is:<p>import requests\nfrom polymcp import expose_tools_http<p>def get_weather(city: str):\n    &quot;&quot;&quot;Return current weather data for a city&quot;&quot;&quot;\n    response = requests.get(\n        f&quot;<a href=\"https:&#x2F;&#x2F;api.weatherapi.com&#x2F;v1&#x2F;current.json?q={city}\" rel=\"nofollow\">https:&#x2F;&#x2F;api.weatherapi.com&#x2F;v1&#x2F;current.json?q={city}</a>&quot;\n    )\n    return response.json()<p>app = expose_tools_http([get_weather], title=&quot;Weather Tools&quot;)<p>Agents can now call:<p>get_weather(&quot;London&quot;)<p>and receive real-time data.<p>\u2e3b<p>3) Business &amp; internal workflows<p>Example: internal reporting logic reused directly by agents.<p>import pandas as pd\nfrom polymcp import expose_tools_http<p>def calculate_commissions(sales_data: list[dict]):\n    &quot;&quot;&quot;Calculate sales commissions from sales data&quot;&quot;&quot;\n    df = pd.DataFrame(sales_data)\n    df[&quot;commission&quot;] = df[&quot;sales_amount&quot;] * 0.05\n    return df.to_dict(orient=&quot;records&quot;)<p>app = expose_tools_http([calculate_commissions], title=&quot;Business Tools&quot;)<p>No rewriting legacy logic.<p>4) PolyMCP Inspector (visual debugging)<p>To make MCP development usable in practice, I added PolyMCP Inspector:\n \u2022 Visual UI to browse tools, prompts, and resources\n \u2022 Call MCP tools interactively\n \u2022 Inspect schemas, inputs, outputs, and errors\n \u2022 Multi-server support (HTTP + stdio)\n \u2022 Built-in chat playground (OpenAI &#x2F; Anthropic &#x2F; Ollama)<p>Think \u201cPostman + DevTools\u201d for MCP servers.<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector</a><p>\u2e3b<p>5) MCP SDK Apps (tools + UI)<p>The latest addition is PolyMCP MCP SDK Apps:\n \u2022 Build MCP apps, not just tools\n \u2022 Expose:\n \u2022 tools\n \u2022 UI resources (HTML&#x2F;JS dashboards)\n \u2022 app-level workflows\n \u2022 Let agents interact with both tools and UIs<p>This is useful for:\n \u2022 internal copilots\n \u2022 ops dashboards\n \u2022 support tools\n \u2022 enterprise AI frontends<p>Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps</a><p>\u2e3b<p>Why this matters (especially for companies)\n \u2022 Reuse existing code immediately (scripts, APIs, internal libs)\n \u2022 Standard MCP interface instead of vendor-specific agent SDKs\n \u2022 Multiple tools, one server\n \u2022 Agent-driven orchestration, not hardcoded flows\n \u2022 Faster AI adoption without refactoring everything<p>PolyMCP treats AI agents as clients of your software, not magic wrappers around it.<p>\u2e3b<p>Repos\n \u2022 Core framework: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a>\n \u2022 Inspector UI: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-Inspector</a>\n \u2022 MCP SDK Apps: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP-MCP-SDK-Apps</a><p>Happy to hear feedback from people building MCP servers, agents, or internal AI tools.","title":"Show HN: PolyMCP \u2013 AI-Callable Python and TS Tools with Inspector and Apps","updated_at":"2026-02-11T03:47:55Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"abilafredkb"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","orchestration"],"value":"Hi\nI\u2019m building Orcbot, an open-source <em>AI</em> agent focused on autonomy over chat.<p>The goal is not \u201canother chatbot\u201d, but an agent that can:<p>decompose goals<p>plan actions<p>use tools<p>reflect on failures<p>and improve its behavior over time<p>Think long-running agents, not prompt \u2192 response.<p>What Orcbot does today<p>Plugin-based architecture (skills are first-class)<p>CLI + messaging integrations (Telegram / WhatsApp)<p>Autonomous execution loops<p>Error recovery &amp; retry logic<p>TypeScript / Node.js, MIT licensed<p>Repo:\n <a href=\"https://github.com/fredabila/orcbot\" rel=\"nofollow\">https://github.com/fredabila/orcbot</a><p>Why I\u2019m posting<p>The project has reached the point where architecture decisions matter more than code volume, and I\u2019d love feedback and contributors who care about:<p>agent planning &amp; <em>orchestration</em><p>memory systems (episodic / vector)<p>tool-using agents<p>self-correction and evaluation loops<p>multi-agent coordination<p>I\u2019m especially interested in people who\u2019ve built:<p>production bots<p>autonomous systems<p>developer tools<p>or have opinions on how agents should fail and recover<p>What I\u2019m explicitly not claiming<p>This is not AGI<p>This is not magic<p>This is an evolving experiment in practical autonomy<p>How to get involved<p>Technical feedback in this thread is very welcome<p>Issues and PRs on GitHub<p>If you\u2019re curious but unsure where to start, open a discussion \u2014 I\u2019m happy to guide<p>I\u2019m posting this mainly to learn from the HN community and see where this direction breaks or shines.<p>Thanks for reading."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Orcbot \u2013 an open-source autonomous agent framework"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/fredabila/orcbot"}},"_tags":["story","author_abilafredkb","story_46965767","show_hn"],"author":"abilafredkb","created_at":"2026-02-10T19:48:33Z","created_at_i":1770752913,"num_comments":0,"objectID":"46965767","points":4,"story_id":46965767,"story_text":"Hi\nI\u2019m building Orcbot, an open-source AI agent focused on autonomy over chat.<p>The goal is not \u201canother chatbot\u201d, but an agent that can:<p>decompose goals<p>plan actions<p>use tools<p>reflect on failures<p>and improve its behavior over time<p>Think long-running agents, not prompt \u2192 response.<p>What Orcbot does today<p>Plugin-based architecture (skills are first-class)<p>CLI + messaging integrations (Telegram &#x2F; WhatsApp)<p>Autonomous execution loops<p>Error recovery &amp; retry logic<p>TypeScript &#x2F; Node.js, MIT licensed<p>Repo:\n <a href=\"https:&#x2F;&#x2F;github.com&#x2F;fredabila&#x2F;orcbot\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;fredabila&#x2F;orcbot</a><p>Why I\u2019m posting<p>The project has reached the point where architecture decisions matter more than code volume, and I\u2019d love feedback and contributors who care about:<p>agent planning &amp; orchestration<p>memory systems (episodic &#x2F; vector)<p>tool-using agents<p>self-correction and evaluation loops<p>multi-agent coordination<p>I\u2019m especially interested in people who\u2019ve built:<p>production bots<p>autonomous systems<p>developer tools<p>or have opinions on how agents should fail and recover<p>What I\u2019m explicitly not claiming<p>This is not AGI<p>This is not magic<p>This is an evolving experiment in practical autonomy<p>How to get involved<p>Technical feedback in this thread is very welcome<p>Issues and PRs on GitHub<p>If you\u2019re curious but unsure where to start, open a discussion \u2014 I\u2019m happy to guide<p>I\u2019m posting this mainly to learn from the HN community and see where this direction breaks or shines.<p>Thanks for reading.","title":"Show HN: Orcbot \u2013 an open-source autonomous agent framework","updated_at":"2026-02-10T20:00:03Z","url":"https://github.com/fredabila/orcbot"}],"hitsPerPage":10,"nbHits":334,"nbPages":34,"page":0,"params":"query=AI+orchestration&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":9,"processingTimingsMS":{"_request":{"roundTrip":14},"fetch":{"query":5,"scanning":3,"total":9},"total":9},"query":"AI orchestration","serverTimeMS":11}
