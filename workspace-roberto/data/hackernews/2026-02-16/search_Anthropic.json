{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"chadbyte"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"I built a local relay server that puts Claude Code in your browser.<p>No signup, no install, no cloud. Just &quot;npx claude-relay&quot;.<p>The problem: Claude Code runs in the terminal. When it needs approval for a command, you have to be staring at that terminal. Walk away for coffee, and it sits there waiting.<p>claude-relay runs a local WebSocket server that streams Claude Code's output to a browser tab. When approval is needed, you get a push notification on your phone. Tap to approve or deny.<p>Technical choices:<p>Built on <em>Anthropic</em>'s Agent SDK (TypeScript)<p>WebSocket streaming, not polling<p>Web Push API for mobile notifications (no app install)<p>Everything runs locally \u2014 no data leaves your machine<p>PIN-based auth for the web UI<p>It also supports multiple sessions (one per git worktree), so you can run parallel Claude Code instances from one dashboard.<p>Setup: npx claude-relay"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Claude Relay \u2013 Web UI for Claude Code, zero install, push notifications"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/chadbyte/claude-relay"}},"_tags":["story","author_chadbyte","story_47033722","show_hn"],"author":"chadbyte","children":[47033735],"created_at":"2026-02-16T11:21:11Z","created_at_i":1771240871,"num_comments":1,"objectID":"47033722","points":1,"story_id":47033722,"story_text":"I built a local relay server that puts Claude Code in your browser.<p>No signup, no install, no cloud. Just &quot;npx claude-relay&quot;.<p>The problem: Claude Code runs in the terminal. When it needs approval for a command, you have to be staring at that terminal. Walk away for coffee, and it sits there waiting.<p>claude-relay runs a local WebSocket server that streams Claude Code&#x27;s output to a browser tab. When approval is needed, you get a push notification on your phone. Tap to approve or deny.<p>Technical choices:<p>Built on Anthropic&#x27;s Agent SDK (TypeScript)<p>WebSocket streaming, not polling<p>Web Push API for mobile notifications (no app install)<p>Everything runs locally \u2014 no data leaves your machine<p>PIN-based auth for the web UI<p>It also supports multiple sessions (one per git worktree), so you can run parallel Claude Code instances from one dashboard.<p>Setup: npx claude-relay","title":"Show HN: Claude Relay \u2013 Web UI for Claude Code, zero install, push notifications","updated_at":"2026-02-16T11:32:00Z","url":"https://github.com/chadbyte/claude-relay"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"beardyw"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"<em>Anthropic</em> tries to hide Claude's AI actions. Devs hate it"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.theregister.com/2026/02/16/<em>anthropic</em>_claude_ai_edits/"}},"_tags":["story","author_beardyw","story_47033622","front_page"],"author":"beardyw","children":[47034401,47034361,47034281,47034387,47034365,47034236,47034073],"created_at":"2026-02-16T11:06:28Z","created_at_i":1771239988,"num_comments":12,"objectID":"47033622","points":47,"story_id":47033622,"title":"Anthropic tries to hide Claude's AI actions. Devs hate it","updated_at":"2026-02-16T12:59:44Z","url":"https://www.theregister.com/2026/02/16/anthropic_claude_ai_edits/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"rajish"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"I built a menu-bar utility for Claude Code users who want to view their remaining token headroom without checking the web dashboard. It polls the <em>Anthropic</em> usage API (not the chat API, so no tokens are spent) and displays your remaining capacity with burn-rate indicators.<p><pre><code>  v1.3 adds dollar-based subscription tracking: see what percentage of your monthly subscription you've actually used, track extra usage spend in real time, and get tier recommendations based on your usage patterns (overpaying? underpowered? forgotten subscription?). All computed locally \u2014 nothing leaves your machine.\n\n  Zero config \u2014 reads OAuth credentials directly from macOS Keychain (from your existing Claude Code login). Pure Swift/SwiftUI, no dependencies.\n\n  Install: brew install rajish/tap/cc-hdrm</code></pre>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: cc-hdrm v1.3 \u2013 macOS menu bar app that tracks your Claude subscription"}},"_tags":["story","author_rajish","story_47033546","show_hn"],"author":"rajish","created_at":"2026-02-16T10:54:53Z","created_at_i":1771239293,"num_comments":0,"objectID":"47033546","points":2,"story_id":47033546,"story_text":"I built a menu-bar utility for Claude Code users who want to view their remaining token headroom without checking the web dashboard. It polls the Anthropic usage API (not the chat API, so no tokens are spent) and displays your remaining capacity with burn-rate indicators.<p><pre><code>  v1.3 adds dollar-based subscription tracking: see what percentage of your monthly subscription you&#x27;ve actually used, track extra usage spend in real time, and get tier recommendations based on your usage patterns (overpaying? underpowered? forgotten subscription?). All computed locally \u2014 nothing leaves your machine.\n\n  Zero config \u2014 reads OAuth credentials directly from macOS Keychain (from your existing Claude Code login). Pure Swift&#x2F;SwiftUI, no dependencies.\n\n  Install: brew install rajish&#x2F;tap&#x2F;cc-hdrm</code></pre>","title":"Show HN: cc-hdrm v1.3 \u2013 macOS menu bar app that tracks your Claude subscription","updated_at":"2026-02-16T11:10:13Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ChilinAI"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hi HN,\nI\u2019m a full-stack developer and I built a small tool that I now use every day.<p>Claude Code from <em>Anthropic</em> is a very capable AI coding assistant, but it only runs locally on your computer. That means if you\u2019re away from your desk \u2014 commuting, walking, or just on the couch \u2014 you can\u2019t easily give it tasks.\nI wanted a simple way to send commands to Claude Code running on my home Mac from anywhere.\nSo I built Claude Remote \u2014 a free, open-source app that lets you control Claude Code through a browser.<p>How it works\nInstall a lightweight macOS app (menu bar app, ~5 MB, Apple Silicon).\nOpen a web chat from your phone or any device.\nSend a task \u2014 Claude Code executes it locally on your Mac and returns the result.\nThe Mac app acts as a bridge between the browser and Claude Code. All execution happens locally on your machine.<p>What I use it for\nFixing bugs or generating small features in side projects\nCreating or editing landing pages\nChecking or organizing files\nRunning scripts\nOpening websites in Chrome and interacting with them\nSummarizing or generating content\nPreparing quick reports\nClaude Code can control Chrome (open pages, read content, fill forms, take screenshots), so you can automate simple browser tasks remotely.\nResponses are returned as formatted markdown. I also added optional text-to-speech playback, which makes it usable while driving.\nPrivacy &amp; security\nOpen source (GitHub link below)\nNo subscriptions\nFirebase Auth (each user only sees their own sessions)\nAll AI execution happens on your machine\nThis is currently macOS (Apple Silicon) only.<p>I\u2019d really appreciate feedback \u2014 especially on security, architecture, and potential edge cases.<p>Website: <a href=\"https://clauderemote.web.app\" rel=\"nofollow\">https://clauderemote.web.app</a><p>GitHub: <a href=\"https://github.com/ChilinAI/claude-remote\" rel=\"nofollow\">https://github.com/ChilinAI/claude-remote</a><p>Thanks!"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Claude Remote \u2013 control Claude Code on your Mac from your phone"}},"_tags":["story","author_ChilinAI","story_47032993","show_hn"],"author":"ChilinAI","children":[47033354],"created_at":"2026-02-16T09:45:52Z","created_at_i":1771235152,"num_comments":1,"objectID":"47032993","points":2,"story_id":47032993,"story_text":"Hi HN,\nI\u2019m a full-stack developer and I built a small tool that I now use every day.<p>Claude Code from Anthropic is a very capable AI coding assistant, but it only runs locally on your computer. That means if you\u2019re away from your desk \u2014 commuting, walking, or just on the couch \u2014 you can\u2019t easily give it tasks.\nI wanted a simple way to send commands to Claude Code running on my home Mac from anywhere.\nSo I built Claude Remote \u2014 a free, open-source app that lets you control Claude Code through a browser.<p>How it works\nInstall a lightweight macOS app (menu bar app, ~5 MB, Apple Silicon).\nOpen a web chat from your phone or any device.\nSend a task \u2014 Claude Code executes it locally on your Mac and returns the result.\nThe Mac app acts as a bridge between the browser and Claude Code. All execution happens locally on your machine.<p>What I use it for\nFixing bugs or generating small features in side projects\nCreating or editing landing pages\nChecking or organizing files\nRunning scripts\nOpening websites in Chrome and interacting with them\nSummarizing or generating content\nPreparing quick reports\nClaude Code can control Chrome (open pages, read content, fill forms, take screenshots), so you can automate simple browser tasks remotely.\nResponses are returned as formatted markdown. I also added optional text-to-speech playback, which makes it usable while driving.\nPrivacy &amp; security\nOpen source (GitHub link below)\nNo subscriptions\nFirebase Auth (each user only sees their own sessions)\nAll AI execution happens on your machine\nThis is currently macOS (Apple Silicon) only.<p>I\u2019d really appreciate feedback \u2014 especially on security, architecture, and potential edge cases.<p>Website: <a href=\"https:&#x2F;&#x2F;clauderemote.web.app\" rel=\"nofollow\">https:&#x2F;&#x2F;clauderemote.web.app</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ChilinAI&#x2F;claude-remote\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ChilinAI&#x2F;claude-remote</a><p>Thanks!","title":"Show HN: Claude Remote \u2013 control Claude Code on your Mac from your phone","updated_at":"2026-02-16T10:30:14Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"san-techie21"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hi HN,<p>I'm a security engineer with 15+ years in enterprise security. After watching OpenClaw explode to 180K stars while binding to 0.0.0.0 by default, shipping no encryption, and accumulating 512 CVEs \u2014 I decided to build what I think a personal AI agent should look like when security comes first.<p>Gulama is an open-source personal AI agent with 15+ security mechanisms built into the core:<p>- AES-256-GCM encryption for all credentials and memories (never plaintext)\n- Sandboxed execution via bubblewrap/Docker (same sandbox <em>Anthropic</em> uses for Claude Code)\n- Ed25519-signed skills (no unsigned code runs \u2014 unlike ClawHub's 230+ malicious skills)\n- Cedar-inspired policy engine for deterministic authorization\n- Canary tokens for prompt injection detection\n- Egress filtering + DLP to prevent data exfiltration\n- Gateway binds 127.0.0.1 ONLY by default (not 0.0.0.0)\n- Cryptographic hash-chain audit trail<p>Beyond security, it's a full-featured agent:<p>- 100+ LLM providers via LiteLLM (<em>Anthropic</em>, OpenAI, DeepSeek, Ollama, etc.)\n- 19 built-in skills (files, shell, web, browser, email, calendar, GitHub, Notion, Spotify, voice, MCP bridge, and more)\n- 10 communication channels (CLI, Telegram, Discord, Slack, WhatsApp, Matrix, Teams, Web UI, Voice Wake)\n- Full MCP server + client support\n- Multi-agent orchestration with background sub-agents\n- RAG-powered memory via ChromaDB\n- Self-modifying: the agent writes its own new skills at runtime (sandboxed)\n- 5 autonomy levels from &quot;ask before everything&quot; to full autopilot<p>Install: pip install gulama &amp;&amp; gulama setup &amp;&amp; gulama chat<p>Stack: Python 3.12+, FastAPI, LiteLLM, SQLite, ChromaDB, Click\nPyPI: <a href=\"https://pypi.org/project/gulama/\" rel=\"nofollow\">https://pypi.org/project/gulama/</a><p>Happy to answer any questions about the security architecture or design decisions."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Gulama \u2013 Security-first open-source AI agent (OpenClaw alternative)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/san-techie21/gulama-bot"}},"_tags":["story","author_san-techie21","story_47031982","show_hn"],"author":"san-techie21","created_at":"2026-02-16T07:27:20Z","created_at_i":1771226840,"num_comments":0,"objectID":"47031982","points":1,"story_id":47031982,"story_text":"Hi HN,<p>I&#x27;m a security engineer with 15+ years in enterprise security. After watching OpenClaw explode to 180K stars while binding to 0.0.0.0 by default, shipping no encryption, and accumulating 512 CVEs \u2014 I decided to build what I think a personal AI agent should look like when security comes first.<p>Gulama is an open-source personal AI agent with 15+ security mechanisms built into the core:<p>- AES-256-GCM encryption for all credentials and memories (never plaintext)\n- Sandboxed execution via bubblewrap&#x2F;Docker (same sandbox Anthropic uses for Claude Code)\n- Ed25519-signed skills (no unsigned code runs \u2014 unlike ClawHub&#x27;s 230+ malicious skills)\n- Cedar-inspired policy engine for deterministic authorization\n- Canary tokens for prompt injection detection\n- Egress filtering + DLP to prevent data exfiltration\n- Gateway binds 127.0.0.1 ONLY by default (not 0.0.0.0)\n- Cryptographic hash-chain audit trail<p>Beyond security, it&#x27;s a full-featured agent:<p>- 100+ LLM providers via LiteLLM (Anthropic, OpenAI, DeepSeek, Ollama, etc.)\n- 19 built-in skills (files, shell, web, browser, email, calendar, GitHub, Notion, Spotify, voice, MCP bridge, and more)\n- 10 communication channels (CLI, Telegram, Discord, Slack, WhatsApp, Matrix, Teams, Web UI, Voice Wake)\n- Full MCP server + client support\n- Multi-agent orchestration with background sub-agents\n- RAG-powered memory via ChromaDB\n- Self-modifying: the agent writes its own new skills at runtime (sandboxed)\n- 5 autonomy levels from &quot;ask before everything&quot; to full autopilot<p>Install: pip install gulama &amp;&amp; gulama setup &amp;&amp; gulama chat<p>Stack: Python 3.12+, FastAPI, LiteLLM, SQLite, ChromaDB, Click\nPyPI: <a href=\"https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;gulama&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;gulama&#x2F;</a><p>Happy to answer any questions about the security architecture or design decisions.","title":"Show HN: Gulama \u2013 Security-first open-source AI agent (OpenClaw alternative)","updated_at":"2026-02-16T07:32:13Z","url":"https://github.com/san-techie21/gulama-bot"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"iamspathan"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hi HN,<p>I built llm-authz-audit because I kept seeing the same security issues in LLM-powered applications: API keys hardcoded next to OpenAI calls, FastAPI endpoints serving chat completions with zero auth, user input concatenated straight into prompts, and shared conversation memory with no session isolation.<p>These aren't hypothetical \u2014 they're patterns I found repeatedly across open-source LLM projects and production codebases.<p>What it does:<p>It's a static analyzer (think eslint/semgrep but purpose-built for LLM security) that scans Python, JavaScript, and TypeScript codebases for authorization and security gaps. It ships with 13 analyzers and 27 rules covering the OWASP Top 10 for LLM Applications:<p>- Prompt injection risks (unsanitized input in prompts, missing delimiters)\n- Hardcoded API keys (OpenAI, <em>Anthropic</em>, HuggingFace, AWS, generic)\n- Unauthenticated LLM endpoints (FastAPI, Flask, Express)\n- LangChain/LlamaIndex tools without RBAC\n- RAG retrievals without document-level access controls\n- Over-permissioned MCP server configs\n- Shared conversation memory without user scoping\n- Missing rate limiting, audit logging, output filtering\n- Credentials forwarded to LLM via prompt templates\nWould love feedback from anyone building or securing LLM applications."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: LLM AuthZ Audit \u2013 find auth gaps and prompt injection in LLM apps"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/aiauthz/llm-authz-audit"}},"_tags":["story","author_iamspathan","story_47031695","show_hn"],"author":"iamspathan","created_at":"2026-02-16T06:50:39Z","created_at_i":1771224639,"num_comments":0,"objectID":"47031695","points":1,"story_id":47031695,"story_text":"Hi HN,<p>I built llm-authz-audit because I kept seeing the same security issues in LLM-powered applications: API keys hardcoded next to OpenAI calls, FastAPI endpoints serving chat completions with zero auth, user input concatenated straight into prompts, and shared conversation memory with no session isolation.<p>These aren&#x27;t hypothetical \u2014 they&#x27;re patterns I found repeatedly across open-source LLM projects and production codebases.<p>What it does:<p>It&#x27;s a static analyzer (think eslint&#x2F;semgrep but purpose-built for LLM security) that scans Python, JavaScript, and TypeScript codebases for authorization and security gaps. It ships with 13 analyzers and 27 rules covering the OWASP Top 10 for LLM Applications:<p>- Prompt injection risks (unsanitized input in prompts, missing delimiters)\n- Hardcoded API keys (OpenAI, Anthropic, HuggingFace, AWS, generic)\n- Unauthenticated LLM endpoints (FastAPI, Flask, Express)\n- LangChain&#x2F;LlamaIndex tools without RBAC\n- RAG retrievals without document-level access controls\n- Over-permissioned MCP server configs\n- Shared conversation memory without user scoping\n- Missing rate limiting, audit logging, output filtering\n- Credentials forwarded to LLM via prompt templates\nWould love feedback from anyone building or securing LLM applications.","title":"Show HN: LLM AuthZ Audit \u2013 find auth gaps and prompt injection in LLM apps","updated_at":"2026-02-16T06:55:28Z","url":"https://github.com/aiauthz/llm-authz-audit"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"sugeul"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"Hi HN, I built Jsiphon to solve a common frustration with LLM streaming: you ask for structured JSON output, but can't use any of it until the entire stream finishes.<p>If you've used JSON mode (OpenAI, <em>Anthropic</em>, etc.), you've hit this \u2014 you want {&quot;answer&quot;: &quot;...&quot;, &quot;sources&quot;: [...]}, but JSON.parse() fails on every incomplete chunk.<p>LLM responses are inherently append-only (tokens arrive left to right, never go back), so Jsiphon leans into that with three ideas:<p>1) Append-only parsing \u2014 Feed in {&quot;msg&quot;: &quot;Hel and get {msg: &quot;Hel&quot;} immediately. Values are only extended, never removed or mutated.<p>2) Delta tracking \u2014 Each snapshot contains only what's new. For a chat bubble, just append delta.content to the DOM \u2014 when the LLM produces next chunk &quot;lo, World!&quot;, we immediately get {msg: &quot;lo, World!&quot;}. No need to repeat partial JSON parsing or full tree rerendering.<p>3) Ambiguity tree \u2014 A tree that mirrors the shape of your data and tracks which subtrees are finalized at every depth. For example, if you're streaming {&quot;header&quot;: {&quot;title&quot;: &quot;...&quot;, &quot;date&quot;: &quot;...&quot;}, &quot;body&quot;: &quot;...&quot;}, you can check isAmbiguous(ambiguous.header.title) to use the title the moment it's done, even while header.date and body are still streaming. This isn't a flat &quot;is the whole thing done?&quot; flag \u2014 it's per-node stability tracking that propagates up, so isAmbiguous(ambiguous.header) turns false only when all of header's children are finalized.<p>Existing partial JSON parsers like partial-json and gjp-4-gpt do a great job at the core parsing problem \u2014 turning broken JSON into usable objects. Jsiphon builds on that foundation and takes it one step further: instead of just parsing, it gives you a streaming data pipeline where append-only snapshots, per-field deltas, and multi-depth ambiguity tracking all come out of a single async iteration. If you've been using partial-json and wished you knew which fields were done vs still streaming without polling the whole object, that's exactly the gap this fills.<p>Zero dependencies, never throws on invalid input, handles junk text before/after the JSON root (which LLMs sometimes produce).<p>GitHub: <a href=\"https://github.com/webtoon-today/jsiphon\" rel=\"nofollow\">https://github.com/webtoon-today/jsiphon</a>\nnpm install jsiphon<p>Would love feedback on the API design \u2014 especially the ambiguity tree.\nTracking per-node stability across arbitrary nesting depth was the trickiest part. Curious if anyone sees a cleaner approach.<p>Disclosure: I'm a native Korean speaker. I used Claude to help structure and translate this post into English. The ideas and code are mine."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Jsiphon \u2013 Streaming JSON parser with delta tracking and ambiguity trees"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/webtoon-today/jsiphon"}},"_tags":["story","author_sugeul","story_47030961","show_hn"],"author":"sugeul","created_at":"2026-02-16T04:40:41Z","created_at_i":1771216841,"num_comments":0,"objectID":"47030961","points":1,"story_id":47030961,"story_text":"Hi HN, I built Jsiphon to solve a common frustration with LLM streaming: you ask for structured JSON output, but can&#x27;t use any of it until the entire stream finishes.<p>If you&#x27;ve used JSON mode (OpenAI, Anthropic, etc.), you&#x27;ve hit this \u2014 you want {&quot;answer&quot;: &quot;...&quot;, &quot;sources&quot;: [...]}, but JSON.parse() fails on every incomplete chunk.<p>LLM responses are inherently append-only (tokens arrive left to right, never go back), so Jsiphon leans into that with three ideas:<p>1) Append-only parsing \u2014 Feed in {&quot;msg&quot;: &quot;Hel and get {msg: &quot;Hel&quot;} immediately. Values are only extended, never removed or mutated.<p>2) Delta tracking \u2014 Each snapshot contains only what&#x27;s new. For a chat bubble, just append delta.content to the DOM \u2014 when the LLM produces next chunk &quot;lo, World!&quot;, we immediately get {msg: &quot;lo, World!&quot;}. No need to repeat partial JSON parsing or full tree rerendering.<p>3) Ambiguity tree \u2014 A tree that mirrors the shape of your data and tracks which subtrees are finalized at every depth. For example, if you&#x27;re streaming {&quot;header&quot;: {&quot;title&quot;: &quot;...&quot;, &quot;date&quot;: &quot;...&quot;}, &quot;body&quot;: &quot;...&quot;}, you can check isAmbiguous(ambiguous.header.title) to use the title the moment it&#x27;s done, even while header.date and body are still streaming. This isn&#x27;t a flat &quot;is the whole thing done?&quot; flag \u2014 it&#x27;s per-node stability tracking that propagates up, so isAmbiguous(ambiguous.header) turns false only when all of header&#x27;s children are finalized.<p>Existing partial JSON parsers like partial-json and gjp-4-gpt do a great job at the core parsing problem \u2014 turning broken JSON into usable objects. Jsiphon builds on that foundation and takes it one step further: instead of just parsing, it gives you a streaming data pipeline where append-only snapshots, per-field deltas, and multi-depth ambiguity tracking all come out of a single async iteration. If you&#x27;ve been using partial-json and wished you knew which fields were done vs still streaming without polling the whole object, that&#x27;s exactly the gap this fills.<p>Zero dependencies, never throws on invalid input, handles junk text before&#x2F;after the JSON root (which LLMs sometimes produce).<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;webtoon-today&#x2F;jsiphon\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;webtoon-today&#x2F;jsiphon</a>\nnpm install jsiphon<p>Would love feedback on the API design \u2014 especially the ambiguity tree.\nTracking per-node stability across arbitrary nesting depth was the trickiest part. Curious if anyone sees a cleaner approach.<p>Disclosure: I&#x27;m a native Korean speaker. I used Claude to help structure and translate this post into English. The ideas and code are mine.","title":"Show HN: Jsiphon \u2013 Streaming JSON parser with delta tracking and ambiguity trees","updated_at":"2026-02-16T04:44:13Z","url":"https://github.com/webtoon-today/jsiphon"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"gnabgib"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"<em>Anthropic</em> improves free Claude tier as OpenAI prepares insert ads into ChatGPT"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://www.engadget.com/ai/<em>anthropic</em>-beefs-up-claudes-free-tier-as-openai-prepares-to-stuff-ads-into-chatgpts-194100939.html"}},"_tags":["story","author_gnabgib","story_47029911"],"author":"gnabgib","created_at":"2026-02-16T01:43:01Z","created_at_i":1771206181,"num_comments":0,"objectID":"47029911","points":4,"story_id":47029911,"title":"Anthropic improves free Claude tier as OpenAI prepares insert ads into ChatGPT","updated_at":"2026-02-16T03:12:42Z","url":"https://www.engadget.com/ai/anthropic-beefs-up-claudes-free-tier-as-openai-prepares-to-stuff-ads-into-chatgpts-194100939.html"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"gdhaliwal23"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"I built MarginDash because I couldn't answer a basic question: which of my customers actually make me money after AI costs? My Stripe dashboard showed revenue going up. My OpenAI bills showed costs going up faster. I had no way to connect the two at the customer level.\nMarginDash is a few line SDK integration (TypeScript, Python, or REST) that tracks model usage per customer and connects it to revenue \u2014 either through Stripe sync or by passing revenue directly in the API call. You get a per-customer P&amp;L showing revenue, cost, and margin.<p>A cost simulator lets you pick any feature, swap the underlying model, and see projected savings. Models are ranked by intelligence-per-dollar using public benchmarks (MMLU-Pro, GPQA, AIME) so you can find cheaper options that aren't actually worse. Budget alerts email you before a customer or feature blows past a threshold.<p>The pricing database covers 100+ models across OpenAI, <em>Anthropic</em>, Google, AWS Bedrock, Azure, and Groq with daily updates \u2014 so cost calculations stay accurate without you maintaining a spreadsheet. The SDK only sends model name, token counts, and customer ID. No prompts, no responses.<p>Solo founder, built the whole thing for $239.72 in AI costs (wrote about that too). Currently free while I get feedback \u2014 would love to hear what you think, especially about the cost simulator."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: MarginDash \u2013 See which AI customers are profitable"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://margindash.com/"}},"_tags":["story","author_gdhaliwal23","story_47029486","show_hn"],"author":"gdhaliwal23","children":[47029492],"created_at":"2026-02-16T00:46:21Z","created_at_i":1771202781,"num_comments":1,"objectID":"47029486","points":1,"story_id":47029486,"story_text":"I built MarginDash because I couldn&#x27;t answer a basic question: which of my customers actually make me money after AI costs? My Stripe dashboard showed revenue going up. My OpenAI bills showed costs going up faster. I had no way to connect the two at the customer level.\nMarginDash is a few line SDK integration (TypeScript, Python, or REST) that tracks model usage per customer and connects it to revenue \u2014 either through Stripe sync or by passing revenue directly in the API call. You get a per-customer P&amp;L showing revenue, cost, and margin.<p>A cost simulator lets you pick any feature, swap the underlying model, and see projected savings. Models are ranked by intelligence-per-dollar using public benchmarks (MMLU-Pro, GPQA, AIME) so you can find cheaper options that aren&#x27;t actually worse. Budget alerts email you before a customer or feature blows past a threshold.<p>The pricing database covers 100+ models across OpenAI, Anthropic, Google, AWS Bedrock, Azure, and Groq with daily updates \u2014 so cost calculations stay accurate without you maintaining a spreadsheet. The SDK only sends model name, token counts, and customer ID. No prompts, no responses.<p>Solo founder, built the whole thing for $239.72 in AI costs (wrote about that too). Currently free while I get feedback \u2014 would love to hear what you think, especially about the cost simulator.","title":"Show HN: MarginDash \u2013 See which AI customers are profitable","updated_at":"2026-02-16T00:47:57Z","url":"https://margindash.com/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"infinitewars"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"<em>Anthropic</em> resists as Department of War wants AI to kill"},"url":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["anthropic"],"value":"https://timesofindia.indiatimes.com/technology/tech-news/a-very-angry-pentagon-to-<em>anthropic</em>-dont-lecture-us-you-can-go-and-/articleshow/128383504.cms"}},"_tags":["story","author_infinitewars","story_47029346"],"author":"infinitewars","children":[47029364,47029352],"created_at":"2026-02-16T00:28:22Z","created_at_i":1771201702,"num_comments":3,"objectID":"47029346","points":2,"story_id":47029346,"title":"Anthropic resists as Department of War wants AI to kill","updated_at":"2026-02-16T02:06:13Z","url":"https://timesofindia.indiatimes.com/technology/tech-news/a-very-angry-pentagon-to-anthropic-dont-lecture-us-you-can-go-and-/articleshow/128383504.cms"}],"hitsPerPage":10,"nbHits":3084,"nbPages":100,"page":0,"params":"query=Anthropic&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":7,"processingTimingsMS":{"_request":{"roundTrip":19},"fetch":{"query":3,"scanning":2,"total":6},"total":7},"query":"Anthropic","serverTimeMS":9}
