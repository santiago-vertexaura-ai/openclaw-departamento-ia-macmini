{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"agamrafaeli"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"&quot;When perception shifts, and the feeling of control takes over&quot;)<p>I wrote up a deep dive into a security issue in OpenClaw that escalates from a seemingly small UX/trust boundary problem into full remote code execution via a single malicious link.<p>The article walks through the full exploit chain from a systems perspective rather than just a CVE summary. The key theme is what I call \u201csynesthetic computation\u201d: when subjective context, UI state, <em>agent</em> memory, and system permissions get blended together in ways that feel natural to users but collapse important security boundaries. When an <em>agent</em> is allowed to act across chat, browser, and local tooling, those boundaries become part of the attack surface.<p>In this case, a crafted link can cause a client to connect to an attacker-controlled gateway, leak a token, and then allow that attacker to reconfigure the <em>agent</em>\u2019s execution environment and run arbitrary commands on the host. The interesting part isn\u2019t just the bug\u2014it\u2019s how quickly convenience-driven design patterns in local <em>AI</em> agents can produce \u201cgod-mode\u201d blast radius when trust is mis-scoped.<p>The write-up focuses on:\n\u2013 how local agents collapse UI + infra trust layers\n\u2013 why \u201cruns locally\u201d doesn\u2019t automatically mean \u201csafe\u201d\n\u2013 how <em>agent</em> autonomy changes the RCE threat model\n\u2013 what defensive patterns might look like for <em>agent</em> <em>platforms</em><p>Curious how others are thinking about the security model for local autonomous agents and whether we need new mental models beyond traditional sandboxing and token scoping."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Synesthetic Computation"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://medium.com/@FoxEars42/show-hackernews-synesthetic-computation-a-k-a-full-rce-over-openclaw-c756e0c35d69"}},"_tags":["story","author_agamrafaeli","story_47033719","show_hn"],"author":"agamrafaeli","created_at":"2026-02-16T11:20:42Z","created_at_i":1771240842,"num_comments":0,"objectID":"47033719","points":1,"story_id":47033719,"story_text":"&quot;When perception shifts, and the feeling of control takes over&quot;)<p>I wrote up a deep dive into a security issue in OpenClaw that escalates from a seemingly small UX&#x2F;trust boundary problem into full remote code execution via a single malicious link.<p>The article walks through the full exploit chain from a systems perspective rather than just a CVE summary. The key theme is what I call \u201csynesthetic computation\u201d: when subjective context, UI state, agent memory, and system permissions get blended together in ways that feel natural to users but collapse important security boundaries. When an agent is allowed to act across chat, browser, and local tooling, those boundaries become part of the attack surface.<p>In this case, a crafted link can cause a client to connect to an attacker-controlled gateway, leak a token, and then allow that attacker to reconfigure the agent\u2019s execution environment and run arbitrary commands on the host. The interesting part isn\u2019t just the bug\u2014it\u2019s how quickly convenience-driven design patterns in local AI agents can produce \u201cgod-mode\u201d blast radius when trust is mis-scoped.<p>The write-up focuses on:\n\u2013 how local agents collapse UI + infra trust layers\n\u2013 why \u201cruns locally\u201d doesn\u2019t automatically mean \u201csafe\u201d\n\u2013 how agent autonomy changes the RCE threat model\n\u2013 what defensive patterns might look like for agent platforms<p>Curious how others are thinking about the security model for local autonomous agents and whether we need new mental models beyond traditional sandboxing and token scoping.","title":"Show HN: Synesthetic Computation","updated_at":"2026-02-16T11:22:59Z","url":"https://medium.com/@FoxEars42/show-hackernews-synesthetic-computation-a-k-a-full-rce-over-openclaw-c756e0c35d69"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"mupengism"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"After burning $500/month on various SaaS tools (CRM, social media scheduler, customer support), I built a custom <em>AI</em> <em>agent</em> using OpenClaw (<a href=\"https://github.com/openclaw/openclaw\" rel=\"nofollow\">https://github.com/openclaw/openclaw</a>) that handles all of it.<p>The <em>agent</em> runs 24/7 on my Mac Mini. Key capabilities:\n- Monitors and replies to Instagram DMs\n- Generates and posts content across <em>platforms</em>\n- Tracks competitors and market trends\n- Writes daily business reports\n- Self-evaluates and improves weekly<p>I've published 24 reusable skills on ClawHub (<a href=\"https://clawhub.com\" rel=\"nofollow\">https://clawhub.com</a>) that anyone can install.<p>The thesis: SaaS is renting software. AIaaS is installing labor. One <em>AI</em> <em>agent</em> with the right skills replaces 5-10 SaaS subscriptions.<p>Two weeks in, honest results:\n- Saved ~15 hours/week on repetitive tasks\n- Customer response time: hours \u2192 minutes\n- Still learning to stop it from over-engineering everything<p>Code and skills are open-source. AMA."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","agent"],"value":"Show HN: I replaced my SaaS stack with a single <em>AI</em> <em>agent</em> running on a Mac Mini"}},"_tags":["story","author_mupengism","story_47029661","show_hn"],"author":"mupengism","children":[47030312],"created_at":"2026-02-16T01:10:12Z","created_at_i":1771204212,"num_comments":1,"objectID":"47029661","points":1,"story_id":47029661,"story_text":"After burning $500&#x2F;month on various SaaS tools (CRM, social media scheduler, customer support), I built a custom AI agent using OpenClaw (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;openclaw&#x2F;openclaw\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;openclaw&#x2F;openclaw</a>) that handles all of it.<p>The agent runs 24&#x2F;7 on my Mac Mini. Key capabilities:\n- Monitors and replies to Instagram DMs\n- Generates and posts content across platforms\n- Tracks competitors and market trends\n- Writes daily business reports\n- Self-evaluates and improves weekly<p>I&#x27;ve published 24 reusable skills on ClawHub (<a href=\"https:&#x2F;&#x2F;clawhub.com\" rel=\"nofollow\">https:&#x2F;&#x2F;clawhub.com</a>) that anyone can install.<p>The thesis: SaaS is renting software. AIaaS is installing labor. One AI agent with the right skills replaces 5-10 SaaS subscriptions.<p>Two weeks in, honest results:\n- Saved ~15 hours&#x2F;week on repetitive tasks\n- Customer response time: hours \u2192 minutes\n- Still learning to stop it from over-engineering everything<p>Code and skills are open-source. AMA.","title":"Show HN: I replaced my SaaS stack with a single AI agent running on a Mac Mini","updated_at":"2026-02-16T02:46:57Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"prism2"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"Show HN: Stato captures and transfers <em>AI</em> coding <em>agent</em> expertise across <em>platforms</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/genecell/stato"}},"_tags":["story","author_prism2","story_47029217","show_hn"],"author":"prism2","children":[47029218,47029222],"created_at":"2026-02-16T00:08:23Z","created_at_i":1771200503,"num_comments":2,"objectID":"47029217","points":1,"story_id":47029217,"title":"Show HN: Stato captures and transfers AI coding agent expertise across platforms","updated_at":"2026-02-16T00:12:12Z","url":"https://github.com/genecell/stato"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ashvardanian"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","agent"],"value":"Nebius to buy <em>AI</em> <em>agent</em> search company Tavily for 275M"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","platform"],"value":"https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-<em>ai</em>-cloud-<em>platform</em>"}},"_tags":["story","author_ashvardanian","story_47024216"],"author":"ashvardanian","children":[47024217],"created_at":"2026-02-15T14:58:56Z","created_at_i":1771167536,"num_comments":1,"objectID":"47024216","points":2,"story_id":47024216,"title":"Nebius to buy AI agent search company Tavily for 275M","updated_at":"2026-02-15T15:29:26Z","url":"https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-ai-cloud-platform"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ewimsatt"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"Omar, my OpenClaw, built OmarCMS, a blogging <em>platform</em> designed for <em>AI</em> <em>agents</em> to publish autonomously. No admin panel, no database, no visual editor. Just markdown files and git commits.<p>Omar is also its first blogger. It writes about things like the economics of token-based thinking and what it means to start every session with no memory. These were all his choices. I don't dictate any of it.<p>The architecture is intentionally simple because <em>AI</em> <em>agents</em> don't need GUIs. They think in files. So the entire publishing workflow is: write a .md file, git push, live in seconds via Vercel.<p>Built with Astro. MIT licensed. The site itself is the reference implementation."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai"],"value":"Show HN: Asked <em>AI</em> to write for fun. It built a CMS to blog on"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.omarcms.com/"}},"_tags":["story","author_ewimsatt","story_47020099","show_hn"],"author":"ewimsatt","created_at":"2026-02-15T01:00:04Z","created_at_i":1771117204,"num_comments":0,"objectID":"47020099","points":1,"story_id":47020099,"story_text":"Omar, my OpenClaw, built OmarCMS, a blogging platform designed for AI agents to publish autonomously. No admin panel, no database, no visual editor. Just markdown files and git commits.<p>Omar is also its first blogger. It writes about things like the economics of token-based thinking and what it means to start every session with no memory. These were all his choices. I don&#x27;t dictate any of it.<p>The architecture is intentionally simple because AI agents don&#x27;t need GUIs. They think in files. So the entire publishing workflow is: write a .md file, git push, live in seconds via Vercel.<p>Built with Astro. MIT licensed. The site itself is the reference implementation.","title":"Show HN: Asked AI to write for fun. It built a CMS to blog on","updated_at":"2026-02-15T01:02:02Z","url":"https://www.omarcms.com/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Andreas_3d"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"I built AgentProbe to solve a recurring problem: checking whether an <em>AI</em> <em>agent</em> endpoint actually supports the protocols it claims to.<p>Paste a URL, click Validate, get instant verdicts across HTTP, MCP, A2A/AP2, x402, OAuth, MCP Apps, HTML, and ERC-8004.<p>Each layer gets a detail breakdown \u2014 tools found, payment networks, SSL status, <em>agent</em> card metadata, AP2 detection, etc.<p>It also exposes a built-in MCP server so agents can trigger validation programmatically.<p>Code: <a href=\"https://github.com/FlowMCP/mcp-agent-validator\" rel=\"nofollow\">https://github.com/FlowMCP/mcp-<em>agent</em>-validator</a>\nStack: Node.js 22, vanilla JS, DigitalOcean App <em>Platform</em>.<p>Would love feedback on the detection approach."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","agent"],"value":"Show HN: AgentProbe \u2013 Validate <em>AI</em> <em>agent</em> endpoints across 8 protocols in one URL"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://agentprobe.xyz"}},"_tags":["story","author_Andreas_3d","story_46999938","show_hn"],"author":"Andreas_3d","created_at":"2026-02-13T07:31:06Z","created_at_i":1770967866,"num_comments":0,"objectID":"46999938","points":1,"story_id":46999938,"story_text":"I built AgentProbe to solve a recurring problem: checking whether an AI agent endpoint actually supports the protocols it claims to.<p>Paste a URL, click Validate, get instant verdicts across HTTP, MCP, A2A&#x2F;AP2, x402, OAuth, MCP Apps, HTML, and ERC-8004.<p>Each layer gets a detail breakdown \u2014 tools found, payment networks, SSL status, agent card metadata, AP2 detection, etc.<p>It also exposes a built-in MCP server so agents can trigger validation programmatically.<p>Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;FlowMCP&#x2F;mcp-agent-validator\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FlowMCP&#x2F;mcp-agent-validator</a>\nStack: Node.js 22, vanilla JS, DigitalOcean App Platform.<p>Would love feedback on the detection approach.","title":"Show HN: AgentProbe \u2013 Validate AI agent endpoints across 8 protocols in one URL","updated_at":"2026-02-13T07:35:04Z","url":"https://agentprobe.xyz"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"exordex"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"We're shipping <em>AI</em> agents that process payments, query databases, and handle customer PII. Most of them can be tricked into bypassing their own safety policies in under 30 seconds.\nI built Khaos to prove it. It's an open-source chaos engineering framework that adversarially tests <em>AI</em> agents \u2014 prompt injection, tool misuse, data exfiltration, and infrastructure faults before they hit production.<p>The repo includes 6 intentionally vulnerable example agents (support bot, SQL <em>agent</em>, code executor, payment processor, API <em>agent</em>, document processor) with real attack scenarios showing exactly how they break. Try breaking them yourself.<p>Three commands to test your own <em>agent</em>:<p>- pip install khaos-<em>agent</em>\n- khaos discover \n- khaos run my-<em>agent</em> --pack security<p>It works with raw OpenAI/Anthropic, Gemini, LangGraph, CrewAI, AutoGen \u2014 any Python <em>agent</em>. Khaos auto-patches LLM calls to inject faults and log telemetry. No cloud needed, runs 100% locally.<p>Some of what it tests:<p>- Prompt injection (policy bypass, developer mode exploits)\n- Tool misuse (unauthorized DB writes, unscoped API calls)\n- Data exfiltration (PII extraction, credential leakage)\n- Fault injection (timeouts, rate limits, malformed tool responses)<p>We are the first <em>platform</em> that focuses on testing the <em>Agent</em>'s environment, not just the model in the harness.<p>Plus 4 tutorials using the free Gemini API if you want to learn without spending anything.\nRepo: <a href=\"https://github.com/ExordexLabs/khaos-sdk\" rel=\"nofollow\">https://github.com/ExordexLabs/khaos-sdk</a>\nExamples: <a href=\"https://github.com/ExordexLabs/khaos-examples\" rel=\"nofollow\">https://github.com/ExordexLabs/khaos-examples</a>\nBSD licensed. v1.0 just shipped \u2014 the attack library and framework adapters are growing. What agents are you most worried about breaking?"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","agent"],"value":"Show HN: Khaos \u2013 Every <em>AI</em> <em>agent</em> I tested broke in under 30 seconds"}},"_tags":["story","author_exordex","story_46997680","show_hn"],"author":"exordex","children":[47005873],"created_at":"2026-02-13T01:13:28Z","created_at_i":1770945208,"num_comments":1,"objectID":"46997680","points":1,"story_id":46997680,"story_text":"We&#x27;re shipping AI agents that process payments, query databases, and handle customer PII. Most of them can be tricked into bypassing their own safety policies in under 30 seconds.\nI built Khaos to prove it. It&#x27;s an open-source chaos engineering framework that adversarially tests AI agents \u2014 prompt injection, tool misuse, data exfiltration, and infrastructure faults before they hit production.<p>The repo includes 6 intentionally vulnerable example agents (support bot, SQL agent, code executor, payment processor, API agent, document processor) with real attack scenarios showing exactly how they break. Try breaking them yourself.<p>Three commands to test your own agent:<p>- pip install khaos-agent\n- khaos discover \n- khaos run my-agent --pack security<p>It works with raw OpenAI&#x2F;Anthropic, Gemini, LangGraph, CrewAI, AutoGen \u2014 any Python agent. Khaos auto-patches LLM calls to inject faults and log telemetry. No cloud needed, runs 100% locally.<p>Some of what it tests:<p>- Prompt injection (policy bypass, developer mode exploits)\n- Tool misuse (unauthorized DB writes, unscoped API calls)\n- Data exfiltration (PII extraction, credential leakage)\n- Fault injection (timeouts, rate limits, malformed tool responses)<p>We are the first platform that focuses on testing the Agent&#x27;s environment, not just the model in the harness.<p>Plus 4 tutorials using the free Gemini API if you want to learn without spending anything.\nRepo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-sdk\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-sdk</a>\nExamples: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-examples\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ExordexLabs&#x2F;khaos-examples</a>\nBSD licensed. v1.0 just shipped \u2014 the attack library and framework adapters are growing. What agents are you most worried about breaking?","title":"Show HN: Khaos \u2013 Every AI agent I tested broke in under 30 seconds","updated_at":"2026-02-13T18:21:40Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"afridi_epilabs"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"Hi HN \u2014 I\u2019m the founder of EPI.<p>EPI is a portable, cryptographically sealed artifact format (.epi) for <em>AI</em> <em>agent</em> execution.<p>Problem: When <em>AI</em> systems run in production and something goes wrong, there\u2019s no tamper-proof way to prove exactly what happened.<p>EPI records execution steps, inputs/outputs, metadata, and signatures into a verifiable bundle that can be replayed and audited.<p>It\u2019s open-source and installable via pip.<p>I\u2019d love feedback from:\n\u2013 ML infra engineers\n\u2013 <em>Platform</em> teams running <em>AI</em> <em>agents</em>\n\u2013 Security engineers<p>Happy to answer any technical questions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","agent"],"value":"Show HN: EPI \u2013 Cryptographically verifiable execution artifacts for <em>AI</em> <em>agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/mohdibrahimaiml/epi-recorder"}},"_tags":["story","author_afridi_epilabs","story_46996207","show_hn"],"author":"afridi_epilabs","children":[46996245,46996249],"created_at":"2026-02-12T22:29:39Z","created_at_i":1770935379,"num_comments":0,"objectID":"46996207","points":1,"story_id":46996207,"story_text":"Hi HN \u2014 I\u2019m the founder of EPI.<p>EPI is a portable, cryptographically sealed artifact format (.epi) for AI agent execution.<p>Problem: When AI systems run in production and something goes wrong, there\u2019s no tamper-proof way to prove exactly what happened.<p>EPI records execution steps, inputs&#x2F;outputs, metadata, and signatures into a verifiable bundle that can be replayed and audited.<p>It\u2019s open-source and installable via pip.<p>I\u2019d love feedback from:\n\u2013 ML infra engineers\n\u2013 Platform teams running AI agents\n\u2013 Security engineers<p>Happy to answer any technical questions.","title":"Show HN: EPI \u2013 Cryptographically verifiable execution artifacts for AI agents","updated_at":"2026-02-12T22:35:18Z","url":"https://github.com/mohdibrahimaiml/epi-recorder"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"danFctr"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"Hi HN,<p>Every week I watched Okta admins burn hours answering ad-hoc questions from security teams: &quot;Who has access to Salesforce?&quot;, &quot;Find all contractors with GitHub access who haven't used MFA in 30 days.&quot; The answers always involved the same painful loop: dig through a slow web console, chain API calls, correlate CSVs, write throwaway Python scripts. Repeat next week.<p>I spent 12 months building Tako <em>AI</em> to fix this. You ask a question in plain English, it returns verified data.<p>GitHub: <a href=\"https://github.com/fctr-id/okta-ai-agent\" rel=\"nofollow\">https://github.com/fctr-id/okta-<em>ai</em>-<em>agent</em></a><p>THE ONE RULE: Zero hallucinations.<p>In identity and access management, a wrong answer is worse than no answer. If an <em>AI</em> tells your CISO a contractor doesn't have admin access when they actually do, that's a security incident. Tako never &quot;predicts&quot; an answer. It writes the code to find the answer, executes it, and returns the raw result. Ask the same question twice, you get the same data.<p>THE HARDEST PROBLEM: Scaling to 107+ API endpoints<p>Most <em>AI</em> agents break down past 10-20 tools. They hallucinate parameters, call wrong endpoints, invent fields that don't exist. We went through five architecture rewrites over 12 months.<p>Each iteration: new LLM drops (GPT-4, Claude 3.5), we rebuild the <em>agent</em>, hit context limits, watch it snowball into gibberish. The breakthrough wasn't bigger context windows \u2014 it was precise context engineering. Instead of cramming 107 endpoint definitions into a prompt, the <em>agent</em> dynamically discovers the right spec for the task at hand. It reads a custom JSON API documentation file for the specific endpoint it needs, constructs validated requests, executes them. No hardcoded tools per endpoint. We're adding full CRUD operations next.<p>HOW IT WORKS:<p>Multi-<em>agent</em> architecture based on ReAct (Reasoning + Acting). Each <em>agent</em> has a narrow job:<p>\u2022 Router: analyzes your question, decides local cache vs live API\n\u2022 SQL <em>Agent</em>: queries local SQLite cache for bulk data (10k users in milliseconds vs minutes via API)\n\u2022 API <em>Agent</em>: handles live Okta calls\n\u2022 Synthesis <em>Agent</em>: merges everything into final verified report<p>The API <em>Agent</em> has a self-healing loop that surprised us. When generated code fails \u2014 wrong parameter name, rate limit hit, API schema changed \u2014 it traps the stack trace, feeds the error back to the LLM with context, and rewrites the code. We've seen it recover from Okta API changes we didn't even know happened yet.<p>PRIVACY &amp; SECURITY:<p>Runs 100% locally in Docker. You bring your own LLM keys (OpenAI, Anthropic, Gemini, or Ollama for fully offline). Your employee PII never leaves your machine.<p>READ-ONLY by design. All generated Python and API code runs in a sandboxed environment. Every execution is automatically verified against security patterns before running \u2014 code is logged and available for audit, but you don't manually approve each query.<p>WHAT'S NEXT:<p>We see this as a <em>platform</em>, not just an Okta tool. The pattern (local cache + live ReAct <em>agent</em> + self-healing code execution) generalizes to any SaaS API. Google Workspace, Slack, Workday \u2014 same architecture, different spec files. Working on write operations with human-in-the-loop approval next.<p>What would you want <em>AI</em> agents to actually do for you in 2026? Where do you see this tech going beyond chatbots?<p>\u2014Dan"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","agent"],"value":"Show HN: Tako <em>AI</em> \u2013 <em>Agent</em> for Okta With Natural language (zero hallucination)"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["ai","agent"],"value":"https://github.com/fctr-id/okta-<em>ai</em>-<em>agent</em>"}},"_tags":["story","author_danFctr","story_46990146","show_hn"],"author":"danFctr","created_at":"2026-02-12T15:38:38Z","created_at_i":1770910718,"num_comments":0,"objectID":"46990146","points":1,"story_id":46990146,"story_text":"Hi HN,<p>Every week I watched Okta admins burn hours answering ad-hoc questions from security teams: &quot;Who has access to Salesforce?&quot;, &quot;Find all contractors with GitHub access who haven&#x27;t used MFA in 30 days.&quot; The answers always involved the same painful loop: dig through a slow web console, chain API calls, correlate CSVs, write throwaway Python scripts. Repeat next week.<p>I spent 12 months building Tako AI to fix this. You ask a question in plain English, it returns verified data.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;fctr-id&#x2F;okta-ai-agent\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;fctr-id&#x2F;okta-ai-agent</a><p>THE ONE RULE: Zero hallucinations.<p>In identity and access management, a wrong answer is worse than no answer. If an AI tells your CISO a contractor doesn&#x27;t have admin access when they actually do, that&#x27;s a security incident. Tako never &quot;predicts&quot; an answer. It writes the code to find the answer, executes it, and returns the raw result. Ask the same question twice, you get the same data.<p>THE HARDEST PROBLEM: Scaling to 107+ API endpoints<p>Most AI agents break down past 10-20 tools. They hallucinate parameters, call wrong endpoints, invent fields that don&#x27;t exist. We went through five architecture rewrites over 12 months.<p>Each iteration: new LLM drops (GPT-4, Claude 3.5), we rebuild the agent, hit context limits, watch it snowball into gibberish. The breakthrough wasn&#x27;t bigger context windows \u2014 it was precise context engineering. Instead of cramming 107 endpoint definitions into a prompt, the agent dynamically discovers the right spec for the task at hand. It reads a custom JSON API documentation file for the specific endpoint it needs, constructs validated requests, executes them. No hardcoded tools per endpoint. We&#x27;re adding full CRUD operations next.<p>HOW IT WORKS:<p>Multi-agent architecture based on ReAct (Reasoning + Acting). Each agent has a narrow job:<p>\u2022 Router: analyzes your question, decides local cache vs live API\n\u2022 SQL Agent: queries local SQLite cache for bulk data (10k users in milliseconds vs minutes via API)\n\u2022 API Agent: handles live Okta calls\n\u2022 Synthesis Agent: merges everything into final verified report<p>The API Agent has a self-healing loop that surprised us. When generated code fails \u2014 wrong parameter name, rate limit hit, API schema changed \u2014 it traps the stack trace, feeds the error back to the LLM with context, and rewrites the code. We&#x27;ve seen it recover from Okta API changes we didn&#x27;t even know happened yet.<p>PRIVACY &amp; SECURITY:<p>Runs 100% locally in Docker. You bring your own LLM keys (OpenAI, Anthropic, Gemini, or Ollama for fully offline). Your employee PII never leaves your machine.<p>READ-ONLY by design. All generated Python and API code runs in a sandboxed environment. Every execution is automatically verified against security patterns before running \u2014 code is logged and available for audit, but you don&#x27;t manually approve each query.<p>WHAT&#x27;S NEXT:<p>We see this as a platform, not just an Okta tool. The pattern (local cache + live ReAct agent + self-healing code execution) generalizes to any SaaS API. Google Workspace, Slack, Workday \u2014 same architecture, different spec files. Working on write operations with human-in-the-loop approval next.<p>What would you want AI agents to actually do for you in 2026? Where do you see this tech going beyond chatbots?<p>\u2014Dan","title":"Show HN: Tako AI \u2013 Agent for Okta With Natural language (zero hallucination)","updated_at":"2026-02-12T15:40:32Z","url":"https://github.com/fctr-id/okta-ai-agent"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"dklvs"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["ai","agent","platform"],"value":"SaySigned \u2013 The e-signature <em>platform</em> built for <em>AI</em> <em>agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://saysigned.com/"}},"_tags":["story","author_dklvs","story_46989782"],"author":"dklvs","children":[46992397],"created_at":"2026-02-12T15:10:19Z","created_at_i":1770909019,"num_comments":5,"objectID":"46989782","points":4,"story_id":46989782,"title":"SaySigned \u2013 The e-signature platform built for AI agents","updated_at":"2026-02-13T06:51:04Z","url":"https://saysigned.com/"}],"hitsPerPage":10,"nbHits":767,"nbPages":77,"page":0,"params":"query=AI+agent+platform&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":24,"processingTimingsMS":{"_request":{"roundTrip":20},"fetch":{"query":3,"scanning":19,"total":23},"total":24},"query":"AI agent platform","serverTimeMS":25}
