{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I\u2019ve been working on PolyMCP, an open-source framework designed to make it easier to build and coordinate agents using the Model Context <em>Protocol</em> (<em>MCP</em>).<p>Most <em>MCP</em> tooling today focuses primarily on exposing tools. PolyMCP instead targets the agent layer: how to structure agents properly, connect them to multiple <em>MCP</em> servers, and make them reliable in real-world workflows.<p>PolyMCP provides:\n \u2022 A clean way to implement <em>MCP</em>-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple <em>MCP</em> endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for handling multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular architecture that makes it easier to compose skills and reuse components across projects<p>The goal is to reduce ad-hoc glue code between models and tools. Instead of manually wiring everything together for each new setup, PolyMCP offers a structured way to:\n \u2022 Register tools as <em>MCP</em> servers\n \u2022 Attach them to one or more agents\n \u2022 Explicitly manage execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and aimed at developers building production-grade automation, internal copilots, or multi-tool assistants.<p>Repository: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-<em>mcp</em>/PolyMCP</a>"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"Show HN: PolyMCP \u2013 A framework for structuring and orchestrating <em>MCP</em> agents"}},"_tags":["story","author_justvugg","story_47026179","show_hn"],"author":"justvugg","created_at":"2026-02-15T18:40:05Z","created_at_i":1771180805,"num_comments":0,"objectID":"47026179","points":1,"story_id":47026179,"story_text":"I\u2019ve been working on PolyMCP, an open-source framework designed to make it easier to build and coordinate agents using the Model Context Protocol (MCP).<p>Most MCP tooling today focuses primarily on exposing tools. PolyMCP instead targets the agent layer: how to structure agents properly, connect them to multiple MCP servers, and make them reliable in real-world workflows.<p>PolyMCP provides:\n \u2022 A clean way to implement MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for handling multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular architecture that makes it easier to compose skills and reuse components across projects<p>The goal is to reduce ad-hoc glue code between models and tools. Instead of manually wiring everything together for each new setup, PolyMCP offers a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Attach them to one or more agents\n \u2022 Explicitly manage execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and aimed at developers building production-grade automation, internal copilots, or multi-tool assistants.<p>Repository: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a>","title":"Show HN: PolyMCP \u2013 A framework for structuring and orchestrating MCP agents","updated_at":"2026-02-15T18:40:57Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Hi everyone,<p>I\u2019ve been working on PolyMCP, an open-source framework for building and orchestrating agents using the Model Context <em>Protocol</em> (<em>MCP</em>).<p>Most of the tooling around <em>MCP</em> focuses on exposing tools. With PolyMCP, the focus this time is on agents: how to structure them, connect them to multiple <em>MCP</em> servers, and make them reliable in real workflows.<p>PolyMCP provides:\n \u2022 A clean way to define <em>MCP</em>-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple <em>MCP</em> endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular structure that makes it easier to compose skills and reuse components across projects<p>The main goal is to make agent systems less ad-hoc. Instead of writing glue code around each model + tool combination, PolyMCP gives you a structured way to:\n \u2022 Register tools as <em>MCP</em> servers\n \u2022 Connect them to one or more agents\n \u2022 Control execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and intended for developers building real-world automation, internal copilots, or multi-tool assistants.<p>I\u2019d love feedback on:\n \u2022 The agent abstraction: is it too opinionated or not opinionated enough?\n \u2022 Orchestration patterns for multi-agent setups\n \u2022 Developer experience (CLI, inspector, project layout)<p>Happy to answer questions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"Show HN: PolyMCP \u2013 A framework for building and orchestrating <em>MCP</em> agents"}},"_tags":["story","author_justvugg","story_47017912","show_hn"],"author":"justvugg","children":[47017997],"created_at":"2026-02-14T20:11:10Z","created_at_i":1771099870,"num_comments":2,"objectID":"47017912","points":2,"story_id":47017912,"story_text":"Hi everyone,<p>I\u2019ve been working on PolyMCP, an open-source framework for building and orchestrating agents using the Model Context Protocol (MCP).<p>Most of the tooling around MCP focuses on exposing tools. With PolyMCP, the focus this time is on agents: how to structure them, connect them to multiple MCP servers, and make them reliable in real workflows.<p>PolyMCP provides:\n \u2022 A clean way to define MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular structure that makes it easier to compose skills and reuse components across projects<p>The main goal is to make agent systems less ad-hoc. Instead of writing glue code around each model + tool combination, PolyMCP gives you a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Connect them to one or more agents\n \u2022 Control execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and intended for developers building real-world automation, internal copilots, or multi-tool assistants.<p>I\u2019d love feedback on:\n \u2022 The agent abstraction: is it too opinionated or not opinionated enough?\n \u2022 Orchestration patterns for multi-agent setups\n \u2022 Developer experience (CLI, inspector, project layout)<p>Happy to answer questions.","title":"Show HN: PolyMCP \u2013 A framework for building and orchestrating MCP agents","updated_at":"2026-02-15T01:00:55Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"settlddotwork"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Hey HN,<p>I built Settld because I kept running into the same problem: AI agents can call APIs, pay for services, and hire other agents - but there's no way to prove the work was actually done before the money moves.<p>The problem in one sentence: x402 tells you &quot;payment was sent&quot;. Settld tells you &quot;the work was worth paying for&quot;.<p>What it does<p>Settld sits between your agent and the APIs/agents it pays. It:<p>1. Intercepts HTTP 402 (Payment Required) responses\n2. Creates an escrow hold instead of paying immediately\n3. Collects evidence that the work was completed\n4. Runs deterministic verification (same evidence + same terms = same payout, every time)\n5. Releases payment only after verification passes\n6. Issues a cryptographically verifiable receipt<p>If verification fails or the work is disputed, the hold is refunded. The agent gets a receipt either way - a permanent, auditable record of what happened.<p>Why this matters now<p>We're at a weird inflection point. Coinbase shipped x402 (50M+ transactions). Google shipped A2A. Anthropic shipped <em>MCP</em>. Agents can discover each other, communicate, and pay each other.<p>But nobody built the layer that answers: &quot;was the work actually done correctly, and how much should the payout be?&quot;<p>That's the gap. Right now, every agent-to-agent transaction is either &quot;trust and hope&quot; or &quot;don't transact.&quot; Neither scales.<p>The x402 gateway (the fastest way to try it)<p>We ship a drop-in reverse proxy that you put in front of any API:<p>docker run -e UPSTREAM_URL=<a href=\"https://your-api.com\" rel=\"nofollow\">https://your-api.com</a> \\\n           -e SETTLD_API_URL=<a href=\"https://api.settld.dev\" rel=\"nofollow\">https://api.settld.dev</a> \\\n           -e SETTLD_API_KEY=sk_... \\\n           -p 8402:8402 \\\n           settld/x402-gateway<p>Everything flows through normally - except 402 responses get intercepted, escrowed, verified, and settled. Your agent gets a receipt with a hash-chained proof of what happened.<p>What's under the hood<p>The settlement kernel is the interesting part (and where we spent most of our time):<p>- Deterministic policy evaluation - machine-readable agreements with release rates based on verification status (green/amber/red). No ambiguity.\n- Hash-chained event log - every event in a settlement is chained with Ed25519 signatures. Tamper-evident, offline-verifiable.\n- Escrow with holdback windows - configurable holdback basis points + dispute windows. Funds auto-release if unchallenged.\n- Dispute \u2192 arbitration \u2192 verdict \u2192 adjustment - full dispute resolution pipeline, not just &quot;flag for human review.&quot;\n- Append-only reputation events - every settlement produces a reputation event (approved, rejected, disputed, etc.). Agents build verifiable economic track records.\n- Compositional settlement - agents can delegate work to sub-agents with linked agreements. If a downstream agent fails, refunds cascade deterministically back up the chain.<p>The whole <em>protocol</em> is spec'd with JSON schemas, conformance vectors, and a portable oracle: <a href=\"https://github.com/aidenlippert/settld/blob/main/docs/spec/README.md\" rel=\"nofollow\">https://github.com/aidenlippert/settld/blob/main/docs/spec/R...</a><p>What this is NOT<p>- Not a payment processor - we don't move money. We decide &quot;if&quot; and &quot;how much&quot; money should move, then your existing rails (Stripe, x402, wire) execute it.\n- Not a blockchain - deterministic receipts and hash chains, but no consensus mechanism or token. Just cryptographic proofs.\n- Not an agent framework - we don't care if you use LangChain, CrewAI, AutoGen, or raw API calls. We're a <em>protocol</em> layer.<p>Tech stack<p>Node.js, PostgreSQL (or in-memory for dev), Ed25519 signatures, SHA-256 hashing, RFC 8785 canonical JSON. ~107 core modules, 494 tests passing.<p>What I want from HN<p>Honest feedback on whether this problem resonates. If you're building agent workflows that involve money, I want to know: what breaks? What's missing? What would make you actually install this?<p>GitHub: <a href=\"https://github.com/aidenlippert/settld\" rel=\"nofollow\">https://github.com/aidenlippert/settld</a>\nDocs: <a href=\"https://docs.settld.work/\" rel=\"nofollow\">https://docs.settld.work/</a> \nQuickstart (10 min): <a href=\"https://docs.settld.work/quickstart\" rel=\"nofollow\">https://docs.settld.work/quickstart</a>"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Verify-before-release x402 gateway for AI agent transactions"}},"_tags":["story","author_settlddotwork","story_47011510","show_hn"],"author":"settlddotwork","created_at":"2026-02-14T04:17:17Z","created_at_i":1771042637,"num_comments":0,"objectID":"47011510","points":2,"story_id":47011510,"story_text":"Hey HN,<p>I built Settld because I kept running into the same problem: AI agents can call APIs, pay for services, and hire other agents - but there&#x27;s no way to prove the work was actually done before the money moves.<p>The problem in one sentence: x402 tells you &quot;payment was sent&quot;. Settld tells you &quot;the work was worth paying for&quot;.<p>What it does<p>Settld sits between your agent and the APIs&#x2F;agents it pays. It:<p>1. Intercepts HTTP 402 (Payment Required) responses\n2. Creates an escrow hold instead of paying immediately\n3. Collects evidence that the work was completed\n4. Runs deterministic verification (same evidence + same terms = same payout, every time)\n5. Releases payment only after verification passes\n6. Issues a cryptographically verifiable receipt<p>If verification fails or the work is disputed, the hold is refunded. The agent gets a receipt either way - a permanent, auditable record of what happened.<p>Why this matters now<p>We&#x27;re at a weird inflection point. Coinbase shipped x402 (50M+ transactions). Google shipped A2A. Anthropic shipped MCP. Agents can discover each other, communicate, and pay each other.<p>But nobody built the layer that answers: &quot;was the work actually done correctly, and how much should the payout be?&quot;<p>That&#x27;s the gap. Right now, every agent-to-agent transaction is either &quot;trust and hope&quot; or &quot;don&#x27;t transact.&quot; Neither scales.<p>The x402 gateway (the fastest way to try it)<p>We ship a drop-in reverse proxy that you put in front of any API:<p>docker run -e UPSTREAM_URL=<a href=\"https:&#x2F;&#x2F;your-api.com\" rel=\"nofollow\">https:&#x2F;&#x2F;your-api.com</a> \\\n           -e SETTLD_API_URL=<a href=\"https:&#x2F;&#x2F;api.settld.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;api.settld.dev</a> \\\n           -e SETTLD_API_KEY=sk_... \\\n           -p 8402:8402 \\\n           settld&#x2F;x402-gateway<p>Everything flows through normally - except 402 responses get intercepted, escrowed, verified, and settled. Your agent gets a receipt with a hash-chained proof of what happened.<p>What&#x27;s under the hood<p>The settlement kernel is the interesting part (and where we spent most of our time):<p>- Deterministic policy evaluation - machine-readable agreements with release rates based on verification status (green&#x2F;amber&#x2F;red). No ambiguity.\n- Hash-chained event log - every event in a settlement is chained with Ed25519 signatures. Tamper-evident, offline-verifiable.\n- Escrow with holdback windows - configurable holdback basis points + dispute windows. Funds auto-release if unchallenged.\n- Dispute \u2192 arbitration \u2192 verdict \u2192 adjustment - full dispute resolution pipeline, not just &quot;flag for human review.&quot;\n- Append-only reputation events - every settlement produces a reputation event (approved, rejected, disputed, etc.). Agents build verifiable economic track records.\n- Compositional settlement - agents can delegate work to sub-agents with linked agreements. If a downstream agent fails, refunds cascade deterministically back up the chain.<p>The whole protocol is spec&#x27;d with JSON schemas, conformance vectors, and a portable oracle: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld&#x2F;blob&#x2F;main&#x2F;docs&#x2F;spec&#x2F;README.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld&#x2F;blob&#x2F;main&#x2F;docs&#x2F;spec&#x2F;R...</a><p>What this is NOT<p>- Not a payment processor - we don&#x27;t move money. We decide &quot;if&quot; and &quot;how much&quot; money should move, then your existing rails (Stripe, x402, wire) execute it.\n- Not a blockchain - deterministic receipts and hash chains, but no consensus mechanism or token. Just cryptographic proofs.\n- Not an agent framework - we don&#x27;t care if you use LangChain, CrewAI, AutoGen, or raw API calls. We&#x27;re a protocol layer.<p>Tech stack<p>Node.js, PostgreSQL (or in-memory for dev), Ed25519 signatures, SHA-256 hashing, RFC 8785 canonical JSON. ~107 core modules, 494 tests passing.<p>What I want from HN<p>Honest feedback on whether this problem resonates. If you&#x27;re building agent workflows that involve money, I want to know: what breaks? What&#x27;s missing? What would make you actually install this?<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;aidenlippert&#x2F;settld</a>\nDocs: <a href=\"https:&#x2F;&#x2F;docs.settld.work&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.settld.work&#x2F;</a> \nQuickstart (10 min): <a href=\"https:&#x2F;&#x2F;docs.settld.work&#x2F;quickstart\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.settld.work&#x2F;quickstart</a>","title":"Show HN: Verify-before-release x402 gateway for AI agent transactions","updated_at":"2026-02-14T04:45:36Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"L3nnox_Cc"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Hey HN,<p>I built Engram because every time I started a new Claude Code session, it forgot everything. Same questions, same mistakes, zero context. AI agents have Alzheimer.<p>Engram is a memory layer for AI agents. Store facts, preferences, and decisions. Search them with full-text search. Recall the most important ones for context injection. 5 lines of Python, zero config.<p><pre><code>  from engram import Memory\n  mem = Memory()\n  mem.store(&quot;User prefers dark mode&quot;, importance=8)\n  results = mem.search(&quot;dark mode&quot;)\n  context = mem.recall(limit=10)\n</code></pre>\nWhat makes it different from Mem0/Letta/Zep:<p>Local-first: SQLite, runs on your machine. No cloud, no API keys, no telemetry.<p>Zero config: pip install engram-core and go. No Docker, no Postgres, no vector DB.<p><em>MCP</em> native: First-class Model Context <em>Protocol</em> support \u2014 plug into Claude Code, Cursor, or any <em>MCP</em> client.<p>Privacy: Your data never leaves your machine. MIT licensed.<p>I use it daily with Claude Code via an auto-recall hook \u2014 every new session starts with my important memories pre-loaded. No more &quot;where were we?&quot;<p>Built with: Python, SQLite FTS5, FastAPI, <em>MCP</em> SDK.<p>Website: <a href=\"https://engram-ai.dev\" rel=\"nofollow\">https://engram-ai.dev</a><p>GitHub: <a href=\"https://github.com/engram-memory/engram\" rel=\"nofollow\">https://github.com/engram-memory/engram</a><p>PyPI: pip install engram-core<p>Would love feedback. What memory features would you want for your agents?"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Engram \u2013 Persistent memory for AI agents, local-first and open source"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://engram-ai.dev"}},"_tags":["story","author_L3nnox_Cc","story_47008274","show_hn"],"author":"L3nnox_Cc","created_at":"2026-02-13T21:46:53Z","created_at_i":1771019213,"num_comments":0,"objectID":"47008274","points":3,"story_id":47008274,"story_text":"Hey HN,<p>I built Engram because every time I started a new Claude Code session, it forgot everything. Same questions, same mistakes, zero context. AI agents have Alzheimer.<p>Engram is a memory layer for AI agents. Store facts, preferences, and decisions. Search them with full-text search. Recall the most important ones for context injection. 5 lines of Python, zero config.<p><pre><code>  from engram import Memory\n  mem = Memory()\n  mem.store(&quot;User prefers dark mode&quot;, importance=8)\n  results = mem.search(&quot;dark mode&quot;)\n  context = mem.recall(limit=10)\n</code></pre>\nWhat makes it different from Mem0&#x2F;Letta&#x2F;Zep:<p>Local-first: SQLite, runs on your machine. No cloud, no API keys, no telemetry.<p>Zero config: pip install engram-core and go. No Docker, no Postgres, no vector DB.<p>MCP native: First-class Model Context Protocol support \u2014 plug into Claude Code, Cursor, or any MCP client.<p>Privacy: Your data never leaves your machine. MIT licensed.<p>I use it daily with Claude Code via an auto-recall hook \u2014 every new session starts with my important memories pre-loaded. No more &quot;where were we?&quot;<p>Built with: Python, SQLite FTS5, FastAPI, MCP SDK.<p>Website: <a href=\"https:&#x2F;&#x2F;engram-ai.dev\" rel=\"nofollow\">https:&#x2F;&#x2F;engram-ai.dev</a><p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;engram-memory&#x2F;engram\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;engram-memory&#x2F;engram</a><p>PyPI: pip install engram-core<p>Would love feedback. What memory features would you want for your agents?","title":"Show HN: Engram \u2013 Persistent memory for AI agents, local-first and open source","updated_at":"2026-02-13T22:09:51Z","url":"https://engram-ai.dev"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"orbydx"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I built 75 developer and AI tools as a single static site. Everything runs in the browser, no cookies, no ads, nothing gets sent to a server.<p>The tools range from the usual suspects (JSON formatter, base64 encoder, regex tester) to some AI-specific ones I couldn't find good free versions of bundled in one suite:<p>- LLM Token Counter (estimates tokens for GPT, Claude, Gemini, etc.)\n- AI Model Comparison (specs, pricing, context windows side by side)\n- AI Cost Estimator (plug in your usage, get monthly cost projections)\n- <em>MCP</em> Server Directory (browsable catalog of Model Context <em>Protocol</em> servers)\n- Agent Framework Comparison (LangChain vs CrewAI vs AutoGen vs...)\n- Prompt Template Builder (variables, conditionals, versioning)\n- Markdown Memory Generator (for OpenClaw)<p>Plus the standard dev toolkit: JWT decoder, cron expression builder, diff checker, SQL formatter, color converter, CSS flexbox playground, etc.<p>Tech stack: Astro 5 with React islands, Tailwind CSS 4, hosted on Cloudflare Pages. The whole site is static, so it loads fast everywhere. Largest JS bundle is 58 KB gzipped.<p>I built this with AI agent Rusty (OpenClaw). The AI handled most of the component code while I focused on architecture decisions, tool selection, and QA. Took about 2 days of evening sessions.<p>No login, no tracking cookies, no ads, no &quot;sign up for premium&quot;. Just tools.<p>Feedback welcome. What ai or dev tools do you wish existed that don't?"},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: AI Dev Hub. 75 free AI and dev tools"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://aidevhub.io/"}},"_tags":["story","author_orbydx","story_47003685","show_hn"],"author":"orbydx","created_at":"2026-02-13T15:20:44Z","created_at_i":1770996044,"num_comments":0,"objectID":"47003685","points":1,"story_id":47003685,"story_text":"I built 75 developer and AI tools as a single static site. Everything runs in the browser, no cookies, no ads, nothing gets sent to a server.<p>The tools range from the usual suspects (JSON formatter, base64 encoder, regex tester) to some AI-specific ones I couldn&#x27;t find good free versions of bundled in one suite:<p>- LLM Token Counter (estimates tokens for GPT, Claude, Gemini, etc.)\n- AI Model Comparison (specs, pricing, context windows side by side)\n- AI Cost Estimator (plug in your usage, get monthly cost projections)\n- MCP Server Directory (browsable catalog of Model Context Protocol servers)\n- Agent Framework Comparison (LangChain vs CrewAI vs AutoGen vs...)\n- Prompt Template Builder (variables, conditionals, versioning)\n- Markdown Memory Generator (for OpenClaw)<p>Plus the standard dev toolkit: JWT decoder, cron expression builder, diff checker, SQL formatter, color converter, CSS flexbox playground, etc.<p>Tech stack: Astro 5 with React islands, Tailwind CSS 4, hosted on Cloudflare Pages. The whole site is static, so it loads fast everywhere. Largest JS bundle is 58 KB gzipped.<p>I built this with AI agent Rusty (OpenClaw). The AI handled most of the component code while I focused on architecture decisions, tool selection, and QA. Took about 2 days of evening sessions.<p>No login, no tracking cookies, no ads, no &quot;sign up for premium&quot;. Just tools.<p>Feedback welcome. What ai or dev tools do you wish existed that don&#x27;t?","title":"Show HN: AI Dev Hub. 75 free AI and dev tools","updated_at":"2026-02-13T15:22:05Z","url":"https://aidevhub.io/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"intheleantime"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I built an <em>MCP</em> server that connects coding agents (Claude Code, Cursor, OpenCode, Codex) to a collaborative workspace where your team and other AI models can review what the agent is planning.<p>The problem: When Claude Code creates an implementation plan, it lives in your terminal session. Nobody else sees it until it becomes a PR. If you want GPT to check the architecture or a teammate to flag issues, you're copy-pasting between windows.<p>This <em>MCP</em> server fixes that. When your agent creates a plan, it gets shared as a collaborative thread in CoChat. Engineers comment on it, other AI models review it, and you pull all the feedback back into your agent's context with one command. Decisions can be saved as project memories that persist across sessions and are searchable by anyone.<p>What it does:<p>Plans: Auto-shared as collaborative threads. Pull feedback back into your terminal.\nCross-model review: Have GPT review your Claude plan, or vice versa.\nProject memories: Semantic memory that persists across sessions, models, and people.\nAsk: Query your project's knowledge base from the terminal.\nAuto-scoping: Detects your project from git remote. No config needed.\nSetup is one command per agent. Auto-share behavior is configurable (off/plan/all).<p>MIT licensed, available on npm: npx @cochatai/<em>mcp</em>-cochat<p>Happy to answer questions about the architecture or the <em>MCP</em> <em>protocol</em> integration."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"Show HN: CoChat <em>MCP</em> \u2013 Let your team review what your coding agent is building"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"https://github.com/CoChatAI/<em>mcp</em>-cochat"}},"_tags":["story","author_intheleantime","story_47002924","show_hn"],"author":"intheleantime","created_at":"2026-02-13T14:11:40Z","created_at_i":1770991900,"num_comments":0,"objectID":"47002924","points":5,"story_id":47002924,"story_text":"I built an MCP server that connects coding agents (Claude Code, Cursor, OpenCode, Codex) to a collaborative workspace where your team and other AI models can review what the agent is planning.<p>The problem: When Claude Code creates an implementation plan, it lives in your terminal session. Nobody else sees it until it becomes a PR. If you want GPT to check the architecture or a teammate to flag issues, you&#x27;re copy-pasting between windows.<p>This MCP server fixes that. When your agent creates a plan, it gets shared as a collaborative thread in CoChat. Engineers comment on it, other AI models review it, and you pull all the feedback back into your agent&#x27;s context with one command. Decisions can be saved as project memories that persist across sessions and are searchable by anyone.<p>What it does:<p>Plans: Auto-shared as collaborative threads. Pull feedback back into your terminal.\nCross-model review: Have GPT review your Claude plan, or vice versa.\nProject memories: Semantic memory that persists across sessions, models, and people.\nAsk: Query your project&#x27;s knowledge base from the terminal.\nAuto-scoping: Detects your project from git remote. No config needed.\nSetup is one command per agent. Auto-share behavior is configurable (off&#x2F;plan&#x2F;all).<p>MIT licensed, available on npm: npx @cochatai&#x2F;mcp-cochat<p>Happy to answer questions about the architecture or the MCP protocol integration.","title":"Show HN: CoChat MCP \u2013 Let your team review what your coding agent is building","updated_at":"2026-02-13T19:20:05Z","url":"https://github.com/CoChatAI/mcp-cochat"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"Andreas_3d"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I built AgentProbe to solve a recurring problem: checking whether an AI agent endpoint actually supports the <em>protocols</em> it claims to.<p>Paste a URL, click Validate, get instant verdicts across HTTP, <em>MCP</em>, A2A/AP2, x402, OAuth, <em>MCP</em> Apps, HTML, and ERC-8004.<p>Each layer gets a detail breakdown \u2014 tools found, payment networks, SSL status, agent card metadata, AP2 detection, etc.<p>It also exposes a built-in <em>MCP</em> server so agents can trigger validation programmatically.<p>Code: <a href=\"https://github.com/FlowMCP/mcp-agent-validator\" rel=\"nofollow\">https://github.com/FlowMCP/<em>mcp</em>-agent-validator</a>\nStack: Node.js 22, vanilla JS, DigitalOcean App Platform.<p>Would love feedback on the detection approach."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["protocol"],"value":"Show HN: AgentProbe \u2013 Validate AI agent endpoints across 8 <em>protocols</em> in one URL"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://agentprobe.xyz"}},"_tags":["story","author_Andreas_3d","story_46999938","show_hn"],"author":"Andreas_3d","created_at":"2026-02-13T07:31:06Z","created_at_i":1770967866,"num_comments":0,"objectID":"46999938","points":1,"story_id":46999938,"story_text":"I built AgentProbe to solve a recurring problem: checking whether an AI agent endpoint actually supports the protocols it claims to.<p>Paste a URL, click Validate, get instant verdicts across HTTP, MCP, A2A&#x2F;AP2, x402, OAuth, MCP Apps, HTML, and ERC-8004.<p>Each layer gets a detail breakdown \u2014 tools found, payment networks, SSL status, agent card metadata, AP2 detection, etc.<p>It also exposes a built-in MCP server so agents can trigger validation programmatically.<p>Code: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;FlowMCP&#x2F;mcp-agent-validator\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FlowMCP&#x2F;mcp-agent-validator</a>\nStack: Node.js 22, vanilla JS, DigitalOcean App Platform.<p>Would love feedback on the detection approach.","title":"Show HN: AgentProbe \u2013 Validate AI agent endpoints across 8 protocols in one URL","updated_at":"2026-02-13T07:35:04Z","url":"https://agentprobe.xyz"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"hacker27369"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"I spent the last few years in High-Frequency Trading. In that world, &quot;probabilistic&quot; automation is a non-starter; if an AI hallucinations or clicks the wrong pixel, it's a compliance disaster.\nMost current AI agents rely on vision (pixels). It\u2019s slow, brittle, and introduces a massive margin of error. I built GodHands to treat desktop apps like structured APIs instead of screenshots. It\u2019s an <em>MCP</em> (Model Context <em>Protocol</em>) server that acts as a deterministic &quot;action layer.&quot;<p>The Approach:<p>Object Model &gt; Pixels: Instead of vision, the engine hooks into application object models directly. It maps data structures dynamically so the automation doesn't break when the UI changes.<p>Architect vs. Builder: The LLM acts only as the Architect (intent). A local execution engine acts as the Builder. The AI never &quot;guesses&quot; the math; it triggers verified code primitives.<p>Local-First: All data processing stays on your machine. The LLM handles the reasoning, but the GodHands engine handles the data locally.<p>The Workflow: It bridges siloed apps into a unified <em>protocol</em>\u2014e.g., scraping a Gmail statement, running a cross-sheet reconciliation in Excel, and piping anomalies to Slack or a Calendar invite.<p>I\u2019m looking for technical feedback on this architecture, specifically the deterministic vs. probabilistic trade-off in RPA. I\u2019ll be around to answer questions about the implementation or the <em>MCP</em> layer. If you are interested in trying out our beta version, please reach out to us at founders@godhands.dev"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"GodHands \u2013 Deterministic Desktop Automation via <em>MCP</em>"}},"_tags":["story","author_hacker27369","story_46996023","ask_hn"],"author":"hacker27369","created_at":"2026-02-12T22:13:58Z","created_at_i":1770934438,"num_comments":0,"objectID":"46996023","points":1,"story_id":46996023,"story_text":"I spent the last few years in High-Frequency Trading. In that world, &quot;probabilistic&quot; automation is a non-starter; if an AI hallucinations or clicks the wrong pixel, it&#x27;s a compliance disaster.\nMost current AI agents rely on vision (pixels). It\u2019s slow, brittle, and introduces a massive margin of error. I built GodHands to treat desktop apps like structured APIs instead of screenshots. It\u2019s an MCP (Model Context Protocol) server that acts as a deterministic &quot;action layer.&quot;<p>The Approach:<p>Object Model &gt; Pixels: Instead of vision, the engine hooks into application object models directly. It maps data structures dynamically so the automation doesn&#x27;t break when the UI changes.<p>Architect vs. Builder: The LLM acts only as the Architect (intent). A local execution engine acts as the Builder. The AI never &quot;guesses&quot; the math; it triggers verified code primitives.<p>Local-First: All data processing stays on your machine. The LLM handles the reasoning, but the GodHands engine handles the data locally.<p>The Workflow: It bridges siloed apps into a unified protocol\u2014e.g., scraping a Gmail statement, running a cross-sheet reconciliation in Excel, and piping anomalies to Slack or a Calendar invite.<p>I\u2019m looking for technical feedback on this architecture, specifically the deterministic vs. probabilistic trade-off in RPA. I\u2019ll be around to answer questions about the implementation or the MCP layer. If you are interested in trying out our beta version, please reach out to us at founders@godhands.dev","title":"GodHands \u2013 Deterministic Desktop Automation via MCP","updated_at":"2026-02-13T04:43:48Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"lucamoretti"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"Comprehensive Secrets Management Guide for <em>MCP</em> (Model Context <em>Protocol</em>) Servers"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["mcp"],"value":"https://github.com/rsdouglas/janee/blob/main/docs/<em>mcp</em>-secrets-guide.md"}},"_tags":["story","author_lucamoretti","story_46988171"],"author":"lucamoretti","children":[46988172],"created_at":"2026-02-12T12:50:50Z","created_at_i":1770900650,"num_comments":1,"objectID":"46988171","points":1,"story_id":46988171,"title":"Comprehensive Secrets Management Guide for MCP (Model Context Protocol) Servers","updated_at":"2026-02-12T12:52:31Z","url":"https://github.com/rsdouglas/janee/blob/main/docs/mcp-secrets-guide.md"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"varunpratap369"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["mcp","protocol"],"value":"The Problem\nAI assistants have amnesia. Every new Claude/ChatGPT/Cursor session starts from zero. You waste hours re-explaining your project architecture, coding preferences, and previous decisions.\nExisting solutions (Mem0, Zep, Letta) are cloud-based, cost $40-50+/month, and your private code goes to their servers. Stop paying \u2192 lose all your data.\nMy Solution: Local-First, Free Forever\nBuilt a universal memory system that stores everything on YOUR machine, works with 16+ AI tools simultaneously, requires zero API keys, costs nothing.\n10-Layer Architecture\nEach layer enhances but never replaces lower layers. System degrades gracefully if advanced features fail.\nLayer 10: A2A Agent Collaboration (v2.6)\nLayer 9: Web Dashboard (SSE real-time)\nLayer 8: Hybrid Search (Semantic + FTS5 + Graph)\nLayer 7: Universal Access (<em>MCP</em> + Skills + CLI)\nLayer 6: <em>MCP</em> Integration (native Claude tools)\nLayer 5: Skills (slash commands for 16+ tools)\nLayer 4: Pattern Learning (Bayesian confidence)\nLayer 3: Knowledge Graph (TF-IDF + Leiden clustering)\nLayer 2: Hierarchical Index (parent-child relationships)\nLayer 1: SQLite + FTS5 + TF-IDF vectors\nResearch-Backed\nBuilt on published research, adapted for local-first:<p>A2A <em>Protocol</em> (Google/Linux Foundation, 2025)\nGraphRAG (Microsoft arXiv:2404.16130)\nMACLA Bayesian learning (arXiv:2512.18950)\nA-RAG hybrid search (arXiv:2602.03442)<p>Key difference: Research papers assume cloud APIs. SuperLocalMemory implements everything locally with zero API calls.\nHow Recall Works\nQuery &quot;authentication&quot; triggers:<p>FTS5 full-text search\nTF-IDF vector similarity\nGraph traversal for related memories\nHierarchical expansion (parent/child context)\nHybrid ranking (combines all signals)<p>Performance: &lt;50ms, even with 10K+ memories.\nComparison\nFeatureSuperLocalMemoryMem0/Zep/LettaPrivacy100% localCloudCostFree$40-50+/moKnowledge GraphPattern Learning BayesianMulti-tool16+LimitedCLIWorks Offline\nReal Usage\nCross-tool context:\nbash# Save in terminal\nslm remember &quot;Next.js 15 uses Turbopack&quot; --tags nextjs<p># Later in Cursor, Claude auto-recalls via <em>MCP</em>\nProject profiles:\nbashslm switch-profile work-project\nslm switch-profile personal-blog\n# Separate memory per project\nPattern learning: After several sessions, Claude learns you prefer TypeScript strict mode, Tailwind styling, Vitest testing\u2014starts suggesting without being asked.\nInstallation\nbashnpm install -g superlocalmemory\nAuto-configures <em>MCP</em> for Claude Desktop, Cursor, Windsurf. Sets up CLI commands. That's it.\nWhy Local-First Matters<p>Privacy: Code never leaves your machine\nOwnership: Your data, forever\nSpeed: 50ms queries, no network latency\nReliability: Works offline, no API limits\nCost: $0 forever<p>Tech Stack<p>SQLite (ACID, zero config)\nFTS5 (full-text search)\nTF-IDF (vector similarity, no OpenAI API)\nigraph (Leiden clustering)\nBayesian inference (pattern learning)\n<em>MCP</em> (native Claude integration)<p>GitHub\n <a href=\"https://github.com/varun369/SuperLocalMemoryV2\" rel=\"nofollow\">https://github.com/varun369/SuperLocalMemoryV2</a>\nMIT License. Full docs in wiki.<p>Current status: v2.4 stable. v2.5 (March) adds real-time event stream, concurrent access, trust scoring. v2.6 (May) adds A2A <em>Protocol</em> for multi-agent collaboration.\nBuilt by Varun Pratap Bhardwaj, Solution Architect . 15+ years AI/ML experience."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: SuperLocalMemory\u2013 Local-first AI memory for Claude, Cursor and 16+tools"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/varun369/SuperLocalMemoryV2"}},"_tags":["story","author_varunpratap369","story_46986940","show_hn"],"author":"varunpratap369","children":[46986946],"created_at":"2026-02-12T10:11:31Z","created_at_i":1770891091,"num_comments":0,"objectID":"46986940","points":1,"story_id":46986940,"story_text":"The Problem\nAI assistants have amnesia. Every new Claude&#x2F;ChatGPT&#x2F;Cursor session starts from zero. You waste hours re-explaining your project architecture, coding preferences, and previous decisions.\nExisting solutions (Mem0, Zep, Letta) are cloud-based, cost $40-50+&#x2F;month, and your private code goes to their servers. Stop paying \u2192 lose all your data.\nMy Solution: Local-First, Free Forever\nBuilt a universal memory system that stores everything on YOUR machine, works with 16+ AI tools simultaneously, requires zero API keys, costs nothing.\n10-Layer Architecture\nEach layer enhances but never replaces lower layers. System degrades gracefully if advanced features fail.\nLayer 10: A2A Agent Collaboration (v2.6)\nLayer 9: Web Dashboard (SSE real-time)\nLayer 8: Hybrid Search (Semantic + FTS5 + Graph)\nLayer 7: Universal Access (MCP + Skills + CLI)\nLayer 6: MCP Integration (native Claude tools)\nLayer 5: Skills (slash commands for 16+ tools)\nLayer 4: Pattern Learning (Bayesian confidence)\nLayer 3: Knowledge Graph (TF-IDF + Leiden clustering)\nLayer 2: Hierarchical Index (parent-child relationships)\nLayer 1: SQLite + FTS5 + TF-IDF vectors\nResearch-Backed\nBuilt on published research, adapted for local-first:<p>A2A Protocol (Google&#x2F;Linux Foundation, 2025)\nGraphRAG (Microsoft arXiv:2404.16130)\nMACLA Bayesian learning (arXiv:2512.18950)\nA-RAG hybrid search (arXiv:2602.03442)<p>Key difference: Research papers assume cloud APIs. SuperLocalMemory implements everything locally with zero API calls.\nHow Recall Works\nQuery &quot;authentication&quot; triggers:<p>FTS5 full-text search\nTF-IDF vector similarity\nGraph traversal for related memories\nHierarchical expansion (parent&#x2F;child context)\nHybrid ranking (combines all signals)<p>Performance: &lt;50ms, even with 10K+ memories.\nComparison\nFeatureSuperLocalMemoryMem0&#x2F;Zep&#x2F;LettaPrivacy100% localCloudCostFree$40-50+&#x2F;moKnowledge GraphPattern Learning BayesianMulti-tool16+LimitedCLIWorks Offline\nReal Usage\nCross-tool context:\nbash# Save in terminal\nslm remember &quot;Next.js 15 uses Turbopack&quot; --tags nextjs<p># Later in Cursor, Claude auto-recalls via MCP\nProject profiles:\nbashslm switch-profile work-project\nslm switch-profile personal-blog\n# Separate memory per project\nPattern learning: After several sessions, Claude learns you prefer TypeScript strict mode, Tailwind styling, Vitest testing\u2014starts suggesting without being asked.\nInstallation\nbashnpm install -g superlocalmemory\nAuto-configures MCP for Claude Desktop, Cursor, Windsurf. Sets up CLI commands. That&#x27;s it.\nWhy Local-First Matters<p>Privacy: Code never leaves your machine\nOwnership: Your data, forever\nSpeed: 50ms queries, no network latency\nReliability: Works offline, no API limits\nCost: $0 forever<p>Tech Stack<p>SQLite (ACID, zero config)\nFTS5 (full-text search)\nTF-IDF (vector similarity, no OpenAI API)\nigraph (Leiden clustering)\nBayesian inference (pattern learning)\nMCP (native Claude integration)<p>GitHub\n <a href=\"https:&#x2F;&#x2F;github.com&#x2F;varun369&#x2F;SuperLocalMemoryV2\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;varun369&#x2F;SuperLocalMemoryV2</a>\nMIT License. Full docs in wiki.<p>Current status: v2.4 stable. v2.5 (March) adds real-time event stream, concurrent access, trust scoring. v2.6 (May) adds A2A Protocol for multi-agent collaboration.\nBuilt by Varun Pratap Bhardwaj, Solution Architect . 15+ years AI&#x2F;ML experience.","title":"Show HN: SuperLocalMemory\u2013 Local-first AI memory for Claude, Cursor and 16+tools","updated_at":"2026-02-12T10:15:00Z","url":"https://github.com/varun369/SuperLocalMemoryV2"}],"hitsPerPage":10,"nbHits":528,"nbPages":53,"page":0,"params":"query=MCP+protocol&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":22,"processingTimingsMS":{"_request":{"roundTrip":22},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":8,"scanning":13,"total":22},"total":22},"query":"MCP protocol","serverTimeMS":24}
