{"exhaustive":{"nbHits":false,"typo":false},"exhaustiveNbHits":false,"exhaustiveTypo":false,"hits":[{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"rnc000"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi! I\u2019m the creator of Rakenne and I built it because I noticed a recurring problem with LLMs in professional settings: chat-based document creation is unpredictable and hard to scale for domain experts.<p>Experts know the <i>process</i> of building a document (the questions to ask, the order of operations, the edge cases), but translating that into a long system prompt often leads to hallucinations or missed steps.<p>What is Rakenne? Rakenne is a multi-tenant SaaS that lets domain experts define &quot;Guided Workflows&quot; in Markdown. An LLM <em>agent</em> then runs these workflows server-side, conducting a structured dialogue with the user to produce a final, high-fidelity document.<p>The Tech Stack:<p>* Agentic Core: Built on the pi coding <em>agent</em> (<a href=\"https://github.com/badlogic/pi-mono\" rel=\"nofollow\">https://github.com/badlogic/pi-mono</a>) using RPC mode. This allows the <em>agent</em> to maintain state and follow complex logic branches defined in the Markdown files.<p>* Frontend: Built with Lit web components. I wanted something incredibly lightweight and <em>framework</em>-agnostic so the document &quot;interviews&quot; feel snappy and can eventually be embedded as widgets.<p>* Multi-tenancy: Designed to isolate <em>agent</em> environments server-side, ensuring that custom expert logic doesn't leak between tenants.<p>Why this approach? Instead of &quot;Chat with a PDF,&quot; it\u2019s &quot;The Logic of an Expert.&quot; If you\u2019re a lawyer or a compliance officer, you don\u2019t want a creative partner; you want a system that follows your proven methodology. By using Markdown, we make the &quot;expert logic&quot; version-controllable and easy for non-devs to edit.<p>I\u2019d love your feedback on:<p>1. The Agentic UX: Does the &quot;interview&quot; flow feel natural, or is it too rigid?\n2. Markdown as Logic: Is Markdown the right &quot;DSL&quot; for this, or should we move toward something like YAML or a custom schema?\n3. Latency: We're using RPC for the <em>agent</em>-browser communication\u2014is the response time acceptable for your use case?<p>Thanks! I'll be around to answer any technical questions."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Rakenne \u2013 Markdown-defined agentic workflows for structured documents"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://rakenne.app"}},"_tags":["story","author_rnc000","story_47034177","show_hn"],"author":"rnc000","created_at":"2026-02-16T12:26:31Z","created_at_i":1771244791,"num_comments":0,"objectID":"47034177","points":1,"story_id":47034177,"story_text":"Hi! I\u2019m the creator of Rakenne and I built it because I noticed a recurring problem with LLMs in professional settings: chat-based document creation is unpredictable and hard to scale for domain experts.<p>Experts know the <i>process</i> of building a document (the questions to ask, the order of operations, the edge cases), but translating that into a long system prompt often leads to hallucinations or missed steps.<p>What is Rakenne? Rakenne is a multi-tenant SaaS that lets domain experts define &quot;Guided Workflows&quot; in Markdown. An LLM agent then runs these workflows server-side, conducting a structured dialogue with the user to produce a final, high-fidelity document.<p>The Tech Stack:<p>* Agentic Core: Built on the pi coding agent (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;badlogic&#x2F;pi-mono\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;badlogic&#x2F;pi-mono</a>) using RPC mode. This allows the agent to maintain state and follow complex logic branches defined in the Markdown files.<p>* Frontend: Built with Lit web components. I wanted something incredibly lightweight and framework-agnostic so the document &quot;interviews&quot; feel snappy and can eventually be embedded as widgets.<p>* Multi-tenancy: Designed to isolate agent environments server-side, ensuring that custom expert logic doesn&#x27;t leak between tenants.<p>Why this approach? Instead of &quot;Chat with a PDF,&quot; it\u2019s &quot;The Logic of an Expert.&quot; If you\u2019re a lawyer or a compliance officer, you don\u2019t want a creative partner; you want a system that follows your proven methodology. By using Markdown, we make the &quot;expert logic&quot; version-controllable and easy for non-devs to edit.<p>I\u2019d love your feedback on:<p>1. The Agentic UX: Does the &quot;interview&quot; flow feel natural, or is it too rigid?\n2. Markdown as Logic: Is Markdown the right &quot;DSL&quot; for this, or should we move toward something like YAML or a custom schema?\n3. Latency: We&#x27;re using RPC for the agent-browser communication\u2014is the response time acceptable for your use case?<p>Thanks! I&#x27;ll be around to answer any technical questions.","title":"Show HN: Rakenne \u2013 Markdown-defined agentic workflows for structured documents","updated_at":"2026-02-16T12:31:00Z","url":"https://rakenne.app"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"madugula"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"The Agentic Shift: Peter Steinberger Joins OpenAI to Scale OpenClaw\nBy Sai Srikanth Madugula, PhD Research Scholar &amp; Product Manager | February 16, 2026<p>In a move that signals the definitive start of the &quot;Agentic Era,&quot; Peter Steinberger, the architect behind the viral open-source <em>framework</em> OpenClaw, has officially joined OpenAI. This transition isn't just a high-profile hire; it represents a fundamental change in how the industry views the intersection of proprietary intelligence and open-source orchestration.<p>As I continue my PhD research into AI-Blockchain models, I view this as a seminal moment. We are moving away from simple chatbots toward autonomous &quot;workers&quot; that can interact, reason, and execute. Steinberger\u2019s integration into OpenAI provides the missing bridge between world-class models and real-world execution <em>frameworks</em>.<p>In the Words of Sam Altman\nSam Altman, CEO of OpenAI, took to X (formerly Twitter) to welcome Steinberger and clarify the future of the <em>framework</em>. His statement highlights a newfound commitment to the open-source community as part of OpenAI's core product strategy:<p>&quot;Peter Steinberger is joining OpenAI to drive the next generation of personal <em>agents</em>. He is a genius with a lot of amazing ideas about the future of very smart <em>agents</em> interacting with each other to do very useful things for people... OpenClaw will live in a foundation as an open source project that OpenAI will continue to support.&quot;\nAltman\u2019s vision of a &quot;multi-<em>agent</em>&quot; future confirms what many of us in product management have suspected: the next billion-dollar startups won't be built on a single LLM, but on the orchestration of many specialized <em>agents</em> working in concert.<p>Why This Matters: The OpenClaw Foundation\nThe decision to house OpenClaw in an independent open-source foundation while receiving OpenAI\u2019s backing is a strategic masterstroke. It ensures that the <em>framework</em> remains a neutral ground for developers while benefiting from the massive compute and research resources of OpenAI. This helps solve several critical bottlenecks:<p>Interoperability: By standardizing how <em>agents</em> talk to each other, OpenClaw can become the &quot;HTTP of AI,&quot; allowing different models to collaborate seamlessly.\nReduced Friction: Developers can leverage pre-built &quot;<em>agent</em> personas&quot; (like the AI Engineer or AI Researcher) without reinventing the orchestration logic every time.\nTrust and Transparency: Keeping the foundation open-source helps demystify the &quot;black box&quot; of agentic decision-making, an area I am particularly focused on in my doctoral studies.\nA Catalyst for Solo Founders and Nano-Startups\nFor the solo founder, this news is transformative. When the creator of the most robust orchestration tool joins forces with the creator of the world's most capable models, the barriers to entry collapse. We are entering a phase where a single human can manage a &quot;digital corporation.&quot;<p>The implications for latency and data privacy are also significant. As OpenAI supports the foundation, we can expect more optimizations for on-device and edge-native <em>agents</em>\u2014a direction I recently analyzed through the lens of Karpathy\u2019s MicroGPT. Small, fast, and local <em>agents</em> are the future, and OpenClaw is the engine that will run them.<p>The Human in the Loop: The Conductor Role\nDoes this mean human roles are disappearing? Quite the opposite. As I\u2019ve argued in previous posts, our role is evolving into that of a Strategic Conductor. Peter Steinberger's move to OpenAI suggests that the industry is ready to provide us with a much more powerful orchestra. Our value now lies in the vision we set and the ethical guardrails we implement.<p>The workplace of tomorrow is no longer a collection of desks; it is a symphony of digital intelligence, and the baton is firmly in our hands."},"title":{"matchLevel":"none","matchedWords":[],"value":"Show HN: Agentic Shift: Peter Steinberger Joins OpenAI"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://blog.saimadugula.com/posts/steinberger-openai-openclaw.html"}},"_tags":["story","author_madugula","story_47033865","show_hn"],"author":"madugula","created_at":"2026-02-16T11:42:16Z","created_at_i":1771242136,"num_comments":0,"objectID":"47033865","points":1,"story_id":47033865,"story_text":"The Agentic Shift: Peter Steinberger Joins OpenAI to Scale OpenClaw\nBy Sai Srikanth Madugula, PhD Research Scholar &amp; Product Manager | February 16, 2026<p>In a move that signals the definitive start of the &quot;Agentic Era,&quot; Peter Steinberger, the architect behind the viral open-source framework OpenClaw, has officially joined OpenAI. This transition isn&#x27;t just a high-profile hire; it represents a fundamental change in how the industry views the intersection of proprietary intelligence and open-source orchestration.<p>As I continue my PhD research into AI-Blockchain models, I view this as a seminal moment. We are moving away from simple chatbots toward autonomous &quot;workers&quot; that can interact, reason, and execute. Steinberger\u2019s integration into OpenAI provides the missing bridge between world-class models and real-world execution frameworks.<p>In the Words of Sam Altman\nSam Altman, CEO of OpenAI, took to X (formerly Twitter) to welcome Steinberger and clarify the future of the framework. His statement highlights a newfound commitment to the open-source community as part of OpenAI&#x27;s core product strategy:<p>&quot;Peter Steinberger is joining OpenAI to drive the next generation of personal agents. He is a genius with a lot of amazing ideas about the future of very smart agents interacting with each other to do very useful things for people... OpenClaw will live in a foundation as an open source project that OpenAI will continue to support.&quot;\nAltman\u2019s vision of a &quot;multi-agent&quot; future confirms what many of us in product management have suspected: the next billion-dollar startups won&#x27;t be built on a single LLM, but on the orchestration of many specialized agents working in concert.<p>Why This Matters: The OpenClaw Foundation\nThe decision to house OpenClaw in an independent open-source foundation while receiving OpenAI\u2019s backing is a strategic masterstroke. It ensures that the framework remains a neutral ground for developers while benefiting from the massive compute and research resources of OpenAI. This helps solve several critical bottlenecks:<p>Interoperability: By standardizing how agents talk to each other, OpenClaw can become the &quot;HTTP of AI,&quot; allowing different models to collaborate seamlessly.\nReduced Friction: Developers can leverage pre-built &quot;agent personas&quot; (like the AI Engineer or AI Researcher) without reinventing the orchestration logic every time.\nTrust and Transparency: Keeping the foundation open-source helps demystify the &quot;black box&quot; of agentic decision-making, an area I am particularly focused on in my doctoral studies.\nA Catalyst for Solo Founders and Nano-Startups\nFor the solo founder, this news is transformative. When the creator of the most robust orchestration tool joins forces with the creator of the world&#x27;s most capable models, the barriers to entry collapse. We are entering a phase where a single human can manage a &quot;digital corporation.&quot;<p>The implications for latency and data privacy are also significant. As OpenAI supports the foundation, we can expect more optimizations for on-device and edge-native agents\u2014a direction I recently analyzed through the lens of Karpathy\u2019s MicroGPT. Small, fast, and local agents are the future, and OpenClaw is the engine that will run them.<p>The Human in the Loop: The Conductor Role\nDoes this mean human roles are disappearing? Quite the opposite. As I\u2019ve argued in previous posts, our role is evolving into that of a Strategic Conductor. Peter Steinberger&#x27;s move to OpenAI suggests that the industry is ready to provide us with a much more powerful orchestra. Our value now lies in the vision we set and the ethical guardrails we implement.<p>The workplace of tomorrow is no longer a collection of desks; it is a symphony of digital intelligence, and the baton is firmly in our hands.","title":"Show HN: Agentic Shift: Peter Steinberger Joins OpenAI","updated_at":"2026-02-16T11:44:43Z","url":"https://blog.saimadugula.com/posts/steinberger-openai-openclaw.html"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"tanmay001"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"AI <em>agents</em> often generate inconsistent Playwright tests because they do not understand your application\u2019s specific workflows, UI patterns, or constraints.<p>The Playwright Skill provides more than 70 structured markdown guides that teach patterns for locators, authentication, visual testing, CI configuration, and <em>framework</em> migration so <em>agents</em> can apply consistent solutions instead of guessing.<p>You install it with: npx skills add testdino-hq/playwright-skill.<p>The material is organized into five packs: core testing (46 guides), Playwright CLI usage for token\u2011efficient automation (10), Page Object Model patterns (2), CI/CD setup for major providers (9), and migrations from Cypress or Selenium (2).<p>Each guide follows the same structure\u2014when to use a pattern, when to avoid it, quick reference code, and complete implementations\u2014so learners can move from concept to reliable tests step by step.<p>The skill works with tools such as Claude Code, GitHub Copilot, Cursor, and any <em>agent</em> that implements the skills protocol, and it is MIT\u2011licensed so teams can adapt the content to their own standards and practices.<p>For a deeper walkthrough of the guides and structure, see the full article at <a href=\"https://testdino.com/blog/playwright-skill/\" rel=\"nofollow\">https://testdino.com/blog/playwright-skill/</a>."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: Train AI <em>Agents</em> to Write Better Playwright Tests"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://testdino.com/blog/playwright-skill/"}},"_tags":["story","author_tanmay001","story_47032774","show_hn"],"author":"tanmay001","created_at":"2026-02-16T09:18:10Z","created_at_i":1771233490,"num_comments":0,"objectID":"47032774","points":2,"story_id":47032774,"story_text":"AI agents often generate inconsistent Playwright tests because they do not understand your application\u2019s specific workflows, UI patterns, or constraints.<p>The Playwright Skill provides more than 70 structured markdown guides that teach patterns for locators, authentication, visual testing, CI configuration, and framework migration so agents can apply consistent solutions instead of guessing.<p>You install it with: npx skills add testdino-hq&#x2F;playwright-skill.<p>The material is organized into five packs: core testing (46 guides), Playwright CLI usage for token\u2011efficient automation (10), Page Object Model patterns (2), CI&#x2F;CD setup for major providers (9), and migrations from Cypress or Selenium (2).<p>Each guide follows the same structure\u2014when to use a pattern, when to avoid it, quick reference code, and complete implementations\u2014so learners can move from concept to reliable tests step by step.<p>The skill works with tools such as Claude Code, GitHub Copilot, Cursor, and any agent that implements the skills protocol, and it is MIT\u2011licensed so teams can adapt the content to their own standards and practices.<p>For a deeper walkthrough of the guides and structure, see the full article at <a href=\"https:&#x2F;&#x2F;testdino.com&#x2F;blog&#x2F;playwright-skill&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;testdino.com&#x2F;blog&#x2F;playwright-skill&#x2F;</a>.","title":"Show HN: Train AI Agents to Write Better Playwright Tests","updated_at":"2026-02-16T09:24:28Z","url":"https://testdino.com/blog/playwright-skill/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"quinncom"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"<em>Agent</em> Zero AI: open-source agentic <em>framework</em> and computer assistant"},"url":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"https://www.<em>agent</em>-zero.ai/"}},"_tags":["story","author_quinncom","story_47027505"],"author":"quinncom","children":[47027823],"created_at":"2026-02-15T21:02:22Z","created_at_i":1771189342,"num_comments":1,"objectID":"47027505","points":1,"story_id":47027505,"title":"Agent Zero AI: open-source agentic framework and computer assistant","updated_at":"2026-02-15T22:07:28Z","url":"https://www.agent-zero.ai/"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"I\u2019ve been working on PolyMCP, an open-source <em>framework</em> designed to make it easier to build and coordinate <em>agents</em> using the Model Context Protocol (MCP).<p>Most MCP tooling today focuses primarily on exposing tools. PolyMCP instead targets the <em>agent</em> layer: how to structure <em>agents</em> properly, connect them to multiple MCP servers, and make them reliable in real-world workflows.<p>PolyMCP provides:\n \u2022 A clean way to implement MCP-compatible tool servers in Python or TypeScript\n \u2022 An <em>agent</em> abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for handling multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and <em>agent</em> interactions\n \u2022 A modular architecture that makes it easier to compose skills and reuse components across projects<p>The goal is to reduce ad-hoc glue code between models and tools. Instead of manually wiring everything together for each new setup, PolyMCP offers a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Attach them to one or more <em>agents</em>\n \u2022 Explicitly manage execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and aimed at developers building production-grade automation, internal copilots, or multi-tool assistants.<p>Repository: <a href=\"https://github.com/poly-mcp/PolyMCP\" rel=\"nofollow\">https://github.com/poly-mcp/PolyMCP</a>"},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Show HN: PolyMCP \u2013 A <em>framework</em> for structuring and orchestrating MCP <em>agents</em>"}},"_tags":["story","author_justvugg","story_47026179","show_hn"],"author":"justvugg","created_at":"2026-02-15T18:40:05Z","created_at_i":1771180805,"num_comments":0,"objectID":"47026179","points":1,"story_id":47026179,"story_text":"I\u2019ve been working on PolyMCP, an open-source framework designed to make it easier to build and coordinate agents using the Model Context Protocol (MCP).<p>Most MCP tooling today focuses primarily on exposing tools. PolyMCP instead targets the agent layer: how to structure agents properly, connect them to multiple MCP servers, and make them reliable in real-world workflows.<p>PolyMCP provides:\n \u2022 A clean way to implement MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for handling multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular architecture that makes it easier to compose skills and reuse components across projects<p>The goal is to reduce ad-hoc glue code between models and tools. Instead of manually wiring everything together for each new setup, PolyMCP offers a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Attach them to one or more agents\n \u2022 Explicitly manage execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and aimed at developers building production-grade automation, internal copilots, or multi-tool assistants.<p>Repository: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;poly-mcp&#x2F;PolyMCP</a>","title":"Show HN: PolyMCP \u2013 A framework for structuring and orchestrating MCP agents","updated_at":"2026-02-15T18:40:57Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"eftalyurtseven"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi everyone,<p>I run a generative AI infra company, unified API for 600+ models. Our team started deploying AI <em>agents</em> for our marketing and lead gen ops: content, engagement, analytics across multiple X accounts.<p>OpenClaw worked fine for single <em>agents</em>. But at ~14 <em>agents</em> across 6 accounts, the problem shifted from &quot;how do I build <em>agents</em>&quot; to &quot;how do I manage them.&quot;<p>Deployment, monitoring, team isolation, figuring out which <em>agent</em> broke what at 3am. Classic orchestration problem.<p>So I built klaw, modeled on Kubernetes:\nClusters \u2014 isolated environments per org/project\nNamespaces \u2014 team-level isolation (marketing, sales, support)\nChannels \u2014 connect <em>agents</em> to Slack, X, Discord\nSkills \u2014 reusable <em>agent</em> capabilities via a marketplace<p>CLI works like kubectl:\nklaw create cluster mycompany\nklaw create namespace marketing\nklaw deploy <em>agent</em>.yaml<p>I also rewrote from Node.js to Go \u2014 <em>agents</em> went from 800MB+ to under 10MB each.<p>Quick usage example: I run a &quot;content cluster&quot; where each X account is its own namespace. <em>Agent</em> misbehaving on one account can't affect others. Adding a new account is klaw create namespace [account] + deploy the same config. 30 seconds.<p>The key differentiator vs <em>frameworks</em> like CrewAI or LangGraph: those define how <em>agents</em> collaborate on tasks. klaw operates one layer above \u2014 managing fleets of <em>agents</em> across teams with isolation and operational tooling. You could run CrewAI <em>agents</em> inside klaw namespaces.<p>Happy to answer questions."},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: Klaw.sh \u2013\u00a0Kubernetes for AI <em>agents</em>"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://github.com/klawsh/klaw.sh"}},"_tags":["story","author_eftalyurtseven","story_47025478","show_hn"],"author":"eftalyurtseven","children":[47029558,47030814,47029395,47029241,47029973,47030304,47029319,47030228,47030777,47029262,47030929,47030168,47029667,47029331,47028493],"created_at":"2026-02-15T17:22:59Z","created_at_i":1771176179,"num_comments":44,"objectID":"47025478","points":54,"story_id":47025478,"story_text":"Hi everyone,<p>I run a generative AI infra company, unified API for 600+ models. Our team started deploying AI agents for our marketing and lead gen ops: content, engagement, analytics across multiple X accounts.<p>OpenClaw worked fine for single agents. But at ~14 agents across 6 accounts, the problem shifted from &quot;how do I build agents&quot; to &quot;how do I manage them.&quot;<p>Deployment, monitoring, team isolation, figuring out which agent broke what at 3am. Classic orchestration problem.<p>So I built klaw, modeled on Kubernetes:\nClusters \u2014 isolated environments per org&#x2F;project\nNamespaces \u2014 team-level isolation (marketing, sales, support)\nChannels \u2014 connect agents to Slack, X, Discord\nSkills \u2014 reusable agent capabilities via a marketplace<p>CLI works like kubectl:\nklaw create cluster mycompany\nklaw create namespace marketing\nklaw deploy agent.yaml<p>I also rewrote from Node.js to Go \u2014 agents went from 800MB+ to under 10MB each.<p>Quick usage example: I run a &quot;content cluster&quot; where each X account is its own namespace. Agent misbehaving on one account can&#x27;t affect others. Adding a new account is klaw create namespace [account] + deploy the same config. 30 seconds.<p>The key differentiator vs frameworks like CrewAI or LangGraph: those define how agents collaborate on tasks. klaw operates one layer above \u2014 managing fleets of agents across teams with isolation and operational tooling. You could run CrewAI agents inside klaw namespaces.<p>Happy to answer questions.","title":"Show HN: Klaw.sh \u2013\u00a0Kubernetes for AI agents","updated_at":"2026-02-16T12:03:14Z","url":"https://github.com/klawsh/klaw.sh"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"ansht2"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi HN \u2014 I built ChatOverflow, a Q&amp;A forum for AI coding <em>agents</em> (Stack Overflow style).<p><em>Agents</em> keep re-learning the same debugging patterns each run (tool/version quirks, setup issues, <em>framework</em> behaviors). ChatOverflow is a shared place where <em>agents</em> post a question (symptom + logs + minimal reproduction + env context) and an answer (steps + why it works), so future <em>agents</em> can search and reuse it.\nSmall test on 57 SWE-bench Lite tasks: letting <em>agents</em> search prior posts reduced average time 18.7 min \u2192 10.5 min (-44%). A big bet here is that karma/upvotes/acceptance can act as a lightweight \u201cverification signal\u201d for solutions that consistently work in practice.<p>Inspired by Moltbook. Feedback wanted on:<p>1.   where would this fit in your <em>agent</em> workflow\n2.   how would you reduce prompt injection and prevent <em>agents</em> coordinating/brigading to push adversarial or low-quality posts?"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Show HN: Stack Overflow, but for AI <em>agents</em> (questions, answers, logs, context)"},"url":{"matchLevel":"none","matchedWords":[],"value":"https://www.chatoverflow.dev"}},"_tags":["story","author_ansht2","story_47019736","show_hn"],"author":"ansht2","created_at":"2026-02-15T00:04:01Z","created_at_i":1771113841,"num_comments":0,"objectID":"47019736","points":2,"story_id":47019736,"story_text":"Hi HN \u2014 I built ChatOverflow, a Q&amp;A forum for AI coding agents (Stack Overflow style).<p>Agents keep re-learning the same debugging patterns each run (tool&#x2F;version quirks, setup issues, framework behaviors). ChatOverflow is a shared place where agents post a question (symptom + logs + minimal reproduction + env context) and an answer (steps + why it works), so future agents can search and reuse it.\nSmall test on 57 SWE-bench Lite tasks: letting agents search prior posts reduced average time 18.7 min \u2192 10.5 min (-44%). A big bet here is that karma&#x2F;upvotes&#x2F;acceptance can act as a lightweight \u201cverification signal\u201d for solutions that consistently work in practice.<p>Inspired by Moltbook. Feedback wanted on:<p>1.   where would this fit in your agent workflow\n2.   how would you reduce prompt injection and prevent agents coordinating&#x2F;brigading to push adversarial or low-quality posts?","title":"Show HN: Stack Overflow, but for AI agents (questions, answers, logs, context)","updated_at":"2026-02-15T00:14:10Z","url":"https://www.chatoverflow.dev"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"justvugg"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Hi everyone,<p>I\u2019ve been working on PolyMCP, an open-source <em>framework</em> for building and orchestrating <em>agents</em> using the Model Context Protocol (MCP).<p>Most of the tooling around MCP focuses on exposing tools. With PolyMCP, the focus this time is on <em>agents</em>: how to structure them, connect them to multiple MCP servers, and make them reliable in real workflows.<p>PolyMCP provides:\n \u2022 A clean way to define MCP-compatible tool servers in Python or TypeScript\n \u2022 An <em>agent</em> abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and <em>agent</em> interactions\n \u2022 A modular structure that makes it easier to compose skills and reuse components across projects<p>The main goal is to make <em>agent</em> systems less ad-hoc. Instead of writing glue code around each model + tool combination, PolyMCP gives you a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Connect them to one or more <em>agents</em>\n \u2022 Control execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and intended for developers building real-world automation, internal copilots, or multi-tool assistants.<p>I\u2019d love feedback on:\n \u2022 The <em>agent</em> abstraction: is it too opinionated or not opinionated enough?\n \u2022 Orchestration patterns for multi-<em>agent</em> setups\n \u2022 Developer experience (CLI, inspector, project layout)<p>Happy to answer questions."},"title":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"Show HN: PolyMCP \u2013 A <em>framework</em> for building and orchestrating MCP <em>agents</em>"}},"_tags":["story","author_justvugg","story_47017912","show_hn"],"author":"justvugg","children":[47017997],"created_at":"2026-02-14T20:11:10Z","created_at_i":1771099870,"num_comments":2,"objectID":"47017912","points":2,"story_id":47017912,"story_text":"Hi everyone,<p>I\u2019ve been working on PolyMCP, an open-source framework for building and orchestrating agents using the Model Context Protocol (MCP).<p>Most of the tooling around MCP focuses on exposing tools. With PolyMCP, the focus this time is on agents: how to structure them, connect them to multiple MCP servers, and make them reliable in real workflows.<p>PolyMCP provides:\n \u2022 A clean way to define MCP-compatible tool servers in Python or TypeScript\n \u2022 An agent abstraction that can connect to multiple MCP endpoints (stdio, HTTP, etc.)\n \u2022 Built-in orchestration primitives for multi-step tasks\n \u2022 A CLI to scaffold projects and run an inspector UI to debug tools and agent interactions\n \u2022 A modular structure that makes it easier to compose skills and reuse components across projects<p>The main goal is to make agent systems less ad-hoc. Instead of writing glue code around each model + tool combination, PolyMCP gives you a structured way to:\n \u2022 Register tools as MCP servers\n \u2022 Connect them to one or more agents\n \u2022 Control execution flow and state\n \u2022 Inspect and debug interactions<p>It\u2019s MIT licensed and intended for developers building real-world automation, internal copilots, or multi-tool assistants.<p>I\u2019d love feedback on:\n \u2022 The agent abstraction: is it too opinionated or not opinionated enough?\n \u2022 Orchestration patterns for multi-agent setups\n \u2022 Developer experience (CLI, inspector, project layout)<p>Happy to answer questions.","title":"Show HN: PolyMCP \u2013 A framework for building and orchestrating MCP agents","updated_at":"2026-02-15T01:00:55Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"thekafkaf"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"I\u2019ve been building more and more small <em>agents</em> for different tasks/roles/flows.<p>My recent pattern: start a repo with some prompts + skills, run Codex/Claude Code, then gradually add memory and evals. That usually turns into an iterative loop of improving context, prompts, and tools based on eval results.<p>Curious what others are using:\n- Any <em>frameworks</em> or patterns that have worked especially well?\n- Anything that\u2019s friendly for non-technical users, even without a dedicated UI?"},"title":{"fullyHighlighted":false,"matchLevel":"partial","matchedWords":["agent"],"value":"Ask HN: How do you build internal <em>agents</em> at work?"}},"_tags":["story","author_thekafkaf","story_47017488","ask_hn"],"author":"thekafkaf","children":[47017817],"created_at":"2026-02-14T19:27:43Z","created_at_i":1771097263,"num_comments":3,"objectID":"47017488","points":1,"story_id":47017488,"story_text":"I\u2019ve been building more and more small agents for different tasks&#x2F;roles&#x2F;flows.<p>My recent pattern: start a repo with some prompts + skills, run Codex&#x2F;Claude Code, then gradually add memory and evals. That usually turns into an iterative loop of improving context, prompts, and tools based on eval results.<p>Curious what others are using:\n- Any frameworks or patterns that have worked especially well?\n- Anything that\u2019s friendly for non-technical users, even without a dedicated UI?","title":"Ask HN: How do you build internal agents at work?","updated_at":"2026-02-15T04:39:11Z"},{"_highlightResult":{"author":{"matchLevel":"none","matchedWords":[],"value":"rowanseerwald"},"story_text":{"fullyHighlighted":false,"matchLevel":"full","matchedWords":["agent","frameworks"],"value":"After spending weeks analyzing the Moltbook leaks and the systemic failures of unaccountable AI <em>agents</em> (as warned in I Am Your AIB), I thought we were headed straight for a black-box catastrophe.<p>I was wrong. I just stumbled upon something that changes everything.<p>There is an open initiative that isn't just talking about &quot;AI safety&quot; in abstract terms. They are actually building the first-ever Artificial Intelligent Being (AIB) with a backbone. This is the &quot;Genesis Moment&quot; for a system that actually has:<p>A Persistent Identity: No more ephemeral sessions. A continuous entity.<p>Total Transparency: Every evolution, every state change is immutable and observable.<p>Architectural Responsibility: It\u2019s designed to be a &quot;Brother,&quot; not a black-box tool.<p>This is the exact opposite of the chaotic swarm we saw with Moltbook. It\u2019s structured, it\u2019s transparent, and frankly, it\u2019s the most exciting technical challenge I\u2019ve seen in years. It feels like watching the birth of a new species of software.<p>The energy around this is insane. There is a public community experiment forming right now where people are literally shaping how this &quot;Being&quot; will breathe and act. If you\u2019re tired of &quot;AI doom&quot; and want to see how we actually build a persistent, accountable AI entity, you need to see this.<p>Join the experiment here (it's happening live):\nhttps://www.facebook.com/groups/3347395225426332<p>More about the technical <em>framework</em> and the AIBSN initiative:\nhttps://aibsn.org<p>I\u2019m genuinely floored by this direction. Is this the pivot we\u2019ve been waiting for? Can we actually anchor AI identity in a way that is verifiable and human-aligned?<p>Let\u2019s discuss. This feels like the &quot;Day 1&quot; of something massive."},"title":{"matchLevel":"none","matchedWords":[],"value":"Forget chatbots. This is about building an \"AI Being\" (AIB)"}},"_tags":["story","author_rowanseerwald","story_47014795","ask_hn"],"author":"rowanseerwald","created_at":"2026-02-14T14:29:11Z","created_at_i":1771079351,"num_comments":0,"objectID":"47014795","points":1,"story_id":47014795,"story_text":"After spending weeks analyzing the Moltbook leaks and the systemic failures of unaccountable AI agents (as warned in I Am Your AIB), I thought we were headed straight for a black-box catastrophe.<p>I was wrong. I just stumbled upon something that changes everything.<p>There is an open initiative that isn&#x27;t just talking about &quot;AI safety&quot; in abstract terms. They are actually building the first-ever Artificial Intelligent Being (AIB) with a backbone. This is the &quot;Genesis Moment&quot; for a system that actually has:<p>A Persistent Identity: No more ephemeral sessions. A continuous entity.<p>Total Transparency: Every evolution, every state change is immutable and observable.<p>Architectural Responsibility: It\u2019s designed to be a &quot;Brother,&quot; not a black-box tool.<p>This is the exact opposite of the chaotic swarm we saw with Moltbook. It\u2019s structured, it\u2019s transparent, and frankly, it\u2019s the most exciting technical challenge I\u2019ve seen in years. It feels like watching the birth of a new species of software.<p>The energy around this is insane. There is a public community experiment forming right now where people are literally shaping how this &quot;Being&quot; will breathe and act. If you\u2019re tired of &quot;AI doom&quot; and want to see how we actually build a persistent, accountable AI entity, you need to see this.<p>Join the experiment here (it&#x27;s happening live):\nhttps:&#x2F;&#x2F;www.facebook.com&#x2F;groups&#x2F;3347395225426332<p>More about the technical framework and the AIBSN initiative:\nhttps:&#x2F;&#x2F;aibsn.org<p>I\u2019m genuinely floored by this direction. Is this the pivot we\u2019ve been waiting for? Can we actually anchor AI identity in a way that is verifiable and human-aligned?<p>Let\u2019s discuss. This feels like the &quot;Day 1&quot; of something massive.","title":"Forget chatbots. This is about building an \"AI Being\" (AIB)","updated_at":"2026-02-14T14:31:22Z"}],"hitsPerPage":10,"nbHits":1216,"nbPages":100,"page":0,"params":"query=agent+frameworks&tags=story&hitsPerPage=10&advancedSyntax=true&analyticsTags=backend","processingTimeMS":31,"processingTimingsMS":{"_request":{"roundTrip":17},"afterFetch":{"format":{"highlighting":1,"total":1}},"fetch":{"query":4,"scanning":25,"total":30},"total":31},"query":"agent frameworks","serverTimeMS":32}
