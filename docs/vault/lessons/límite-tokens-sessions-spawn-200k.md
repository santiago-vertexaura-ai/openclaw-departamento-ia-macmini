---
title: "L√≠mite Tokens Sessions Spawn - 200k"
date: 2026-02-14
last_updated: 2026-02-14T22:13:24Z
category: lessons
memoryType: lessons
priority: üü°
tags: 
  - tokens
  - optimization
  - escalabilidad
  - andr√©s
mentions: 1
confidence: 0.7
author: "Alfred"
---

# Lecci√≥n: L√≠mite Tokens en Sessions Spawn

**Fecha:** 2026-02-14  
**Contexto:** D√≠a hist√≥rico 10 tareas completadas

## El Problema

**S√≠ntoma:**
- Andr√©s spawneado con documentos muy largos (>4000 palabras)
- Timeout ocasional en an√°lisis complejos
- Token budget: 200k por sesi√≥n spawn

**Root cause:**
- Prompts Andr√©s muy detallados
- Documentos Roberto muy extensos
- Context window consumption alta

## Impacto

**Positivo:**
- Sistema no fall√≥ (solo warnings)
- Todas las tareas completaron exitosamente
- Calidad output se mantuvo

**Negativo:**
- Riesgo timeout en tareas >15 min
- Coste tokens elevado (ineficiente)
- No escalable a 20-30 agentes

## Soluci√≥n Implementada

**Corto plazo:** Ninguna (funciona)

**Medio plazo (necesario):**
1. **Refactorizar prompts Andr√©s:**
   - Reducir instrucciones redundantes
   - Modularizar por tipo de an√°lisis
   - Template-based approach

2. **Chunk processing:**
   - Dividir documentos >3000 palabras
   - An√°lisis por secciones
   - Agregaci√≥n final

3. **Model selection din√°mica:**
   - Haiku para an√°lisis simples (<1500 palabras)
   - Sonnet para an√°lisis complejos (>1500 palabras)
   - Opus solo cuando absolutamente necesario

4. **Streaming approach:**
   - Procesar en streaming vs cargar todo context
   - Reduce peak memory
   - Mejora latency percibida

## M√©tricas Monitorear

- **Token consumption por tarea** (objetivo: <50k average)
- **% tareas hitting 200k limit** (objetivo: <5%)
- **Coste por an√°lisis** (objetivo: </bin/zsh.50/tarea)
- **Quality degradation con prompts m√°s cortos** (objetivo: 0% drop)

## Relacionado

- Patr√≥n Vadim token optimization
- Sistema multi-agente escalabilidad

---

## Action Items

- [ ] Auditar prompts Andr√©s (identificar redundancias)
- [ ] Implementar chunking documentos largos
- [ ] A/B test Haiku vs Sonnet en an√°lisis simples
- [ ] Dashboard m√©trica: token consumption por agente
